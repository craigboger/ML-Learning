{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet Simulator NN Training for Loading Data from External Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Craig Boger\n",
    "06/11/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the simulator takes a long time to produce larger quantities of data, this version of the training simulation reads in the data from a CSV into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.172615e+00</td>\n",
       "      <td>6.062380e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.694355e+09</td>\n",
       "      <td>5.679263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>1.099443e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.835000e+08</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.477000e+08</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.937903e+01</td>\n",
       "      <td>2.412908e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.354860e+09</td>\n",
       "      <td>5.617584e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>1.097784e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.367000e+09</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.095400e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.496000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666238e+02</td>\n",
       "      <td>5.419895e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394778e+10</td>\n",
       "      <td>5.515330e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>1.095024e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.050500e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643100e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424400e+09</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948516e+02</td>\n",
       "      <td>9.627002e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843961e+10</td>\n",
       "      <td>5.373113e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>1.091166e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.734000e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190800e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.899200e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.709150e+02</td>\n",
       "      <td>1.503396e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279721e+10</td>\n",
       "      <td>5.191794e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>1.086215e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.417499e+09</td>\n",
       "      <td>2.799998e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738500e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374000e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.138930e+06</td>\n",
       "      <td>5.399689e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.050288e+10</td>\n",
       "      <td>-4.133027e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578892e+10</td>\n",
       "      <td>-1.109137e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441446e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.560995e+10</td>\n",
       "      <td>2.799207e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.257803e+10</td>\n",
       "      <td>4.499694e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557899e+10</td>\n",
       "      <td>3.699547e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.259370e+06</td>\n",
       "      <td>5.511102e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606635e+10</td>\n",
       "      <td>-4.407848e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238219e+10</td>\n",
       "      <td>-1.113485e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431961e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.629326e+10</td>\n",
       "      <td>2.799191e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.312570e+10</td>\n",
       "      <td>4.499687e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.605374e+10</td>\n",
       "      <td>3.699537e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.381922e+06</td>\n",
       "      <td>5.623611e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137176e+10</td>\n",
       "      <td>-4.638955e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.963734e+09</td>\n",
       "      <td>-1.116778e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421936e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.697656e+10</td>\n",
       "      <td>2.799174e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.367336e+10</td>\n",
       "      <td>4.499681e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.652848e+10</td>\n",
       "      <td>3.699528e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.506591e+06</td>\n",
       "      <td>5.737214e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646399e+10</td>\n",
       "      <td>-4.823708e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536787e+09</td>\n",
       "      <td>-1.119012e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411373e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.765986e+10</td>\n",
       "      <td>2.799157e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.422102e+10</td>\n",
       "      <td>4.499674e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700322e+10</td>\n",
       "      <td>3.699518e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.633378e+06</td>\n",
       "      <td>5.851910e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139102e+10</td>\n",
       "      <td>-4.959972e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104599e+09</td>\n",
       "      <td>-1.120185e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400277e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.834316e+10</td>\n",
       "      <td>2.799140e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.476868e+10</td>\n",
       "      <td>4.499668e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747796e+10</td>\n",
       "      <td>3.699508e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0   6.172615e+00  6.062380e+03    0.0  4.694355e+09  5.679263e+10        0.0   \n",
       "1   4.937903e+01  2.412908e+04    0.0  9.354860e+09  5.617584e+10        0.0   \n",
       "2   1.666238e+02  5.419895e+04    0.0  1.394778e+10  5.515330e+10        0.0   \n",
       "3   3.948516e+02  9.627002e+04    0.0  1.843961e+10  5.373113e+10        0.0   \n",
       "4   7.709150e+02  1.503396e+05    0.0  2.279721e+10  5.191794e+10        0.0   \n",
       "..           ...           ...    ...           ...           ...        ...   \n",
       "95  4.138930e+06  5.399689e+07    0.0  3.050288e+10 -4.133027e+10        0.0   \n",
       "96  4.259370e+06  5.511102e+07    0.0  2.606635e+10 -4.407848e+10        0.0   \n",
       "97  4.381922e+06  5.623611e+07    0.0  2.137176e+10 -4.638955e+10        0.0   \n",
       "98  4.506591e+06  5.737214e+07    0.0  1.646399e+10 -4.823708e+10        0.0   \n",
       "99  4.633378e+06  5.851910e+07    0.0  1.139102e+10 -4.959972e+10        0.0   \n",
       "\n",
       "         venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0   3.499415e+09  1.099443e+11      0.0  2.999802e+09  ...       0.0   \n",
       "1   6.995321e+09  1.097784e+11      0.0  5.998418e+09  ...       0.0   \n",
       "2   1.048421e+10  1.095024e+11      0.0  8.994662e+09  ...       0.0   \n",
       "3   1.396259e+10  1.091166e+11      0.0  1.198735e+10  ...       0.0   \n",
       "4   1.742697e+10  1.086215e+11      0.0  1.497529e+10  ...       0.0   \n",
       "..           ...           ...      ...           ...  ...       ...   \n",
       "95  1.578892e+10 -1.109137e+11      0.0  1.441446e+11  ...       0.0   \n",
       "96  1.238219e+10 -1.113485e+11      0.0  1.431961e+11  ...       0.0   \n",
       "97  8.963734e+09 -1.116778e+11      0.0  1.421936e+11  ...       0.0   \n",
       "98  5.536787e+09 -1.119012e+11      0.0  1.411373e+11  ...       0.0   \n",
       "99  2.104599e+09 -1.120185e+11      0.0  1.400277e+11  ...       0.0   \n",
       "\n",
       "        uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0   6.835000e+08  2.800000e+12       0.0  5.477000e+08  4.500000e+12   \n",
       "1   1.367000e+09  2.800000e+12       0.0  1.095400e+09  4.500000e+12   \n",
       "2   2.050500e+09  2.799999e+12       0.0  1.643100e+09  4.500000e+12   \n",
       "3   2.734000e+09  2.799999e+12       0.0  2.190800e+09  4.499999e+12   \n",
       "4   3.417499e+09  2.799998e+12       0.0  2.738500e+09  4.499999e+12   \n",
       "..           ...           ...       ...           ...           ...   \n",
       "95  6.560995e+10  2.799207e+12       0.0  5.257803e+10  4.499694e+12   \n",
       "96  6.629326e+10  2.799191e+12       0.0  5.312570e+10  4.499687e+12   \n",
       "97  6.697656e+10  2.799174e+12       0.0  5.367336e+10  4.499681e+12   \n",
       "98  6.765986e+10  2.799157e+12       0.0  5.422102e+10  4.499674e+12   \n",
       "99  6.834316e+10  2.799140e+12       0.0  5.476868e+10  4.499668e+12   \n",
       "\n",
       "    neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0         0.0  4.748000e+08  3.700000e+12      0.0  \n",
       "1         0.0  9.496000e+08  3.700000e+12      0.0  \n",
       "2         0.0  1.424400e+09  3.700000e+12      0.0  \n",
       "3         0.0  1.899200e+09  3.699999e+12      0.0  \n",
       "4         0.0  2.374000e+09  3.699999e+12      0.0  \n",
       "..        ...           ...           ...      ...  \n",
       "95        0.0  4.557899e+10  3.699547e+12      0.0  \n",
       "96        0.0  4.605374e+10  3.699537e+12      0.0  \n",
       "97        0.0  4.652848e+10  3.699528e+12      0.0  \n",
       "98        0.0  4.700322e+10  3.699518e+12      0.0  \n",
       "99        0.0  4.747796e+10  3.699508e+12      0.0  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the simulator data from CSV file.\n",
    "complete_motion_df = pd.read_csv(\"raw_model_output.csv\")\n",
    "complete_motion_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single dataframe with all bodies and all positions with each time step as the index of our rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Create a tf.data Dataset from the Constructed, Unrandomized, Unnormalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "# Probably not needed since not using regressor or doing any feature engineering.\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler  # Scaler for normalizing data.\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaler for normalizing data.\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "# Recommended to enable eager execution when developing model.\n",
    "# Processing data: https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Use sklearn for data processing\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here with Trying to Process Data with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the difficulties is using a mixture of numpy, pandas, and sklearn to take input data (influx), arrange it, split it out, normalize it, and then train a model.  With tf.data input pipelines (similar to sklearn pipelines), we can create data and machine learning pipelines for training or inference.  This allows us to encapsulate not only the machine learning into a Tensorflow model, but the necessary transformations to that data.  That allows us to deploy the model and data transformations as a single object to the later simulator. \\\n",
    "The input pipeline let's us take raw data from any source, like csv, numpy arrays, distributed file system, etc, and convert it into the tensors we will use to train our model.\n",
    "\n",
    "Intro to tensors:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "Good source on how data loading and preprocessing is usually done: https://stackoverflow.com/questions/55321905/want-to-split-train-and-test-data-gotten-from-a-csv-with-tensorflow\n",
    "1) Load the data into memory with numpy\n",
    "2) Split the data into train and validation\n",
    "\n",
    "Since we are not using a massive dataset, then we might be able to use tf.split to split an exsting tf dataset into train and validation.\n",
    "https://docs.w3cub.com/tensorflow~python/tf/split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Numpy Version of the Data as a Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of the complete dataframe and shuffle it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.889717e+11</td>\n",
       "      <td>4.311948e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.296923e+11</td>\n",
       "      <td>4.266766e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.947162e+11</td>\n",
       "      <td>-5.552750e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441240e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.112877e+12</td>\n",
       "      <td>1.282452e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.119568e+12</td>\n",
       "      <td>2.882535e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.303299e+12</td>\n",
       "      <td>3.039877e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.745414e+10</td>\n",
       "      <td>6.028683e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.491124e+08</td>\n",
       "      <td>-2.269692e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.177246e+11</td>\n",
       "      <td>8.552863e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.970702e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590140e+12</td>\n",
       "      <td>-6.938491e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.485545e+12</td>\n",
       "      <td>2.851862e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.478649e+12</td>\n",
       "      <td>1.085408e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.122757e+11</td>\n",
       "      <td>7.185786e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.853322e+10</td>\n",
       "      <td>6.547241e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.264556e+11</td>\n",
       "      <td>-1.040085e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.021243e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.373976e+12</td>\n",
       "      <td>-8.527723e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.099523e+12</td>\n",
       "      <td>-1.780883e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.315107e+12</td>\n",
       "      <td>1.169301e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.180028e+10</td>\n",
       "      <td>2.177074e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.918273e+10</td>\n",
       "      <td>5.628288e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.628451e+10</td>\n",
       "      <td>-1.088321e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.913764e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180339e+11</td>\n",
       "      <td>-2.466855e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.378569e+12</td>\n",
       "      <td>1.039023e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.143306e+11</td>\n",
       "      <td>-1.465600e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.485654e+11</td>\n",
       "      <td>6.642455e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.495762e+11</td>\n",
       "      <td>-4.423134e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.628439e+10</td>\n",
       "      <td>8.019626e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.139247e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.665792e+11</td>\n",
       "      <td>2.636456e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.684981e+12</td>\n",
       "      <td>-4.040729e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.234202e+11</td>\n",
       "      <td>3.646024e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.305906e+10</td>\n",
       "      <td>3.906845e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.118140e+10</td>\n",
       "      <td>-2.697114e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.224180e+11</td>\n",
       "      <td>1.023242e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.734481e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.935700e+11</td>\n",
       "      <td>-2.512840e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.414266e+12</td>\n",
       "      <td>8.708596e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.944116e+11</td>\n",
       "      <td>-1.551802e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.996154e+11</td>\n",
       "      <td>7.424711e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.462352e+11</td>\n",
       "      <td>3.333065e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.103902e+11</td>\n",
       "      <td>-6.463292e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.635855e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.763723e+12</td>\n",
       "      <td>1.821144e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.772982e+12</td>\n",
       "      <td>3.253324e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.256016e+11</td>\n",
       "      <td>3.331220e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.614333e+11</td>\n",
       "      <td>1.829171e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.486666e+11</td>\n",
       "      <td>5.729214e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.713162e+11</td>\n",
       "      <td>1.644962e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.636167e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.463279e+12</td>\n",
       "      <td>-1.914666e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.136329e+12</td>\n",
       "      <td>4.194634e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.005770e+12</td>\n",
       "      <td>1.055951e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.263006e+10</td>\n",
       "      <td>6.369784e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.063830e+11</td>\n",
       "      <td>1.241539e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.529750e+10</td>\n",
       "      <td>1.114445e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.249608e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.287836e+12</td>\n",
       "      <td>-1.340019e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.804936e+12</td>\n",
       "      <td>2.409231e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.397623e+12</td>\n",
       "      <td>3.484430e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.036031e+10</td>\n",
       "      <td>6.906773e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.864248e+10</td>\n",
       "      <td>6.387885e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.411395e+10</td>\n",
       "      <td>1.143293e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.833314e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.557160e+12</td>\n",
       "      <td>9.976932e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500723e+12</td>\n",
       "      <td>3.743914e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.041736e+12</td>\n",
       "      <td>2.541823e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0  2.889717e+11  4.311948e+09    0.0  3.296923e+11  4.266766e+10        0.0   \n",
       "1  4.745414e+10  6.028683e+08    0.0  4.491124e+08 -2.269692e+10        0.0   \n",
       "2  1.122757e+11  7.185786e+09    0.0  5.853322e+10  6.547241e+09        0.0   \n",
       "3  7.180028e+10  2.177074e+09    0.0  8.918273e+10  5.628288e+10        0.0   \n",
       "4  1.485654e+11  6.642455e+09    0.0  1.495762e+11 -4.423134e+10        0.0   \n",
       "5  7.305906e+10  3.906845e+09    0.0  3.118140e+10 -2.697114e+10        0.0   \n",
       "6  2.996154e+11  7.424711e+09    0.0  2.462352e+11  3.333065e+09        0.0   \n",
       "7  2.614333e+11  1.829171e+09    0.0  2.486666e+11  5.729214e+10        0.0   \n",
       "8  5.263006e+10  6.369784e+09    0.0  1.063830e+11  1.241539e+10        0.0   \n",
       "9  3.036031e+10  6.906773e+09    0.0  2.864248e+10  6.387885e+10        0.0   \n",
       "\n",
       "        venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0  1.947162e+11 -5.552750e+10      0.0  1.441240e+11  ...       0.0   \n",
       "1  1.177246e+11  8.552863e+10      0.0 -4.970702e+10  ...       0.0   \n",
       "2  1.264556e+11 -1.040085e+11      0.0  2.021243e+11  ...       0.0   \n",
       "3  5.628451e+10 -1.088321e+11      0.0  1.913764e+11  ...       0.0   \n",
       "4  6.628439e+10  8.019626e+10      0.0  2.139247e+11  ...       0.0   \n",
       "5  1.224180e+11  1.023242e+11      0.0  1.734481e+11  ...       0.0   \n",
       "6  4.103902e+11 -6.463292e+08      0.0  1.635855e+11  ...       0.0   \n",
       "7  3.713162e+11  1.644962e+10      0.0  2.636167e+11  ...       0.0   \n",
       "8  8.529750e+10  1.114445e+11      0.0 -9.249608e+10  ...       0.0   \n",
       "9  5.411395e+10  1.143293e+11      0.0  7.833314e+10  ...       0.0   \n",
       "\n",
       "       uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0 -2.112877e+12  1.282452e+12       0.0 -3.119568e+12  2.882535e+12   \n",
       "1  2.590140e+12 -6.938491e+11       0.0  3.485545e+12  2.851862e+12   \n",
       "2 -2.373976e+12 -8.527723e+11       0.0  4.099523e+12 -1.780883e+12   \n",
       "3  7.180339e+11 -2.466855e+12       0.0  4.378569e+12  1.039023e+12   \n",
       "4 -7.665792e+11  2.636456e+12       0.0  1.684981e+12 -4.040729e+12   \n",
       "5  4.935700e+11 -2.512840e+12       0.0  4.414266e+12  8.708596e+11   \n",
       "6 -1.763723e+12  1.821144e+12       0.0 -2.772982e+12  3.253324e+12   \n",
       "7 -1.463279e+12 -1.914666e+12       0.0 -4.136329e+12  4.194634e+11   \n",
       "8  2.287836e+12 -1.340019e+12       0.0  3.804936e+12  2.409231e+12   \n",
       "9  2.557160e+12  9.976932e+11       0.0  2.500723e+12  3.743914e+12   \n",
       "\n",
       "   neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0        0.0 -1.303299e+12  3.039877e+12      0.0  \n",
       "1        0.0  2.478649e+12  1.085408e+12      0.0  \n",
       "2        0.0 -2.315107e+12  1.169301e+12      0.0  \n",
       "3        0.0  8.143306e+11 -1.465600e+12      0.0  \n",
       "4        0.0 -3.234202e+11  3.646024e+12      0.0  \n",
       "5        0.0  4.944116e+11 -1.551802e+12      0.0  \n",
       "6        0.0 -9.256016e+11  3.331220e+12      0.0  \n",
       "7        0.0 -2.005770e+12  1.055951e+11      0.0  \n",
       "8        0.0  2.397623e+12  3.484430e+11      0.0  \n",
       "9        0.0  2.041736e+12  2.541823e+12      0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy1_complete_motion_df = complete_motion_df.copy()\n",
    "copy1_complete_motion_df = copy1_complete_motion_df.sample(frac=1).reset_index(drop=True)\n",
    "copy1_complete_motion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split out the target x,y,z columns as the last 3 columns in the dataframe.  Skipping scaling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.303299e+12</td>\n",
       "      <td>3.039877e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.478649e+12</td>\n",
       "      <td>1.085408e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.315107e+12</td>\n",
       "      <td>1.169301e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.143306e+11</td>\n",
       "      <td>-1.465600e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.234202e+11</td>\n",
       "      <td>3.646024e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pluto_x       pluto_y  pluto_z\n",
       "0 -1.303299e+12  3.039877e+12      0.0\n",
       "1  2.478649e+12  1.085408e+12      0.0\n",
       "2 -2.315107e+12  1.169301e+12      0.0\n",
       "3  8.143306e+11 -1.465600e+12      0.0\n",
       "4 -3.234202e+11  3.646024e+12      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = copy1_complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "copy1_complete_motion_df.drop(copy1_complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = target.iloc[:,0]\n",
    "target_y = target.iloc[:,1]\n",
    "target_z = target.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all pandas dataframes to numpy arrays so they are compatible with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_motion_np = copy1_complete_motion_df.to_numpy()\n",
    "target_np = target.to_numpy()\n",
    "target_x_np = target_x.to_numpy()\n",
    "target_y_np = target_y.to_numpy()\n",
    "target_z_np = target_z.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "X_train, X_valid, X_test = complete_motion_np[:train_size], complete_motion_np[train_size:(train_size+val_size)], complete_motion_np[(train_size + val_size):]\n",
    "y_train_x, y_valid_x, y_test_x = target_x_np[:train_size], target_x_np[train_size:(train_size+val_size)], target_x_np[(train_size + val_size):]\n",
    "y_train_y, y_valid_y, y_test_y = target_y_np[:train_size], target_y_np[train_size:(train_size+val_size)], target_y_np[(train_size + val_size):]\n",
    "y_train_z, y_valid_z, y_test_z = target_z_np[:train_size], target_z_np[train_size:(train_size+val_size)], target_z_np[(train_size + val_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf dataset from slices (numpy array, pandas dataframe, etc). \n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "Probably one of the better articles on using tensorflow datasets: \\\n",
    "https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "\n",
    "TF documentation on tf.data: Building Tensorflow Input Pipelines: \\\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "Method for splitting tensorflow datasets into train, validation, and test: \\\n",
    "https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets/51126863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into input and targets for the x, y, and z coordinates.\n",
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "complete_motion_df.drop(complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "# Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output.\n",
    "# Convert targets to numpy arrays as well so we can use them in the model.\n",
    "target_x_np = target.iloc[:,0].to_numpy()\n",
    "target_y_np = target.iloc[:,1].to_numpy()\n",
    "target_z_np = target.iloc[:,2].to_numpy()\n",
    "# Usually training, validation, and test data would be coming from different CSV files or sources.\n",
    "# complete_motion_df only consists of input data at this point.\n",
    "complete_motion_np = complete_motion_df.to_numpy()\n",
    "\n",
    "#Create one large tensorflow dataset.\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((complete_motion_np, \n",
    "                                                   target_x_np, \n",
    "                                                   target_y_np,\n",
    "                                                   target_z_np)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [6.17261536e+00 6.06237951e+03 0.00000000e+00 4.69435521e+09\n",
      " 5.67926313e+10 0.00000000e+00 3.49941507e+09 1.09944304e+11\n",
      " 0.00000000e+00 2.99980227e+09 1.49970050e+11 0.00000000e+00\n",
      " 2.39994986e+09 2.19986084e+11 0.00000000e+00 1.29999937e+09\n",
      " 7.69998864e+11 0.00000000e+00 8.99999929e+08 1.39999965e+12\n",
      " 0.00000000e+00 6.83499993e+08 2.79999991e+12 0.00000000e+00\n",
      " 5.47699999e+08 4.49999997e+12 0.00000000e+00] Target_X: 474799997.9580196 Target_Y: 3699999950348.1753 Target_Z: 0.0\n",
      "Features: [4.93790293e+01 2.41290843e+04 0.00000000e+00 9.35485981e+09\n",
      " 5.61758433e+10 0.00000000e+00 6.99532091e+09 1.09778377e+11\n",
      " 0.00000000e+00 5.99841813e+09 1.49880804e+11 0.00000000e+00\n",
      " 4.79959882e+09 2.19944611e+11 0.00000000e+00 2.59999493e+09\n",
      " 7.69995477e+11 0.00000000e+00 1.79999943e+09 1.39999860e+12\n",
      " 0.00000000e+00 1.36699995e+09 2.79999965e+12 0.00000000e+00\n",
      " 1.09539999e+09 4.49999987e+12 0.00000000e+00] Target_X: 949599983.6629324 Target_Y: 3699999802375.905 Target_Z: 0.0\n",
      "Features: [1.66623838e+02 5.41989476e+04 0.00000000e+00 1.39477770e+10\n",
      " 5.51532975e+10 0.00000000e+00 1.04842120e+10 1.09502387e+11\n",
      " 0.00000000e+00 8.99466168e+09 1.49732300e+11 0.00000000e+00\n",
      " 7.19864603e+09 2.19875587e+11 0.00000000e+00 3.89998289e+09\n",
      " 7.69989840e+11 0.00000000e+00 2.69999808e+09 1.39999685e+12\n",
      " 0.00000000e+00 2.05049982e+09 2.79999922e+12 0.00000000e+00\n",
      " 1.64309996e+09 4.49999970e+12 0.00000000e+00] Target_X: 1424399944.8616266 Target_Y: 3699999556083.186 Target_Z: 0.0\n",
      "Features: [3.94851583e+02 9.62700181e+04 0.00000000e+00 1.84396060e+10\n",
      " 5.37311252e+10 0.00000000e+00 1.39625905e+10 1.09116617e+11\n",
      " 0.00000000e+00 1.19873480e+10 1.49524596e+11 0.00000000e+00\n",
      " 9.59679064e+09 2.19779019e+11 0.00000000e+00 5.19995945e+09\n",
      " 7.69981952e+11 0.00000000e+00 3.59999544e+09 1.39999440e+12\n",
      " 0.00000000e+00 2.73399956e+09 2.79999862e+12 0.00000000e+00\n",
      " 2.19079992e+09 4.49999947e+12 0.00000000e+00] Target_X: 1899199869.3009844 Target_Y: 3699999211470.024 Target_Z: 0.0\n",
      "Features: [7.70915008e+02 1.50339559e+05 0.00000000e+00 2.27972101e+10\n",
      " 5.19179389e+10 0.00000000e+00 1.74269696e+10 1.08621464e+11\n",
      " 0.00000000e+00 1.49752939e+10 1.49257779e+11 0.00000000e+00\n",
      " 1.19937319e+10 2.19654917e+11 0.00000000e+00 6.49992080e+09\n",
      " 7.69971814e+11 0.00000000e+00 4.49999110e+09 1.39999126e+12\n",
      " 0.00000000e+00 3.41749915e+09 2.79999785e+12 0.00000000e+00\n",
      " 2.73849984e+09 4.49999917e+12 0.00000000e+00] Target_X: 2373999744.727879 Target_Y: 3699998768536.4214 Target_Z: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataset and print the input and targets.\n",
    "# Will select top 5 to iterate through.\n",
    "for feat, targ_x, targ_y, targ_z in full_dataset.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the full dataset before splitting into train, validation, and test.\n",
    "# Since dataset can fit in memory, can set buffer to be the size of the data.\n",
    "full_dataset_num_samples = complete_motion_df.shape[0]  #Get the size of the dataset to set the randomize buffer\n",
    "#full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples).batch(1)\n",
    "full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "# Take the shuffled dataset and split into train, validation, and test datasets.\n",
    "train_dataset = full_dataset.take(train_size)   # Take top of dataset for training data\n",
    "test_dataset = full_dataset.skip(train_size)    # Take the rest of the dataset for validation and test\n",
    "val_dataset = test_dataset.skip(test_size)      # Take a part of the test data for validation during training\n",
    "test_dataset = test_dataset.take(test_size)     # Get rid of the validation data from the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Quick Neural Net for Predicting Jupiter's Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \\\n",
    "<br>\n",
    "Instead of using sklearn to normalize or manually making a normalization and standardization layer like p. 431 of the book, try using at least 1 Batch normalization layer after the input layer.  Can also add after hidden layers. \\\n",
    "<br>\n",
    "Might need to add an activation function to the output layer later to help with scaling of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Creating Single Input, Multiple Output Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a regression NN where instead of designating an output layer of 3 nodes, 3 output layers of a single node are used to designate specific datasets and loss functions.  Still need to figure out later how to get a 3 node output to correspond to the input training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functional API to build basic NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions with different versions of the neural network.\n",
    "\n",
    "def get_model1(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_2(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"tanh\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"tanh\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_3(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    \n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=10, rho=0.9)\n",
    "    \n",
    "def get_model_4(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(normal1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=2, rho=0.9)\n",
    "    \n",
    "def get_model_5(input_shape):  #Best one yet.  Typically takes about 1500 epochs to get decend results.\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "    hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "    #Set \n",
    "    input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "    input_loss_weights = [0.4, 0.4, 0.2]\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=0.0000005, rho=0.01)\n",
    "    input_metrics = [\"mae\"]\n",
    "    input_num_epochs = 200\n",
    "    input_batch_size = 64\n",
    "\n",
    "    model.summary()\n",
    "    #Also can use and probably should use Adam\n",
    "    input_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "\n",
    "def get_model_6(input_shape):    \n",
    "    # Create model with specified input and output layers.\n",
    "    # Select which model to try.\n",
    "    # Pass shape of input layer to the function.\n",
    "    #model = get_model_2(complete_motion_np.shape[1:])\n",
    "\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "    hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "    #Set \n",
    "    input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "    input_loss_weights = [0.4, 0.4, 0.2]\n",
    "    input_optimizer = keras.optimizers.Adam(learning_rate=1e-6, beta_1=0.9, beta_2=0.999)\n",
    "    input_metrics = [\"mae\"]\n",
    "    input_num_epochs = 3500\n",
    "    input_batch_size = 128\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with specified input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 300)          8400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          90300       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_x (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_y (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_z (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 99,603\n",
      "Trainable params: 99,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model with specified input and output layers.\n",
    "# Select which model to try.\n",
    "# Pass shape of input layer to the function.\n",
    "#model = get_model_2(complete_motion_np.shape[1:])\n",
    "\n",
    "# Use functional API to build basic NN architecture.\n",
    "input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "#Set \n",
    "input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "input_loss_weights = [0.4, 0.4, 0.2]\n",
    "input_optimizer = keras.optimizers.Adam(learning_rate=1e-6, beta_1=0.9, beta_2=0.999)\n",
    "input_metrics = [\"mae\"]\n",
    "input_num_epochs = 200\n",
    "input_batch_size = 128\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting the model, create callbacks for the various stages.\n",
    "\n",
    "# Callback to implement overfitting.  Helps with regularization.  \n",
    "# Keep from over-training.  Stops training when validation error starts increasing again.\n",
    "# https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping/\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                 min_delta=0.0001,\n",
    "                                                 patience=20)\n",
    "\n",
    "# Callback for learning rate scheduling.  This way we can start with a higher learning rate then reduce as we go.\n",
    "# Reducing the learning rate by a factor of \"factor\" every so many epochs or \"patience\".\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=50)\n",
    "\n",
    "#Create list of all callbacks.\n",
    "#callback_list = [early_stopping_cb, lr_scheduler]\n",
    "callback_list = [early_stopping_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with specified loss functions for each output and specify weighting to provide each output.\n",
    "# Weighting X and Y output more than Z\n",
    "model.compile(loss=input_losses, \n",
    "              loss_weights=input_loss_weights, \n",
    "              optimizer=input_optimizer,\n",
    "              metrics=input_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with separate x, y, z training sets.  Choose either numpy data or tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1559995613184.0000 - output_x_loss: 1469748871168.0000 - output_y_loss: 2041372344320.0000 - output_z_loss: 777729343488.0000 - output_x_mae: 1469748871168.0000 - output_y_mae: 2041372344320.0000 - output_z_mae: 777729343488.0000 - val_loss: 1468327264256.0000 - val_output_x_loss: 1379338944512.0000 - val_output_y_loss: 1927811694592.0000 - val_output_z_loss: 727336681472.0000 - val_output_x_mae: 1379338944512.0000 - val_output_y_mae: 1927811694592.0000 - val_output_z_mae: 727336681472.0000\n",
      "Epoch 2/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1393166647296.0000 - output_x_loss: 1298635816960.0000 - output_y_loss: 1846721249280.0000 - output_z_loss: 675116154880.0000 - output_x_mae: 1298635816960.0000 - output_y_mae: 1846721249280.0000 - output_z_mae: 675116154880.0000 - val_loss: 1307510833152.0000 - val_output_x_loss: 1213725409280.0000 - val_output_y_loss: 1742843936768.0000 - val_output_z_loss: 624414228480.0000 - val_output_x_mae: 1213725409280.0000 - val_output_y_mae: 1742843936768.0000 - val_output_z_mae: 624414228480.0000\n",
      "Epoch 3/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1231539798016.0000 - output_x_loss: 1131393056768.0000 - output_y_loss: 1660110503936.0000 - output_z_loss: 574691672064.0000 - output_x_mae: 1131393056768.0000 - output_y_mae: 1660110503936.0000 - output_z_mae: 574691672064.0000 - val_loss: 1150451187712.0000 - val_output_x_loss: 1051026063360.0000 - val_output_y_loss: 1562037321728.0000 - val_output_z_loss: 526129201152.0000 - val_output_x_mae: 1051026063360.0000 - val_output_y_mae: 1562037321728.0000 - val_output_z_mae: 526129201152.0000\n",
      "Epoch 4/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 1074510102528.0000 - output_x_loss: 969448816640.0000 - output_y_loss: 1478106808320.0000 - output_z_loss: 477439328256.0000 - output_x_mae: 969448816640.0000 - output_y_mae: 1478106808320.0000 - output_z_mae: 477439328256.0000 - val_loss: 999226277888.0000 - val_output_x_loss: 898067988480.0000 - val_output_y_loss: 1384068284416.0000 - val_output_z_loss: 431856680960.0000 - val_output_x_mae: 898067988480.0000 - val_output_y_mae: 1384068284416.0000 - val_output_z_mae: 431856680960.0000\n",
      "Epoch 5/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 925347610624.0000 - output_x_loss: 820343734272.0000 - output_y_loss: 1296316366848.0000 - output_z_loss: 393417818112.0000 - output_x_mae: 820343734272.0000 - output_y_mae: 1296316366848.0000 - output_z_mae: 393417818112.0000 - val_loss: 857213501440.0000 - val_output_x_loss: 757875867648.0000 - val_output_y_loss: 1204684980224.0000 - val_output_z_loss: 360945352704.0000 - val_output_x_mae: 757875867648.0000 - val_output_y_mae: 1204684980224.0000 - val_output_z_mae: 360945352704.0000\n",
      "Epoch 6/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 788388577280.0000 - output_x_loss: 687955509248.0000 - output_y_loss: 1116682846208.0000 - output_z_loss: 332665651200.0000 - output_x_mae: 687955509248.0000 - output_y_mae: 1116682846208.0000 - output_z_mae: 332665651200.0000 - val_loss: 731517747200.0000 - val_output_x_loss: 641410138112.0000 - val_output_y_loss: 1033618325504.0000 - val_output_z_loss: 307532136448.0000 - val_output_x_mae: 641410138112.0000 - val_output_y_mae: 1033618325504.0000 - val_output_z_mae: 307532136448.0000\n",
      "Epoch 7/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 673771618304.0000 - output_x_loss: 588448530432.0000 - output_y_loss: 954948059136.0000 - output_z_loss: 282065076224.0000 - output_x_mae: 588448530432.0000 - output_y_mae: 954948059136.0000 - output_z_mae: 282065076224.0000 - val_loss: 627966869504.0000 - val_output_x_loss: 552437481472.0000 - val_output_y_loss: 887132651520.0000 - val_output_z_loss: 260694016000.0000 - val_output_x_mae: 552437481472.0000 - val_output_y_mae: 887132651520.0000 - val_output_z_mae: 260694016000.0000\n",
      "Epoch 8/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 577390575616.0000 - output_x_loss: 503544184832.0000 - output_y_loss: 820502790144.0000 - output_z_loss: 238857453568.0000 - output_x_mae: 503544184832.0000 - output_y_mae: 820502790144.0000 - output_z_mae: 238857453568.0000 - val_loss: 536347705344.0000 - val_output_x_loss: 469519368192.0000 - val_output_y_loss: 760933122048.0000 - val_output_z_loss: 220833873920.0000 - val_output_x_mae: 469519368192.0000 - val_output_y_mae: 760933122048.0000 - val_output_z_mae: 220833873920.0000\n",
      "Epoch 9/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 489867870208.0000 - output_x_loss: 424943157248.0000 - output_y_loss: 698636828672.0000 - output_z_loss: 202179297280.0000 - output_x_mae: 424943157248.0000 - output_y_mae: 698636828672.0000 - output_z_mae: 202179297280.0000 - val_loss: 454200852480.0000 - val_output_x_loss: 398821425152.0000 - val_output_y_loss: 643906797568.0000 - val_output_z_loss: 185548144640.0000 - val_output_x_mae: 398821425152.0000 - val_output_y_mae: 643906797568.0000 - val_output_z_mae: 185548144640.0000\n",
      "Epoch 10/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 414858149888.0000 - output_x_loss: 365729906688.0000 - output_y_loss: 586786734080.0000 - output_z_loss: 169257844736.0000 - output_x_mae: 365729906688.0000 - output_y_mae: 586786734080.0000 - output_z_mae: 169257844736.0000 - val_loss: 386353954816.0000 - val_output_x_loss: 347754496000.0000 - val_output_y_loss: 540400025600.0000 - val_output_z_loss: 155460304896.0000 - val_output_x_mae: 347754496000.0000 - val_output_y_mae: 540400025600.0000 - val_output_z_mae: 155460304896.0000\n",
      "Epoch 11/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 354218311680.0000 - output_x_loss: 319734611968.0000 - output_y_loss: 493991297024.0000 - output_z_loss: 143639904256.0000 - output_x_mae: 319734611968.0000 - output_y_mae: 493991297024.0000 - output_z_mae: 143639904256.0000 - val_loss: 333362823168.0000 - val_output_x_loss: 305522409472.0000 - val_output_y_loss: 460973178880.0000 - val_output_z_loss: 133822668800.0000 - val_output_x_mae: 305522409472.0000 - val_output_y_mae: 460973178880.0000 - val_output_z_mae: 133822668800.0000\n",
      "Epoch 12/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 309484519424.0000 - output_x_loss: 281097076736.0000 - output_y_loss: 430152646656.0000 - output_z_loss: 124922265600.0000 - output_x_mae: 281097076736.0000 - output_y_mae: 430152646656.0000 - output_z_mae: 124922265600.0000 - val_loss: 294317359104.0000 - val_output_x_loss: 267570544640.0000 - val_output_y_loss: 409187680256.0000 - val_output_z_loss: 118070304768.0000 - val_output_x_mae: 267570544640.0000 - val_output_y_mae: 409187680256.0000 - val_output_z_mae: 118070304768.0000\n",
      "Epoch 13/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 275000229888.0000 - output_x_loss: 246457352192.0000 - output_y_loss: 385254064128.0000 - output_z_loss: 111579103232.0000 - output_x_mae: 246457352192.0000 - output_y_mae: 385254064128.0000 - output_z_mae: 111579103232.0000 - val_loss: 261966577664.0000 - val_output_x_loss: 234430119936.0000 - val_output_y_loss: 367082864640.0000 - val_output_z_loss: 106806976512.0000 - val_output_x_mae: 234430119936.0000 - val_output_y_mae: 367082864640.0000 - val_output_z_mae: 106806976512.0000\n",
      "Epoch 14/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 245409005568.0000 - output_x_loss: 216544985088.0000 - output_y_loss: 346126548992.0000 - output_z_loss: 101701345280.0000 - output_x_mae: 216544985088.0000 - output_y_mae: 346126548992.0000 - output_z_mae: 101701345280.0000 - val_loss: 233688825856.0000 - val_output_x_loss: 205659193344.0000 - val_output_y_loss: 329440591872.0000 - val_output_z_loss: 98244673536.0000 - val_output_x_mae: 205659193344.0000 - val_output_y_mae: 329440591872.0000 - val_output_z_mae: 98244673536.0000\n",
      "Epoch 15/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 219518763008.0000 - output_x_loss: 190504271872.0000 - output_y_loss: 311297015808.0000 - output_z_loss: 93991346176.0000 - output_x_mae: 190504271872.0000 - output_y_mae: 311297015808.0000 - output_z_mae: 93991346176.0000 - val_loss: 208509599744.0000 - val_output_x_loss: 180243038208.0000 - val_output_y_loss: 295473283072.0000 - val_output_z_loss: 91115003904.0000 - val_output_x_mae: 180243038208.0000 - val_output_y_mae: 295473283072.0000 - val_output_z_mae: 91115003904.0000\n",
      "Epoch 16/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 197029740544.0000 - output_x_loss: 168429305856.0000 - output_y_loss: 280655921152.0000 - output_z_loss: 86978486272.0000 - output_x_mae: 168429305856.0000 - output_y_mae: 280655921152.0000 - output_z_mae: 86978486272.0000 - val_loss: 187844935680.0000 - val_output_x_loss: 160020938752.0000 - val_output_y_loss: 267481235456.0000 - val_output_z_loss: 84220272640.0000 - val_output_x_mae: 160020938752.0000 - val_output_y_mae: 267481235456.0000 - val_output_z_mae: 84220272640.0000\n",
      "Epoch 17/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 179254476800.0000 - output_x_loss: 152277417984.0000 - output_y_loss: 255766921216.0000 - output_z_loss: 80183869440.0000 - output_x_mae: 152277417984.0000 - output_y_mae: 255766921216.0000 - output_z_mae: 80183869440.0000 - val_loss: 171799363584.0000 - val_output_x_loss: 146123931648.0000 - val_output_y_loss: 244439040000.0000 - val_output_z_loss: 77870792704.0000 - val_output_x_mae: 146123931648.0000 - val_output_y_mae: 244439040000.0000 - val_output_z_mae: 77870792704.0000\n",
      "Epoch 18/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 164724948992.0000 - output_x_loss: 140583616512.0000 - output_y_loss: 234121248768.0000 - output_z_loss: 74214744064.0000 - output_x_mae: 140583616512.0000 - output_y_mae: 234121248768.0000 - output_z_mae: 74214744064.0000 - val_loss: 158284791808.0000 - val_output_x_loss: 135523442688.0000 - val_output_y_loss: 223968575488.0000 - val_output_z_loss: 72439988224.0000 - val_output_x_mae: 135523442688.0000 - val_output_y_mae: 223968575488.0000 - val_output_z_mae: 72439988224.0000\n",
      "Epoch 19/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 152250646528.0000 - output_x_loss: 130869387264.0000 - output_y_loss: 215230709760.0000 - output_z_loss: 69052563456.0000 - output_x_mae: 130869387264.0000 - output_y_mae: 215230709760.0000 - output_z_mae: 69052563456.0000 - val_loss: 146658557952.0000 - val_output_x_loss: 126470807552.0000 - val_output_y_loss: 206398930944.0000 - val_output_z_loss: 67553337344.0000 - val_output_x_mae: 126470807552.0000 - val_output_y_mae: 206398930944.0000 - val_output_z_mae: 67553337344.0000\n",
      "Epoch 20/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 141504266240.0000 - output_x_loss: 122461126656.0000 - output_y_loss: 199059324928.0000 - output_z_loss: 64480497664.0000 - output_x_mae: 122461126656.0000 - output_y_mae: 199059324928.0000 - output_z_mae: 64480497664.0000 - val_loss: 136566530048.0000 - val_output_x_loss: 118675922944.0000 - val_output_y_loss: 191103139840.0000 - val_output_z_loss: 63274491904.0000 - val_output_x_mae: 118675922944.0000 - val_output_y_mae: 191103139840.0000 - val_output_z_mae: 63274491904.0000\n",
      "Epoch 21/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 132119199744.0000 - output_x_loss: 115237126144.0000 - output_y_loss: 184841699328.0000 - output_z_loss: 60438478848.0000 - output_x_mae: 115237126144.0000 - output_y_mae: 184841699328.0000 - output_z_mae: 60438478848.0000 - val_loss: 127922577408.0000 - val_output_x_loss: 112085843968.0000 - val_output_y_loss: 178048221184.0000 - val_output_z_loss: 59344572416.0000 - val_output_x_mae: 112085843968.0000 - val_output_y_mae: 178048221184.0000 - val_output_z_mae: 59344572416.0000\n",
      "Epoch 22/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 124157599744.0000 - output_x_loss: 109092184064.0000 - output_y_loss: 172954746880.0000 - output_z_loss: 56694030336.0000 - output_x_mae: 109092184064.0000 - output_y_mae: 172954746880.0000 - output_z_mae: 56694030336.0000 - val_loss: 120655208448.0000 - val_output_x_loss: 106503806976.0000 - val_output_y_loss: 167288586240.0000 - val_output_z_loss: 55691231232.0000 - val_output_x_mae: 106503806976.0000 - val_output_y_mae: 167288586240.0000 - val_output_z_mae: 55691231232.0000\n",
      "Epoch 23/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 117321498624.0000 - output_x_loss: 103964942336.0000 - output_y_loss: 162722234368.0000 - output_z_loss: 53233238016.0000 - output_x_mae: 103964942336.0000 - output_y_mae: 162722234368.0000 - output_z_mae: 53233238016.0000 - val_loss: 114262401024.0000 - val_output_x_loss: 101882535936.0000 - val_output_y_loss: 157623042048.0000 - val_output_z_loss: 52300763136.0000 - val_output_x_mae: 101882535936.0000 - val_output_y_mae: 157623042048.0000 - val_output_z_mae: 52300763136.0000\n",
      "Epoch 24/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 111245533184.0000 - output_x_loss: 99568926720.0000 - output_y_loss: 153551060992.0000 - output_z_loss: 49987272704.0000 - output_x_mae: 99568926720.0000 - output_y_mae: 153551060992.0000 - output_z_mae: 49987272704.0000 - val_loss: 108566437888.0000 - val_output_x_loss: 97907523584.0000 - val_output_y_loss: 148955086848.0000 - val_output_z_loss: 49106960384.0000 - val_output_x_mae: 97907523584.0000 - val_output_y_mae: 148955086848.0000 - val_output_z_mae: 49106960384.0000\n",
      "Epoch 25/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 105736642560.0000 - output_x_loss: 95703187456.0000 - output_y_loss: 145166041088.0000 - output_z_loss: 46944731136.0000 - output_x_mae: 95703187456.0000 - output_y_mae: 145166041088.0000 - output_z_mae: 46944731136.0000 - val_loss: 103297417216.0000 - val_output_x_loss: 94354374656.0000 - val_output_y_loss: 140833243136.0000 - val_output_z_loss: 46111862784.0000 - val_output_x_mae: 94354374656.0000 - val_output_y_mae: 140833243136.0000 - val_output_z_mae: 46111862784.0000\n",
      "Epoch 26/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 100593844224.0000 - output_x_loss: 92130164736.0000 - output_y_loss: 137290440704.0000 - output_z_loss: 44127760384.0000 - output_x_mae: 92130164736.0000 - output_y_mae: 137290440704.0000 - output_z_mae: 44127760384.0000 - val_loss: 98329092096.0000 - val_output_x_loss: 90923819008.0000 - val_output_y_loss: 133220229120.0000 - val_output_z_loss: 43357388800.0000 - val_output_x_mae: 90923819008.0000 - val_output_y_mae: 133220229120.0000 - val_output_z_mae: 43357388800.0000\n",
      "Epoch 27/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 95779766272.0000 - output_x_loss: 88743215104.0000 - output_y_loss: 129903001600.0000 - output_z_loss: 41606307840.0000 - output_x_mae: 88743215104.0000 - output_y_mae: 129903001600.0000 - output_z_mae: 41606307840.0000 - val_loss: 93702438912.0000 - val_output_x_loss: 87631847424.0000 - val_output_y_loss: 126110318592.0000 - val_output_z_loss: 41027862528.0000 - val_output_x_mae: 87631847424.0000 - val_output_y_mae: 126110318592.0000 - val_output_z_mae: 41027862528.0000\n",
      "Epoch 28/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 91320672256.0000 - output_x_loss: 85534089216.0000 - output_y_loss: 123036565504.0000 - output_z_loss: 39461888000.0000 - output_x_mae: 85534089216.0000 - output_y_mae: 123036565504.0000 - output_z_mae: 39461888000.0000 - val_loss: 89452273664.0000 - val_output_x_loss: 84621631488.0000 - val_output_y_loss: 119505584128.0000 - val_output_z_loss: 39006998528.0000 - val_output_x_mae: 84621631488.0000 - val_output_y_mae: 119505584128.0000 - val_output_z_mae: 39006998528.0000\n",
      "Epoch 29/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 87156686848.0000 - output_x_loss: 82481758208.0000 - output_y_loss: 116626284544.0000 - output_z_loss: 37567537152.0000 - output_x_mae: 82481758208.0000 - output_y_mae: 116626284544.0000 - output_z_mae: 37567537152.0000 - val_loss: 85428035584.0000 - val_output_x_loss: 81698119680.0000 - val_output_y_loss: 113252687872.0000 - val_output_z_loss: 37238484992.0000 - val_output_x_mae: 81698119680.0000 - val_output_y_mae: 113252687872.0000 - val_output_z_mae: 37238484992.0000\n",
      "Epoch 30/200\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 83239493632.0000 - output_x_loss: 79652954112.0000 - output_y_loss: 110510538752.0000 - output_z_loss: 35870310400.0000 - output_x_mae: 79652954112.0000 - output_y_mae: 110510538752.0000 - output_z_mae: 35870310400.0000 - val_loss: 81633148928.0000 - val_output_x_loss: 78870339584.0000 - val_output_y_loss: 107373486080.0000 - val_output_z_loss: 35678097408.0000 - val_output_x_mae: 78870339584.0000 - val_output_y_mae: 107373486080.0000 - val_output_z_mae: 35678097408.0000\n",
      "Epoch 31/200\n",
      "329/329 [==============================] - 2s 7ms/step - loss: 79565053952.0000 - output_x_loss: 76929122304.0000 - output_y_loss: 104749203456.0000 - output_z_loss: 34468651008.0000 - output_x_mae: 76929122304.0000 - output_y_mae: 104749203456.0000 - output_z_mae: 34468651008.0000 - val_loss: 78089854976.0000 - val_output_x_loss: 76224823296.0000 - val_output_y_loss: 101832212480.0000 - val_output_z_loss: 34335029248.0000 - val_output_x_mae: 76224823296.0000 - val_output_y_mae: 101832212480.0000 - val_output_z_mae: 34335029248.0000\n",
      "Epoch 32/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 76111085568.0000 - output_x_loss: 74330914816.0000 - output_y_loss: 99306315776.0000 - output_z_loss: 33280858112.0000 - output_x_mae: 74330914816.0000 - output_y_mae: 99306315776.0000 - output_z_mae: 33280858112.0000 - val_loss: 74734026752.0000 - val_output_x_loss: 73694756864.0000 - val_output_y_loss: 96555819008.0000 - val_output_z_loss: 33169016832.0000 - val_output_x_mae: 73694756864.0000 - val_output_y_mae: 96555819008.0000 - val_output_z_mae: 33169016832.0000\n",
      "Epoch 33/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 72814182400.0000 - output_x_loss: 71809515520.0000 - output_y_loss: 94082867200.0000 - output_z_loss: 32286031872.0000 - output_x_mae: 71809515520.0000 - output_y_mae: 94082867200.0000 - output_z_mae: 32286031872.0000 - val_loss: 71560593408.0000 - val_output_x_loss: 71242137600.0000 - val_output_y_loss: 91546656768.0000 - val_output_z_loss: 32225417216.0000 - val_output_x_mae: 71242137600.0000 - val_output_y_mae: 91546656768.0000 - val_output_z_mae: 32225417216.0000\n",
      "Epoch 34/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 69643993088.0000 - output_x_loss: 69318254592.0000 - output_y_loss: 89072033792.0000 - output_z_loss: 31439216640.0000 - output_x_mae: 69318254592.0000 - output_y_mae: 89072033792.0000 - output_z_mae: 31439216640.0000 - val_loss: 68462555136.0000 - val_output_x_loss: 68850819072.0000 - val_output_y_loss: 86597951488.0000 - val_output_z_loss: 31415121920.0000 - val_output_x_mae: 68850819072.0000 - val_output_y_mae: 86597951488.0000 - val_output_z_mae: 31415121920.0000\n",
      "Epoch 35/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 66614292480.0000 - output_x_loss: 66938109952.0000 - output_y_loss: 84240433152.0000 - output_z_loss: 30714300416.0000 - output_x_mae: 66938109952.0000 - output_y_mae: 84240433152.0000 - output_z_mae: 30714300416.0000 - val_loss: 65523851264.0000 - val_output_x_loss: 66543714304.0000 - val_output_y_loss: 81920425984.0000 - val_output_z_loss: 30690910208.0000 - val_output_x_mae: 66543714304.0000 - val_output_y_mae: 81920425984.0000 - val_output_z_mae: 30690910208.0000\n",
      "Epoch 36/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 63741362176.0000 - output_x_loss: 64704335872.0000 - output_y_loss: 79614771200.0000 - output_z_loss: 30068529152.0000 - output_x_mae: 64704335872.0000 - output_y_mae: 79614771200.0000 - output_z_mae: 30068529152.0000 - val_loss: 62693720064.0000 - val_output_x_loss: 64330973184.0000 - val_output_y_loss: 77373046784.0000 - val_output_z_loss: 30060509184.0000 - val_output_x_mae: 64330973184.0000 - val_output_y_mae: 77373046784.0000 - val_output_z_mae: 30060509184.0000\n",
      "Epoch 37/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 60974026752.0000 - output_x_loss: 62547615744.0000 - output_y_loss: 75157512192.0000 - output_z_loss: 29459916800.0000 - output_x_mae: 62547615744.0000 - output_y_mae: 75157512192.0000 - output_z_mae: 29459916800.0000 - val_loss: 60032131072.0000 - val_output_x_loss: 62280978432.0000 - val_output_y_loss: 73071140864.0000 - val_output_z_loss: 29456351232.0000 - val_output_x_mae: 62280978432.0000 - val_output_y_mae: 73071140864.0000 - val_output_z_mae: 29456351232.0000\n",
      "Epoch 38/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 58401759232.0000 - output_x_loss: 60458856448.0000 - output_y_loss: 71092314112.0000 - output_z_loss: 28906643456.0000 - output_x_mae: 60458856448.0000 - output_y_mae: 71092314112.0000 - output_z_mae: 28906643456.0000 - val_loss: 57528852480.0000 - val_output_x_loss: 60248993792.0000 - val_output_y_loss: 69133312000.0000 - val_output_z_loss: 28879630336.0000 - val_output_x_mae: 60248993792.0000 - val_output_y_mae: 69133312000.0000 - val_output_z_mae: 28879630336.0000\n",
      "Epoch 39/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 55974686720.0000 - output_x_loss: 58488205312.0000 - output_y_loss: 67260321792.0000 - output_z_loss: 28376395776.0000 - output_x_mae: 58488205312.0000 - output_y_mae: 67260321792.0000 - output_z_mae: 28376395776.0000 - val_loss: 55119912960.0000 - val_output_x_loss: 58154266624.0000 - val_output_y_loss: 65472479232.0000 - val_output_z_loss: 28346073088.0000 - val_output_x_mae: 58154266624.0000 - val_output_y_mae: 65472479232.0000 - val_output_z_mae: 28346073088.0000\n",
      "Epoch 40/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 53692211200.0000 - output_x_loss: 56522444800.0000 - output_y_loss: 63772565504.0000 - output_z_loss: 27871137792.0000 - output_x_mae: 56522444800.0000 - output_y_mae: 63772565504.0000 - output_z_mae: 27871137792.0000 - val_loss: 52898754560.0000 - val_output_x_loss: 56217194496.0000 - val_output_y_loss: 62104936448.0000 - val_output_z_loss: 27849533440.0000 - val_output_x_mae: 56217194496.0000 - val_output_y_mae: 62104936448.0000 - val_output_z_mae: 27849533440.0000\n",
      "Epoch 41/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 51545571328.0000 - output_x_loss: 54621954048.0000 - output_y_loss: 60535140352.0000 - output_z_loss: 27413684224.0000 - output_x_mae: 54621954048.0000 - output_y_mae: 60535140352.0000 - output_z_mae: 27413684224.0000 - val_loss: 50826674176.0000 - val_output_x_loss: 54304792576.0000 - val_output_y_loss: 59062149120.0000 - val_output_z_loss: 27399489536.0000 - val_output_x_mae: 54304792576.0000 - val_output_y_mae: 59062149120.0000 - val_output_z_mae: 27399489536.0000\n",
      "Epoch 42/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 49560252416.0000 - output_x_loss: 52812320768.0000 - output_y_loss: 57589833728.0000 - output_z_loss: 26996871168.0000 - output_x_mae: 52812320768.0000 - output_y_mae: 57589833728.0000 - output_z_mae: 26996871168.0000 - val_loss: 48875483136.0000 - val_output_x_loss: 52442890240.0000 - val_output_y_loss: 56271994880.0000 - val_output_z_loss: 26947622912.0000 - val_output_x_mae: 52442890240.0000 - val_output_y_mae: 56271994880.0000 - val_output_z_mae: 26947622912.0000\n",
      "Epoch 43/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 47731802112.0000 - output_x_loss: 51091001344.0000 - output_y_loss: 54940893184.0000 - output_z_loss: 26595084288.0000 - output_x_mae: 51091001344.0000 - output_y_mae: 54940893184.0000 - output_z_mae: 26595084288.0000 - val_loss: 47159779328.0000 - val_output_x_loss: 50748547072.0000 - val_output_y_loss: 53886054400.0000 - val_output_z_loss: 26529644544.0000 - val_output_x_mae: 50748547072.0000 - val_output_y_mae: 53886054400.0000 - val_output_z_mae: 26529644544.0000\n",
      "Epoch 44/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 46079946752.0000 - output_x_loss: 49418473472.0000 - output_y_loss: 52675493888.0000 - output_z_loss: 26211780608.0000 - output_x_mae: 49418473472.0000 - output_y_mae: 52675493888.0000 - output_z_mae: 26211780608.0000 - val_loss: 45606977536.0000 - val_output_x_loss: 49162170368.0000 - val_output_y_loss: 51771359232.0000 - val_output_z_loss: 26167715840.0000 - val_output_x_mae: 49162170368.0000 - val_output_y_mae: 51771359232.0000 - val_output_z_mae: 26167715840.0000\n",
      "Epoch 45/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 44538634240.0000 - output_x_loss: 47795183616.0000 - output_y_loss: 50622476288.0000 - output_z_loss: 25857886208.0000 - output_x_mae: 47795183616.0000 - output_y_mae: 50622476288.0000 - output_z_mae: 25857886208.0000 - val_loss: 44126863360.0000 - val_output_x_loss: 47593672704.0000 - val_output_y_loss: 49790152704.0000 - val_output_z_loss: 25866708992.0000 - val_output_x_mae: 47593672704.0000 - val_output_y_mae: 49790152704.0000 - val_output_z_mae: 25866708992.0000\n",
      "Epoch 46/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 43095326720.0000 - output_x_loss: 46212620288.0000 - output_y_loss: 48763719680.0000 - output_z_loss: 25523974144.0000 - output_x_mae: 46212620288.0000 - output_y_mae: 48763719680.0000 - output_z_mae: 25523974144.0000 - val_loss: 42690031616.0000 - val_output_x_loss: 45956149248.0000 - val_output_y_loss: 48026333184.0000 - val_output_z_loss: 25485248512.0000 - val_output_x_mae: 45956149248.0000 - val_output_y_mae: 48026333184.0000 - val_output_z_mae: 25485248512.0000\n",
      "Epoch 47/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 41736339456.0000 - output_x_loss: 44711272448.0000 - output_y_loss: 47031287808.0000 - output_z_loss: 25196412928.0000 - output_x_mae: 44711272448.0000 - output_y_mae: 47031287808.0000 - output_z_mae: 25196412928.0000 - val_loss: 41367535616.0000 - val_output_x_loss: 44451295232.0000 - val_output_y_loss: 46400065536.0000 - val_output_z_loss: 25134911488.0000 - val_output_x_mae: 44451295232.0000 - val_output_y_mae: 46400065536.0000 - val_output_z_mae: 25134911488.0000\n",
      "Epoch 48/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 40467910656.0000 - output_x_loss: 43294195712.0000 - output_y_loss: 45441630208.0000 - output_z_loss: 24867901440.0000 - output_x_mae: 43294195712.0000 - output_y_mae: 45441630208.0000 - output_z_mae: 24867901440.0000 - val_loss: 40139759616.0000 - val_output_x_loss: 43059863552.0000 - val_output_y_loss: 44871827456.0000 - val_output_z_loss: 24835383296.0000 - val_output_x_mae: 43059863552.0000 - val_output_y_mae: 44871827456.0000 - val_output_z_mae: 24835383296.0000\n",
      "Epoch 49/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 39262568448.0000 - output_x_loss: 41914560512.0000 - output_y_loss: 43969138688.0000 - output_z_loss: 24545271808.0000 - output_x_mae: 41914560512.0000 - output_y_mae: 43969138688.0000 - output_z_mae: 24545271808.0000 - val_loss: 38981591040.0000 - val_output_x_loss: 41715064832.0000 - val_output_y_loss: 43474067456.0000 - val_output_z_loss: 24529776640.0000 - val_output_x_mae: 41715064832.0000 - val_output_y_mae: 43474067456.0000 - val_output_z_mae: 24529776640.0000\n",
      "Epoch 50/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 38110130176.0000 - output_x_loss: 40564383744.0000 - output_y_loss: 42593624064.0000 - output_z_loss: 24234582016.0000 - output_x_mae: 40564383744.0000 - output_y_mae: 42593624064.0000 - output_z_mae: 24234582016.0000 - val_loss: 37901434880.0000 - val_output_x_loss: 40437977088.0000 - val_output_y_loss: 42181894144.0000 - val_output_z_loss: 24267407360.0000 - val_output_x_mae: 40437977088.0000 - val_output_y_mae: 42181894144.0000 - val_output_z_mae: 24267407360.0000\n",
      "Epoch 51/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 37014700032.0000 - output_x_loss: 39254863872.0000 - output_y_loss: 41315405824.0000 - output_z_loss: 23932989440.0000 - output_x_mae: 39254863872.0000 - output_y_mae: 41315405824.0000 - output_z_mae: 23932989440.0000 - val_loss: 36792324096.0000 - val_output_x_loss: 39046545408.0000 - val_output_y_loss: 40965173248.0000 - val_output_z_loss: 23938166784.0000 - val_output_x_mae: 39046545408.0000 - val_output_y_mae: 40965173248.0000 - val_output_z_mae: 23938166784.0000\n",
      "Epoch 52/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 35961761792.0000 - output_x_loss: 37948739584.0000 - output_y_loss: 40139366400.0000 - output_z_loss: 23632517120.0000 - output_x_mae: 37948739584.0000 - output_y_mae: 40139366400.0000 - output_z_mae: 23632517120.0000 - val_loss: 35792650240.0000 - val_output_x_loss: 37739630592.0000 - val_output_y_loss: 39925219328.0000 - val_output_z_loss: 23633473536.0000 - val_output_x_mae: 37739630592.0000 - val_output_y_mae: 39925219328.0000 - val_output_z_mae: 23633473536.0000\n",
      "Epoch 53/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 34971209728.0000 - output_x_loss: 36696707072.0000 - output_y_loss: 39061729280.0000 - output_z_loss: 23339198464.0000 - output_x_mae: 36696707072.0000 - output_y_mae: 39061729280.0000 - output_z_mae: 23339198464.0000 - val_loss: 34824708096.0000 - val_output_x_loss: 36497940480.0000 - val_output_y_loss: 38877077504.0000 - val_output_z_loss: 23373484032.0000 - val_output_x_mae: 36497940480.0000 - val_output_y_mae: 38877077504.0000 - val_output_z_mae: 23373484032.0000\n",
      "Epoch 54/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 34027659264.0000 - output_x_loss: 35489726464.0000 - output_y_loss: 38055223296.0000 - output_z_loss: 23048329216.0000 - output_x_mae: 35489726464.0000 - output_y_mae: 38055223296.0000 - output_z_mae: 23048329216.0000 - val_loss: 33914726400.0000 - val_output_x_loss: 35315294208.0000 - val_output_y_loss: 37924429824.0000 - val_output_z_loss: 23094136832.0000 - val_output_x_mae: 35315294208.0000 - val_output_y_mae: 37924429824.0000 - val_output_z_mae: 23094136832.0000\n",
      "Epoch 55/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 33121437696.0000 - output_x_loss: 34334797824.0000 - output_y_loss: 37079326720.0000 - output_z_loss: 22778910720.0000 - output_x_mae: 34334797824.0000 - output_y_mae: 37079326720.0000 - output_z_mae: 22778910720.0000 - val_loss: 33025816576.0000 - val_output_x_loss: 34132613120.0000 - val_output_y_loss: 37018685440.0000 - val_output_z_loss: 22826473472.0000 - val_output_x_mae: 34132613120.0000 - val_output_y_mae: 37018685440.0000 - val_output_z_mae: 22826473472.0000\n",
      "Epoch 56/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 32264056832.0000 - output_x_loss: 33249427456.0000 - output_y_loss: 36158328832.0000 - output_z_loss: 22504790016.0000 - output_x_mae: 33249427456.0000 - output_y_mae: 36158328832.0000 - output_z_mae: 22504790016.0000 - val_loss: 32161060864.0000 - val_output_x_loss: 33025880064.0000 - val_output_y_loss: 36104507392.0000 - val_output_z_loss: 22544533504.0000 - val_output_x_mae: 33025880064.0000 - val_output_y_mae: 36104507392.0000 - val_output_z_mae: 22544533504.0000\n",
      "Epoch 57/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 31422846976.0000 - output_x_loss: 32185528320.0000 - output_y_loss: 35253641216.0000 - output_z_loss: 22235865088.0000 - output_x_mae: 32185528320.0000 - output_y_mae: 35253641216.0000 - output_z_mae: 22235865088.0000 - val_loss: 31384363008.0000 - val_output_x_loss: 32028026880.0000 - val_output_y_loss: 35283779584.0000 - val_output_z_loss: 22298202112.0000 - val_output_x_mae: 32028026880.0000 - val_output_y_mae: 35283779584.0000 - val_output_z_mae: 22298202112.0000\n",
      "Epoch 58/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 30626134016.0000 - output_x_loss: 31199307776.0000 - output_y_loss: 34382057472.0000 - output_z_loss: 21967902720.0000 - output_x_mae: 31199307776.0000 - output_y_mae: 34382057472.0000 - output_z_mae: 21967902720.0000 - val_loss: 30552657920.0000 - val_output_x_loss: 30939742208.0000 - val_output_y_loss: 34433540096.0000 - val_output_z_loss: 22016718848.0000 - val_output_x_mae: 30939742208.0000 - val_output_y_mae: 34433540096.0000 - val_output_z_mae: 22016718848.0000\n",
      "Epoch 59/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 29868783616.0000 - output_x_loss: 30260416512.0000 - output_y_loss: 33557372928.0000 - output_z_loss: 21708337152.0000 - output_x_mae: 30260416512.0000 - output_y_mae: 33557372928.0000 - output_z_mae: 21708337152.0000 - val_loss: 29815658496.0000 - val_output_x_loss: 30055892992.0000 - val_output_y_loss: 33605814272.0000 - val_output_z_loss: 21754859520.0000 - val_output_x_mae: 30055892992.0000 - val_output_y_mae: 33605814272.0000 - val_output_z_mae: 21754859520.0000\n",
      "Epoch 60/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 29150578688.0000 - output_x_loss: 29425004544.0000 - output_y_loss: 32734748672.0000 - output_z_loss: 21433364480.0000 - output_x_mae: 29425004544.0000 - output_y_mae: 32734748672.0000 - output_z_mae: 21433364480.0000 - val_loss: 29147437056.0000 - val_output_x_loss: 29286709248.0000 - val_output_y_loss: 32848439296.0000 - val_output_z_loss: 21466892288.0000 - val_output_x_mae: 29286709248.0000 - val_output_y_mae: 32848439296.0000 - val_output_z_mae: 21466892288.0000\n",
      "Epoch 61/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 28485314560.0000 - output_x_loss: 28667166720.0000 - output_y_loss: 31964319744.0000 - output_z_loss: 21163554816.0000 - output_x_mae: 28667166720.0000 - output_y_mae: 31964319744.0000 - output_z_mae: 21163554816.0000 - val_loss: 28492300288.0000 - val_output_x_loss: 28553263104.0000 - val_output_y_loss: 32070248448.0000 - val_output_z_loss: 21214486528.0000 - val_output_x_mae: 28553263104.0000 - val_output_y_mae: 32070248448.0000 - val_output_z_mae: 21214486528.0000\n",
      "Epoch 62/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 27862990848.0000 - output_x_loss: 27989057536.0000 - output_y_loss: 31221553152.0000 - output_z_loss: 20893745152.0000 - output_x_mae: 27989057536.0000 - output_y_mae: 31221553152.0000 - output_z_mae: 20893745152.0000 - val_loss: 27906166784.0000 - val_output_x_loss: 27925256192.0000 - val_output_y_loss: 31357300736.0000 - val_output_z_loss: 20965709824.0000 - val_output_x_mae: 27925256192.0000 - val_output_y_mae: 31357300736.0000 - val_output_z_mae: 20965709824.0000\n",
      "Epoch 63/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 27275159552.0000 - output_x_loss: 27347873792.0000 - output_y_loss: 30526541824.0000 - output_z_loss: 20626944000.0000 - output_x_mae: 27347873792.0000 - output_y_mae: 30526541824.0000 - output_z_mae: 20626944000.0000 - val_loss: 27294689280.0000 - val_output_x_loss: 27197845504.0000 - val_output_y_loss: 30684780544.0000 - val_output_z_loss: 20708194304.0000 - val_output_x_mae: 27197845504.0000 - val_output_y_mae: 30684780544.0000 - val_output_z_mae: 20708194304.0000\n",
      "Epoch 64/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 26716000256.0000 - output_x_loss: 26760202240.0000 - output_y_loss: 29841625088.0000 - output_z_loss: 20376367104.0000 - output_x_mae: 26760202240.0000 - output_y_mae: 29841625088.0000 - output_z_mae: 20376367104.0000 - val_loss: 26763501568.0000 - val_output_x_loss: 26653173760.0000 - val_output_y_loss: 30031716352.0000 - val_output_z_loss: 20447737856.0000 - val_output_x_mae: 26653173760.0000 - val_output_y_mae: 30031716352.0000 - val_output_z_mae: 20447737856.0000\n",
      "Epoch 65/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 26167533568.0000 - output_x_loss: 26176815104.0000 - output_y_loss: 29181808640.0000 - output_z_loss: 20120387584.0000 - output_x_mae: 26176815104.0000 - output_y_mae: 29181808640.0000 - output_z_mae: 20120387584.0000 - val_loss: 26229442560.0000 - val_output_x_loss: 26076286976.0000 - val_output_y_loss: 29412603904.0000 - val_output_z_loss: 20169447424.0000 - val_output_x_mae: 26076286976.0000 - val_output_y_mae: 29412603904.0000 - val_output_z_mae: 20169447424.0000\n",
      "Epoch 66/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 25648228352.0000 - output_x_loss: 25652656128.0000 - output_y_loss: 28529152000.0000 - output_z_loss: 19877527552.0000 - output_x_mae: 25652656128.0000 - output_y_mae: 28529152000.0000 - output_z_mae: 19877527552.0000 - val_loss: 25672781824.0000 - val_output_x_loss: 25513117696.0000 - val_output_y_loss: 28699580416.0000 - val_output_z_loss: 19938521088.0000 - val_output_x_mae: 25513117696.0000 - val_output_y_mae: 28699580416.0000 - val_output_z_mae: 19938521088.0000\n",
      "Epoch 67/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 25148155904.0000 - output_x_loss: 25158649856.0000 - output_y_loss: 27881076736.0000 - output_z_loss: 19661363200.0000 - output_x_mae: 25158649856.0000 - output_y_mae: 27881076736.0000 - output_z_mae: 19661363200.0000 - val_loss: 25182535680.0000 - val_output_x_loss: 25035145216.0000 - val_output_y_loss: 28058976256.0000 - val_output_z_loss: 19724466176.0000 - val_output_x_mae: 25035145216.0000 - val_output_y_mae: 28058976256.0000 - val_output_z_mae: 19724466176.0000\n",
      "Epoch 68/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 24663191552.0000 - output_x_loss: 24689442816.0000 - output_y_loss: 27247134720.0000 - output_z_loss: 19442817024.0000 - output_x_mae: 24689442816.0000 - output_y_mae: 27247134720.0000 - output_z_mae: 19442817024.0000 - val_loss: 24708282368.0000 - val_output_x_loss: 24578146304.0000 - val_output_y_loss: 27417141248.0000 - val_output_z_loss: 19550846976.0000 - val_output_x_mae: 24578146304.0000 - val_output_y_mae: 27417141248.0000 - val_output_z_mae: 19550846976.0000\n",
      "Epoch 69/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 24191518720.0000 - output_x_loss: 24233883648.0000 - output_y_loss: 26623043584.0000 - output_z_loss: 19243696128.0000 - output_x_mae: 24233883648.0000 - output_y_mae: 26623043584.0000 - output_z_mae: 19243696128.0000 - val_loss: 24278521856.0000 - val_output_x_loss: 24142891008.0000 - val_output_y_loss: 26883846144.0000 - val_output_z_loss: 19339112448.0000 - val_output_x_mae: 24142891008.0000 - val_output_y_mae: 26883846144.0000 - val_output_z_mae: 19339112448.0000\n",
      "Epoch 70/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 23762677760.0000 - output_x_loss: 23814840320.0000 - output_y_loss: 26073481216.0000 - output_z_loss: 19036753920.0000 - output_x_mae: 23814840320.0000 - output_y_mae: 26073481216.0000 - output_z_mae: 19036753920.0000 - val_loss: 23838885888.0000 - val_output_x_loss: 23729272832.0000 - val_output_y_loss: 26298574848.0000 - val_output_z_loss: 19138725888.0000 - val_output_x_mae: 23729272832.0000 - val_output_y_mae: 26298574848.0000 - val_output_z_mae: 19138725888.0000\n",
      "Epoch 71/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 23349176320.0000 - output_x_loss: 23404032000.0000 - output_y_loss: 25551040512.0000 - output_z_loss: 18835775488.0000 - output_x_mae: 23404032000.0000 - output_y_mae: 25551040512.0000 - output_z_mae: 18835775488.0000 - val_loss: 23459762176.0000 - val_output_x_loss: 23406684160.0000 - val_output_y_loss: 25770807296.0000 - val_output_z_loss: 18943836160.0000 - val_output_x_mae: 23406684160.0000 - val_output_y_mae: 25770807296.0000 - val_output_z_mae: 18943836160.0000\n",
      "Epoch 72/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 22966595584.0000 - output_x_loss: 23052398592.0000 - output_y_loss: 25049690112.0000 - output_z_loss: 18628751360.0000 - output_x_mae: 23052398592.0000 - output_y_mae: 25049690112.0000 - output_z_mae: 18628751360.0000 - val_loss: 23053799424.0000 - val_output_x_loss: 23000238080.0000 - val_output_y_loss: 25271490560.0000 - val_output_z_loss: 18725539840.0000 - val_output_x_mae: 23000238080.0000 - val_output_y_mae: 25271490560.0000 - val_output_z_mae: 18725539840.0000\n",
      "Epoch 73/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 22611419136.0000 - output_x_loss: 22732167168.0000 - output_y_loss: 24586223616.0000 - output_z_loss: 18420310016.0000 - output_x_mae: 22732167168.0000 - output_y_mae: 24586223616.0000 - output_z_mae: 18420310016.0000 - val_loss: 22731241472.0000 - val_output_x_loss: 22774788096.0000 - val_output_y_loss: 24801523712.0000 - val_output_z_loss: 18503581696.0000 - val_output_x_mae: 22774788096.0000 - val_output_y_mae: 24801523712.0000 - val_output_z_mae: 18503581696.0000\n",
      "Epoch 74/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 22262089728.0000 - output_x_loss: 22420146176.0000 - output_y_loss: 24126044160.0000 - output_z_loss: 18218074112.0000 - output_x_mae: 22420146176.0000 - output_y_mae: 24126044160.0000 - output_z_mae: 18218074112.0000 - val_loss: 22389522432.0000 - val_output_x_loss: 22485532672.0000 - val_output_y_loss: 24323477504.0000 - val_output_z_loss: 18329593856.0000 - val_output_x_mae: 22485532672.0000 - val_output_y_mae: 24323477504.0000 - val_output_z_mae: 18329593856.0000\n",
      "Epoch 75/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 21940180992.0000 - output_x_loss: 22140512256.0000 - output_y_loss: 23703681024.0000 - output_z_loss: 18012504064.0000 - output_x_mae: 22140512256.0000 - output_y_mae: 23703681024.0000 - output_z_mae: 18012504064.0000 - val_loss: 22049722368.0000 - val_output_x_loss: 22137008128.0000 - val_output_y_loss: 23913467904.0000 - val_output_z_loss: 18147657728.0000 - val_output_x_mae: 22137008128.0000 - val_output_y_mae: 23913467904.0000 - val_output_z_mae: 18147657728.0000\n",
      "Epoch 76/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 21618593792.0000 - output_x_loss: 21839771648.0000 - output_y_loss: 23294797824.0000 - output_z_loss: 17823854592.0000 - output_x_mae: 21839771648.0000 - output_y_mae: 23294797824.0000 - output_z_mae: 17823854592.0000 - val_loss: 21742571520.0000 - val_output_x_loss: 21880264704.0000 - val_output_y_loss: 23506313216.0000 - val_output_z_loss: 17939679232.0000 - val_output_x_mae: 21880264704.0000 - val_output_y_mae: 23506313216.0000 - val_output_z_mae: 17939679232.0000\n",
      "Epoch 77/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 21320214528.0000 - output_x_loss: 21581713408.0000 - output_y_loss: 22903742464.0000 - output_z_loss: 17630185472.0000 - output_x_mae: 21581713408.0000 - output_y_mae: 22903742464.0000 - output_z_mae: 17630185472.0000 - val_loss: 21430540288.0000 - val_output_x_loss: 21638901760.0000 - val_output_y_loss: 23089104896.0000 - val_output_z_loss: 17696679936.0000 - val_output_x_mae: 21638901760.0000 - val_output_y_mae: 23089104896.0000 - val_output_z_mae: 17696679936.0000\n",
      "Epoch 78/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 21038833664.0000 - output_x_loss: 21332596736.0000 - output_y_loss: 22542358528.0000 - output_z_loss: 17444220928.0000 - output_x_mae: 21332596736.0000 - output_y_mae: 22542358528.0000 - output_z_mae: 17444220928.0000 - val_loss: 21154734080.0000 - val_output_x_loss: 21398605824.0000 - val_output_y_loss: 22722660352.0000 - val_output_z_loss: 17531131904.0000 - val_output_x_mae: 21398605824.0000 - val_output_y_mae: 22722660352.0000 - val_output_z_mae: 17531131904.0000\n",
      "Epoch 79/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 20759658496.0000 - output_x_loss: 21093685248.0000 - output_y_loss: 22174130176.0000 - output_z_loss: 17262684160.0000 - output_x_mae: 21093685248.0000 - output_y_mae: 22174130176.0000 - output_z_mae: 17262684160.0000 - val_loss: 20895234048.0000 - val_output_x_loss: 21174552576.0000 - val_output_y_loss: 22380759040.0000 - val_output_z_loss: 17365544960.0000 - val_output_x_mae: 21174552576.0000 - val_output_y_mae: 22380759040.0000 - val_output_z_mae: 17365544960.0000\n",
      "Epoch 80/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 20496076800.0000 - output_x_loss: 20870873088.0000 - output_y_loss: 21826959360.0000 - output_z_loss: 17084725248.0000 - output_x_mae: 20870873088.0000 - output_y_mae: 21826959360.0000 - output_z_mae: 17084725248.0000 - val_loss: 20627177472.0000 - val_output_x_loss: 20976715776.0000 - val_output_y_loss: 21995962368.0000 - val_output_z_loss: 17190529024.0000 - val_output_x_mae: 20976715776.0000 - val_output_y_mae: 21995962368.0000 - val_output_z_mae: 17190529024.0000\n",
      "Epoch 81/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 20234893312.0000 - output_x_loss: 20643940352.0000 - output_y_loss: 21491648512.0000 - output_z_loss: 16903260160.0000 - output_x_mae: 20643940352.0000 - output_y_mae: 21491648512.0000 - output_z_mae: 16903260160.0000 - val_loss: 20388988928.0000 - val_output_x_loss: 20828936192.0000 - val_output_y_loss: 21646788608.0000 - val_output_z_loss: 16993529856.0000 - val_output_x_mae: 20828936192.0000 - val_output_y_mae: 21646788608.0000 - val_output_z_mae: 16993529856.0000\n",
      "Epoch 82/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 19987253248.0000 - output_x_loss: 20436733952.0000 - output_y_loss: 21162887168.0000 - output_z_loss: 16737011712.0000 - output_x_mae: 20436733952.0000 - output_y_mae: 21162887168.0000 - output_z_mae: 16737011712.0000 - val_loss: 20090447872.0000 - val_output_x_loss: 20535676928.0000 - val_output_y_loss: 21289027584.0000 - val_output_z_loss: 16802828288.0000 - val_output_x_mae: 20535676928.0000 - val_output_y_mae: 21289027584.0000 - val_output_z_mae: 16802828288.0000\n",
      "Epoch 83/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 19737145344.0000 - output_x_loss: 20215644160.0000 - output_y_loss: 20848076800.0000 - output_z_loss: 16558265344.0000 - output_x_mae: 20215644160.0000 - output_y_mae: 20848076800.0000 - output_z_mae: 16558265344.0000 - val_loss: 19860891648.0000 - val_output_x_loss: 20371449856.0000 - val_output_y_loss: 20955715584.0000 - val_output_z_loss: 16650102784.0000 - val_output_x_mae: 20371449856.0000 - val_output_y_mae: 20955715584.0000 - val_output_z_mae: 16650102784.0000\n",
      "Epoch 84/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 19509547008.0000 - output_x_loss: 20027199488.0000 - output_y_loss: 20547229696.0000 - output_z_loss: 16398860288.0000 - output_x_mae: 20027199488.0000 - output_y_mae: 20547229696.0000 - output_z_mae: 16398860288.0000 - val_loss: 19626412032.0000 - val_output_x_loss: 20153901056.0000 - val_output_y_loss: 20672964608.0000 - val_output_z_loss: 16478318592.0000 - val_output_x_mae: 20153901056.0000 - val_output_y_mae: 20672964608.0000 - val_output_z_mae: 16478318592.0000\n",
      "Epoch 85/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 19268857856.0000 - output_x_loss: 19804944384.0000 - output_y_loss: 20249018368.0000 - output_z_loss: 16236369920.0000 - output_x_mae: 19804944384.0000 - output_y_mae: 20249018368.0000 - output_z_mae: 16236369920.0000 - val_loss: 19412717568.0000 - val_output_x_loss: 19942899712.0000 - val_output_y_loss: 20436697088.0000 - val_output_z_loss: 16304389120.0000 - val_output_x_mae: 19942899712.0000 - val_output_y_mae: 20436697088.0000 - val_output_z_mae: 16304389120.0000\n",
      "Epoch 86/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 19045722112.0000 - output_x_loss: 19609837568.0000 - output_y_loss: 19960883200.0000 - output_z_loss: 16087200768.0000 - output_x_mae: 19609837568.0000 - output_y_mae: 19960883200.0000 - output_z_mae: 16087200768.0000 - val_loss: 19166238720.0000 - val_output_x_loss: 19771500544.0000 - val_output_y_loss: 20057808896.0000 - val_output_z_loss: 16172574720.0000 - val_output_x_mae: 19771500544.0000 - val_output_y_mae: 20057808896.0000 - val_output_z_mae: 16172574720.0000\n",
      "Epoch 87/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 18836613120.0000 - output_x_loss: 19429869568.0000 - output_y_loss: 19693635584.0000 - output_z_loss: 15936037888.0000 - output_x_mae: 19429869568.0000 - output_y_mae: 19693635584.0000 - output_z_mae: 15936037888.0000 - val_loss: 18935650304.0000 - val_output_x_loss: 19555239936.0000 - val_output_y_loss: 19773224960.0000 - val_output_z_loss: 16021307392.0000 - val_output_x_mae: 19555239936.0000 - val_output_y_mae: 19773224960.0000 - val_output_z_mae: 16021307392.0000\n",
      "Epoch 88/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 18623635456.0000 - output_x_loss: 19252150272.0000 - output_y_loss: 19416969216.0000 - output_z_loss: 15779937280.0000 - output_x_mae: 19252150272.0000 - output_y_mae: 19416969216.0000 - output_z_mae: 15779937280.0000 - val_loss: 18742943744.0000 - val_output_x_loss: 19396442112.0000 - val_output_y_loss: 19507384320.0000 - val_output_z_loss: 15907067904.0000 - val_output_x_mae: 19396442112.0000 - val_output_y_mae: 19507384320.0000 - val_output_z_mae: 15907067904.0000\n",
      "Epoch 89/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 18416134144.0000 - output_x_loss: 19062933504.0000 - output_y_loss: 19159392256.0000 - output_z_loss: 15635926016.0000 - output_x_mae: 19062933504.0000 - output_y_mae: 19159392256.0000 - output_z_mae: 15635926016.0000 - val_loss: 18544261120.0000 - val_output_x_loss: 19216007168.0000 - val_output_y_loss: 19273705472.0000 - val_output_z_loss: 15741867008.0000 - val_output_x_mae: 19216007168.0000 - val_output_y_mae: 19273705472.0000 - val_output_z_mae: 15741867008.0000\n",
      "Epoch 90/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 18220259328.0000 - output_x_loss: 18877362176.0000 - output_y_loss: 18922420224.0000 - output_z_loss: 15501751296.0000 - output_x_mae: 18877362176.0000 - output_y_mae: 18922420224.0000 - output_z_mae: 15501751296.0000 - val_loss: 18332162048.0000 - val_output_x_loss: 19004205056.0000 - val_output_y_loss: 19021357056.0000 - val_output_z_loss: 15609690112.0000 - val_output_x_mae: 19004205056.0000 - val_output_y_mae: 19021357056.0000 - val_output_z_mae: 15609690112.0000\n",
      "Epoch 91/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 18023528448.0000 - output_x_loss: 18704259072.0000 - output_y_loss: 18669774848.0000 - output_z_loss: 15369564160.0000 - output_x_mae: 18704259072.0000 - output_y_mae: 18669774848.0000 - output_z_mae: 15369564160.0000 - val_loss: 18143275008.0000 - val_output_x_loss: 18881239040.0000 - val_output_y_loss: 18730971136.0000 - val_output_z_loss: 15491940352.0000 - val_output_x_mae: 18881239040.0000 - val_output_y_mae: 18730971136.0000 - val_output_z_mae: 15491940352.0000\n",
      "Epoch 92/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 17828825088.0000 - output_x_loss: 18530373632.0000 - output_y_loss: 18421018624.0000 - output_z_loss: 15241335808.0000 - output_x_mae: 18530373632.0000 - output_y_mae: 18421018624.0000 - output_z_mae: 15241335808.0000 - val_loss: 17944020992.0000 - val_output_x_loss: 18697177088.0000 - val_output_y_loss: 18483546112.0000 - val_output_z_loss: 15358637056.0000 - val_output_x_mae: 18697177088.0000 - val_output_y_mae: 18483546112.0000 - val_output_z_mae: 15358637056.0000\n",
      "Epoch 93/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 17645641728.0000 - output_x_loss: 18363449344.0000 - output_y_loss: 18191124480.0000 - output_z_loss: 15119065088.0000 - output_x_mae: 18363449344.0000 - output_y_mae: 18191124480.0000 - output_z_mae: 15119065088.0000 - val_loss: 17737261056.0000 - val_output_x_loss: 18488348672.0000 - val_output_y_loss: 18233047040.0000 - val_output_z_loss: 15243507712.0000 - val_output_x_mae: 18488348672.0000 - val_output_y_mae: 18233047040.0000 - val_output_z_mae: 15243507712.0000\n",
      "Epoch 94/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 17457868800.0000 - output_x_loss: 18186872832.0000 - output_y_loss: 17960554496.0000 - output_z_loss: 14994512896.0000 - output_x_mae: 18186872832.0000 - output_y_mae: 17960554496.0000 - output_z_mae: 14994512896.0000 - val_loss: 17564690432.0000 - val_output_x_loss: 18323881984.0000 - val_output_y_loss: 18020831232.0000 - val_output_z_loss: 15134025728.0000 - val_output_x_mae: 18323881984.0000 - val_output_y_mae: 18020831232.0000 - val_output_z_mae: 15134025728.0000\n",
      "Epoch 95/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 17276917760.0000 - output_x_loss: 18022014976.0000 - output_y_loss: 17733486592.0000 - output_z_loss: 14873592832.0000 - output_x_mae: 18022014976.0000 - output_y_mae: 17733486592.0000 - output_z_mae: 14873592832.0000 - val_loss: 17412114432.0000 - val_output_x_loss: 18238640128.0000 - val_output_y_loss: 17781149696.0000 - val_output_z_loss: 15021015040.0000 - val_output_x_mae: 18238640128.0000 - val_output_y_mae: 17781149696.0000 - val_output_z_mae: 15021015040.0000\n",
      "Epoch 96/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 17103986688.0000 - output_x_loss: 17867132928.0000 - output_y_loss: 17515448320.0000 - output_z_loss: 14754749440.0000 - output_x_mae: 17867132928.0000 - output_y_mae: 17515448320.0000 - output_z_mae: 14754749440.0000 - val_loss: 17194883072.0000 - val_output_x_loss: 17996398592.0000 - val_output_y_loss: 17543129088.0000 - val_output_z_loss: 14895348736.0000 - val_output_x_mae: 17996398592.0000 - val_output_y_mae: 17543129088.0000 - val_output_z_mae: 14895348736.0000\n",
      "Epoch 97/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 16923502592.0000 - output_x_loss: 17698332672.0000 - output_y_loss: 17286879232.0000 - output_z_loss: 14647073792.0000 - output_x_mae: 17698332672.0000 - output_y_mae: 17286879232.0000 - output_z_mae: 14647073792.0000 - val_loss: 17031821312.0000 - val_output_x_loss: 17843470336.0000 - val_output_y_loss: 17352392704.0000 - val_output_z_loss: 14767369216.0000 - val_output_x_mae: 17843470336.0000 - val_output_y_mae: 17352392704.0000 - val_output_z_mae: 14767369216.0000\n",
      "Epoch 98/200\n",
      "329/329 [==============================] - 3s 11ms/step - loss: 16758479872.0000 - output_x_loss: 17552416768.0000 - output_y_loss: 17077564416.0000 - output_z_loss: 14532440064.0000 - output_x_mae: 17552416768.0000 - output_y_mae: 17077564416.0000 - output_z_mae: 14532440064.0000 - val_loss: 16859489280.0000 - val_output_x_loss: 17681117184.0000 - val_output_y_loss: 17139265536.0000 - val_output_z_loss: 14656661504.0000 - val_output_x_mae: 17681117184.0000 - val_output_y_mae: 17139265536.0000 - val_output_z_mae: 14656661504.0000\n",
      "Epoch 99/200\n",
      "329/329 [==============================] - 3s 9ms/step - loss: 16601790464.0000 - output_x_loss: 17408186368.0000 - output_y_loss: 16884121600.0000 - output_z_loss: 14424336384.0000 - output_x_mae: 17408186368.0000 - output_y_mae: 16884121600.0000 - output_z_mae: 14424336384.0000 - val_loss: 16683002880.0000 - val_output_x_loss: 17559248896.0000 - val_output_y_loss: 16867528704.0000 - val_output_z_loss: 14561465344.0000 - val_output_x_mae: 17559248896.0000 - val_output_y_mae: 16867528704.0000 - val_output_z_mae: 14561465344.0000\n",
      "Epoch 100/200\n",
      "329/329 [==============================] - 2s 6ms/step - loss: 16446733312.0000 - output_x_loss: 17252950016.0000 - output_y_loss: 16698362880.0000 - output_z_loss: 14331065344.0000 - output_x_mae: 17252950016.0000 - output_y_mae: 16698362880.0000 - output_z_mae: 14331065344.0000 - val_loss: 16532877312.0000 - val_output_x_loss: 17411192832.0000 - val_output_y_loss: 16699443200.0000 - val_output_z_loss: 14443089920.0000 - val_output_x_mae: 17411192832.0000 - val_output_y_mae: 16699443200.0000 - val_output_z_mae: 14443089920.0000\n",
      "Epoch 101/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 16280604672.0000 - output_x_loss: 17094195200.0000 - output_y_loss: 16498391040.0000 - output_z_loss: 14217806848.0000 - output_x_mae: 17094195200.0000 - output_y_mae: 16498391040.0000 - output_z_mae: 14217806848.0000 - val_loss: 16395254784.0000 - val_output_x_loss: 17290588160.0000 - val_output_y_loss: 16494288896.0000 - val_output_z_loss: 14406520832.0000 - val_output_x_mae: 17290588160.0000 - val_output_y_mae: 16494288896.0000 - val_output_z_mae: 14406520832.0000\n",
      "Epoch 102/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 16136408064.0000 - output_x_loss: 16958797824.0000 - output_y_loss: 16325166080.0000 - output_z_loss: 14114145280.0000 - output_x_mae: 16958797824.0000 - output_y_mae: 16325166080.0000 - output_z_mae: 14114145280.0000 - val_loss: 16212967424.0000 - val_output_x_loss: 17101480960.0000 - val_output_y_loss: 16308587520.0000 - val_output_z_loss: 14244707328.0000 - val_output_x_mae: 17101480960.0000 - val_output_y_mae: 16308587520.0000 - val_output_z_mae: 14244707328.0000\n",
      "Epoch 103/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15983955968.0000 - output_x_loss: 16811234304.0000 - output_y_loss: 16140248064.0000 - output_z_loss: 14016771072.0000 - output_x_mae: 16811234304.0000 - output_y_mae: 16140248064.0000 - output_z_mae: 14016771072.0000 - val_loss: 16086238208.0000 - val_output_x_loss: 16943390720.0000 - val_output_y_loss: 16195725312.0000 - val_output_z_loss: 14152958976.0000 - val_output_x_mae: 16943390720.0000 - val_output_y_mae: 16195725312.0000 - val_output_z_mae: 14152958976.0000\n",
      "Epoch 104/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15843252224.0000 - output_x_loss: 16673583104.0000 - output_y_loss: 15975895040.0000 - output_z_loss: 13917358080.0000 - output_x_mae: 16673583104.0000 - output_y_mae: 15975895040.0000 - output_z_mae: 13917358080.0000 - val_loss: 15942864896.0000 - val_output_x_loss: 16811758592.0000 - val_output_y_loss: 16006804480.0000 - val_output_z_loss: 14077211648.0000 - val_output_x_mae: 16811758592.0000 - val_output_y_mae: 16006804480.0000 - val_output_z_mae: 14077211648.0000\n",
      "Epoch 105/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15697555456.0000 - output_x_loss: 16526820352.0000 - output_y_loss: 15806054400.0000 - output_z_loss: 13822025728.0000 - output_x_mae: 16526820352.0000 - output_y_mae: 15806054400.0000 - output_z_mae: 13822025728.0000 - val_loss: 15788725248.0000 - val_output_x_loss: 16687882240.0000 - val_output_y_loss: 15787505664.0000 - val_output_z_loss: 13992857600.0000 - val_output_x_mae: 16687882240.0000 - val_output_y_mae: 15787505664.0000 - val_output_z_mae: 13992857600.0000\n",
      "Epoch 106/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15563328512.0000 - output_x_loss: 16388160512.0000 - output_y_loss: 15656765440.0000 - output_z_loss: 13726832640.0000 - output_x_mae: 16388160512.0000 - output_y_mae: 15656765440.0000 - output_z_mae: 13726832640.0000 - val_loss: 15669490688.0000 - val_output_x_loss: 16547275776.0000 - val_output_y_loss: 15679138816.0000 - val_output_z_loss: 13894612992.0000 - val_output_x_mae: 16547275776.0000 - val_output_y_mae: 15679138816.0000 - val_output_z_mae: 13894612992.0000\n",
      "Epoch 107/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15426097152.0000 - output_x_loss: 16263127040.0000 - output_y_loss: 15480492032.0000 - output_z_loss: 13643271168.0000 - output_x_mae: 16263127040.0000 - output_y_mae: 15480492032.0000 - output_z_mae: 13643271168.0000 - val_loss: 15510549504.0000 - val_output_x_loss: 16400704512.0000 - val_output_y_loss: 15462779904.0000 - val_output_z_loss: 13825788928.0000 - val_output_x_mae: 16400704512.0000 - val_output_y_mae: 15462779904.0000 - val_output_z_mae: 13825788928.0000\n",
      "Epoch 108/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15296206848.0000 - output_x_loss: 16118862848.0000 - output_y_loss: 15342009344.0000 - output_z_loss: 13559256064.0000 - output_x_mae: 16118862848.0000 - output_y_mae: 15342009344.0000 - output_z_mae: 13559256064.0000 - val_loss: 15427684352.0000 - val_output_x_loss: 16283309056.0000 - val_output_y_loss: 15419555840.0000 - val_output_z_loss: 13732691968.0000 - val_output_x_mae: 16283309056.0000 - val_output_y_mae: 15419555840.0000 - val_output_z_mae: 13732691968.0000\n",
      "Epoch 109/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 15166328832.0000 - output_x_loss: 15999301632.0000 - output_y_loss: 15179901952.0000 - output_z_loss: 13473256448.0000 - output_x_mae: 15999301632.0000 - output_y_mae: 15179901952.0000 - output_z_mae: 13473256448.0000 - val_loss: 15265639424.0000 - val_output_x_loss: 16201637888.0000 - val_output_y_loss: 15160643584.0000 - val_output_z_loss: 13603651584.0000 - val_output_x_mae: 16201637888.0000 - val_output_y_mae: 15160643584.0000 - val_output_z_mae: 13603651584.0000\n",
      "Epoch 110/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 15027825664.0000 - output_x_loss: 15859761152.0000 - output_y_loss: 15020806144.0000 - output_z_loss: 13377986560.0000 - output_x_mae: 15859761152.0000 - output_y_mae: 15020806144.0000 - output_z_mae: 13377986560.0000 - val_loss: 15109912576.0000 - val_output_x_loss: 16022077440.0000 - val_output_y_loss: 14989671424.0000 - val_output_z_loss: 13526053888.0000 - val_output_x_mae: 16022077440.0000 - val_output_y_mae: 14989671424.0000 - val_output_z_mae: 13526053888.0000\n",
      "Epoch 111/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 14911851520.0000 - output_x_loss: 15742087168.0000 - output_y_loss: 14891923456.0000 - output_z_loss: 13291238400.0000 - output_x_mae: 15742087168.0000 - output_y_mae: 14891923456.0000 - output_z_mae: 13291238400.0000 - val_loss: 14998966272.0000 - val_output_x_loss: 15918061568.0000 - val_output_y_loss: 14833272832.0000 - val_output_z_loss: 13492174848.0000 - val_output_x_mae: 15918061568.0000 - val_output_y_mae: 14833272832.0000 - val_output_z_mae: 13492174848.0000\n",
      "Epoch 112/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 14786696192.0000 - output_x_loss: 15609640960.0000 - output_y_loss: 14754097152.0000 - output_z_loss: 13206013952.0000 - output_x_mae: 15609640960.0000 - output_y_mae: 14754097152.0000 - output_z_mae: 13206013952.0000 - val_loss: 14917754880.0000 - val_output_x_loss: 15747367936.0000 - val_output_y_loss: 14862578688.0000 - val_output_z_loss: 13368880128.0000 - val_output_x_mae: 15747367936.0000 - val_output_y_mae: 14862578688.0000 - val_output_z_mae: 13368880128.0000\n",
      "Epoch 113/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 14667872256.0000 - output_x_loss: 15491905536.0000 - output_y_loss: 14613668864.0000 - output_z_loss: 13128193024.0000 - output_x_mae: 15491905536.0000 - output_y_mae: 14613668864.0000 - output_z_mae: 13128193024.0000 - val_loss: 14750039040.0000 - val_output_x_loss: 15615600640.0000 - val_output_y_loss: 14609880064.0000 - val_output_z_loss: 13299232768.0000 - val_output_x_mae: 15615600640.0000 - val_output_y_mae: 14609880064.0000 - val_output_z_mae: 13299232768.0000\n",
      "Epoch 114/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 14541375488.0000 - output_x_loss: 15359560704.0000 - output_y_loss: 14473043968.0000 - output_z_loss: 13041651712.0000 - output_x_mae: 15359560704.0000 - output_y_mae: 14473043968.0000 - output_z_mae: 13041651712.0000 - val_loss: 14613855232.0000 - val_output_x_loss: 15533191168.0000 - val_output_y_loss: 14401773568.0000 - val_output_z_loss: 13199348736.0000 - val_output_x_mae: 15533191168.0000 - val_output_y_mae: 14401773568.0000 - val_output_z_mae: 13199348736.0000\n",
      "Epoch 115/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 14424631296.0000 - output_x_loss: 15238251520.0000 - output_y_loss: 14342174720.0000 - output_z_loss: 12962314240.0000 - output_x_mae: 15238251520.0000 - output_y_mae: 14342174720.0000 - output_z_mae: 12962314240.0000 - val_loss: 14494298112.0000 - val_output_x_loss: 15356293120.0000 - val_output_y_loss: 14290134016.0000 - val_output_z_loss: 13178647552.0000 - val_output_x_mae: 15356293120.0000 - val_output_y_mae: 14290134016.0000 - val_output_z_mae: 13178647552.0000\n",
      "Epoch 116/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 14307904512.0000 - output_x_loss: 15118195712.0000 - output_y_loss: 14202518528.0000 - output_z_loss: 12898083840.0000 - output_x_mae: 15118195712.0000 - output_y_mae: 14202518528.0000 - output_z_mae: 12898083840.0000 - val_loss: 14378259456.0000 - val_output_x_loss: 15251488768.0000 - val_output_y_loss: 14157480960.0000 - val_output_z_loss: 13073360896.0000 - val_output_x_mae: 15251488768.0000 - val_output_y_mae: 14157480960.0000 - val_output_z_mae: 13073360896.0000\n",
      "Epoch 117/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 14201917440.0000 - output_x_loss: 15008109568.0000 - output_y_loss: 14088237056.0000 - output_z_loss: 12816885760.0000 - output_x_mae: 15008109568.0000 - output_y_mae: 14088237056.0000 - output_z_mae: 12816885760.0000 - val_loss: 14257044480.0000 - val_output_x_loss: 15145025536.0000 - val_output_y_loss: 14010911744.0000 - val_output_z_loss: 12973350912.0000 - val_output_x_mae: 15145025536.0000 - val_output_y_mae: 14010911744.0000 - val_output_z_mae: 12973350912.0000\n",
      "Epoch 118/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 14086018048.0000 - output_x_loss: 14888282112.0000 - output_y_loss: 13959995392.0000 - output_z_loss: 12733536256.0000 - output_x_mae: 14888282112.0000 - output_y_mae: 13959995392.0000 - output_z_mae: 12733536256.0000 - val_loss: 14146299904.0000 - val_output_x_loss: 15008320512.0000 - val_output_y_loss: 13893899264.0000 - val_output_z_loss: 12927062016.0000 - val_output_x_mae: 15008320512.0000 - val_output_y_mae: 13893899264.0000 - val_output_z_mae: 12927062016.0000\n",
      "Epoch 119/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13974681600.0000 - output_x_loss: 14776678400.0000 - output_y_loss: 13828805632.0000 - output_z_loss: 12662460416.0000 - output_x_mae: 14776678400.0000 - output_y_mae: 13828805632.0000 - output_z_mae: 12662460416.0000 - val_loss: 14040217600.0000 - val_output_x_loss: 14922449920.0000 - val_output_y_loss: 13766268928.0000 - val_output_z_loss: 12823650304.0000 - val_output_x_mae: 14922449920.0000 - val_output_y_mae: 13766268928.0000 - val_output_z_mae: 12823650304.0000\n",
      "Epoch 120/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 13864879104.0000 - output_x_loss: 14664295424.0000 - output_y_loss: 13701321728.0000 - output_z_loss: 12593149952.0000 - output_x_mae: 14664295424.0000 - output_y_mae: 13701321728.0000 - output_z_mae: 12593149952.0000 - val_loss: 13998690304.0000 - val_output_x_loss: 14913175552.0000 - val_output_y_loss: 13707468800.0000 - val_output_z_loss: 12752172032.0000 - val_output_x_mae: 14913175552.0000 - val_output_y_mae: 13707468800.0000 - val_output_z_mae: 12752172032.0000\n",
      "Epoch 121/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13756566528.0000 - output_x_loss: 14551657472.0000 - output_y_loss: 13584881664.0000 - output_z_loss: 12509759488.0000 - output_x_mae: 14551657472.0000 - output_y_mae: 13584881664.0000 - output_z_mae: 12509759488.0000 - val_loss: 13851762688.0000 - val_output_x_loss: 14682585088.0000 - val_output_y_loss: 13610638336.0000 - val_output_z_loss: 12672376832.0000 - val_output_x_mae: 14682585088.0000 - val_output_y_mae: 13610638336.0000 - val_output_z_mae: 12672376832.0000\n",
      "Epoch 122/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13653741568.0000 - output_x_loss: 14438017024.0000 - output_y_loss: 13479561216.0000 - output_z_loss: 12433587200.0000 - output_x_mae: 14438017024.0000 - output_y_mae: 13479561216.0000 - output_z_mae: 12433587200.0000 - val_loss: 13746144256.0000 - val_output_x_loss: 14602814464.0000 - val_output_y_loss: 13447590912.0000 - val_output_z_loss: 12629902336.0000 - val_output_x_mae: 14602814464.0000 - val_output_y_mae: 13447590912.0000 - val_output_z_mae: 12629902336.0000\n",
      "Epoch 123/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13548643328.0000 - output_x_loss: 14328220672.0000 - output_y_loss: 13355821056.0000 - output_z_loss: 12375121920.0000 - output_x_mae: 14328220672.0000 - output_y_mae: 13355821056.0000 - output_z_mae: 12375121920.0000 - val_loss: 13620004864.0000 - val_output_x_loss: 14493805568.0000 - val_output_y_loss: 13289026560.0000 - val_output_z_loss: 12534345728.0000 - val_output_x_mae: 14493805568.0000 - val_output_y_mae: 13289026560.0000 - val_output_z_mae: 12534345728.0000\n",
      "Epoch 124/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13441563648.0000 - output_x_loss: 14219634688.0000 - output_y_loss: 13237936128.0000 - output_z_loss: 12292668416.0000 - output_x_mae: 14219634688.0000 - output_y_mae: 13237936128.0000 - output_z_mae: 12292668416.0000 - val_loss: 13534014464.0000 - val_output_x_loss: 14369263616.0000 - val_output_y_loss: 13199764480.0000 - val_output_z_loss: 12532022272.0000 - val_output_x_mae: 14369263616.0000 - val_output_y_mae: 13199764480.0000 - val_output_z_mae: 12532022272.0000\n",
      "Epoch 125/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13357704192.0000 - output_x_loss: 14135372800.0000 - output_y_loss: 13139145728.0000 - output_z_loss: 12239495168.0000 - output_x_mae: 14135372800.0000 - output_y_mae: 13139145728.0000 - output_z_mae: 12239495168.0000 - val_loss: 13423430656.0000 - val_output_x_loss: 14287561728.0000 - val_output_y_loss: 13071072256.0000 - val_output_z_loss: 12399883264.0000 - val_output_x_mae: 14287561728.0000 - val_output_y_mae: 13071072256.0000 - val_output_z_mae: 12399883264.0000\n",
      "Epoch 126/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13236961280.0000 - output_x_loss: 13991556096.0000 - output_y_loss: 13022059520.0000 - output_z_loss: 12157607936.0000 - output_x_mae: 13991556096.0000 - output_y_mae: 13022059520.0000 - output_z_mae: 12157607936.0000 - val_loss: 13352170496.0000 - val_output_x_loss: 14203860992.0000 - val_output_y_loss: 13011527680.0000 - val_output_z_loss: 12330079232.0000 - val_output_x_mae: 14203860992.0000 - val_output_y_mae: 13011527680.0000 - val_output_z_mae: 12330079232.0000\n",
      "Epoch 127/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13150651392.0000 - output_x_loss: 13901953024.0000 - output_y_loss: 12927379456.0000 - output_z_loss: 12094618624.0000 - output_x_mae: 13901953024.0000 - output_y_mae: 12927379456.0000 - output_z_mae: 12094618624.0000 - val_loss: 13218269184.0000 - val_output_x_loss: 14053373952.0000 - val_output_y_loss: 12868426752.0000 - val_output_z_loss: 12247763968.0000 - val_output_x_mae: 14053373952.0000 - val_output_y_mae: 12868426752.0000 - val_output_z_mae: 12247763968.0000\n",
      "Epoch 128/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 13052108800.0000 - output_x_loss: 13787457536.0000 - output_y_loss: 12826393600.0000 - output_z_loss: 12032847872.0000 - output_x_mae: 13787457536.0000 - output_y_mae: 12826393600.0000 - output_z_mae: 12032847872.0000 - val_loss: 13185814528.0000 - val_output_x_loss: 13976197120.0000 - val_output_y_loss: 12867782656.0000 - val_output_z_loss: 12241113088.0000 - val_output_x_mae: 13976197120.0000 - val_output_y_mae: 12867782656.0000 - val_output_z_mae: 12241113088.0000\n",
      "Epoch 129/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12963301376.0000 - output_x_loss: 13690017792.0000 - output_y_loss: 12734016512.0000 - output_z_loss: 11968446464.0000 - output_x_mae: 13690017792.0000 - output_y_mae: 12734016512.0000 - output_z_mae: 11968446464.0000 - val_loss: 13041288192.0000 - val_output_x_loss: 13857637376.0000 - val_output_y_loss: 12688176128.0000 - val_output_z_loss: 12114798592.0000 - val_output_x_mae: 13857637376.0000 - val_output_y_mae: 12688176128.0000 - val_output_z_mae: 12114798592.0000\n",
      "Epoch 130/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12871953408.0000 - output_x_loss: 13595685888.0000 - output_y_loss: 12631828480.0000 - output_z_loss: 11904751616.0000 - output_x_mae: 13595685888.0000 - output_y_mae: 12631828480.0000 - output_z_mae: 11904751616.0000 - val_loss: 12967458816.0000 - val_output_x_loss: 13817127936.0000 - val_output_y_loss: 12560271360.0000 - val_output_z_loss: 12082478080.0000 - val_output_x_mae: 13817127936.0000 - val_output_y_mae: 12560271360.0000 - val_output_z_mae: 12082478080.0000\n",
      "Epoch 131/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12780532736.0000 - output_x_loss: 13505524736.0000 - output_y_loss: 12524820480.0000 - output_z_loss: 11841939456.0000 - output_x_mae: 13505524736.0000 - output_y_mae: 12524820480.0000 - output_z_mae: 11841939456.0000 - val_loss: 12844601344.0000 - val_output_x_loss: 13669411840.0000 - val_output_y_loss: 12439054336.0000 - val_output_z_loss: 12006073344.0000 - val_output_x_mae: 13669411840.0000 - val_output_y_mae: 12439054336.0000 - val_output_z_mae: 12006073344.0000\n",
      "Epoch 132/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12680699904.0000 - output_x_loss: 13383095296.0000 - output_y_loss: 12427038720.0000 - output_z_loss: 11783226368.0000 - output_x_mae: 13383095296.0000 - output_y_mae: 12427038720.0000 - output_z_mae: 11783226368.0000 - val_loss: 12764336128.0000 - val_output_x_loss: 13555792896.0000 - val_output_y_loss: 12384638976.0000 - val_output_z_loss: 11940808704.0000 - val_output_x_mae: 13555792896.0000 - val_output_y_mae: 12384638976.0000 - val_output_z_mae: 11940808704.0000\n",
      "Epoch 133/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12601339904.0000 - output_x_loss: 13305322496.0000 - output_y_loss: 12339672064.0000 - output_z_loss: 11716702208.0000 - output_x_mae: 13305322496.0000 - output_y_mae: 12339672064.0000 - output_z_mae: 11716702208.0000 - val_loss: 12676711424.0000 - val_output_x_loss: 13457162240.0000 - val_output_y_loss: 12288730112.0000 - val_output_z_loss: 11891758080.0000 - val_output_x_mae: 13457162240.0000 - val_output_y_mae: 12288730112.0000 - val_output_z_mae: 11891758080.0000\n",
      "Epoch 134/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12505695232.0000 - output_x_loss: 13198056448.0000 - output_y_loss: 12235084800.0000 - output_z_loss: 11662186496.0000 - output_x_mae: 13198056448.0000 - output_y_mae: 12235084800.0000 - output_z_mae: 11662186496.0000 - val_loss: 12579134464.0000 - val_output_x_loss: 13349598208.0000 - val_output_y_loss: 12179198976.0000 - val_output_z_loss: 11838068736.0000 - val_output_x_mae: 13349598208.0000 - val_output_y_mae: 12179198976.0000 - val_output_z_mae: 11838068736.0000\n",
      "Epoch 135/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12423370752.0000 - output_x_loss: 13095613440.0000 - output_y_loss: 12163599360.0000 - output_z_loss: 11598415872.0000 - output_x_mae: 13095613440.0000 - output_y_mae: 12163599360.0000 - output_z_mae: 11598415872.0000 - val_loss: 12525546496.0000 - val_output_x_loss: 13345985536.0000 - val_output_y_loss: 12085395456.0000 - val_output_z_loss: 11764973568.0000 - val_output_x_mae: 13345985536.0000 - val_output_y_mae: 12085395456.0000 - val_output_z_mae: 11764973568.0000\n",
      "Epoch 136/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12338551808.0000 - output_x_loss: 13010587648.0000 - output_y_loss: 12059460608.0000 - output_z_loss: 11552694272.0000 - output_x_mae: 13010587648.0000 - output_y_mae: 12059460608.0000 - output_z_mae: 11552694272.0000 - val_loss: 12445074432.0000 - val_output_x_loss: 13246313472.0000 - val_output_y_loss: 12000217088.0000 - val_output_z_loss: 11732310016.0000 - val_output_x_mae: 13246313472.0000 - val_output_y_mae: 12000217088.0000 - val_output_z_mae: 11732310016.0000\n",
      "Epoch 137/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12259081216.0000 - output_x_loss: 12926128128.0000 - output_y_loss: 11975996416.0000 - output_z_loss: 11491163136.0000 - output_x_mae: 12926128128.0000 - output_y_mae: 11975996416.0000 - output_z_mae: 11491163136.0000 - val_loss: 12368034816.0000 - val_output_x_loss: 13209175040.0000 - val_output_y_loss: 11887538176.0000 - val_output_z_loss: 11646739456.0000 - val_output_x_mae: 13209175040.0000 - val_output_y_mae: 11887538176.0000 - val_output_z_mae: 11646739456.0000\n",
      "Epoch 138/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12174659584.0000 - output_x_loss: 12828310528.0000 - output_y_loss: 11889001472.0000 - output_z_loss: 11438644224.0000 - output_x_mae: 12828310528.0000 - output_y_mae: 11889001472.0000 - output_z_mae: 11438644224.0000 - val_loss: 12284480512.0000 - val_output_x_loss: 13058696192.0000 - val_output_y_loss: 11852675072.0000 - val_output_z_loss: 11599663104.0000 - val_output_x_mae: 13058696192.0000 - val_output_y_mae: 11852675072.0000 - val_output_z_mae: 11599663104.0000\n",
      "Epoch 139/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12088862720.0000 - output_x_loss: 12733789184.0000 - output_y_loss: 11796634624.0000 - output_z_loss: 11383481344.0000 - output_x_mae: 12733789184.0000 - output_y_mae: 11796634624.0000 - output_z_mae: 11383481344.0000 - val_loss: 12151331840.0000 - val_output_x_loss: 12897231872.0000 - val_output_y_loss: 11704765440.0000 - val_output_z_loss: 11552666624.0000 - val_output_x_mae: 12897231872.0000 - val_output_y_mae: 11704765440.0000 - val_output_z_mae: 11552666624.0000\n",
      "Epoch 140/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 12000567296.0000 - output_x_loss: 12632564736.0000 - output_y_loss: 11704588288.0000 - output_z_loss: 11328470016.0000 - output_x_mae: 12632564736.0000 - output_y_mae: 11704588288.0000 - output_z_mae: 11328470016.0000 - val_loss: 12103951360.0000 - val_output_x_loss: 12864514048.0000 - val_output_y_loss: 11640409088.0000 - val_output_z_loss: 11509913600.0000 - val_output_x_mae: 12864514048.0000 - val_output_y_mae: 11640409088.0000 - val_output_z_mae: 11509913600.0000\n",
      "Epoch 141/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11924814848.0000 - output_x_loss: 12555100160.0000 - output_y_loss: 11619119104.0000 - output_z_loss: 11275631616.0000 - output_x_mae: 12555100160.0000 - output_y_mae: 11619119104.0000 - output_z_mae: 11275631616.0000 - val_loss: 12011049984.0000 - val_output_x_loss: 12779212800.0000 - val_output_y_loss: 11524707328.0000 - val_output_z_loss: 11447409664.0000 - val_output_x_mae: 12779212800.0000 - val_output_y_mae: 11524707328.0000 - val_output_z_mae: 11447409664.0000\n",
      "Epoch 142/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11842471936.0000 - output_x_loss: 12461933568.0000 - output_y_loss: 11529843712.0000 - output_z_loss: 11228810240.0000 - output_x_mae: 12461933568.0000 - output_y_mae: 11529843712.0000 - output_z_mae: 11228810240.0000 - val_loss: 11913223168.0000 - val_output_x_loss: 12613929984.0000 - val_output_y_loss: 11474758656.0000 - val_output_z_loss: 11388741632.0000 - val_output_x_mae: 12613929984.0000 - val_output_y_mae: 11474758656.0000 - val_output_z_mae: 11388741632.0000\n",
      "Epoch 143/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11759769600.0000 - output_x_loss: 12362829824.0000 - output_y_loss: 11449141248.0000 - output_z_loss: 11174893568.0000 - output_x_mae: 12362829824.0000 - output_y_mae: 11449141248.0000 - output_z_mae: 11174893568.0000 - val_loss: 11855582208.0000 - val_output_x_loss: 12581076992.0000 - val_output_y_loss: 11349257216.0000 - val_output_z_loss: 11417245696.0000 - val_output_x_mae: 12581076992.0000 - val_output_y_mae: 11349257216.0000 - val_output_z_mae: 11417245696.0000\n",
      "Epoch 144/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11684777984.0000 - output_x_loss: 12282829824.0000 - output_y_loss: 11370198016.0000 - output_z_loss: 11117831168.0000 - output_x_mae: 12282829824.0000 - output_y_mae: 11370198016.0000 - output_z_mae: 11117831168.0000 - val_loss: 11776558080.0000 - val_output_x_loss: 12514414592.0000 - val_output_y_loss: 11271862272.0000 - val_output_z_loss: 11310231552.0000 - val_output_x_mae: 12514414592.0000 - val_output_y_mae: 11271862272.0000 - val_output_z_mae: 11310231552.0000\n",
      "Epoch 145/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11611150336.0000 - output_x_loss: 12201194496.0000 - output_y_loss: 11287812096.0000 - output_z_loss: 11077720064.0000 - output_x_mae: 12201194496.0000 - output_y_mae: 11287812096.0000 - output_z_mae: 11077720064.0000 - val_loss: 11703022592.0000 - val_output_x_loss: 12413834240.0000 - val_output_y_loss: 11206524928.0000 - val_output_z_loss: 11274387456.0000 - val_output_x_mae: 12413834240.0000 - val_output_y_mae: 11206524928.0000 - val_output_z_mae: 11274387456.0000\n",
      "Epoch 146/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11531393024.0000 - output_x_loss: 12107698176.0000 - output_y_loss: 11206150144.0000 - output_z_loss: 11029258240.0000 - output_x_mae: 12107698176.0000 - output_y_mae: 11206150144.0000 - output_z_mae: 11029258240.0000 - val_loss: 11604643840.0000 - val_output_x_loss: 12301117440.0000 - val_output_y_loss: 11105926144.0000 - val_output_z_loss: 11209124864.0000 - val_output_x_mae: 12301117440.0000 - val_output_y_mae: 11105926144.0000 - val_output_z_mae: 11209124864.0000\n",
      "Epoch 147/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11451640832.0000 - output_x_loss: 12016428032.0000 - output_y_loss: 11126581248.0000 - output_z_loss: 10972189696.0000 - output_x_mae: 12016428032.0000 - output_y_mae: 11126581248.0000 - output_z_mae: 10972189696.0000 - val_loss: 11541442560.0000 - val_output_x_loss: 12186927104.0000 - val_output_y_loss: 11089551360.0000 - val_output_z_loss: 11154248704.0000 - val_output_x_mae: 12186927104.0000 - val_output_y_mae: 11089551360.0000 - val_output_z_mae: 11154248704.0000\n",
      "Epoch 148/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11377344512.0000 - output_x_loss: 11932968960.0000 - output_y_loss: 11045526528.0000 - output_z_loss: 10929742848.0000 - output_x_mae: 11932968960.0000 - output_y_mae: 11045526528.0000 - output_z_mae: 10929742848.0000 - val_loss: 11466545152.0000 - val_output_x_loss: 12167662592.0000 - val_output_y_loss: 10957275136.0000 - val_output_z_loss: 11082860544.0000 - val_output_x_mae: 12167662592.0000 - val_output_y_mae: 10957275136.0000 - val_output_z_mae: 11082860544.0000\n",
      "Epoch 149/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11302482944.0000 - output_x_loss: 11857580032.0000 - output_y_loss: 10958397440.0000 - output_z_loss: 10880445440.0000 - output_x_mae: 11857580032.0000 - output_y_mae: 10958397440.0000 - output_z_mae: 10880445440.0000 - val_loss: 11399554048.0000 - val_output_x_loss: 12041296896.0000 - val_output_y_loss: 10934165504.0000 - val_output_z_loss: 11046856704.0000 - val_output_x_mae: 12041296896.0000 - val_output_y_mae: 10934165504.0000 - val_output_z_mae: 11046856704.0000\n",
      "Epoch 150/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11232372736.0000 - output_x_loss: 11770285056.0000 - output_y_loss: 10893216768.0000 - output_z_loss: 10834823168.0000 - output_x_mae: 11770285056.0000 - output_y_mae: 10893216768.0000 - output_z_mae: 10834823168.0000 - val_loss: 11314750464.0000 - val_output_x_loss: 11994472448.0000 - val_output_y_loss: 10789459968.0000 - val_output_z_loss: 11005892608.0000 - val_output_x_mae: 11994472448.0000 - val_output_y_mae: 10789459968.0000 - val_output_z_mae: 11005892608.0000\n",
      "Epoch 151/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11159984128.0000 - output_x_loss: 11695345664.0000 - output_y_loss: 10816778240.0000 - output_z_loss: 10775659520.0000 - output_x_mae: 11695345664.0000 - output_y_mae: 10816778240.0000 - output_z_mae: 10775659520.0000 - val_loss: 11252260864.0000 - val_output_x_loss: 11921158144.0000 - val_output_y_loss: 10705186816.0000 - val_output_z_loss: 11008616448.0000 - val_output_x_mae: 11921158144.0000 - val_output_y_mae: 10705186816.0000 - val_output_z_mae: 11008616448.0000\n",
      "Epoch 152/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11084441600.0000 - output_x_loss: 11616227328.0000 - output_y_loss: 10727702528.0000 - output_z_loss: 10734345216.0000 - output_x_mae: 11616227328.0000 - output_y_mae: 10727702528.0000 - output_z_mae: 10734345216.0000 - val_loss: 11160205312.0000 - val_output_x_loss: 11811394560.0000 - val_output_y_loss: 10628709376.0000 - val_output_z_loss: 10920813568.0000 - val_output_x_mae: 11811394560.0000 - val_output_y_mae: 10628709376.0000 - val_output_z_mae: 10920813568.0000\n",
      "Epoch 153/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 11018736640.0000 - output_x_loss: 11543706624.0000 - output_y_loss: 10661900288.0000 - output_z_loss: 10682459136.0000 - output_x_mae: 11543706624.0000 - output_y_mae: 10661900288.0000 - output_z_mae: 10682459136.0000 - val_loss: 11148151808.0000 - val_output_x_loss: 11829782528.0000 - val_output_y_loss: 10605410304.0000 - val_output_z_loss: 10870372352.0000 - val_output_x_mae: 11829782528.0000 - val_output_y_mae: 10605410304.0000 - val_output_z_mae: 10870372352.0000\n",
      "Epoch 154/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 10953282560.0000 - output_x_loss: 11475251200.0000 - output_y_loss: 10584053760.0000 - output_z_loss: 10647799808.0000 - output_x_mae: 11475251200.0000 - output_y_mae: 10584053760.0000 - output_z_mae: 10647799808.0000 - val_loss: 11033955328.0000 - val_output_x_loss: 11666443264.0000 - val_output_y_loss: 10518415360.0000 - val_output_z_loss: 10800058368.0000 - val_output_x_mae: 11666443264.0000 - val_output_y_mae: 10518415360.0000 - val_output_z_mae: 10800058368.0000\n",
      "Epoch 155/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10880207872.0000 - output_x_loss: 11387955200.0000 - output_y_loss: 10513456128.0000 - output_z_loss: 10598219776.0000 - output_x_mae: 11387955200.0000 - output_y_mae: 10513456128.0000 - output_z_mae: 10598219776.0000 - val_loss: 10952236032.0000 - val_output_x_loss: 11579140096.0000 - val_output_y_loss: 10426470400.0000 - val_output_z_loss: 10749959168.0000 - val_output_x_mae: 11579140096.0000 - val_output_y_mae: 10426470400.0000 - val_output_z_mae: 10749959168.0000\n",
      "Epoch 156/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10819315712.0000 - output_x_loss: 11321966592.0000 - output_y_loss: 10448748544.0000 - output_z_loss: 10555141120.0000 - output_x_mae: 11321966592.0000 - output_y_mae: 10448748544.0000 - output_z_mae: 10555141120.0000 - val_loss: 10889289728.0000 - val_output_x_loss: 11508301824.0000 - val_output_y_loss: 10356033536.0000 - val_output_z_loss: 10717770752.0000 - val_output_x_mae: 11508301824.0000 - val_output_y_mae: 10356033536.0000 - val_output_z_mae: 10717770752.0000\n",
      "Epoch 157/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10741978112.0000 - output_x_loss: 11237807104.0000 - output_y_loss: 10366745600.0000 - output_z_loss: 10500812800.0000 - output_x_mae: 11237807104.0000 - output_y_mae: 10366745600.0000 - output_z_mae: 10500812800.0000 - val_loss: 10826497024.0000 - val_output_x_loss: 11435991040.0000 - val_output_y_loss: 10292028416.0000 - val_output_z_loss: 10676424704.0000 - val_output_x_mae: 11435991040.0000 - val_output_y_mae: 10292028416.0000 - val_output_z_mae: 10676424704.0000\n",
      "Epoch 158/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10675295232.0000 - output_x_loss: 11159434240.0000 - output_y_loss: 10295418880.0000 - output_z_loss: 10466769920.0000 - output_x_mae: 11159434240.0000 - output_y_mae: 10295418880.0000 - output_z_mae: 10466769920.0000 - val_loss: 10792842240.0000 - val_output_x_loss: 11378502656.0000 - val_output_y_loss: 10287288320.0000 - val_output_z_loss: 10632633344.0000 - val_output_x_mae: 11378502656.0000 - val_output_y_mae: 10287288320.0000 - val_output_z_mae: 10632633344.0000\n",
      "Epoch 159/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10615694336.0000 - output_x_loss: 11097646080.0000 - output_y_loss: 10234849280.0000 - output_z_loss: 10413473792.0000 - output_x_mae: 11097646080.0000 - output_y_mae: 10234849280.0000 - output_z_mae: 10413473792.0000 - val_loss: 10696571904.0000 - val_output_x_loss: 11292817408.0000 - val_output_y_loss: 10157392896.0000 - val_output_z_loss: 10582430720.0000 - val_output_x_mae: 11292817408.0000 - val_output_y_mae: 10157392896.0000 - val_output_z_mae: 10582430720.0000\n",
      "Epoch 160/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10548070400.0000 - output_x_loss: 11018457088.0000 - output_y_loss: 10166437888.0000 - output_z_loss: 10370533376.0000 - output_x_mae: 11018457088.0000 - output_y_mae: 10166437888.0000 - output_z_mae: 10370533376.0000 - val_loss: 10639216640.0000 - val_output_x_loss: 11208807424.0000 - val_output_y_loss: 10119760896.0000 - val_output_z_loss: 10538955776.0000 - val_output_x_mae: 11208807424.0000 - val_output_y_mae: 10119760896.0000 - val_output_z_mae: 10538955776.0000\n",
      "Epoch 161/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10489007104.0000 - output_x_loss: 10955878400.0000 - output_y_loss: 10104094720.0000 - output_z_loss: 10325104640.0000 - output_x_mae: 10955878400.0000 - output_y_mae: 10104094720.0000 - output_z_mae: 10325104640.0000 - val_loss: 10568639488.0000 - val_output_x_loss: 11169233920.0000 - val_output_y_loss: 10008273920.0000 - val_output_z_loss: 10488168448.0000 - val_output_x_mae: 11169233920.0000 - val_output_y_mae: 10008273920.0000 - val_output_z_mae: 10488168448.0000\n",
      "Epoch 162/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10426168320.0000 - output_x_loss: 10887843840.0000 - output_y_loss: 10036371456.0000 - output_z_loss: 10282413056.0000 - output_x_mae: 10887843840.0000 - output_y_mae: 10036371456.0000 - output_z_mae: 10282413056.0000 - val_loss: 10504382464.0000 - val_output_x_loss: 11069777920.0000 - val_output_y_loss: 9964922880.0000 - val_output_z_loss: 10452500480.0000 - val_output_x_mae: 11069777920.0000 - val_output_y_mae: 9964922880.0000 - val_output_z_mae: 10452500480.0000\n",
      "Epoch 163/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10362589184.0000 - output_x_loss: 10812065792.0000 - output_y_loss: 9970557952.0000 - output_z_loss: 10247674880.0000 - output_x_mae: 10812065792.0000 - output_y_mae: 9970557952.0000 - output_z_mae: 10247674880.0000 - val_loss: 10438184960.0000 - val_output_x_loss: 11025871872.0000 - val_output_y_loss: 9869134848.0000 - val_output_z_loss: 10400896000.0000 - val_output_x_mae: 11025871872.0000 - val_output_y_mae: 9869134848.0000 - val_output_z_mae: 10400896000.0000\n",
      "Epoch 164/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10297695232.0000 - output_x_loss: 10744190976.0000 - output_y_loss: 9897757696.0000 - output_z_loss: 10204571648.0000 - output_x_mae: 10744190976.0000 - output_y_mae: 9897757696.0000 - output_z_mae: 10204571648.0000 - val_loss: 10396591104.0000 - val_output_x_loss: 10994081792.0000 - val_output_y_loss: 9805895680.0000 - val_output_z_loss: 10383001600.0000 - val_output_x_mae: 10994081792.0000 - val_output_y_mae: 9805895680.0000 - val_output_z_mae: 10383001600.0000\n",
      "Epoch 165/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 10244669440.0000 - output_x_loss: 10692043776.0000 - output_y_loss: 9839131648.0000 - output_z_loss: 10160964608.0000 - output_x_mae: 10692043776.0000 - output_y_mae: 9839131648.0000 - output_z_mae: 10160964608.0000 - val_loss: 10316571648.0000 - val_output_x_loss: 10893388800.0000 - val_output_y_loss: 9733653504.0000 - val_output_z_loss: 10328779776.0000 - val_output_x_mae: 10893388800.0000 - val_output_y_mae: 9733653504.0000 - val_output_z_mae: 10328779776.0000\n",
      "Epoch 166/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10185135104.0000 - output_x_loss: 10621765632.0000 - output_y_loss: 9780274176.0000 - output_z_loss: 10121589760.0000 - output_x_mae: 10621765632.0000 - output_y_mae: 9780274176.0000 - output_z_mae: 10121589760.0000 - val_loss: 10258532352.0000 - val_output_x_loss: 10813626368.0000 - val_output_y_loss: 9690514432.0000 - val_output_z_loss: 10284387328.0000 - val_output_x_mae: 10813626368.0000 - val_output_y_mae: 9690514432.0000 - val_output_z_mae: 10284387328.0000\n",
      "Epoch 167/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10119732224.0000 - output_x_loss: 10544254976.0000 - output_y_loss: 9713878016.0000 - output_z_loss: 10082385920.0000 - output_x_mae: 10544254976.0000 - output_y_mae: 9713878016.0000 - output_z_mae: 10082385920.0000 - val_loss: 10194555904.0000 - val_output_x_loss: 10735893504.0000 - val_output_y_loss: 9630394368.0000 - val_output_z_loss: 10240220160.0000 - val_output_x_mae: 10735893504.0000 - val_output_y_mae: 9630394368.0000 - val_output_z_mae: 10240220160.0000\n",
      "Epoch 168/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10064769024.0000 - output_x_loss: 10480684032.0000 - output_y_loss: 9658894336.0000 - output_z_loss: 10044698624.0000 - output_x_mae: 10480684032.0000 - output_y_mae: 9658894336.0000 - output_z_mae: 10044698624.0000 - val_loss: 10145164288.0000 - val_output_x_loss: 10710053888.0000 - val_output_y_loss: 9538564096.0000 - val_output_z_loss: 10228586496.0000 - val_output_x_mae: 10710053888.0000 - val_output_y_mae: 9538564096.0000 - val_output_z_mae: 10228586496.0000\n",
      "Epoch 169/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 10011782144.0000 - output_x_loss: 10421448704.0000 - output_y_loss: 9605187584.0000 - output_z_loss: 10005638144.0000 - output_x_mae: 10421448704.0000 - output_y_mae: 9605187584.0000 - output_z_mae: 10005638144.0000 - val_loss: 10091345920.0000 - val_output_x_loss: 10626677760.0000 - val_output_y_loss: 9510057984.0000 - val_output_z_loss: 10183266304.0000 - val_output_x_mae: 10626677760.0000 - val_output_y_mae: 9510057984.0000 - val_output_z_mae: 10183266304.0000\n",
      "Epoch 170/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9945499648.0000 - output_x_loss: 10352229376.0000 - output_y_loss: 9528379392.0000 - output_z_loss: 9966274560.0000 - output_x_mae: 10352229376.0000 - output_y_mae: 9528379392.0000 - output_z_mae: 9966274560.0000 - val_loss: 10024109056.0000 - val_output_x_loss: 10581448704.0000 - val_output_y_loss: 9413652480.0000 - val_output_z_loss: 10130347008.0000 - val_output_x_mae: 10581448704.0000 - val_output_y_mae: 9413652480.0000 - val_output_z_mae: 10130347008.0000\n",
      "Epoch 171/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9894606848.0000 - output_x_loss: 10302424064.0000 - output_y_loss: 9469492224.0000 - output_z_loss: 9929192448.0000 - output_x_mae: 10302424064.0000 - output_y_mae: 9469492224.0000 - output_z_mae: 9929192448.0000 - val_loss: 9970533376.0000 - val_output_x_loss: 10493060096.0000 - val_output_y_loss: 9383145472.0000 - val_output_z_loss: 10100257792.0000 - val_output_x_mae: 10493060096.0000 - val_output_y_mae: 9383145472.0000 - val_output_z_mae: 10100257792.0000\n",
      "Epoch 172/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9840542720.0000 - output_x_loss: 10239226880.0000 - output_y_loss: 9414934528.0000 - output_z_loss: 9894402048.0000 - output_x_mae: 10239226880.0000 - output_y_mae: 9414934528.0000 - output_z_mae: 9894402048.0000 - val_loss: 9908695040.0000 - val_output_x_loss: 10425315328.0000 - val_output_y_loss: 9316341760.0000 - val_output_z_loss: 10060160000.0000 - val_output_x_mae: 10425315328.0000 - val_output_y_mae: 9316341760.0000 - val_output_z_mae: 10060160000.0000\n",
      "Epoch 173/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9783204864.0000 - output_x_loss: 10166468608.0000 - output_y_loss: 9358518272.0000 - output_z_loss: 9866067968.0000 - output_x_mae: 10166468608.0000 - output_y_mae: 9358518272.0000 - output_z_mae: 9866067968.0000 - val_loss: 9876133888.0000 - val_output_x_loss: 10389148672.0000 - val_output_y_loss: 9287389184.0000 - val_output_z_loss: 10027588608.0000 - val_output_x_mae: 10389148672.0000 - val_output_y_mae: 9287389184.0000 - val_output_z_mae: 10027588608.0000\n",
      "Epoch 174/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9728326656.0000 - output_x_loss: 10113876992.0000 - output_y_loss: 9294539776.0000 - output_z_loss: 9824801792.0000 - output_x_mae: 10113876992.0000 - output_y_mae: 9294539776.0000 - output_z_mae: 9824801792.0000 - val_loss: 9811120128.0000 - val_output_x_loss: 10310432768.0000 - val_output_y_loss: 9226372096.0000 - val_output_z_loss: 9982001152.0000 - val_output_x_mae: 10310432768.0000 - val_output_y_mae: 9226372096.0000 - val_output_z_mae: 9982001152.0000\n",
      "Epoch 175/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9674917888.0000 - output_x_loss: 10045253632.0000 - output_y_loss: 9244397568.0000 - output_z_loss: 9795282944.0000 - output_x_mae: 10045253632.0000 - output_y_mae: 9244397568.0000 - output_z_mae: 9795282944.0000 - val_loss: 9761623040.0000 - val_output_x_loss: 10257020928.0000 - val_output_y_loss: 9155631104.0000 - val_output_z_loss: 9982830592.0000 - val_output_x_mae: 10257020928.0000 - val_output_y_mae: 9155631104.0000 - val_output_z_mae: 9982830592.0000\n",
      "Epoch 176/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9625387008.0000 - output_x_loss: 9996930048.0000 - output_y_loss: 9188262912.0000 - output_z_loss: 9756555264.0000 - output_x_mae: 9996930048.0000 - output_y_mae: 9188262912.0000 - output_z_mae: 9756555264.0000 - val_loss: 9719427072.0000 - val_output_x_loss: 10207623168.0000 - val_output_y_loss: 9123337216.0000 - val_output_z_loss: 9935214592.0000 - val_output_x_mae: 10207623168.0000 - val_output_y_mae: 9123337216.0000 - val_output_z_mae: 9935214592.0000\n",
      "Epoch 177/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9572840448.0000 - output_x_loss: 9935833088.0000 - output_y_loss: 9135827968.0000 - output_z_loss: 9720912896.0000 - output_x_mae: 9935833088.0000 - output_y_mae: 9135827968.0000 - output_z_mae: 9720912896.0000 - val_loss: 9652339712.0000 - val_output_x_loss: 10145482752.0000 - val_output_y_loss: 9041604608.0000 - val_output_z_loss: 9887514624.0000 - val_output_x_mae: 10145482752.0000 - val_output_y_mae: 9041604608.0000 - val_output_z_mae: 9887514624.0000\n",
      "Epoch 178/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9520809984.0000 - output_x_loss: 9877618688.0000 - output_y_loss: 9082180608.0000 - output_z_loss: 9684449280.0000 - output_x_mae: 9877618688.0000 - output_y_mae: 9082180608.0000 - output_z_mae: 9684449280.0000 - val_loss: 9623425024.0000 - val_output_x_loss: 10109264896.0000 - val_output_y_loss: 9022256128.0000 - val_output_z_loss: 9854082048.0000 - val_output_x_mae: 10109264896.0000 - val_output_y_mae: 9022256128.0000 - val_output_z_mae: 9854082048.0000\n",
      "Epoch 179/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9475684352.0000 - output_x_loss: 9823152128.0000 - output_y_loss: 9039167488.0000 - output_z_loss: 9653769216.0000 - output_x_mae: 9823152128.0000 - output_y_mae: 9039167488.0000 - output_z_mae: 9653769216.0000 - val_loss: 9566916608.0000 - val_output_x_loss: 10051350528.0000 - val_output_y_loss: 8958146560.0000 - val_output_z_loss: 9815590912.0000 - val_output_x_mae: 10051350528.0000 - val_output_y_mae: 8958146560.0000 - val_output_z_mae: 9815590912.0000\n",
      "Epoch 180/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 9423168512.0000 - output_x_loss: 9762937856.0000 - output_y_loss: 8987064320.0000 - output_z_loss: 9615827968.0000 - output_x_mae: 9762937856.0000 - output_y_mae: 8987064320.0000 - output_z_mae: 9615827968.0000 - val_loss: 9510737920.0000 - val_output_x_loss: 9961457664.0000 - val_output_y_loss: 8912638976.0000 - val_output_z_loss: 9805489152.0000 - val_output_x_mae: 9961457664.0000 - val_output_y_mae: 8912638976.0000 - val_output_z_mae: 9805489152.0000\n",
      "Epoch 181/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 9365915648.0000 - output_x_loss: 9702099968.0000 - output_y_loss: 8923292672.0000 - output_z_loss: 9578790912.0000 - output_x_mae: 9702099968.0000 - output_y_mae: 8923292672.0000 - output_z_mae: 9578790912.0000 - val_loss: 9447715840.0000 - val_output_x_loss: 9914766336.0000 - val_output_y_loss: 8831619072.0000 - val_output_z_loss: 9745806336.0000 - val_output_x_mae: 9914766336.0000 - val_output_y_mae: 8831619072.0000 - val_output_z_mae: 9745806336.0000\n",
      "Epoch 182/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9317036032.0000 - output_x_loss: 9647427584.0000 - output_y_loss: 8870549504.0000 - output_z_loss: 9549254656.0000 - output_x_mae: 9647427584.0000 - output_y_mae: 8870549504.0000 - output_z_mae: 9549254656.0000 - val_loss: 9408819200.0000 - val_output_x_loss: 9892374528.0000 - val_output_y_loss: 8778218496.0000 - val_output_z_loss: 9702903808.0000 - val_output_x_mae: 9892374528.0000 - val_output_y_mae: 8778218496.0000 - val_output_z_mae: 9702903808.0000\n",
      "Epoch 183/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9273497600.0000 - output_x_loss: 9601081344.0000 - output_y_loss: 8825703424.0000 - output_z_loss: 9513931776.0000 - output_x_mae: 9601081344.0000 - output_y_mae: 8825703424.0000 - output_z_mae: 9513931776.0000 - val_loss: 9354019840.0000 - val_output_x_loss: 9805699072.0000 - val_output_y_loss: 8735051776.0000 - val_output_z_loss: 9688590336.0000 - val_output_x_mae: 9805699072.0000 - val_output_y_mae: 8735051776.0000 - val_output_z_mae: 9688590336.0000\n",
      "Epoch 184/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9225939968.0000 - output_x_loss: 9548717056.0000 - output_y_loss: 8776897536.0000 - output_z_loss: 9478445056.0000 - output_x_mae: 9548717056.0000 - output_y_mae: 8776897536.0000 - output_z_mae: 9478445056.0000 - val_loss: 9312852992.0000 - val_output_x_loss: 9774878720.0000 - val_output_y_loss: 8691385344.0000 - val_output_z_loss: 9631737856.0000 - val_output_x_mae: 9774878720.0000 - val_output_y_mae: 8691385344.0000 - val_output_z_mae: 9631737856.0000\n",
      "Epoch 185/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9170881536.0000 - output_x_loss: 9490992128.0000 - output_y_loss: 8712171520.0000 - output_z_loss: 9448084480.0000 - output_x_mae: 9490992128.0000 - output_y_mae: 8712171520.0000 - output_z_mae: 9448084480.0000 - val_loss: 9282933760.0000 - val_output_x_loss: 9712575488.0000 - val_output_y_loss: 8667931648.0000 - val_output_z_loss: 9653641216.0000 - val_output_x_mae: 9712575488.0000 - val_output_y_mae: 8667931648.0000 - val_output_z_mae: 9653641216.0000\n",
      "Epoch 186/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9123135488.0000 - output_x_loss: 9428429824.0000 - output_y_loss: 8672766976.0000 - output_z_loss: 9413310464.0000 - output_x_mae: 9428429824.0000 - output_y_mae: 8672766976.0000 - output_z_mae: 9413310464.0000 - val_loss: 9214424064.0000 - val_output_x_loss: 9659052032.0000 - val_output_y_loss: 8588952064.0000 - val_output_z_loss: 9576109056.0000 - val_output_x_mae: 9659052032.0000 - val_output_y_mae: 8588952064.0000 - val_output_z_mae: 9576109056.0000\n",
      "Epoch 187/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9074450432.0000 - output_x_loss: 9376924672.0000 - output_y_loss: 8623007744.0000 - output_z_loss: 9372368896.0000 - output_x_mae: 9376924672.0000 - output_y_mae: 8623007744.0000 - output_z_mae: 9372368896.0000 - val_loss: 9170541568.0000 - val_output_x_loss: 9634596864.0000 - val_output_y_loss: 8516690432.0000 - val_output_z_loss: 9550129152.0000 - val_output_x_mae: 9634596864.0000 - val_output_y_mae: 8516690432.0000 - val_output_z_mae: 9550129152.0000\n",
      "Epoch 188/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 9030650880.0000 - output_x_loss: 9328792576.0000 - output_y_loss: 8574687744.0000 - output_z_loss: 9346293760.0000 - output_x_mae: 9328792576.0000 - output_y_mae: 8574687744.0000 - output_z_mae: 9346293760.0000 - val_loss: 9144231936.0000 - val_output_x_loss: 9559081984.0000 - val_output_y_loss: 8537821696.0000 - val_output_z_loss: 9527350272.0000 - val_output_x_mae: 9559081984.0000 - val_output_y_mae: 8537821696.0000 - val_output_z_mae: 9527350272.0000\n",
      "Epoch 189/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8983247872.0000 - output_x_loss: 9279090688.0000 - output_y_loss: 8521241600.0000 - output_z_loss: 9315574784.0000 - output_x_mae: 9279090688.0000 - output_y_mae: 8521241600.0000 - output_z_mae: 9315574784.0000 - val_loss: 9073640448.0000 - val_output_x_loss: 9508370432.0000 - val_output_y_loss: 8439391744.0000 - val_output_z_loss: 9472676864.0000 - val_output_x_mae: 9508370432.0000 - val_output_y_mae: 8439391744.0000 - val_output_z_mae: 9472676864.0000\n",
      "Epoch 190/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8938814464.0000 - output_x_loss: 9230309376.0000 - output_y_loss: 8474426368.0000 - output_z_loss: 9284586496.0000 - output_x_mae: 9230309376.0000 - output_y_mae: 8474426368.0000 - output_z_mae: 9284586496.0000 - val_loss: 9017061376.0000 - val_output_x_loss: 9449495552.0000 - val_output_y_loss: 8380334080.0000 - val_output_z_loss: 9425642496.0000 - val_output_x_mae: 9449495552.0000 - val_output_y_mae: 8380334080.0000 - val_output_z_mae: 9425642496.0000\n",
      "Epoch 191/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8895773696.0000 - output_x_loss: 9185707008.0000 - output_y_loss: 8428962304.0000 - output_z_loss: 9249525760.0000 - output_x_mae: 9185707008.0000 - output_y_mae: 8428962304.0000 - output_z_mae: 9249525760.0000 - val_loss: 9018204160.0000 - val_output_x_loss: 9445394432.0000 - val_output_y_loss: 8392188416.0000 - val_output_z_loss: 9415851008.0000 - val_output_x_mae: 9445394432.0000 - val_output_y_mae: 8392188416.0000 - val_output_z_mae: 9415851008.0000\n",
      "Epoch 192/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8857065472.0000 - output_x_loss: 9134481408.0000 - output_y_loss: 8398296576.0000 - output_z_loss: 9219775488.0000 - output_x_mae: 9134481408.0000 - output_y_mae: 8398296576.0000 - output_z_mae: 9219775488.0000 - val_loss: 8933725184.0000 - val_output_x_loss: 9369433088.0000 - val_output_y_loss: 8275222528.0000 - val_output_z_loss: 9379310592.0000 - val_output_x_mae: 9369433088.0000 - val_output_y_mae: 8275222528.0000 - val_output_z_mae: 9379310592.0000\n",
      "Epoch 193/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8809223168.0000 - output_x_loss: 9083923456.0000 - output_y_loss: 8346570240.0000 - output_z_loss: 9185139712.0000 - output_x_mae: 9083923456.0000 - output_y_mae: 8346570240.0000 - output_z_mae: 9185139712.0000 - val_loss: 8892929024.0000 - val_output_x_loss: 9313510400.0000 - val_output_y_loss: 8244101120.0000 - val_output_z_loss: 9349422080.0000 - val_output_x_mae: 9313510400.0000 - val_output_y_mae: 8244101120.0000 - val_output_z_mae: 9349422080.0000\n",
      "Epoch 194/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 8763176960.0000 - output_x_loss: 9035603968.0000 - output_y_loss: 8293723648.0000 - output_z_loss: 9157235712.0000 - output_x_mae: 9035603968.0000 - output_y_mae: 8293723648.0000 - output_z_mae: 9157235712.0000 - val_loss: 8871974912.0000 - val_output_x_loss: 9246362624.0000 - val_output_y_loss: 8281641472.0000 - val_output_z_loss: 9303861248.0000 - val_output_x_mae: 9246362624.0000 - val_output_y_mae: 8281641472.0000 - val_output_z_mae: 9303861248.0000\n",
      "Epoch 195/200\n",
      "329/329 [==============================] - 1s 5ms/step - loss: 8718980096.0000 - output_x_loss: 8981719040.0000 - output_y_loss: 8253662208.0000 - output_z_loss: 9124127744.0000 - output_x_mae: 8981719040.0000 - output_y_mae: 8253662208.0000 - output_z_mae: 9124127744.0000 - val_loss: 8828377088.0000 - val_output_x_loss: 9267517440.0000 - val_output_y_loss: 8160408064.0000 - val_output_z_loss: 9286043648.0000 - val_output_x_mae: 9267517440.0000 - val_output_y_mae: 8160408064.0000 - val_output_z_mae: 9286043648.0000\n",
      "Epoch 196/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8674205696.0000 - output_x_loss: 8941415424.0000 - output_y_loss: 8195408384.0000 - output_z_loss: 9097355264.0000 - output_x_mae: 8941415424.0000 - output_y_mae: 8195408384.0000 - output_z_mae: 9097355264.0000 - val_loss: 8768825344.0000 - val_output_x_loss: 9186863104.0000 - val_output_y_loss: 8103817728.0000 - val_output_z_loss: 9262766080.0000 - val_output_x_mae: 9186863104.0000 - val_output_y_mae: 8103817728.0000 - val_output_z_mae: 9262766080.0000\n",
      "Epoch 197/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8631371776.0000 - output_x_loss: 8897546240.0000 - output_y_loss: 8153977856.0000 - output_z_loss: 9053803520.0000 - output_x_mae: 8897546240.0000 - output_y_mae: 8153977856.0000 - output_z_mae: 9053803520.0000 - val_loss: 8708535296.0000 - val_output_x_loss: 9106260992.0000 - val_output_y_loss: 8063967232.0000 - val_output_z_loss: 9202211840.0000 - val_output_x_mae: 9106260992.0000 - val_output_y_mae: 8063967232.0000 - val_output_z_mae: 9202211840.0000\n",
      "Epoch 198/200\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 8588930560.0000 - output_x_loss: 8838641664.0000 - output_y_loss: 8114788352.0000 - output_z_loss: 9037827072.0000 - output_x_mae: 8838641664.0000 - output_y_mae: 8114788352.0000 - output_z_mae: 9037827072.0000 - val_loss: 8666149888.0000 - val_output_x_loss: 9050761216.0000 - val_output_y_loss: 8027019776.0000 - val_output_z_loss: 9175183360.0000 - val_output_x_mae: 9050761216.0000 - val_output_y_mae: 8027019776.0000 - val_output_z_mae: 9175183360.0000\n",
      "Epoch 199/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8547809280.0000 - output_x_loss: 8790219776.0000 - output_y_loss: 8079218176.0000 - output_z_loss: 9000186880.0000 - output_x_mae: 8790219776.0000 - output_y_mae: 8079218176.0000 - output_z_mae: 9000186880.0000 - val_loss: 8636688384.0000 - val_output_x_loss: 9016230912.0000 - val_output_y_loss: 8000011264.0000 - val_output_z_loss: 9150958592.0000 - val_output_x_mae: 9016230912.0000 - val_output_y_mae: 8000011264.0000 - val_output_z_mae: 9150958592.0000\n",
      "Epoch 200/200\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 8511954432.0000 - output_x_loss: 8754951168.0000 - output_y_loss: 8039503360.0000 - output_z_loss: 8970835968.0000 - output_x_mae: 8754951168.0000 - output_y_mae: 8039503360.0000 - output_z_mae: 8970835968.0000 - val_loss: 8593924096.0000 - val_output_x_loss: 8966045696.0000 - val_output_y_loss: 7964585472.0000 - val_output_z_loss: 9108358144.0000 - val_output_x_mae: 8966045696.0000 - val_output_y_mae: 7964585472.0000 - val_output_z_mae: 9108358144.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using numpy formatted training and validation data.\n",
    "history = model.fit(\n",
    "    [X_train], [y_train_x, y_train_y, y_train_z],\n",
    "    epochs=input_num_epochs,\n",
    "    validation_data=([X_valid], [y_valid_x, y_valid_y, y_valid_z]),\n",
    "    batch_size=input_batch_size,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>output_x_loss</th>\n",
       "      <th>output_y_loss</th>\n",
       "      <th>output_z_loss</th>\n",
       "      <th>output_x_mae</th>\n",
       "      <th>output_y_mae</th>\n",
       "      <th>output_z_mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_output_x_loss</th>\n",
       "      <th>val_output_y_loss</th>\n",
       "      <th>val_output_z_loss</th>\n",
       "      <th>val_output_x_mae</th>\n",
       "      <th>val_output_y_mae</th>\n",
       "      <th>val_output_z_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.559996e+12</td>\n",
       "      <td>1.469749e+12</td>\n",
       "      <td>2.041372e+12</td>\n",
       "      <td>7.777293e+11</td>\n",
       "      <td>1.469749e+12</td>\n",
       "      <td>2.041372e+12</td>\n",
       "      <td>7.777293e+11</td>\n",
       "      <td>1.468327e+12</td>\n",
       "      <td>1.379339e+12</td>\n",
       "      <td>1.927812e+12</td>\n",
       "      <td>7.273367e+11</td>\n",
       "      <td>1.379339e+12</td>\n",
       "      <td>1.927812e+12</td>\n",
       "      <td>7.273367e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.393167e+12</td>\n",
       "      <td>1.298636e+12</td>\n",
       "      <td>1.846721e+12</td>\n",
       "      <td>6.751162e+11</td>\n",
       "      <td>1.298636e+12</td>\n",
       "      <td>1.846721e+12</td>\n",
       "      <td>6.751162e+11</td>\n",
       "      <td>1.307511e+12</td>\n",
       "      <td>1.213725e+12</td>\n",
       "      <td>1.742844e+12</td>\n",
       "      <td>6.244142e+11</td>\n",
       "      <td>1.213725e+12</td>\n",
       "      <td>1.742844e+12</td>\n",
       "      <td>6.244142e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.231540e+12</td>\n",
       "      <td>1.131393e+12</td>\n",
       "      <td>1.660111e+12</td>\n",
       "      <td>5.746917e+11</td>\n",
       "      <td>1.131393e+12</td>\n",
       "      <td>1.660111e+12</td>\n",
       "      <td>5.746917e+11</td>\n",
       "      <td>1.150451e+12</td>\n",
       "      <td>1.051026e+12</td>\n",
       "      <td>1.562037e+12</td>\n",
       "      <td>5.261292e+11</td>\n",
       "      <td>1.051026e+12</td>\n",
       "      <td>1.562037e+12</td>\n",
       "      <td>5.261292e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.074510e+12</td>\n",
       "      <td>9.694488e+11</td>\n",
       "      <td>1.478107e+12</td>\n",
       "      <td>4.774393e+11</td>\n",
       "      <td>9.694488e+11</td>\n",
       "      <td>1.478107e+12</td>\n",
       "      <td>4.774393e+11</td>\n",
       "      <td>9.992263e+11</td>\n",
       "      <td>8.980680e+11</td>\n",
       "      <td>1.384068e+12</td>\n",
       "      <td>4.318567e+11</td>\n",
       "      <td>8.980680e+11</td>\n",
       "      <td>1.384068e+12</td>\n",
       "      <td>4.318567e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.253476e+11</td>\n",
       "      <td>8.203437e+11</td>\n",
       "      <td>1.296316e+12</td>\n",
       "      <td>3.934178e+11</td>\n",
       "      <td>8.203437e+11</td>\n",
       "      <td>1.296316e+12</td>\n",
       "      <td>3.934178e+11</td>\n",
       "      <td>8.572135e+11</td>\n",
       "      <td>7.578759e+11</td>\n",
       "      <td>1.204685e+12</td>\n",
       "      <td>3.609454e+11</td>\n",
       "      <td>7.578759e+11</td>\n",
       "      <td>1.204685e+12</td>\n",
       "      <td>3.609454e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>9.074450e+09</td>\n",
       "      <td>9.376925e+09</td>\n",
       "      <td>8.623008e+09</td>\n",
       "      <td>9.372369e+09</td>\n",
       "      <td>9.376925e+09</td>\n",
       "      <td>8.623008e+09</td>\n",
       "      <td>9.372369e+09</td>\n",
       "      <td>9.170542e+09</td>\n",
       "      <td>9.634597e+09</td>\n",
       "      <td>8.516690e+09</td>\n",
       "      <td>9.550129e+09</td>\n",
       "      <td>9.634597e+09</td>\n",
       "      <td>8.516690e+09</td>\n",
       "      <td>9.550129e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>9.030651e+09</td>\n",
       "      <td>9.328793e+09</td>\n",
       "      <td>8.574688e+09</td>\n",
       "      <td>9.346294e+09</td>\n",
       "      <td>9.328793e+09</td>\n",
       "      <td>8.574688e+09</td>\n",
       "      <td>9.346294e+09</td>\n",
       "      <td>9.144232e+09</td>\n",
       "      <td>9.559082e+09</td>\n",
       "      <td>8.537822e+09</td>\n",
       "      <td>9.527350e+09</td>\n",
       "      <td>9.559082e+09</td>\n",
       "      <td>8.537822e+09</td>\n",
       "      <td>9.527350e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8.983248e+09</td>\n",
       "      <td>9.279091e+09</td>\n",
       "      <td>8.521242e+09</td>\n",
       "      <td>9.315575e+09</td>\n",
       "      <td>9.279091e+09</td>\n",
       "      <td>8.521242e+09</td>\n",
       "      <td>9.315575e+09</td>\n",
       "      <td>9.073640e+09</td>\n",
       "      <td>9.508370e+09</td>\n",
       "      <td>8.439392e+09</td>\n",
       "      <td>9.472677e+09</td>\n",
       "      <td>9.508370e+09</td>\n",
       "      <td>8.439392e+09</td>\n",
       "      <td>9.472677e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>8.938814e+09</td>\n",
       "      <td>9.230309e+09</td>\n",
       "      <td>8.474426e+09</td>\n",
       "      <td>9.284586e+09</td>\n",
       "      <td>9.230309e+09</td>\n",
       "      <td>8.474426e+09</td>\n",
       "      <td>9.284586e+09</td>\n",
       "      <td>9.017061e+09</td>\n",
       "      <td>9.449496e+09</td>\n",
       "      <td>8.380334e+09</td>\n",
       "      <td>9.425642e+09</td>\n",
       "      <td>9.449496e+09</td>\n",
       "      <td>8.380334e+09</td>\n",
       "      <td>9.425642e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>8.895774e+09</td>\n",
       "      <td>9.185707e+09</td>\n",
       "      <td>8.428962e+09</td>\n",
       "      <td>9.249526e+09</td>\n",
       "      <td>9.185707e+09</td>\n",
       "      <td>8.428962e+09</td>\n",
       "      <td>9.249526e+09</td>\n",
       "      <td>9.018204e+09</td>\n",
       "      <td>9.445394e+09</td>\n",
       "      <td>8.392188e+09</td>\n",
       "      <td>9.415851e+09</td>\n",
       "      <td>9.445394e+09</td>\n",
       "      <td>8.392188e+09</td>\n",
       "      <td>9.415851e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  output_x_loss  output_y_loss  output_z_loss  output_x_mae  \\\n",
       "0    1.559996e+12   1.469749e+12   2.041372e+12   7.777293e+11  1.469749e+12   \n",
       "1    1.393167e+12   1.298636e+12   1.846721e+12   6.751162e+11  1.298636e+12   \n",
       "2    1.231540e+12   1.131393e+12   1.660111e+12   5.746917e+11  1.131393e+12   \n",
       "3    1.074510e+12   9.694488e+11   1.478107e+12   4.774393e+11  9.694488e+11   \n",
       "4    9.253476e+11   8.203437e+11   1.296316e+12   3.934178e+11  8.203437e+11   \n",
       "..            ...            ...            ...            ...           ...   \n",
       "186  9.074450e+09   9.376925e+09   8.623008e+09   9.372369e+09  9.376925e+09   \n",
       "187  9.030651e+09   9.328793e+09   8.574688e+09   9.346294e+09  9.328793e+09   \n",
       "188  8.983248e+09   9.279091e+09   8.521242e+09   9.315575e+09  9.279091e+09   \n",
       "189  8.938814e+09   9.230309e+09   8.474426e+09   9.284586e+09  9.230309e+09   \n",
       "190  8.895774e+09   9.185707e+09   8.428962e+09   9.249526e+09  9.185707e+09   \n",
       "\n",
       "     output_y_mae  output_z_mae      val_loss  val_output_x_loss  \\\n",
       "0    2.041372e+12  7.777293e+11  1.468327e+12       1.379339e+12   \n",
       "1    1.846721e+12  6.751162e+11  1.307511e+12       1.213725e+12   \n",
       "2    1.660111e+12  5.746917e+11  1.150451e+12       1.051026e+12   \n",
       "3    1.478107e+12  4.774393e+11  9.992263e+11       8.980680e+11   \n",
       "4    1.296316e+12  3.934178e+11  8.572135e+11       7.578759e+11   \n",
       "..            ...           ...           ...                ...   \n",
       "186  8.623008e+09  9.372369e+09  9.170542e+09       9.634597e+09   \n",
       "187  8.574688e+09  9.346294e+09  9.144232e+09       9.559082e+09   \n",
       "188  8.521242e+09  9.315575e+09  9.073640e+09       9.508370e+09   \n",
       "189  8.474426e+09  9.284586e+09  9.017061e+09       9.449496e+09   \n",
       "190  8.428962e+09  9.249526e+09  9.018204e+09       9.445394e+09   \n",
       "\n",
       "     val_output_y_loss  val_output_z_loss  val_output_x_mae  val_output_y_mae  \\\n",
       "0         1.927812e+12       7.273367e+11      1.379339e+12      1.927812e+12   \n",
       "1         1.742844e+12       6.244142e+11      1.213725e+12      1.742844e+12   \n",
       "2         1.562037e+12       5.261292e+11      1.051026e+12      1.562037e+12   \n",
       "3         1.384068e+12       4.318567e+11      8.980680e+11      1.384068e+12   \n",
       "4         1.204685e+12       3.609454e+11      7.578759e+11      1.204685e+12   \n",
       "..                 ...                ...               ...               ...   \n",
       "186       8.516690e+09       9.550129e+09      9.634597e+09      8.516690e+09   \n",
       "187       8.537822e+09       9.527350e+09      9.559082e+09      8.537822e+09   \n",
       "188       8.439392e+09       9.472677e+09      9.508370e+09      8.439392e+09   \n",
       "189       8.380334e+09       9.425642e+09      9.449496e+09      8.380334e+09   \n",
       "190       8.392188e+09       9.415851e+09      9.445394e+09      8.392188e+09   \n",
       "\n",
       "     val_output_z_mae  \n",
       "0        7.273367e+11  \n",
       "1        6.244142e+11  \n",
       "2        5.261292e+11  \n",
       "3        4.318567e+11  \n",
       "4        3.609454e+11  \n",
       "..                ...  \n",
       "186      9.550129e+09  \n",
       "187      9.527350e+09  \n",
       "188      9.472677e+09  \n",
       "189      9.425642e+09  \n",
       "190      9.415851e+09  \n",
       "\n",
       "[191 rows x 14 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training history to dataframe for analysis and plotting.\n",
    "complete_history_data = pd.DataFrame(history.history)\n",
    "complete_history_data.head(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d273bb2f3104f20aff92619703a824f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29a8e194888>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history_data[[\"output_x_mae\", \"val_output_x_mae\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c714e29e996b4eb0874f69a8fb0283be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate MSEs.\n",
    "fig2, mse_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "mse_plots[0][0].plot(complete_history_data[[\"output_x_mae\", \"val_output_x_mae\"]])\n",
    "#mse_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "mse_plots[0][1].plot(complete_history_data[[\"output_y_mae\", \"val_output_y_mae\"]])\n",
    "#mse_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "mse_plots[1][0].plot(complete_history_data[[\"output_z_mae\", \"val_output_z_mae\"]])\n",
    "#mse_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd2f19bae9141f688bdc4dc5ba321e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate loss.\n",
    "fig, loss_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "loss_plots[0][0].plot(complete_history_data[[\"loss\", \"val_loss\"]])\n",
    "#loss_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[0][1].plot(complete_history_data[[\"output_x_loss\", \"val_output_x_loss\"]])\n",
    "#loss_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][0].plot(complete_history_data[[\"output_y_loss\", \"val_output_y_loss\"]])\n",
    "#loss_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][1].plot(complete_history_data[[\"output_z_loss\", \"val_output_z_loss\"]])\n",
    "#loss_plots[1][1].set_ylim(0,1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9001,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 1s 3ms/step - loss: 8524640256.0000 - output_x_loss: 8806619136.0000 - output_y_loss: 7979345408.0000 - output_z_loss: 9051280384.0000 - output_x_mae: 8806619136.0000 - output_y_mae: 7979345408.0000 - output_z_mae: 9051280384.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8524640256.0,\n",
       " 8806619136.0,\n",
       " 7979345408.0,\n",
       " 9051280384.0,\n",
       " 8806619136.0,\n",
       " 7979345408.0,\n",
       " 9051280384.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test],[y_test_x, y_test_y, y_test_z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values and Inspect Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, z_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_x</th>\n",
       "      <th>model_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>model_y</th>\n",
       "      <th>pred_z</th>\n",
       "      <th>model_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.564038e+12</td>\n",
       "      <td>2.552590e+12</td>\n",
       "      <td>3.457142e+11</td>\n",
       "      <td>3.418745e+11</td>\n",
       "      <td>1.673115e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.469287e+12</td>\n",
       "      <td>1.461301e+12</td>\n",
       "      <td>3.183524e+12</td>\n",
       "      <td>3.185488e+12</td>\n",
       "      <td>7.497318e+07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.374607e+12</td>\n",
       "      <td>2.381777e+12</td>\n",
       "      <td>1.734204e+12</td>\n",
       "      <td>1.767490e+12</td>\n",
       "      <td>1.935475e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.770364e+12</td>\n",
       "      <td>-1.754616e+12</td>\n",
       "      <td>-6.680354e+11</td>\n",
       "      <td>-6.620699e+11</td>\n",
       "      <td>1.175600e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.681803e+12</td>\n",
       "      <td>1.681149e+12</td>\n",
       "      <td>3.255692e+12</td>\n",
       "      <td>3.251787e+12</td>\n",
       "      <td>2.464760e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.411108e+12</td>\n",
       "      <td>2.406414e+12</td>\n",
       "      <td>-9.216003e+10</td>\n",
       "      <td>-9.244054e+10</td>\n",
       "      <td>-9.481830e+08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.469840e+12</td>\n",
       "      <td>2.442890e+12</td>\n",
       "      <td>5.787867e+11</td>\n",
       "      <td>5.715344e+11</td>\n",
       "      <td>-8.357970e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.061764e+12</td>\n",
       "      <td>2.061422e+12</td>\n",
       "      <td>-4.548241e+11</td>\n",
       "      <td>-4.509403e+11</td>\n",
       "      <td>-1.332635e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.053075e+12</td>\n",
       "      <td>-1.047319e+12</td>\n",
       "      <td>-1.305085e+12</td>\n",
       "      <td>-1.285923e+12</td>\n",
       "      <td>5.789237e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.108726e+12</td>\n",
       "      <td>-2.113341e+12</td>\n",
       "      <td>1.525562e+12</td>\n",
       "      <td>1.524463e+12</td>\n",
       "      <td>-8.387052e+09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_x       model_x        pred_y       model_y        pred_z  \\\n",
       "0  2.564038e+12  2.552590e+12  3.457142e+11  3.418745e+11  1.673115e+10   \n",
       "1  1.469287e+12  1.461301e+12  3.183524e+12  3.185488e+12  7.497318e+07   \n",
       "2  2.374607e+12  2.381777e+12  1.734204e+12  1.767490e+12  1.935475e+10   \n",
       "3 -1.770364e+12 -1.754616e+12 -6.680354e+11 -6.620699e+11  1.175600e+10   \n",
       "4  1.681803e+12  1.681149e+12  3.255692e+12  3.251787e+12  2.464760e+09   \n",
       "5  2.411108e+12  2.406414e+12 -9.216003e+10 -9.244054e+10 -9.481830e+08   \n",
       "6  2.469840e+12  2.442890e+12  5.787867e+11  5.715344e+11 -8.357970e+09   \n",
       "7  2.061764e+12  2.061422e+12 -4.548241e+11 -4.509403e+11 -1.332635e+10   \n",
       "8 -1.053075e+12 -1.047319e+12 -1.305085e+12 -1.285923e+12  5.789237e+09   \n",
       "9 -2.108726e+12 -2.113341e+12  1.525562e+12  1.524463e+12 -8.387052e+09   \n",
       "\n",
       "   model_z  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      0.0  \n",
       "8      0.0  \n",
       "9      0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison = pd.DataFrame(data=np.concatenate((x_pred, y_test_x.reshape(-1,1), y_pred, y_test_y.reshape(-1,1), z_pred, y_test_z.reshape(-1,1)), axis=1),\n",
    "                                    columns=['pred_x', 'model_x', 'pred_y', 'model_y', 'pred_z', 'model_z'])\n",
    "pred_model_comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b3a2c52f384f60ac37e1fe73fa0162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29a946115c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_x\", \"model_x\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2636ce32591d4a99a881d01b21e4bf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2997f672d08>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_y\", \"model_y\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6062bf3b5d046b8a42ea3ac8c8d3407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29a9462fc08>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_z\", \"model_z\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('NN-Deploy-V1.01_2-layer_relu_he-normal_msle_Adam_lr-1e-6_bs-128_epoch-3500.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try loading the model and making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = tf.keras.models.load_model('NN-Deploy-V1.01_2-layer_selu_lecun-normal_mae_Adam_lr-1e-6_bs-128_epoch-3500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_pred2, y_pred2, z_pred2 = model2.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some random testing code.\n",
    "\n",
    "#data_row = complete_motion_df.iloc[445]\n",
    "#data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pos = data_row.iloc[-3:].values.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
