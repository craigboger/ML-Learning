{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet Simulator with Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Craig Boger\n",
    "06/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes the model prototyping and learning of v1.01 and tries to expand upon it in 2 key areas.\n",
    "\n",
    "1) Perform data normalization and processing in TF data libraries.\n",
    "2) Take predictions in normalized form and output them in their unormalized form for use in simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straight Up Just Stealing Someone's Code and Trying to Run It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to benrules2: https://gist.github.com/benrules2/220d56ea6fe9a85a4d762128b11adfba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e862f46bfeff4c95a6d80e3fa8b7e4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class point:\n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class body:\n",
    "    def __init__(self, location, mass, velocity, name = \"\"):\n",
    "        self.location = location\n",
    "        self.mass = mass\n",
    "        self.velocity = velocity\n",
    "        self.name = name\n",
    "\n",
    "def calculate_single_body_acceleration(bodies, body_index):\n",
    "    G_const = 6.67408e-11 #m3 kg-1 s-2\n",
    "    acceleration = point(0,0,0)\n",
    "    target_body = bodies[body_index]\n",
    "    for index, external_body in enumerate(bodies):\n",
    "        if index != body_index:\n",
    "            r = (target_body.location.x - external_body.location.x)**2 + (target_body.location.y - external_body.location.y)**2 + (target_body.location.z - external_body.location.z)**2\n",
    "            r = math.sqrt(r)\n",
    "            tmp = G_const * external_body.mass / r**3\n",
    "            acceleration.x += tmp * (external_body.location.x - target_body.location.x)\n",
    "            acceleration.y += tmp * (external_body.location.y - target_body.location.y)\n",
    "            acceleration.z += tmp * (external_body.location.z - target_body.location.z)\n",
    "\n",
    "    return acceleration\n",
    "\n",
    "def compute_velocity(bodies, time_step = 1):\n",
    "    for body_index, target_body in enumerate(bodies):\n",
    "        acceleration = calculate_single_body_acceleration(bodies, body_index)\n",
    "\n",
    "        target_body.velocity.x += acceleration.x * time_step\n",
    "        target_body.velocity.y += acceleration.y * time_step\n",
    "        target_body.velocity.z += acceleration.z * time_step \n",
    "\n",
    "\n",
    "def update_location(bodies, time_step = 1):\n",
    "    for target_body in bodies:\n",
    "        target_body.location.x += target_body.velocity.x * time_step\n",
    "        target_body.location.y += target_body.velocity.y * time_step\n",
    "        target_body.location.z += target_body.velocity.z * time_step\n",
    "\n",
    "def compute_gravity_step(bodies, time_step = 1):\n",
    "    compute_velocity(bodies, time_step = time_step)\n",
    "    update_location(bodies, time_step = time_step)\n",
    "\n",
    "def plot_output(bodies, outfile = None):\n",
    "    fig = plot.figure()\n",
    "    colours = ['r','b','g','y','m','c']\n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "    max_range = 0\n",
    "    for current_body in bodies: \n",
    "        max_dim = max(max(current_body[\"x\"]),max(current_body[\"y\"]),max(current_body[\"z\"]))\n",
    "        if max_dim > max_range:\n",
    "            max_range = max_dim\n",
    "        ax.plot(current_body[\"x\"], current_body[\"y\"], current_body[\"z\"], c = random.choice(colours), label = current_body[\"name\"])        \n",
    "    \n",
    "    ax.set_xlim([-max_range,max_range])    \n",
    "    ax.set_ylim([-max_range,max_range])\n",
    "    ax.set_zlim([-max_range,max_range])\n",
    "    ax.legend()        \n",
    "\n",
    "    if outfile:\n",
    "        plot.savefig(outfile)\n",
    "    else:\n",
    "        plot.show()\n",
    "\n",
    "def run_simulation(bodies, names = None, time_step = 1, number_of_steps = 10000, report_freq = 100):\n",
    "\n",
    "    #create output container for each body\n",
    "    body_locations_hist = []\n",
    "    for current_body in bodies:\n",
    "        body_locations_hist.append({\"x\":[], \"y\":[], \"z\":[], \"name\":current_body.name})\n",
    "        \n",
    "    for i in range(1,number_of_steps):\n",
    "        compute_gravity_step(bodies, time_step = 1000)            \n",
    "        \n",
    "        if i % report_freq == 0:\n",
    "            for index, body_location in enumerate(body_locations_hist):\n",
    "                body_location[\"x\"].append(bodies[index].location.x)\n",
    "                body_location[\"y\"].append(bodies[index].location.y)           \n",
    "                body_location[\"z\"].append(bodies[index].location.z)       \n",
    "\n",
    "    return body_locations_hist        \n",
    "            \n",
    "#planet data (location (m), mass (kg), velocity (m/s)\n",
    "sun = {\"location\":point(0,0,0), \"mass\":2e30, \"velocity\":point(0,0,0)}\n",
    "mercury = {\"location\":point(0,5.7e10,0), \"mass\":3.285e23, \"velocity\":point(47000,0,0)}\n",
    "venus = {\"location\":point(0,1.1e11,0), \"mass\":4.8e24, \"velocity\":point(35000,0,0)}\n",
    "earth = {\"location\":point(0,1.5e11,0), \"mass\":6e24, \"velocity\":point(30000,0,0)}\n",
    "mars = {\"location\":point(0,2.2e11,0), \"mass\":2.4e24, \"velocity\":point(24000,0,0)}\n",
    "jupiter = {\"location\":point(0,7.7e11,0), \"mass\":1e28, \"velocity\":point(13000,0,0)}\n",
    "saturn = {\"location\":point(0,1.4e12,0), \"mass\":5.7e26, \"velocity\":point(9000,0,0)}\n",
    "uranus = {\"location\":point(0,2.8e12,0), \"mass\":8.7e25, \"velocity\":point(6835,0,0)}\n",
    "neptune = {\"location\":point(0,4.5e12,0), \"mass\":1e26, \"velocity\":point(5477,0,0)}\n",
    "pluto = {\"location\":point(0,3.7e12,0), \"mass\":1.3e22, \"velocity\":point(4748,0,0)}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #build list of planets in the simulation, or create your own\n",
    "    bodies = [\n",
    "        body( location = sun[\"location\"], mass = sun[\"mass\"], velocity = sun[\"velocity\"], name = \"sun\"),\n",
    "        body( location = mercury[\"location\"], mass = mercury[\"mass\"], velocity = mercury[\"velocity\"], name = \"mercury\"),\n",
    "        body( location = venus[\"location\"], mass = venus[\"mass\"], velocity = venus[\"velocity\"], name = \"venus\"),\n",
    "        body( location = earth[\"location\"], mass = earth[\"mass\"], velocity = earth[\"velocity\"], name = \"earth\"),\n",
    "        body( location = mars[\"location\"], mass = mars[\"mass\"], velocity = mars[\"velocity\"], name = \"mars\"),\n",
    "        body( location = jupiter[\"location\"], mass = jupiter[\"mass\"], velocity = jupiter[\"velocity\"], name = \"jupiter\"),\n",
    "        body( location = saturn[\"location\"], mass = saturn[\"mass\"], velocity = saturn[\"velocity\"], name = \"saturn\"),\n",
    "        body( location = uranus[\"location\"], mass = uranus[\"mass\"], velocity = uranus[\"velocity\"], name = \"uranus\"),\n",
    "        body( location = neptune[\"location\"], mass = neptune[\"mass\"], velocity = neptune[\"velocity\"], name = \"neptune\"),\n",
    "        body( location = pluto[\"location\"], mass = pluto[\"mass\"], velocity = pluto[\"velocity\"], name = \"pluto\")\n",
    "        ]\n",
    "    \n",
    "    # Original defaults of simulation\n",
    "    # motions = run_simulation(bodies, time_step = 100, number_of_steps = 80000, report_freq = 1000)\n",
    "    # Try messing with report frequency to get more data.\n",
    "    motions = run_simulation(bodies, time_step = 10, number_of_steps = 3000000, report_freq = 100)\n",
    "    plot_output(motions, outfile = 'orbits.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take motions data from the above simulation and convert it to a Pandas dataframe.  The \"motions\" output is a list of python dictionaries that can be converted into a dataframe and then manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.17261536148749, 49.37902931004262, 166.6238...</td>\n",
       "      <td>[6062.379510449177, 24129.08432936523, 54198.9...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4694355206.032213, 9354859805.615133, 1394777...</td>\n",
       "      <td>[56792631341.03519, 56175843290.39122, 5515329...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mercury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3499415066.4596167, 6995320910.098446, 104842...</td>\n",
       "      <td>[109944304443.26683, 109778376891.15071, 10950...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2999802268.7561436, 5998418130.146453, 899466...</td>\n",
       "      <td>[149970049806.4969, 149880804295.7356, 1497322...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2399949856.0031266, 4799598821.678605, 719864...</td>\n",
       "      <td>[219986083536.2445, 219944611164.44067, 219875...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1299999366.479779, 2599994931.4595885, 389998...</td>\n",
       "      <td>[769998863558.2162, 769995476739.6332, 7699898...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[899999928.8199571, 1799999430.5168397, 269999...</td>\n",
       "      <td>[1399999647604.3037, 1399998597395.4744, 13999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>saturn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[683499993.1607178, 1366999945.2816358, 205049...</td>\n",
       "      <td>[2799999913115.264, 2799999654181.5522, 279999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>uranus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[547699998.6801858, 1095399989.4406931, 164309...</td>\n",
       "      <td>[4499999966439.355, 4499999866422.006, 4499999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[474799997.95801955, 949599983.6629324, 142439...</td>\n",
       "      <td>[3699999950348.1753, 3699999802375.9053, 36999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>pluto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  [6.17261536148749, 49.37902931004262, 166.6238...   \n",
       "1  [4694355206.032213, 9354859805.615133, 1394777...   \n",
       "2  [3499415066.4596167, 6995320910.098446, 104842...   \n",
       "3  [2999802268.7561436, 5998418130.146453, 899466...   \n",
       "4  [2399949856.0031266, 4799598821.678605, 719864...   \n",
       "5  [1299999366.479779, 2599994931.4595885, 389998...   \n",
       "6  [899999928.8199571, 1799999430.5168397, 269999...   \n",
       "7  [683499993.1607178, 1366999945.2816358, 205049...   \n",
       "8  [547699998.6801858, 1095399989.4406931, 164309...   \n",
       "9  [474799997.95801955, 949599983.6629324, 142439...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [6062.379510449177, 24129.08432936523, 54198.9...   \n",
       "1  [56792631341.03519, 56175843290.39122, 5515329...   \n",
       "2  [109944304443.26683, 109778376891.15071, 10950...   \n",
       "3  [149970049806.4969, 149880804295.7356, 1497322...   \n",
       "4  [219986083536.2445, 219944611164.44067, 219875...   \n",
       "5  [769998863558.2162, 769995476739.6332, 7699898...   \n",
       "6  [1399999647604.3037, 1399998597395.4744, 13999...   \n",
       "7  [2799999913115.264, 2799999654181.5522, 279999...   \n",
       "8  [4499999966439.355, 4499999866422.006, 4499999...   \n",
       "9  [3699999950348.1753, 3699999802375.9053, 36999...   \n",
       "\n",
       "                                                   z     name  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      sun  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  mercury  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    venus  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    earth  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     mars  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  jupiter  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   saturn  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   uranus  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    pluto  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "motions_df = pd.DataFrame(motions)\n",
    "motions_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to separate out each row of list or dataframe into its own dataframe.\n",
    "# Will later put these dataframes back together into 1 large dataframe.\n",
    "\n",
    "motions_df_list = []\n",
    "for body in motions:\n",
    "    motions_df_list.append(pd.DataFrame(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>1.499700e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>1.498808e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>1.497323e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>1.495246e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>1.492578e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>3.365349e+11</td>\n",
       "      <td>-6.931279e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>3.350566e+11</td>\n",
       "      <td>-7.186066e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>3.335293e+11</td>\n",
       "      <td>-7.437856e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>3.319538e+11</td>\n",
       "      <td>-7.686557e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>3.303305e+11</td>\n",
       "      <td>-7.932077e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y    z   name\n",
       "0      2.999802e+09  1.499700e+11  0.0  earth\n",
       "1      5.998418e+09  1.498808e+11  0.0  earth\n",
       "2      8.994662e+09  1.497323e+11  0.0  earth\n",
       "3      1.198735e+10  1.495246e+11  0.0  earth\n",
       "4      1.497529e+10  1.492578e+11  0.0  earth\n",
       "...             ...           ...  ...    ...\n",
       "29994  3.365349e+11 -6.931279e+10  0.0  earth\n",
       "29995  3.350566e+11 -7.186066e+10  0.0  earth\n",
       "29996  3.335293e+11 -7.437856e+10  0.0  earth\n",
       "29997  3.319538e+11 -7.686557e+10  0.0  earth\n",
       "29998  3.303305e+11 -7.932077e+10  0.0  earth\n",
       "\n",
       "[29999 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions_df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.172615e+00</td>\n",
       "      <td>6.062380e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.694355e+09</td>\n",
       "      <td>5.679263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>1.099443e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.835000e+08</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.477000e+08</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.937903e+01</td>\n",
       "      <td>2.412908e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.354860e+09</td>\n",
       "      <td>5.617584e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>1.097784e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.367000e+09</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.095400e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.496000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666238e+02</td>\n",
       "      <td>5.419895e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394778e+10</td>\n",
       "      <td>5.515330e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>1.095024e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.050500e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643100e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424400e+09</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948516e+02</td>\n",
       "      <td>9.627002e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843961e+10</td>\n",
       "      <td>5.373113e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>1.091166e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.734000e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190800e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.899200e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.709150e+02</td>\n",
       "      <td>1.503396e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279721e+10</td>\n",
       "      <td>5.191794e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>1.086215e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.417499e+09</td>\n",
       "      <td>2.799998e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738500e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374000e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.138930e+06</td>\n",
       "      <td>5.399689e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.050288e+10</td>\n",
       "      <td>-4.133027e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578892e+10</td>\n",
       "      <td>-1.109137e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441446e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.560995e+10</td>\n",
       "      <td>2.799207e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.257803e+10</td>\n",
       "      <td>4.499694e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557899e+10</td>\n",
       "      <td>3.699547e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.259370e+06</td>\n",
       "      <td>5.511102e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606635e+10</td>\n",
       "      <td>-4.407848e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238219e+10</td>\n",
       "      <td>-1.113485e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431961e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.629326e+10</td>\n",
       "      <td>2.799191e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.312570e+10</td>\n",
       "      <td>4.499687e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.605374e+10</td>\n",
       "      <td>3.699537e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.381922e+06</td>\n",
       "      <td>5.623611e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137176e+10</td>\n",
       "      <td>-4.638955e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.963734e+09</td>\n",
       "      <td>-1.116778e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421936e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.697656e+10</td>\n",
       "      <td>2.799174e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.367336e+10</td>\n",
       "      <td>4.499681e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.652848e+10</td>\n",
       "      <td>3.699528e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.506591e+06</td>\n",
       "      <td>5.737214e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646399e+10</td>\n",
       "      <td>-4.823708e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536787e+09</td>\n",
       "      <td>-1.119012e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411373e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.765986e+10</td>\n",
       "      <td>2.799157e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.422102e+10</td>\n",
       "      <td>4.499674e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700322e+10</td>\n",
       "      <td>3.699518e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.633378e+06</td>\n",
       "      <td>5.851910e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139102e+10</td>\n",
       "      <td>-4.959972e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104599e+09</td>\n",
       "      <td>-1.120185e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400277e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.834316e+10</td>\n",
       "      <td>2.799140e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.476868e+10</td>\n",
       "      <td>4.499668e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747796e+10</td>\n",
       "      <td>3.699508e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0   6.172615e+00  6.062380e+03    0.0  4.694355e+09  5.679263e+10        0.0   \n",
       "1   4.937903e+01  2.412908e+04    0.0  9.354860e+09  5.617584e+10        0.0   \n",
       "2   1.666238e+02  5.419895e+04    0.0  1.394778e+10  5.515330e+10        0.0   \n",
       "3   3.948516e+02  9.627002e+04    0.0  1.843961e+10  5.373113e+10        0.0   \n",
       "4   7.709150e+02  1.503396e+05    0.0  2.279721e+10  5.191794e+10        0.0   \n",
       "..           ...           ...    ...           ...           ...        ...   \n",
       "95  4.138930e+06  5.399689e+07    0.0  3.050288e+10 -4.133027e+10        0.0   \n",
       "96  4.259370e+06  5.511102e+07    0.0  2.606635e+10 -4.407848e+10        0.0   \n",
       "97  4.381922e+06  5.623611e+07    0.0  2.137176e+10 -4.638955e+10        0.0   \n",
       "98  4.506591e+06  5.737214e+07    0.0  1.646399e+10 -4.823708e+10        0.0   \n",
       "99  4.633378e+06  5.851910e+07    0.0  1.139102e+10 -4.959972e+10        0.0   \n",
       "\n",
       "         venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0   3.499415e+09  1.099443e+11      0.0  2.999802e+09  ...       0.0   \n",
       "1   6.995321e+09  1.097784e+11      0.0  5.998418e+09  ...       0.0   \n",
       "2   1.048421e+10  1.095024e+11      0.0  8.994662e+09  ...       0.0   \n",
       "3   1.396259e+10  1.091166e+11      0.0  1.198735e+10  ...       0.0   \n",
       "4   1.742697e+10  1.086215e+11      0.0  1.497529e+10  ...       0.0   \n",
       "..           ...           ...      ...           ...  ...       ...   \n",
       "95  1.578892e+10 -1.109137e+11      0.0  1.441446e+11  ...       0.0   \n",
       "96  1.238219e+10 -1.113485e+11      0.0  1.431961e+11  ...       0.0   \n",
       "97  8.963734e+09 -1.116778e+11      0.0  1.421936e+11  ...       0.0   \n",
       "98  5.536787e+09 -1.119012e+11      0.0  1.411373e+11  ...       0.0   \n",
       "99  2.104599e+09 -1.120185e+11      0.0  1.400277e+11  ...       0.0   \n",
       "\n",
       "        uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0   6.835000e+08  2.800000e+12       0.0  5.477000e+08  4.500000e+12   \n",
       "1   1.367000e+09  2.800000e+12       0.0  1.095400e+09  4.500000e+12   \n",
       "2   2.050500e+09  2.799999e+12       0.0  1.643100e+09  4.500000e+12   \n",
       "3   2.734000e+09  2.799999e+12       0.0  2.190800e+09  4.499999e+12   \n",
       "4   3.417499e+09  2.799998e+12       0.0  2.738500e+09  4.499999e+12   \n",
       "..           ...           ...       ...           ...           ...   \n",
       "95  6.560995e+10  2.799207e+12       0.0  5.257803e+10  4.499694e+12   \n",
       "96  6.629326e+10  2.799191e+12       0.0  5.312570e+10  4.499687e+12   \n",
       "97  6.697656e+10  2.799174e+12       0.0  5.367336e+10  4.499681e+12   \n",
       "98  6.765986e+10  2.799157e+12       0.0  5.422102e+10  4.499674e+12   \n",
       "99  6.834316e+10  2.799140e+12       0.0  5.476868e+10  4.499668e+12   \n",
       "\n",
       "    neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0         0.0  4.748000e+08  3.700000e+12      0.0  \n",
       "1         0.0  9.496000e+08  3.700000e+12      0.0  \n",
       "2         0.0  1.424400e+09  3.700000e+12      0.0  \n",
       "3         0.0  1.899200e+09  3.699999e+12      0.0  \n",
       "4         0.0  2.374000e+09  3.699999e+12      0.0  \n",
       "..        ...           ...           ...      ...  \n",
       "95        0.0  4.557899e+10  3.699547e+12      0.0  \n",
       "96        0.0  4.605374e+10  3.699537e+12      0.0  \n",
       "97        0.0  4.652848e+10  3.699528e+12      0.0  \n",
       "98        0.0  4.700322e+10  3.699518e+12      0.0  \n",
       "99        0.0  4.747796e+10  3.699508e+12      0.0  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the dataframes into a single, large dataframe.\n",
    "# Can later choose a planet to be the target we train to predict.\n",
    "complete_motion_df = None\n",
    "\n",
    "for body in motions_df_list:\n",
    "    # Append name of body to each column and remove the name column\n",
    "    body_name = body.loc[0, \"name\"]\n",
    "    body.columns = [body_name + \"_x\",\n",
    "                    body_name + \"_y\",\n",
    "                    body_name + \"_z\",\n",
    "                    \"name\"]\n",
    "    # Add current body to the complete dataframe.\n",
    "    complete_motion_df = pd.concat([complete_motion_df, body.iloc[:, 0:3]], axis=1)\n",
    "\n",
    "complete_motion_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the simulation data for later loading and use\n",
    "complete_motion_df.to_csv(\"raw_model_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single dataframe with all bodies and all positions with each time step as the index of our rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Create a tf.data Dataset from the Constructed, Unrandomized, Unnormalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "# Probably not needed since not using regressor or doing any feature engineering.\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler  # Scaler for normalizing data.\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaler for normalizing data.\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "# Recommended to enable eager execution when developing model.\n",
    "# Processing data: https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Use sklearn for data processing\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here with Trying to Process Data with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the difficulties is using a mixture of numpy, pandas, and sklearn to take input data (influx), arrange it, split it out, normalize it, and then train a model.  With tf.data input pipelines (similar to sklearn pipelines), we can create data and machine learning pipelines for training or inference.  This allows us to encapsulate not only the machine learning into a Tensorflow model, but the necessary transformations to that data.  That allows us to deploy the model and data transformations as a single object to the later simulator. \\\n",
    "The input pipeline let's us take raw data from any source, like csv, numpy arrays, distributed file system, etc, and convert it into the tensors we will use to train our model.\n",
    "\n",
    "Intro to tensors:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "Good source on how data loading and preprocessing is usually done: https://stackoverflow.com/questions/55321905/want-to-split-train-and-test-data-gotten-from-a-csv-with-tensorflow\n",
    "1) Load the data into memory with numpy\n",
    "2) Split the data into train and validation\n",
    "\n",
    "Since we are not using a massive dataset, then we might be able to use tf.split to split an exsting tf dataset into train and validation.\n",
    "https://docs.w3cub.com/tensorflow~python/tf/split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Numpy Version of the Data as a Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of the complete dataframe and shuffle it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.920244e+10</td>\n",
       "      <td>5.686479e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.032553e+10</td>\n",
       "      <td>6.151676e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.667728e+10</td>\n",
       "      <td>7.506890e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.535941e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538430e+12</td>\n",
       "      <td>2.322889e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.289335e+12</td>\n",
       "      <td>4.312011e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104673e+12</td>\n",
       "      <td>3.419477e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.902718e+11</td>\n",
       "      <td>1.694320e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.440820e+11</td>\n",
       "      <td>-2.299948e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.826087e+11</td>\n",
       "      <td>1.114354e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.190438e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.418307e+12</td>\n",
       "      <td>1.596072e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.181037e+12</td>\n",
       "      <td>-4.098346e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.003625e+12</td>\n",
       "      <td>2.806892e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.758850e+10</td>\n",
       "      <td>1.055355e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.353789e+10</td>\n",
       "      <td>-4.796439e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.335649e+10</td>\n",
       "      <td>-5.100479e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.716240e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.561260e+12</td>\n",
       "      <td>-7.809737e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.529660e+12</td>\n",
       "      <td>2.797116e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.479084e+12</td>\n",
       "      <td>9.940884e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.899024e+11</td>\n",
       "      <td>2.437582e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.457652e+11</td>\n",
       "      <td>-2.542602e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.931253e+11</td>\n",
       "      <td>-3.944357e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.062093e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.364006e+12</td>\n",
       "      <td>1.674192e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.108539e+12</td>\n",
       "      <td>-4.121624e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.955010e+12</td>\n",
       "      <td>2.863796e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.038638e+10</td>\n",
       "      <td>7.969911e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069335e+11</td>\n",
       "      <td>3.812663e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068480e+11</td>\n",
       "      <td>1.077662e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.527509e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.019313e+12</td>\n",
       "      <td>-1.688765e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.972886e+12</td>\n",
       "      <td>2.120287e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.236657e+12</td>\n",
       "      <td>-1.218232e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.243944e+08</td>\n",
       "      <td>1.810654e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.413073e+10</td>\n",
       "      <td>-4.304647e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.413986e+10</td>\n",
       "      <td>9.098564e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.384013e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.977988e+11</td>\n",
       "      <td>2.770716e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.195935e+11</td>\n",
       "      <td>4.488673e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.768748e+11</td>\n",
       "      <td>3.683235e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.683157e+08</td>\n",
       "      <td>1.891122e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.183452e+10</td>\n",
       "      <td>1.705085e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.941208e+10</td>\n",
       "      <td>1.100695e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.166129e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.072671e+11</td>\n",
       "      <td>2.769298e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.272419e+11</td>\n",
       "      <td>4.488124e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.834918e+11</td>\n",
       "      <td>3.682421e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.685464e+10</td>\n",
       "      <td>5.877291e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.132679e+11</td>\n",
       "      <td>3.626292e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.289651e+10</td>\n",
       "      <td>2.194104e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.127523e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.730946e+12</td>\n",
       "      <td>-1.960661e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.104721e+12</td>\n",
       "      <td>1.851106e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.004408e+12</td>\n",
       "      <td>-5.381296e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.875092e+11</td>\n",
       "      <td>5.227618e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.890685e+11</td>\n",
       "      <td>-4.563363e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.974584e+11</td>\n",
       "      <td>1.943418e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.398200e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.181801e+12</td>\n",
       "      <td>1.900120e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.844063e+11</td>\n",
       "      <td>-4.184815e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.799287e+12</td>\n",
       "      <td>3.026069e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.795748e+10</td>\n",
       "      <td>1.903291e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.227317e+10</td>\n",
       "      <td>5.308105e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.894699e+10</td>\n",
       "      <td>-8.779070e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.080279e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.517418e+12</td>\n",
       "      <td>-8.972011e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.587912e+12</td>\n",
       "      <td>2.722026e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.474939e+12</td>\n",
       "      <td>8.687646e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0  1.920244e+10  5.686479e+09    0.0  3.032553e+10  6.151676e+10        0.0   \n",
       "1  1.902718e+11  1.694320e+09    0.0  1.440820e+11 -2.299948e+10        0.0   \n",
       "2  4.758850e+10  1.055355e+09    0.0  3.353789e+10 -4.796439e+10        0.0   \n",
       "3  1.899024e+11  2.437582e+09    0.0  1.457652e+11 -2.542602e+10        0.0   \n",
       "4  6.038638e+10  7.969911e+09    0.0  1.069335e+11  3.812663e+10        0.0   \n",
       "5  6.243944e+08  1.810654e+09    0.0 -2.413073e+10 -4.304647e+10        0.0   \n",
       "6  6.683157e+08  1.891122e+09    0.0 -5.183452e+10  1.705085e+10        0.0   \n",
       "7  6.685464e+10  5.877291e+09    0.0  1.132679e+11  3.626292e+10        0.0   \n",
       "8  1.875092e+11  5.227618e+09    0.0  1.890685e+11 -4.563363e+10        0.0   \n",
       "9  4.795748e+10  1.903291e+09    0.0  7.227317e+10  5.308105e+10        0.0   \n",
       "\n",
       "        venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0 -6.667728e+10  7.506890e+10      0.0  8.535941e+10  ...       0.0   \n",
       "1  1.826087e+11  1.114354e+11      0.0  4.190438e+10  ...       0.0   \n",
       "2 -6.335649e+10 -5.100479e+09      0.0  5.716240e+10  ...       0.0   \n",
       "3  2.931253e+11 -3.944357e+10      0.0  3.062093e+11  ...       0.0   \n",
       "4  1.068480e+11  1.077662e+11      0.0 -2.527509e+10  ...       0.0   \n",
       "5 -6.413986e+10  9.098564e+10      0.0 -1.384013e+11  ...       0.0   \n",
       "6 -1.941208e+10  1.100695e+11      0.0 -1.166129e+11  ...       0.0   \n",
       "7 -4.289651e+10  2.194104e+10      0.0  2.127523e+11  ...       0.0   \n",
       "8  2.974584e+11  1.943418e+10      0.0  2.398200e+11  ...       0.0   \n",
       "9 -1.894699e+10 -8.779070e+10      0.0  3.080279e+09  ...       0.0   \n",
       "\n",
       "       uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0  1.538430e+12  2.322889e+12       0.0  1.289335e+12  4.312011e+12   \n",
       "1  2.418307e+12  1.596072e+12       0.0 -1.181037e+12 -4.098346e+12   \n",
       "2  2.561260e+12 -7.809737e+11       0.0  3.529660e+12  2.797116e+12   \n",
       "3  2.364006e+12  1.674192e+12       0.0 -1.108539e+12 -4.121624e+12   \n",
       "4  2.019313e+12 -1.688765e+12       0.0  3.972886e+12  2.120287e+12   \n",
       "5  3.977988e+11  2.770716e+12       0.0  3.195935e+11  4.488673e+12   \n",
       "6  4.072671e+11  2.769298e+12       0.0  3.272419e+11  4.488124e+12   \n",
       "7  1.730946e+12 -1.960661e+12       0.0  4.104721e+12  1.851106e+12   \n",
       "8  2.181801e+12  1.900120e+12       0.0 -8.844063e+11 -4.184815e+12   \n",
       "9  2.517418e+12 -8.972011e+11       0.0  3.587912e+12  2.722026e+12   \n",
       "\n",
       "   neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0        0.0  1.104673e+12  3.419477e+12      0.0  \n",
       "1        0.0  2.003625e+12  2.806892e+12      0.0  \n",
       "2        0.0  2.479084e+12  9.940884e+11      0.0  \n",
       "3        0.0  1.955010e+12  2.863796e+12      0.0  \n",
       "4        0.0  2.236657e+12 -1.218232e+11      0.0  \n",
       "5        0.0  2.768748e+11  3.683235e+12      0.0  \n",
       "6        0.0  2.834918e+11  3.682421e+12      0.0  \n",
       "7        0.0  2.004408e+12 -5.381296e+11      0.0  \n",
       "8        0.0  1.799287e+12  3.026069e+12      0.0  \n",
       "9        0.0  2.474939e+12  8.687646e+11      0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy1_complete_motion_df = complete_motion_df.copy()\n",
    "copy1_complete_motion_df = copy1_complete_motion_df.sample(frac=1).reset_index(drop=True)\n",
    "copy1_complete_motion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split out the target x,y,z columns as the last 3 columns in the dataframe.  Skipping scaling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.104673e+12</td>\n",
       "      <td>3.419477e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.003625e+12</td>\n",
       "      <td>2.806892e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.479084e+12</td>\n",
       "      <td>9.940884e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.955010e+12</td>\n",
       "      <td>2.863796e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.236657e+12</td>\n",
       "      <td>-1.218232e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pluto_x       pluto_y  pluto_z\n",
       "0  1.104673e+12  3.419477e+12      0.0\n",
       "1  2.003625e+12  2.806892e+12      0.0\n",
       "2  2.479084e+12  9.940884e+11      0.0\n",
       "3  1.955010e+12  2.863796e+12      0.0\n",
       "4  2.236657e+12 -1.218232e+11      0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = copy1_complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "copy1_complete_motion_df.drop(copy1_complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = target.iloc[:,0]\n",
    "target_y = target.iloc[:,1]\n",
    "target_z = target.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all pandas dataframes to numpy arrays so they are compatible with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_motion_np = copy1_complete_motion_df.to_numpy()\n",
    "target_np = target.to_numpy()\n",
    "target_x_np = target_x.to_numpy()\n",
    "target_y_np = target_y.to_numpy()\n",
    "target_z_np = target_z.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "X_train, X_valid, X_test = complete_motion_np[:train_size], complete_motion_np[train_size:(train_size+val_size)], complete_motion_np[(train_size + val_size):]\n",
    "y_train_x, y_valid_x, y_test_x = target_x_np[:train_size], target_x_np[train_size:(train_size+val_size)], target_x_np[(train_size + val_size):]\n",
    "y_train_y, y_valid_y, y_test_y = target_y_np[:train_size], target_y_np[train_size:(train_size+val_size)], target_y_np[(train_size + val_size):]\n",
    "y_train_z, y_valid_z, y_test_z = target_z_np[:train_size], target_z_np[train_size:(train_size+val_size)], target_z_np[(train_size + val_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf dataset from slices (numpy array, pandas dataframe, etc). \n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "Probably one of the better articles on using tensorflow datasets: \\\n",
    "https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "\n",
    "TF documentation on tf.data: Building Tensorflow Input Pipelines: \\\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "Method for splitting tensorflow datasets into train, validation, and test: \\\n",
    "https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets/51126863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into input and targets for the x, y, and z coordinates.\n",
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "complete_motion_df.drop(complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "# Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output.\n",
    "# Convert targets to numpy arrays as well so we can use them in the model.\n",
    "target_x_np = target.iloc[:,0].to_numpy()\n",
    "target_y_np = target.iloc[:,1].to_numpy()\n",
    "target_z_np = target.iloc[:,2].to_numpy()\n",
    "# Usually training, validation, and test data would be coming from different CSV files or sources.\n",
    "# complete_motion_df only consists of input data at this point.\n",
    "complete_motion_np = complete_motion_df.to_numpy()\n",
    "\n",
    "#Create one large tensorflow dataset.\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((complete_motion_np, \n",
    "                                                   target_x_np, \n",
    "                                                   target_y_np,\n",
    "                                                   target_z_np)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [6.17261536e+00 6.06237951e+03 0.00000000e+00 4.69435521e+09\n",
      " 5.67926313e+10 0.00000000e+00 3.49941507e+09 1.09944304e+11\n",
      " 0.00000000e+00 2.99980227e+09 1.49970050e+11 0.00000000e+00\n",
      " 2.39994986e+09 2.19986084e+11 0.00000000e+00 1.29999937e+09\n",
      " 7.69998864e+11 0.00000000e+00 8.99999929e+08 1.39999965e+12\n",
      " 0.00000000e+00 6.83499993e+08 2.79999991e+12 0.00000000e+00\n",
      " 5.47699999e+08 4.49999997e+12 0.00000000e+00] Target_X: 474799997.95801955 Target_Y: 3699999950348.1753 Target_Z: 0.0\n",
      "Features: [4.93790293e+01 2.41290843e+04 0.00000000e+00 9.35485981e+09\n",
      " 5.61758433e+10 0.00000000e+00 6.99532091e+09 1.09778377e+11\n",
      " 0.00000000e+00 5.99841813e+09 1.49880804e+11 0.00000000e+00\n",
      " 4.79959882e+09 2.19944611e+11 0.00000000e+00 2.59999493e+09\n",
      " 7.69995477e+11 0.00000000e+00 1.79999943e+09 1.39999860e+12\n",
      " 0.00000000e+00 1.36699995e+09 2.79999965e+12 0.00000000e+00\n",
      " 1.09539999e+09 4.49999987e+12 0.00000000e+00] Target_X: 949599983.6629324 Target_Y: 3699999802375.9053 Target_Z: 0.0\n",
      "Features: [1.66623838e+02 5.41989476e+04 0.00000000e+00 1.39477770e+10\n",
      " 5.51532975e+10 0.00000000e+00 1.04842120e+10 1.09502387e+11\n",
      " 0.00000000e+00 8.99466168e+09 1.49732300e+11 0.00000000e+00\n",
      " 7.19864603e+09 2.19875587e+11 0.00000000e+00 3.89998289e+09\n",
      " 7.69989840e+11 0.00000000e+00 2.69999808e+09 1.39999685e+12\n",
      " 0.00000000e+00 2.05049982e+09 2.79999922e+12 0.00000000e+00\n",
      " 1.64309996e+09 4.49999970e+12 0.00000000e+00] Target_X: 1424399944.8616266 Target_Y: 3699999556083.186 Target_Z: 0.0\n",
      "Features: [3.94851583e+02 9.62700181e+04 0.00000000e+00 1.84396060e+10\n",
      " 5.37311252e+10 0.00000000e+00 1.39625905e+10 1.09116617e+11\n",
      " 0.00000000e+00 1.19873480e+10 1.49524596e+11 0.00000000e+00\n",
      " 9.59679064e+09 2.19779019e+11 0.00000000e+00 5.19995945e+09\n",
      " 7.69981952e+11 0.00000000e+00 3.59999544e+09 1.39999440e+12\n",
      " 0.00000000e+00 2.73399956e+09 2.79999862e+12 0.00000000e+00\n",
      " 2.19079992e+09 4.49999947e+12 0.00000000e+00] Target_X: 1899199869.3009844 Target_Y: 3699999211470.024 Target_Z: 0.0\n",
      "Features: [7.70915008e+02 1.50339559e+05 0.00000000e+00 2.27972101e+10\n",
      " 5.19179389e+10 0.00000000e+00 1.74269696e+10 1.08621464e+11\n",
      " 0.00000000e+00 1.49752939e+10 1.49257779e+11 0.00000000e+00\n",
      " 1.19937319e+10 2.19654917e+11 0.00000000e+00 6.49992080e+09\n",
      " 7.69971814e+11 0.00000000e+00 4.49999110e+09 1.39999126e+12\n",
      " 0.00000000e+00 3.41749915e+09 2.79999785e+12 0.00000000e+00\n",
      " 2.73849984e+09 4.49999917e+12 0.00000000e+00] Target_X: 2373999744.727879 Target_Y: 3699998768536.421 Target_Z: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataset and print the input and targets.\n",
    "# Will select top 5 to iterate through.\n",
    "for feat, targ_x, targ_y, targ_z in full_dataset.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the full dataset before splitting into train, validation, and test.\n",
    "# Since dataset can fit in memory, can set buffer to be the size of the data.\n",
    "full_dataset_num_samples = complete_motion_df.shape[0]  #Get the size of the dataset to set the randomize buffer\n",
    "#full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples).batch(1)\n",
    "full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "# Take the shuffled dataset and split into train, validation, and test datasets.\n",
    "train_dataset = full_dataset.take(train_size)   # Take top of dataset for training data\n",
    "test_dataset = full_dataset.skip(train_size)    # Take the rest of the dataset for validation and test\n",
    "val_dataset = test_dataset.skip(test_size)      # Take a part of the test data for validation during training\n",
    "test_dataset = test_dataset.take(test_size)     # Get rid of the validation data from the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Quick Neural Net for Predicting Jupiter's Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \\\n",
    "<br>\n",
    "Instead of using sklearn to normalize or manually making a normalization and standardization layer like p. 431 of the book, try using at least 1 Batch normalization layer after the input layer.  Can also add after hidden layers. \\\n",
    "<br>\n",
    "Might need to add an activation function to the output layer later to help with scaling of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Creating Single Input, Multiple Output Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a regression NN where instead of designating an output layer of 3 nodes, 3 output layers of a single node are used to designate specific datasets and loss functions.  Still need to figure out later how to get a 3 node output to correspond to the input training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functional API to build basic NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions with different versions of the neural network.\n",
    "\n",
    "def get_model1(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_2(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"tanh\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"tanh\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_3(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    \n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=10, rho=0.9)\n",
    "    \n",
    "def get_model_4(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(normal1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=2, rho=0.9)\n",
    "    \n",
    "def get_model_5(input_shape):  #Best one yet.  Typically takes about 1500 epochs to get decend results.\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "    hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "    #Set \n",
    "    input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "    input_loss_weights = [0.4, 0.4, 0.2]\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=0.0000005, rho=0.01)\n",
    "    input_metrics = [\"mae\"]\n",
    "    input_num_epochs = 200\n",
    "    input_batch_size = 64\n",
    "\n",
    "    model.summary()\n",
    "    #Also can use and probably should use Adam\n",
    "    input_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with specified input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 300)          8400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          90300       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_x (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_y (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_z (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 99,603\n",
      "Trainable params: 99,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model with specified input and output layers.\n",
    "# Select which model to try.\n",
    "# Pass shape of input layer to the function.\n",
    "#model = get_model_2(complete_motion_np.shape[1:])\n",
    "\n",
    "# Use functional API to build basic NN architecture.\n",
    "input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "#Set \n",
    "input_losses = [\"msle\", \"msle\", \"msle\"]\n",
    "input_loss_weights = [0.4, 0.4, 0.2]\n",
    "input_optimizer = keras.optimizers.Adam(learning_rate=1e-7, beta_1=0.9, beta_2=0.999)\n",
    "input_metrics = [\"msle\"]\n",
    "input_num_epochs = 500\n",
    "input_batch_size = 128\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting the model, create callbacks for the various stages.\n",
    "\n",
    "# Callback to implement overfitting.  Helps with regularization.  \n",
    "# Keep from over-training.  Stops training when validation error starts increasing again.\n",
    "# https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping/\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                 min_delta=0.0001,\n",
    "                                                 patience=20)\n",
    "\n",
    "# Callback for learning rate scheduling.  This way we can start with a higher learning rate then reduce as we go.\n",
    "# Reducing the learning rate by a factor of \"factor\" every so many epochs or \"patience\".\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=50)\n",
    "\n",
    "#Create list of all callbacks.\n",
    "#callback_list = [early_stopping_cb, lr_scheduler]\n",
    "callback_list = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with specified loss functions for each output and specify weighting to provide each output.\n",
    "# Weighting X and Y output more than Z\n",
    "model.compile(loss=input_losses, \n",
    "              loss_weights=input_loss_weights, \n",
    "              optimizer=input_optimizer,\n",
    "              metrics=input_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with separate x, y, z training sets.  Choose either numpy data or tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 297.0011 - output_x_loss: 380.8471 - output_y_loss: 154.6951 - output_z_loss: 413.9211 - output_x_msle: 380.8471 - output_y_msle: 154.6951 - output_z_msle: 413.9211 - val_loss: 298.2723 - val_output_x_loss: 382.3694 - val_output_y_loss: 156.6541 - val_output_z_loss: 413.3143 - val_output_x_msle: 382.3694 - val_output_y_msle: 156.6541 - val_output_z_msle: 413.3143 - lr: 1.0000e-08\n",
      "Epoch 2/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.8900 - output_x_loss: 380.8356 - output_y_loss: 154.4794 - output_z_loss: 413.8195 - output_x_msle: 380.8356 - output_y_msle: 154.4794 - output_z_msle: 413.8195 - val_loss: 298.2505 - val_output_x_loss: 382.3616 - val_output_y_loss: 156.6281 - val_output_z_loss: 413.2729 - val_output_x_msle: 382.3616 - val_output_y_msle: 156.6281 - val_output_z_msle: 413.2729 - lr: 1.0000e-08\n",
      "Epoch 3/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.8660 - output_x_loss: 380.8283 - output_y_loss: 154.4482 - output_z_loss: 413.7774 - output_x_msle: 380.8283 - output_y_msle: 154.4482 - output_z_msle: 413.7774 - val_loss: 298.2303 - val_output_x_loss: 382.3544 - val_output_y_loss: 156.6051 - val_output_z_loss: 413.2324 - val_output_x_msle: 382.3544 - val_output_y_msle: 156.6051 - val_output_z_msle: 413.2324 - lr: 1.0000e-08\n",
      "Epoch 4/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.8420 - output_x_loss: 380.8211 - output_y_loss: 154.4182 - output_z_loss: 413.7315 - output_x_msle: 380.8211 - output_y_msle: 154.4182 - output_z_msle: 413.7315 - val_loss: 298.2126 - val_output_x_loss: 382.3475 - val_output_y_loss: 156.5864 - val_output_z_loss: 413.1949 - val_output_x_msle: 382.3475 - val_output_y_msle: 156.5864 - val_output_z_msle: 413.1949 - lr: 1.0000e-08\n",
      "Epoch 5/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.8170 - output_x_loss: 380.8142 - output_y_loss: 154.3904 - output_z_loss: 413.6764 - output_x_msle: 380.8142 - output_y_msle: 154.3904 - output_z_msle: 413.6764 - val_loss: 298.1976 - val_output_x_loss: 382.3406 - val_output_y_loss: 156.5729 - val_output_z_loss: 413.1611 - val_output_x_msle: 382.3406 - val_output_y_msle: 156.5729 - val_output_z_msle: 413.1611 - lr: 1.0000e-08\n",
      "Epoch 6/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.7827 - output_x_loss: 380.8074 - output_y_loss: 154.3363 - output_z_loss: 413.6262 - output_x_msle: 380.8074 - output_y_msle: 154.3363 - output_z_msle: 413.6262 - val_loss: 298.1491 - val_output_x_loss: 382.3336 - val_output_y_loss: 156.4746 - val_output_z_loss: 413.1290 - val_output_x_msle: 382.3336 - val_output_y_msle: 156.4746 - val_output_z_msle: 413.1290 - lr: 1.0000e-08\n",
      "Epoch 7/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.7316 - output_x_loss: 380.7671 - output_y_loss: 154.2661 - output_z_loss: 413.5914 - output_x_msle: 380.7671 - output_y_msle: 154.2661 - output_z_msle: 413.5914 - val_loss: 298.1342 - val_output_x_loss: 382.3261 - val_output_y_loss: 156.4617 - val_output_z_loss: 413.0957 - val_output_x_msle: 382.3261 - val_output_y_msle: 156.4617 - val_output_z_msle: 413.0957 - lr: 1.0000e-08\n",
      "Epoch 8/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.7089 - output_x_loss: 380.7588 - output_y_loss: 154.2368 - output_z_loss: 413.5536 - output_x_msle: 380.7588 - output_y_msle: 154.2368 - output_z_msle: 413.5536 - val_loss: 298.1199 - val_output_x_loss: 382.3190 - val_output_y_loss: 156.4502 - val_output_z_loss: 413.0612 - val_output_x_msle: 382.3190 - val_output_y_msle: 156.4502 - val_output_z_msle: 413.0612 - lr: 1.0000e-08\n",
      "Epoch 9/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.6689 - output_x_loss: 380.7515 - output_y_loss: 154.1694 - output_z_loss: 413.5024 - output_x_msle: 380.7515 - output_y_msle: 154.1694 - output_z_msle: 413.5024 - val_loss: 298.0403 - val_output_x_loss: 382.3118 - val_output_y_loss: 156.2754 - val_output_z_loss: 413.0274 - val_output_x_msle: 382.3118 - val_output_y_msle: 156.2754 - val_output_z_msle: 413.0274 - lr: 1.0000e-08\n",
      "Epoch 10/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.6308 - output_x_loss: 380.7439 - output_y_loss: 154.1007 - output_z_loss: 413.4650 - output_x_msle: 380.7439 - output_y_msle: 154.1007 - output_z_msle: 413.4650 - val_loss: 298.0198 - val_output_x_loss: 382.3042 - val_output_y_loss: 156.2499 - val_output_z_loss: 412.9909 - val_output_x_msle: 382.3042 - val_output_y_msle: 156.2499 - val_output_z_msle: 412.9909 - lr: 1.0000e-08\n",
      "Epoch 11/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.6067 - output_x_loss: 380.7361 - output_y_loss: 154.0684 - output_z_loss: 413.4244 - output_x_msle: 380.7361 - output_y_msle: 154.0684 - output_z_msle: 413.4244 - val_loss: 297.9983 - val_output_x_loss: 382.2965 - val_output_y_loss: 156.2229 - val_output_z_loss: 412.9525 - val_output_x_msle: 382.2965 - val_output_y_msle: 156.2229 - val_output_z_msle: 412.9525 - lr: 1.0000e-08\n",
      "Epoch 12/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.5435 - output_x_loss: 380.6689 - output_y_loss: 154.0052 - output_z_loss: 413.3695 - output_x_msle: 380.6689 - output_y_msle: 154.0052 - output_z_msle: 413.3695 - val_loss: 297.9590 - val_output_x_loss: 382.2916 - val_output_y_loss: 156.1479 - val_output_z_loss: 412.9162 - val_output_x_msle: 382.2916 - val_output_y_msle: 156.1479 - val_output_z_msle: 412.9162 - lr: 1.0000e-08\n",
      "Epoch 13/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.5119 - output_x_loss: 380.6599 - output_y_loss: 153.9558 - output_z_loss: 413.3278 - output_x_msle: 380.6599 - output_y_msle: 153.9558 - output_z_msle: 413.3278 - val_loss: 297.9443 - val_output_x_loss: 382.2870 - val_output_y_loss: 156.1355 - val_output_z_loss: 412.8763 - val_output_x_msle: 382.2870 - val_output_y_msle: 156.1355 - val_output_z_msle: 412.8763 - lr: 1.0000e-08\n",
      "Epoch 14/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.4762 - output_x_loss: 380.6232 - output_y_loss: 153.9302 - output_z_loss: 413.2739 - output_x_msle: 380.6232 - output_y_msle: 153.9302 - output_z_msle: 413.2739 - val_loss: 297.8632 - val_output_x_loss: 382.1230 - val_output_y_loss: 156.1141 - val_output_z_loss: 412.8420 - val_output_x_msle: 382.1230 - val_output_y_msle: 156.1141 - val_output_z_msle: 412.8420 - lr: 1.0000e-08\n",
      "Epoch 15/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.4288 - output_x_loss: 380.5821 - output_y_loss: 153.8698 - output_z_loss: 413.2402 - output_x_msle: 380.5821 - output_y_msle: 153.8698 - output_z_msle: 413.2402 - val_loss: 297.8517 - val_output_x_loss: 382.1183 - val_output_y_loss: 156.1053 - val_output_z_loss: 412.8112 - val_output_x_msle: 382.1183 - val_output_y_msle: 156.1053 - val_output_z_msle: 412.8112 - lr: 1.0000e-08\n",
      "Epoch 16/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.4139 - output_x_loss: 380.5776 - output_y_loss: 153.8595 - output_z_loss: 413.1953 - output_x_msle: 380.5776 - output_y_msle: 153.8595 - output_z_msle: 413.1953 - val_loss: 297.8386 - val_output_x_loss: 382.1137 - val_output_y_loss: 156.0916 - val_output_z_loss: 412.7821 - val_output_x_msle: 382.1137 - val_output_y_msle: 156.0916 - val_output_z_msle: 412.7821 - lr: 1.0000e-08\n",
      "Epoch 17/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.3964 - output_x_loss: 380.5731 - output_y_loss: 153.8365 - output_z_loss: 413.1638 - output_x_msle: 380.5731 - output_y_msle: 153.8365 - output_z_msle: 413.1638 - val_loss: 297.7900 - val_output_x_loss: 382.1089 - val_output_y_loss: 155.9920 - val_output_z_loss: 412.7482 - val_output_x_msle: 382.1089 - val_output_y_msle: 155.9920 - val_output_z_msle: 412.7482 - lr: 1.0000e-08\n",
      "Epoch 18/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.3629 - output_x_loss: 380.5683 - output_y_loss: 153.7738 - output_z_loss: 413.1307 - output_x_msle: 380.5683 - output_y_msle: 153.7738 - output_z_msle: 413.1307 - val_loss: 297.7785 - val_output_x_loss: 382.1042 - val_output_y_loss: 155.9843 - val_output_z_loss: 412.7154 - val_output_x_msle: 382.1042 - val_output_y_msle: 155.9843 - val_output_z_msle: 412.7154 - lr: 1.0000e-08\n",
      "Epoch 19/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.3461 - output_x_loss: 380.5635 - output_y_loss: 153.7576 - output_z_loss: 413.0877 - output_x_msle: 380.5635 - output_y_msle: 153.7576 - output_z_msle: 413.0877 - val_loss: 297.7606 - val_output_x_loss: 382.0994 - val_output_y_loss: 155.9679 - val_output_z_loss: 412.6686 - val_output_x_msle: 382.0994 - val_output_y_msle: 155.9679 - val_output_z_msle: 412.6686 - lr: 1.0000e-08\n",
      "Epoch 20/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.3029 - output_x_loss: 380.5589 - output_y_loss: 153.6777 - output_z_loss: 413.0410 - output_x_msle: 380.5589 - output_y_msle: 153.6777 - output_z_msle: 413.0410 - val_loss: 297.7518 - val_output_x_loss: 382.0947 - val_output_y_loss: 155.9603 - val_output_z_loss: 412.6490 - val_output_x_msle: 382.0947 - val_output_y_msle: 155.9603 - val_output_z_msle: 412.6490 - lr: 1.0000e-08\n",
      "Epoch 21/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.2796 - output_x_loss: 380.5543 - output_y_loss: 153.6343 - output_z_loss: 413.0210 - output_x_msle: 380.5543 - output_y_msle: 153.6343 - output_z_msle: 413.0210 - val_loss: 297.7424 - val_output_x_loss: 382.0899 - val_output_y_loss: 155.9524 - val_output_z_loss: 412.6272 - val_output_x_msle: 382.0899 - val_output_y_msle: 155.9524 - val_output_z_msle: 412.6272 - lr: 1.0000e-08\n",
      "Epoch 22/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.2266 - output_x_loss: 380.5493 - output_y_loss: 153.5181 - output_z_loss: 412.9981 - output_x_msle: 380.5493 - output_y_msle: 153.5181 - output_z_msle: 412.9981 - val_loss: 297.6076 - val_output_x_loss: 382.0849 - val_output_y_loss: 155.6321 - val_output_z_loss: 412.6039 - val_output_x_msle: 382.0849 - val_output_y_msle: 155.6321 - val_output_z_msle: 412.6039 - lr: 1.0000e-08\n",
      "Epoch 23/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.2142 - output_x_loss: 380.5444 - output_y_loss: 153.5054 - output_z_loss: 412.9718 - output_x_msle: 380.5444 - output_y_msle: 153.5054 - output_z_msle: 412.9718 - val_loss: 297.5945 - val_output_x_loss: 382.0799 - val_output_y_loss: 155.6183 - val_output_z_loss: 412.5760 - val_output_x_msle: 382.0799 - val_output_y_msle: 155.6183 - val_output_z_msle: 412.5760 - lr: 1.0000e-08\n",
      "Epoch 24/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.1956 - output_x_loss: 380.5393 - output_y_loss: 153.4928 - output_z_loss: 412.9140 - output_x_msle: 380.5393 - output_y_msle: 153.4928 - output_z_msle: 412.9140 - val_loss: 297.5823 - val_output_x_loss: 382.0748 - val_output_y_loss: 155.6062 - val_output_z_loss: 412.5495 - val_output_x_msle: 382.0748 - val_output_y_msle: 155.6062 - val_output_z_msle: 412.5495 - lr: 1.0000e-08\n",
      "Epoch 25/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.1784 - output_x_loss: 380.5340 - output_y_loss: 153.4668 - output_z_loss: 412.8897 - output_x_msle: 380.5340 - output_y_msle: 153.4668 - output_z_msle: 412.8897 - val_loss: 297.5695 - val_output_x_loss: 382.0695 - val_output_y_loss: 155.5941 - val_output_z_loss: 412.5204 - val_output_x_msle: 382.0695 - val_output_y_msle: 155.5941 - val_output_z_msle: 412.5204 - lr: 1.0000e-08\n",
      "Epoch 26/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.1661 - output_x_loss: 380.5286 - output_y_loss: 153.4552 - output_z_loss: 412.8632 - output_x_msle: 380.5286 - output_y_msle: 153.4552 - output_z_msle: 412.8632 - val_loss: 297.5538 - val_output_x_loss: 382.0639 - val_output_y_loss: 155.5792 - val_output_z_loss: 412.4828 - val_output_x_msle: 382.0639 - val_output_y_msle: 155.5792 - val_output_z_msle: 412.4828 - lr: 1.0000e-08\n",
      "Epoch 27/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.1341 - output_x_loss: 380.4905 - output_y_loss: 153.4279 - output_z_loss: 412.8336 - output_x_msle: 380.4905 - output_y_msle: 153.4279 - output_z_msle: 412.8336 - val_loss: 297.4614 - val_output_x_loss: 382.0576 - val_output_y_loss: 155.4074 - val_output_z_loss: 412.3771 - val_output_x_msle: 382.0576 - val_output_y_msle: 155.4074 - val_output_z_msle: 412.3771 - lr: 1.0000e-08\n",
      "Epoch 28/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.1060 - output_x_loss: 380.4820 - output_y_loss: 153.3814 - output_z_loss: 412.8030 - output_x_msle: 380.4820 - output_y_msle: 153.3814 - output_z_msle: 412.8030 - val_loss: 297.4407 - val_output_x_loss: 382.0508 - val_output_y_loss: 155.3779 - val_output_z_loss: 412.3459 - val_output_x_msle: 382.0508 - val_output_y_msle: 155.3779 - val_output_z_msle: 412.3459 - lr: 1.0000e-08\n",
      "Epoch 29/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.0912 - output_x_loss: 380.4758 - output_y_loss: 153.3667 - output_z_loss: 412.7712 - output_x_msle: 380.4758 - output_y_msle: 153.3667 - output_z_msle: 412.7712 - val_loss: 297.3995 - val_output_x_loss: 382.0446 - val_output_y_loss: 155.2987 - val_output_z_loss: 412.3111 - val_output_x_msle: 382.0446 - val_output_y_msle: 155.2987 - val_output_z_msle: 412.3111 - lr: 1.0000e-08\n",
      "Epoch 30/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.0811 - output_x_loss: 380.4694 - output_y_loss: 153.3666 - output_z_loss: 412.7336 - output_x_msle: 380.4694 - output_y_msle: 153.3666 - output_z_msle: 412.7336 - val_loss: 297.3835 - val_output_x_loss: 382.0386 - val_output_y_loss: 155.2851 - val_output_z_loss: 412.2702 - val_output_x_msle: 382.0386 - val_output_y_msle: 155.2851 - val_output_z_msle: 412.2702 - lr: 1.0000e-08\n",
      "Epoch 31/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 296.0540 - output_x_loss: 380.4632 - output_y_loss: 153.3238 - output_z_loss: 412.6956 - output_x_msle: 380.4632 - output_y_msle: 153.3238 - output_z_msle: 412.6956 - val_loss: 297.3676 - val_output_x_loss: 382.0324 - val_output_y_loss: 155.2740 - val_output_z_loss: 412.2249 - val_output_x_msle: 382.0324 - val_output_y_msle: 155.2740 - val_output_z_msle: 412.2249 - lr: 1.0000e-08\n",
      "Epoch 32/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.0297 - output_x_loss: 380.4570 - output_y_loss: 153.2953 - output_z_loss: 412.6436 - output_x_msle: 380.4570 - output_y_msle: 153.2953 - output_z_msle: 412.6436 - val_loss: 297.3373 - val_output_x_loss: 382.0262 - val_output_y_loss: 155.2615 - val_output_z_loss: 412.1115 - val_output_x_msle: 382.0262 - val_output_y_msle: 155.2615 - val_output_z_msle: 412.1115 - lr: 1.0000e-08\n",
      "Epoch 33/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.0022 - output_x_loss: 380.4503 - output_y_loss: 153.2520 - output_z_loss: 412.6065 - output_x_msle: 380.4503 - output_y_msle: 153.2520 - output_z_msle: 412.6065 - val_loss: 297.3229 - val_output_x_loss: 382.0196 - val_output_y_loss: 155.2499 - val_output_z_loss: 412.0753 - val_output_x_msle: 382.0196 - val_output_y_msle: 155.2499 - val_output_z_msle: 412.0753 - lr: 1.0000e-08\n",
      "Epoch 34/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.9747 - output_x_loss: 380.4435 - output_y_loss: 153.2088 - output_z_loss: 412.5690 - output_x_msle: 380.4435 - output_y_msle: 153.2088 - output_z_msle: 412.5690 - val_loss: 297.3073 - val_output_x_loss: 382.0128 - val_output_y_loss: 155.2368 - val_output_z_loss: 412.0373 - val_output_x_msle: 382.0128 - val_output_y_msle: 155.2368 - val_output_z_msle: 412.0373 - lr: 1.0000e-08\n",
      "Epoch 35/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.9597 - output_x_loss: 380.4362 - output_y_loss: 153.1990 - output_z_loss: 412.5278 - output_x_msle: 380.4362 - output_y_msle: 153.1990 - output_z_msle: 412.5278 - val_loss: 297.2920 - val_output_x_loss: 382.0056 - val_output_y_loss: 155.2281 - val_output_z_loss: 411.9928 - val_output_x_msle: 382.0056 - val_output_y_msle: 155.2281 - val_output_z_msle: 411.9928 - lr: 1.0000e-08\n",
      "Epoch 36/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.9435 - output_x_loss: 380.4288 - output_y_loss: 153.1904 - output_z_loss: 412.4792 - output_x_msle: 380.4288 - output_y_msle: 153.1904 - output_z_msle: 412.4792 - val_loss: 297.2737 - val_output_x_loss: 381.9980 - val_output_y_loss: 155.2173 - val_output_z_loss: 411.9379 - val_output_x_msle: 381.9980 - val_output_y_msle: 155.2173 - val_output_z_msle: 411.9379 - lr: 1.0000e-08\n",
      "Epoch 37/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.9121 - output_x_loss: 380.4207 - output_y_loss: 153.1499 - output_z_loss: 412.4187 - output_x_msle: 380.4207 - output_y_msle: 153.1499 - output_z_msle: 412.4187 - val_loss: 297.2436 - val_output_x_loss: 381.9901 - val_output_y_loss: 155.2086 - val_output_z_loss: 411.8205 - val_output_x_msle: 381.9901 - val_output_y_msle: 155.2086 - val_output_z_msle: 411.8205 - lr: 1.0000e-08\n",
      "Epoch 38/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.8945 - output_x_loss: 380.4128 - output_y_loss: 153.1367 - output_z_loss: 412.3733 - output_x_msle: 380.4128 - output_y_msle: 153.1367 - output_z_msle: 412.3733 - val_loss: 297.2265 - val_output_x_loss: 381.9821 - val_output_y_loss: 155.1954 - val_output_z_loss: 411.7777 - val_output_x_msle: 381.9821 - val_output_y_msle: 155.1954 - val_output_z_msle: 411.7777 - lr: 1.0000e-08\n",
      "Epoch 39/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.8685 - output_x_loss: 380.4044 - output_y_loss: 153.1076 - output_z_loss: 412.3185 - output_x_msle: 380.4044 - output_y_msle: 153.1076 - output_z_msle: 412.3185 - val_loss: 297.1790 - val_output_x_loss: 381.9737 - val_output_y_loss: 155.1096 - val_output_z_loss: 411.7284 - val_output_x_msle: 381.9737 - val_output_y_msle: 155.1096 - val_output_z_msle: 411.7284 - lr: 1.0000e-08\n",
      "Epoch 40/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.8282 - output_x_loss: 380.3643 - output_y_loss: 153.0835 - output_z_loss: 412.2459 - output_x_msle: 380.3643 - output_y_msle: 153.0835 - output_z_msle: 412.2459 - val_loss: 297.1623 - val_output_x_loss: 381.9648 - val_output_y_loss: 155.1015 - val_output_z_loss: 411.6786 - val_output_x_msle: 381.9648 - val_output_y_msle: 155.1015 - val_output_z_msle: 411.6786 - lr: 1.0000e-08\n",
      "Epoch 41/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.7887 - output_x_loss: 380.3193 - output_y_loss: 153.0731 - output_z_loss: 412.1586 - output_x_msle: 380.3193 - output_y_msle: 153.0731 - output_z_msle: 412.1586 - val_loss: 297.1474 - val_output_x_loss: 381.9568 - val_output_y_loss: 155.0933 - val_output_z_loss: 411.6370 - val_output_x_msle: 381.9568 - val_output_y_msle: 155.0933 - val_output_z_msle: 411.6370 - lr: 1.0000e-08\n",
      "Epoch 42/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.7662 - output_x_loss: 380.3106 - output_y_loss: 153.0583 - output_z_loss: 412.0929 - output_x_msle: 380.3106 - output_y_msle: 153.0583 - output_z_msle: 412.0929 - val_loss: 297.1281 - val_output_x_loss: 381.9489 - val_output_y_loss: 155.0811 - val_output_z_loss: 411.5803 - val_output_x_msle: 381.9489 - val_output_y_msle: 155.0811 - val_output_z_msle: 411.5803 - lr: 1.0000e-08\n",
      "Epoch 43/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.7359 - output_x_loss: 380.3031 - output_y_loss: 153.0138 - output_z_loss: 412.0455 - output_x_msle: 380.3031 - output_y_msle: 153.0138 - output_z_msle: 412.0455 - val_loss: 297.1157 - val_output_x_loss: 381.9416 - val_output_y_loss: 155.0648 - val_output_z_loss: 411.5654 - val_output_x_msle: 381.9416 - val_output_y_msle: 155.0648 - val_output_z_msle: 411.5654 - lr: 1.0000e-08\n",
      "Epoch 44/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.7127 - output_x_loss: 380.2956 - output_y_loss: 152.9710 - output_z_loss: 412.0304 - output_x_msle: 380.2956 - output_y_msle: 152.9710 - output_z_msle: 412.0304 - val_loss: 297.1061 - val_output_x_loss: 381.9342 - val_output_y_loss: 155.0553 - val_output_z_loss: 411.5514 - val_output_x_msle: 381.9342 - val_output_y_msle: 155.0553 - val_output_z_msle: 411.5514 - lr: 1.0000e-08\n",
      "Epoch 45/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.7014 - output_x_loss: 380.2875 - output_y_loss: 152.9584 - output_z_loss: 412.0149 - output_x_msle: 380.2875 - output_y_msle: 152.9584 - output_z_msle: 412.0149 - val_loss: 297.0969 - val_output_x_loss: 381.9264 - val_output_y_loss: 155.0479 - val_output_z_loss: 411.5360 - val_output_x_msle: 381.9264 - val_output_y_msle: 155.0479 - val_output_z_msle: 411.5360 - lr: 1.0000e-08\n",
      "Epoch 46/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.6796 - output_x_loss: 380.2792 - output_y_loss: 152.9211 - output_z_loss: 411.9977 - output_x_msle: 380.2792 - output_y_msle: 152.9211 - output_z_msle: 411.9977 - val_loss: 297.1317 - val_output_x_loss: 381.9182 - val_output_y_loss: 155.1530 - val_output_z_loss: 411.5164 - val_output_x_msle: 381.9182 - val_output_y_msle: 155.1530 - val_output_z_msle: 411.5164 - lr: 1.0000e-08\n",
      "Epoch 47/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.6394 - output_x_loss: 380.2707 - output_y_loss: 152.8401 - output_z_loss: 411.9755 - output_x_msle: 380.2707 - output_y_msle: 152.8401 - output_z_msle: 411.9755 - val_loss: 297.1217 - val_output_x_loss: 381.9098 - val_output_y_loss: 155.1447 - val_output_z_loss: 411.4994 - val_output_x_msle: 381.9098 - val_output_y_msle: 155.1447 - val_output_z_msle: 411.4994 - lr: 1.0000e-08\n",
      "Epoch 48/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.6152 - output_x_loss: 380.2620 - output_y_loss: 152.7973 - output_z_loss: 411.9576 - output_x_msle: 380.2620 - output_y_msle: 152.7973 - output_z_msle: 411.9576 - val_loss: 297.0475 - val_output_x_loss: 381.9010 - val_output_y_loss: 154.9769 - val_output_z_loss: 411.4819 - val_output_x_msle: 381.9010 - val_output_y_msle: 154.9769 - val_output_z_msle: 411.4819 - lr: 1.0000e-08\n",
      "Epoch 49/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.5560 - output_x_loss: 380.1868 - output_y_loss: 152.7341 - output_z_loss: 411.9381 - output_x_msle: 380.1868 - output_y_msle: 152.7341 - output_z_msle: 411.9381 - val_loss: 297.0374 - val_output_x_loss: 381.8917 - val_output_y_loss: 154.9694 - val_output_z_loss: 411.4647 - val_output_x_msle: 381.8917 - val_output_y_msle: 154.9694 - val_output_z_msle: 411.4647 - lr: 1.0000e-08\n",
      "Epoch 50/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.5415 - output_x_loss: 380.1741 - output_y_loss: 152.7213 - output_z_loss: 411.9170 - output_x_msle: 380.1741 - output_y_msle: 152.7213 - output_z_msle: 411.9170 - val_loss: 297.0245 - val_output_x_loss: 381.8823 - val_output_y_loss: 154.9561 - val_output_z_loss: 411.4456 - val_output_x_msle: 381.8823 - val_output_y_msle: 154.9561 - val_output_z_msle: 411.4456 - lr: 1.0000e-08\n",
      "Epoch 51/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.5225 - output_x_loss: 380.1643 - output_y_loss: 152.6956 - output_z_loss: 411.8921 - output_x_msle: 380.1643 - output_y_msle: 152.6956 - output_z_msle: 411.8921 - val_loss: 297.0119 - val_output_x_loss: 381.8729 - val_output_y_loss: 154.9453 - val_output_z_loss: 411.4232 - val_output_x_msle: 381.8729 - val_output_y_msle: 154.9453 - val_output_z_msle: 411.4232 - lr: 1.0000e-08\n",
      "Epoch 52/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.4994 - output_x_loss: 380.1545 - output_y_loss: 152.6675 - output_z_loss: 411.8539 - output_x_msle: 380.1545 - output_y_msle: 152.6675 - output_z_msle: 411.8539 - val_loss: 296.9428 - val_output_x_loss: 381.8640 - val_output_y_loss: 154.7908 - val_output_z_loss: 411.4046 - val_output_x_msle: 381.8640 - val_output_y_msle: 154.7908 - val_output_z_msle: 411.4046 - lr: 1.0000e-08\n",
      "Epoch 53/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.4543 - output_x_loss: 380.1138 - output_y_loss: 152.6045 - output_z_loss: 411.8353 - output_x_msle: 380.1138 - output_y_msle: 152.6045 - output_z_msle: 411.8353 - val_loss: 296.9291 - val_output_x_loss: 381.8578 - val_output_y_loss: 154.7707 - val_output_z_loss: 411.3886 - val_output_x_msle: 381.8578 - val_output_y_msle: 154.7707 - val_output_z_msle: 411.3886 - lr: 1.0000e-08\n",
      "Epoch 54/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.4260 - output_x_loss: 380.0717 - output_y_loss: 152.5843 - output_z_loss: 411.8175 - output_x_msle: 380.0717 - output_y_msle: 152.5843 - output_z_msle: 411.8175 - val_loss: 296.8932 - val_output_x_loss: 381.8516 - val_output_y_loss: 154.6953 - val_output_z_loss: 411.3720 - val_output_x_msle: 381.8516 - val_output_y_msle: 154.6953 - val_output_z_msle: 411.3720 - lr: 1.0000e-08\n",
      "Epoch 55/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.4154 - output_x_loss: 380.0643 - output_y_loss: 152.5722 - output_z_loss: 411.8041 - output_x_msle: 380.0643 - output_y_msle: 152.5722 - output_z_msle: 411.8041 - val_loss: 296.9123 - val_output_x_loss: 381.8454 - val_output_y_loss: 154.7552 - val_output_z_loss: 411.3606 - val_output_x_msle: 381.8454 - val_output_y_msle: 154.7552 - val_output_z_msle: 411.3606 - lr: 1.0000e-08\n",
      "Epoch 56/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.3952 - output_x_loss: 380.0577 - output_y_loss: 152.5365 - output_z_loss: 411.7878 - output_x_msle: 380.0577 - output_y_msle: 152.5365 - output_z_msle: 411.7878 - val_loss: 296.8437 - val_output_x_loss: 381.8390 - val_output_y_loss: 154.5972 - val_output_z_loss: 411.3461 - val_output_x_msle: 381.8390 - val_output_y_msle: 154.5972 - val_output_z_msle: 411.3461 - lr: 1.0000e-08\n",
      "Epoch 57/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3831 - output_x_loss: 380.0508 - output_y_loss: 152.5227 - output_z_loss: 411.7684 - output_x_msle: 380.0508 - output_y_msle: 152.5227 - output_z_msle: 411.7684 - val_loss: 296.8105 - val_output_x_loss: 381.8323 - val_output_y_loss: 154.5301 - val_output_z_loss: 411.3275 - val_output_x_msle: 381.8323 - val_output_y_msle: 154.5301 - val_output_z_msle: 411.3275 - lr: 1.0000e-08\n",
      "Epoch 58/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3684 - output_x_loss: 380.0438 - output_y_loss: 152.5051 - output_z_loss: 411.7446 - output_x_msle: 380.0438 - output_y_msle: 152.5051 - output_z_msle: 411.7446 - val_loss: 296.7990 - val_output_x_loss: 381.8253 - val_output_y_loss: 154.5185 - val_output_z_loss: 411.3066 - val_output_x_msle: 381.8253 - val_output_y_msle: 154.5185 - val_output_z_msle: 411.3066 - lr: 1.0000e-08\n",
      "Epoch 59/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3542 - output_x_loss: 380.0362 - output_y_loss: 152.4975 - output_z_loss: 411.7036 - output_x_msle: 380.0362 - output_y_msle: 152.4975 - output_z_msle: 411.7036 - val_loss: 296.7885 - val_output_x_loss: 381.8181 - val_output_y_loss: 154.5103 - val_output_z_loss: 411.2857 - val_output_x_msle: 381.8181 - val_output_y_msle: 154.5103 - val_output_z_msle: 411.2857 - lr: 1.0000e-08\n",
      "Epoch 60/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3280 - output_x_loss: 380.0283 - output_y_loss: 152.4594 - output_z_loss: 411.6646 - output_x_msle: 380.0283 - output_y_msle: 152.4594 - output_z_msle: 411.6646 - val_loss: 296.7784 - val_output_x_loss: 381.8105 - val_output_y_loss: 154.5022 - val_output_z_loss: 411.2663 - val_output_x_msle: 381.8105 - val_output_y_msle: 154.5022 - val_output_z_msle: 411.2663 - lr: 1.0000e-08\n",
      "Epoch 61/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3111 - output_x_loss: 380.0204 - output_y_loss: 152.4418 - output_z_loss: 411.6304 - output_x_msle: 380.0204 - output_y_msle: 152.4418 - output_z_msle: 411.6304 - val_loss: 296.7685 - val_output_x_loss: 381.8028 - val_output_y_loss: 154.4940 - val_output_z_loss: 411.2488 - val_output_x_msle: 381.8028 - val_output_y_msle: 154.4940 - val_output_z_msle: 411.2488 - lr: 1.0000e-08\n",
      "Epoch 62/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.3027 - output_x_loss: 380.0122 - output_y_loss: 152.4389 - output_z_loss: 411.6110 - output_x_msle: 380.0122 - output_y_msle: 152.4389 - output_z_msle: 411.6110 - val_loss: 296.6986 - val_output_x_loss: 381.7946 - val_output_y_loss: 154.3372 - val_output_z_loss: 411.2296 - val_output_x_msle: 381.7946 - val_output_y_msle: 154.3372 - val_output_z_msle: 411.2296 - lr: 1.0000e-08\n",
      "Epoch 63/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.2934 - output_x_loss: 380.0035 - output_y_loss: 152.4353 - output_z_loss: 411.5892 - output_x_msle: 380.0035 - output_y_msle: 152.4353 - output_z_msle: 411.5892 - val_loss: 296.6230 - val_output_x_loss: 381.7860 - val_output_y_loss: 154.1675 - val_output_z_loss: 411.2085 - val_output_x_msle: 381.7860 - val_output_y_msle: 154.1675 - val_output_z_msle: 411.2085 - lr: 1.0000e-08\n",
      "Epoch 64/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.2833 - output_x_loss: 379.9943 - output_y_loss: 152.4311 - output_z_loss: 411.5655 - output_x_msle: 379.9943 - output_y_msle: 152.4311 - output_z_msle: 411.5655 - val_loss: 296.5842 - val_output_x_loss: 381.7770 - val_output_y_loss: 154.0908 - val_output_z_loss: 411.1854 - val_output_x_msle: 381.7770 - val_output_y_msle: 154.0908 - val_output_z_msle: 411.1854 - lr: 1.0000e-08\n",
      "Epoch 65/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.2337 - output_x_loss: 379.8892 - output_y_loss: 152.4256 - output_z_loss: 411.5387 - output_x_msle: 379.8892 - output_y_msle: 152.4256 - output_z_msle: 411.5387 - val_loss: 296.5721 - val_output_x_loss: 381.7692 - val_output_y_loss: 154.0812 - val_output_z_loss: 411.1596 - val_output_x_msle: 381.7692 - val_output_y_msle: 154.0812 - val_output_z_msle: 411.1596 - lr: 1.0000e-08\n",
      "Epoch 66/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.1938 - output_x_loss: 379.8147 - output_y_loss: 152.4155 - output_z_loss: 411.5087 - output_x_msle: 379.8147 - output_y_msle: 152.4155 - output_z_msle: 411.5087 - val_loss: 296.4365 - val_output_x_loss: 381.4524 - val_output_y_loss: 154.0733 - val_output_z_loss: 411.1310 - val_output_x_msle: 381.4524 - val_output_y_msle: 154.0733 - val_output_z_msle: 411.1310 - lr: 1.0000e-08\n",
      "Epoch 67/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.1516 - output_x_loss: 379.7694 - output_y_loss: 152.3737 - output_z_loss: 411.4724 - output_x_msle: 379.7694 - output_y_msle: 152.3737 - output_z_msle: 411.4724 - val_loss: 296.4241 - val_output_x_loss: 381.4440 - val_output_y_loss: 154.0668 - val_output_z_loss: 411.0991 - val_output_x_msle: 381.4440 - val_output_y_msle: 154.0668 - val_output_z_msle: 411.0991 - lr: 1.0000e-08\n",
      "Epoch 68/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.1142 - output_x_loss: 379.7316 - output_y_loss: 152.3503 - output_z_loss: 411.4070 - output_x_msle: 379.7316 - output_y_msle: 152.3503 - output_z_msle: 411.4070 - val_loss: 296.4083 - val_output_x_loss: 381.4269 - val_output_y_loss: 154.0579 - val_output_z_loss: 411.0721 - val_output_x_msle: 381.4269 - val_output_y_msle: 154.0579 - val_output_z_msle: 411.0721 - lr: 1.0000e-08\n",
      "Epoch 69/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.0647 - output_x_loss: 379.6511 - output_y_loss: 152.3230 - output_z_loss: 411.3750 - output_x_msle: 379.6511 - output_y_msle: 152.3230 - output_z_msle: 411.3750 - val_loss: 296.3971 - val_output_x_loss: 381.4199 - val_output_y_loss: 154.0521 - val_output_z_loss: 411.0416 - val_output_x_msle: 381.4199 - val_output_y_msle: 154.0521 - val_output_z_msle: 411.0416 - lr: 1.0000e-08\n",
      "Epoch 70/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.0341 - output_x_loss: 379.6436 - output_y_loss: 152.2707 - output_z_loss: 411.3411 - output_x_msle: 379.6436 - output_y_msle: 152.2707 - output_z_msle: 411.3411 - val_loss: 296.3854 - val_output_x_loss: 381.4127 - val_output_y_loss: 154.0457 - val_output_z_loss: 411.0102 - val_output_x_msle: 381.4127 - val_output_y_msle: 154.0457 - val_output_z_msle: 411.0102 - lr: 1.0000e-08\n",
      "Epoch 71/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.0218 - output_x_loss: 379.6360 - output_y_loss: 152.2673 - output_z_loss: 411.3022 - output_x_msle: 379.6360 - output_y_msle: 152.2673 - output_z_msle: 411.3022 - val_loss: 296.3728 - val_output_x_loss: 381.4051 - val_output_y_loss: 154.0400 - val_output_z_loss: 410.9738 - val_output_x_msle: 381.4051 - val_output_y_msle: 154.0400 - val_output_z_msle: 410.9738 - lr: 1.0000e-08\n",
      "Epoch 72/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 295.0042 - output_x_loss: 379.6279 - output_y_loss: 152.2635 - output_z_loss: 411.2376 - output_x_msle: 379.6279 - output_y_msle: 152.2635 - output_z_msle: 411.2376 - val_loss: 296.3582 - val_output_x_loss: 381.3976 - val_output_y_loss: 154.0340 - val_output_z_loss: 410.9276 - val_output_x_msle: 381.3976 - val_output_y_msle: 154.0340 - val_output_z_msle: 410.9276 - lr: 1.0000e-08\n",
      "Epoch 73/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.9859 - output_x_loss: 379.6204 - output_y_loss: 152.2591 - output_z_loss: 411.1705 - output_x_msle: 379.6204 - output_y_msle: 152.2591 - output_z_msle: 411.1705 - val_loss: 296.3441 - val_output_x_loss: 381.3905 - val_output_y_loss: 154.0280 - val_output_z_loss: 410.8839 - val_output_x_msle: 381.3905 - val_output_y_msle: 154.0280 - val_output_z_msle: 410.8839 - lr: 1.0000e-08\n",
      "Epoch 74/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.9691 - output_x_loss: 379.6129 - output_y_loss: 152.2531 - output_z_loss: 411.1134 - output_x_msle: 379.6129 - output_y_msle: 152.2531 - output_z_msle: 411.1134 - val_loss: 296.3325 - val_output_x_loss: 381.3829 - val_output_y_loss: 154.0216 - val_output_z_loss: 410.8531 - val_output_x_msle: 381.3829 - val_output_y_msle: 154.0216 - val_output_z_msle: 410.8531 - lr: 1.0000e-08\n",
      "Epoch 75/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.9507 - output_x_loss: 379.6048 - output_y_loss: 152.2332 - output_z_loss: 411.0772 - output_x_msle: 379.6048 - output_y_msle: 152.2332 - output_z_msle: 411.0772 - val_loss: 296.3199 - val_output_x_loss: 381.3750 - val_output_y_loss: 154.0161 - val_output_z_loss: 410.8174 - val_output_x_msle: 381.3750 - val_output_y_msle: 154.0161 - val_output_z_msle: 410.8174 - lr: 1.0000e-08\n",
      "Epoch 76/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.9226 - output_x_loss: 379.5963 - output_y_loss: 152.1943 - output_z_loss: 411.0319 - output_x_msle: 379.5963 - output_y_msle: 152.1943 - output_z_msle: 411.0319 - val_loss: 296.2489 - val_output_x_loss: 381.2283 - val_output_y_loss: 154.0078 - val_output_z_loss: 410.7724 - val_output_x_msle: 381.2283 - val_output_y_msle: 154.0078 - val_output_z_msle: 410.7724 - lr: 1.0000e-08\n",
      "Epoch 77/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.8937 - output_x_loss: 379.5874 - output_y_loss: 152.1879 - output_z_loss: 410.9175 - output_x_msle: 379.5874 - output_y_msle: 152.1879 - output_z_msle: 410.9175 - val_loss: 296.2160 - val_output_x_loss: 381.2145 - val_output_y_loss: 154.0024 - val_output_z_loss: 410.6463 - val_output_x_msle: 381.2145 - val_output_y_msle: 154.0024 - val_output_z_msle: 410.6463 - lr: 1.0000e-08\n",
      "Epoch 78/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.8448 - output_x_loss: 379.5783 - output_y_loss: 152.1517 - output_z_loss: 410.7635 - output_x_msle: 379.5783 - output_y_msle: 152.1517 - output_z_msle: 410.7635 - val_loss: 296.2016 - val_output_x_loss: 381.2041 - val_output_y_loss: 153.9956 - val_output_z_loss: 410.6080 - val_output_x_msle: 381.2041 - val_output_y_msle: 153.9956 - val_output_z_msle: 410.6080 - lr: 1.0000e-08\n",
      "Epoch 79/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.8258 - output_x_loss: 379.5693 - output_y_loss: 152.1438 - output_z_loss: 410.7028 - output_x_msle: 379.5693 - output_y_msle: 152.1438 - output_z_msle: 410.7028 - val_loss: 296.1873 - val_output_x_loss: 381.1937 - val_output_y_loss: 153.9888 - val_output_z_loss: 410.5715 - val_output_x_msle: 381.1937 - val_output_y_msle: 153.9888 - val_output_z_msle: 410.5715 - lr: 1.0000e-08\n",
      "Epoch 80/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.8061 - output_x_loss: 379.5598 - output_y_loss: 152.1368 - output_z_loss: 410.6371 - output_x_msle: 379.5598 - output_y_msle: 152.1368 - output_z_msle: 410.6371 - val_loss: 296.1684 - val_output_x_loss: 381.1817 - val_output_y_loss: 153.9796 - val_output_z_loss: 410.5194 - val_output_x_msle: 381.1817 - val_output_y_msle: 153.9796 - val_output_z_msle: 410.5194 - lr: 1.0000e-08\n",
      "Epoch 81/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.7737 - output_x_loss: 379.5504 - output_y_loss: 152.1219 - output_z_loss: 410.5237 - output_x_msle: 379.5504 - output_y_msle: 152.1219 - output_z_msle: 410.5237 - val_loss: 296.1429 - val_output_x_loss: 381.1726 - val_output_y_loss: 153.9523 - val_output_z_loss: 410.4648 - val_output_x_msle: 381.1726 - val_output_y_msle: 153.9523 - val_output_z_msle: 410.4648 - lr: 1.0000e-08\n",
      "Epoch 82/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.7421 - output_x_loss: 379.5417 - output_y_loss: 152.1007 - output_z_loss: 410.4255 - output_x_msle: 379.5417 - output_y_msle: 152.1007 - output_z_msle: 410.4255 - val_loss: 296.1323 - val_output_x_loss: 381.1637 - val_output_y_loss: 153.9472 - val_output_z_loss: 410.4393 - val_output_x_msle: 381.1637 - val_output_y_msle: 153.9472 - val_output_z_msle: 410.4393 - lr: 1.0000e-08\n",
      "Epoch 83/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.7334 - output_x_loss: 379.5324 - output_y_loss: 152.0973 - output_z_loss: 410.4071 - output_x_msle: 379.5324 - output_y_msle: 152.0973 - output_z_msle: 410.4071 - val_loss: 296.1230 - val_output_x_loss: 381.1541 - val_output_y_loss: 153.9428 - val_output_z_loss: 410.4211 - val_output_x_msle: 381.1541 - val_output_y_msle: 153.9428 - val_output_z_msle: 410.4211 - lr: 1.0000e-08\n",
      "Epoch 84/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 294.7238 - output_x_loss: 379.5227 - output_y_loss: 152.0943 - output_z_loss: 410.3853 - output_x_msle: 379.5227 - output_y_msle: 152.0943 - output_z_msle: 410.3853 - val_loss: 296.1128 - val_output_x_loss: 381.1442 - val_output_y_loss: 153.9381 - val_output_z_loss: 410.3994 - val_output_x_msle: 381.1442 - val_output_y_msle: 153.9381 - val_output_z_msle: 410.3994 - lr: 1.0000e-08\n",
      "Epoch 85/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.7130 - output_x_loss: 379.5124 - output_y_loss: 152.0913 - output_z_loss: 410.3580 - output_x_msle: 379.5124 - output_y_msle: 152.0913 - output_z_msle: 410.3580 - val_loss: 296.1013 - val_output_x_loss: 381.1340 - val_output_y_loss: 153.9330 - val_output_z_loss: 410.3724 - val_output_x_msle: 381.1340 - val_output_y_msle: 153.9330 - val_output_z_msle: 410.3724 - lr: 1.0000e-08\n",
      "Epoch 86/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6985 - output_x_loss: 379.5017 - output_y_loss: 152.0883 - output_z_loss: 410.3135 - output_x_msle: 379.5017 - output_y_msle: 152.0883 - output_z_msle: 410.3135 - val_loss: 296.0892 - val_output_x_loss: 381.1228 - val_output_y_loss: 153.9272 - val_output_z_loss: 410.3459 - val_output_x_msle: 381.1228 - val_output_y_msle: 153.9272 - val_output_z_msle: 410.3459 - lr: 1.0000e-08\n",
      "Epoch 87/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6831 - output_x_loss: 379.4907 - output_y_loss: 152.0851 - output_z_loss: 410.2643 - output_x_msle: 379.4907 - output_y_msle: 152.0851 - output_z_msle: 410.2643 - val_loss: 296.0749 - val_output_x_loss: 381.1118 - val_output_y_loss: 153.9196 - val_output_z_loss: 410.3118 - val_output_x_msle: 381.1118 - val_output_y_msle: 153.9196 - val_output_z_msle: 410.3118 - lr: 1.0000e-08\n",
      "Epoch 88/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6675 - output_x_loss: 379.4789 - output_y_loss: 152.0817 - output_z_loss: 410.2162 - output_x_msle: 379.4789 - output_y_msle: 152.0817 - output_z_msle: 410.2162 - val_loss: 296.0599 - val_output_x_loss: 381.0995 - val_output_y_loss: 153.9095 - val_output_z_loss: 410.2812 - val_output_x_msle: 381.0995 - val_output_y_msle: 153.9095 - val_output_z_msle: 410.2812 - lr: 1.0000e-08\n",
      "Epoch 89/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6516 - output_x_loss: 379.4668 - output_y_loss: 152.0781 - output_z_loss: 410.1682 - output_x_msle: 379.4668 - output_y_msle: 152.0781 - output_z_msle: 410.1682 - val_loss: 296.0222 - val_output_x_loss: 381.0873 - val_output_y_loss: 153.8446 - val_output_z_loss: 410.2474 - val_output_x_msle: 381.0873 - val_output_y_msle: 153.8446 - val_output_z_msle: 410.2474 - lr: 1.0000e-08\n",
      "Epoch 90/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6375 - output_x_loss: 379.4538 - output_y_loss: 152.0743 - output_z_loss: 410.1314 - output_x_msle: 379.4538 - output_y_msle: 152.0743 - output_z_msle: 410.1314 - val_loss: 296.0065 - val_output_x_loss: 381.0740 - val_output_y_loss: 153.8397 - val_output_z_loss: 410.2049 - val_output_x_msle: 381.0740 - val_output_y_msle: 153.8397 - val_output_z_msle: 410.2049 - lr: 1.0000e-08\n",
      "Epoch 91/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6162 - output_x_loss: 379.4406 - output_y_loss: 152.0703 - output_z_loss: 410.0590 - output_x_msle: 379.4406 - output_y_msle: 152.0703 - output_z_msle: 410.0590 - val_loss: 295.9886 - val_output_x_loss: 381.0606 - val_output_y_loss: 153.8346 - val_output_z_loss: 410.1526 - val_output_x_msle: 381.0606 - val_output_y_msle: 153.8346 - val_output_z_msle: 410.1526 - lr: 1.0000e-08\n",
      "Epoch 92/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.6013 - output_x_loss: 379.4265 - output_y_loss: 152.0659 - output_z_loss: 410.0213 - output_x_msle: 379.4265 - output_y_msle: 152.0659 - output_z_msle: 410.0213 - val_loss: 295.9567 - val_output_x_loss: 381.0464 - val_output_y_loss: 153.8291 - val_output_z_loss: 410.0330 - val_output_x_msle: 381.0464 - val_output_y_msle: 153.8291 - val_output_z_msle: 410.0330 - lr: 1.0000e-08\n",
      "Epoch 93/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.5838 - output_x_loss: 379.4118 - output_y_loss: 152.0610 - output_z_loss: 409.9731 - output_x_msle: 379.4118 - output_y_msle: 152.0610 - output_z_msle: 409.9731 - val_loss: 295.9225 - val_output_x_loss: 381.0316 - val_output_y_loss: 153.8225 - val_output_z_loss: 409.9040 - val_output_x_msle: 381.0316 - val_output_y_msle: 153.8225 - val_output_z_msle: 409.9040 - lr: 1.0000e-08\n",
      "Epoch 94/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.5574 - output_x_loss: 379.3974 - output_y_loss: 152.0556 - output_z_loss: 409.8810 - output_x_msle: 379.3974 - output_y_msle: 152.0556 - output_z_msle: 409.8810 - val_loss: 295.9024 - val_output_x_loss: 381.0171 - val_output_y_loss: 153.8156 - val_output_z_loss: 409.8466 - val_output_x_msle: 381.0171 - val_output_y_msle: 153.8156 - val_output_z_msle: 409.8466 - lr: 1.0000e-08\n",
      "Epoch 95/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.5303 - output_x_loss: 379.3825 - output_y_loss: 152.0497 - output_z_loss: 409.7867 - output_x_msle: 379.3825 - output_y_msle: 152.0497 - output_z_msle: 409.7867 - val_loss: 295.8754 - val_output_x_loss: 381.0019 - val_output_y_loss: 153.8076 - val_output_z_loss: 409.7579 - val_output_x_msle: 381.0019 - val_output_y_msle: 153.8076 - val_output_z_msle: 409.7579 - lr: 1.0000e-08\n",
      "Epoch 96/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.5034 - output_x_loss: 379.3669 - output_y_loss: 152.0430 - output_z_loss: 409.6968 - output_x_msle: 379.3669 - output_y_msle: 152.0430 - output_z_msle: 409.6968 - val_loss: 295.8269 - val_output_x_loss: 380.9861 - val_output_y_loss: 153.7984 - val_output_z_loss: 409.5653 - val_output_x_msle: 380.9861 - val_output_y_msle: 153.7984 - val_output_z_msle: 409.5653 - lr: 1.0000e-08\n",
      "Epoch 97/500\n",
      "165/165 [==============================] - ETA: 0s - loss: 294.4475 - output_x_loss: 379.4427 - output_y_loss: 151.8442 - output_z_loss: 409.6635 - output_x_msle: 379.4427 - output_y_msle: 151.8442 - output_z_msle: 409.663 - 1s 5ms/step - loss: 294.4001 - output_x_loss: 379.3509 - output_y_loss: 151.8338 - output_z_loss: 409.6306 - output_x_msle: 379.3509 - output_y_msle: 151.8338 - output_z_msle: 409.6306 - val_loss: 295.8062 - val_output_x_loss: 380.9699 - val_output_y_loss: 153.7916 - val_output_z_loss: 409.5078 - val_output_x_msle: 380.9699 - val_output_y_msle: 153.7916 - val_output_z_msle: 409.5078 - lr: 1.0000e-08\n",
      "Epoch 98/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.3342 - output_x_loss: 379.3352 - output_y_loss: 151.7511 - output_z_loss: 409.4989 - output_x_msle: 379.3352 - output_y_msle: 151.7511 - output_z_msle: 409.4989 - val_loss: 295.7858 - val_output_x_loss: 380.9551 - val_output_y_loss: 153.7852 - val_output_z_loss: 409.4478 - val_output_x_msle: 380.9551 - val_output_y_msle: 153.7852 - val_output_z_msle: 409.4478 - lr: 1.0000e-08\n",
      "Epoch 99/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.3027 - output_x_loss: 379.3195 - output_y_loss: 151.7447 - output_z_loss: 409.3854 - output_x_msle: 379.3195 - output_y_msle: 151.7447 - output_z_msle: 409.3854 - val_loss: 295.7641 - val_output_x_loss: 380.9394 - val_output_y_loss: 153.7787 - val_output_z_loss: 409.3845 - val_output_x_msle: 380.9394 - val_output_y_msle: 153.7787 - val_output_z_msle: 409.3845 - lr: 1.0000e-08\n",
      "Epoch 100/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.2613 - output_x_loss: 379.3036 - output_y_loss: 151.7077 - output_z_loss: 409.2845 - output_x_msle: 379.3036 - output_y_msle: 151.7077 - output_z_msle: 409.2845 - val_loss: 295.7286 - val_output_x_loss: 380.9240 - val_output_y_loss: 153.7713 - val_output_z_loss: 409.2524 - val_output_x_msle: 380.9240 - val_output_y_msle: 153.7713 - val_output_z_msle: 409.2524 - lr: 1.0000e-08\n",
      "Epoch 101/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.2296 - output_x_loss: 379.2878 - output_y_loss: 151.6992 - output_z_loss: 409.1742 - output_x_msle: 379.2878 - output_y_msle: 151.6992 - output_z_msle: 409.1742 - val_loss: 295.7069 - val_output_x_loss: 380.9082 - val_output_y_loss: 153.7602 - val_output_z_loss: 409.1980 - val_output_x_msle: 380.9082 - val_output_y_msle: 153.7602 - val_output_z_msle: 409.1980 - lr: 1.0000e-08\n",
      "Epoch 102/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.1864 - output_x_loss: 379.2729 - output_y_loss: 151.6619 - output_z_loss: 409.0632 - output_x_msle: 379.2729 - output_y_msle: 151.6619 - output_z_msle: 409.0632 - val_loss: 295.6862 - val_output_x_loss: 380.8942 - val_output_y_loss: 153.7504 - val_output_z_loss: 409.1419 - val_output_x_msle: 380.8942 - val_output_y_msle: 153.7504 - val_output_z_msle: 409.1419 - lr: 1.0000e-08\n",
      "Epoch 103/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.1529 - output_x_loss: 379.2585 - output_y_loss: 151.6346 - output_z_loss: 408.9781 - output_x_msle: 379.2585 - output_y_msle: 151.6346 - output_z_msle: 408.9781 - val_loss: 295.6313 - val_output_x_loss: 380.8798 - val_output_y_loss: 153.6693 - val_output_z_loss: 409.0583 - val_output_x_msle: 380.8798 - val_output_y_msle: 153.6693 - val_output_z_msle: 409.0583 - lr: 1.0000e-08\n",
      "Epoch 104/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.1230 - output_x_loss: 379.2438 - output_y_loss: 151.6279 - output_z_loss: 408.8714 - output_x_msle: 379.2438 - output_y_msle: 151.6279 - output_z_msle: 408.8714 - val_loss: 295.5982 - val_output_x_loss: 380.8648 - val_output_y_loss: 153.6629 - val_output_z_loss: 408.9356 - val_output_x_msle: 380.8648 - val_output_y_msle: 153.6629 - val_output_z_msle: 408.9356 - lr: 1.0000e-08\n",
      "Epoch 105/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.0883 - output_x_loss: 379.2291 - output_y_loss: 151.6189 - output_z_loss: 408.7460 - output_x_msle: 379.2291 - output_y_msle: 151.6189 - output_z_msle: 408.7460 - val_loss: 295.5524 - val_output_x_loss: 380.8506 - val_output_y_loss: 153.6537 - val_output_z_loss: 408.7528 - val_output_x_msle: 380.8506 - val_output_y_msle: 153.6537 - val_output_z_msle: 408.7528 - lr: 1.0000e-08\n",
      "Epoch 106/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.0539 - output_x_loss: 379.2150 - output_y_loss: 151.5934 - output_z_loss: 408.6523 - output_x_msle: 379.2150 - output_y_msle: 151.5934 - output_z_msle: 408.6523 - val_loss: 295.5394 - val_output_x_loss: 380.8367 - val_output_y_loss: 153.6471 - val_output_z_loss: 408.7293 - val_output_x_msle: 380.8367 - val_output_y_msle: 153.6471 - val_output_z_msle: 408.7293 - lr: 1.0000e-08\n",
      "Epoch 107/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.0336 - output_x_loss: 379.2010 - output_y_loss: 151.5836 - output_z_loss: 408.5991 - output_x_msle: 379.2010 - output_y_msle: 151.5836 - output_z_msle: 408.5991 - val_loss: 295.5159 - val_output_x_loss: 380.8229 - val_output_y_loss: 153.6361 - val_output_z_loss: 408.6617 - val_output_x_msle: 380.8229 - val_output_y_msle: 153.6361 - val_output_z_msle: 408.6617 - lr: 1.0000e-08\n",
      "Epoch 108/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.0035 - output_x_loss: 379.1872 - output_y_loss: 151.5578 - output_z_loss: 408.5270 - output_x_msle: 379.1872 - output_y_msle: 151.5578 - output_z_msle: 408.5270 - val_loss: 295.5047 - val_output_x_loss: 380.8094 - val_output_y_loss: 153.6294 - val_output_z_loss: 408.6458 - val_output_x_msle: 380.8094 - val_output_y_msle: 153.6294 - val_output_z_msle: 408.6458 - lr: 1.0000e-08\n",
      "Epoch 109/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.9768 - output_x_loss: 379.1737 - output_y_loss: 151.5127 - output_z_loss: 408.5112 - output_x_msle: 379.1737 - output_y_msle: 151.5127 - output_z_msle: 408.5112 - val_loss: 295.4908 - val_output_x_loss: 380.7957 - val_output_y_loss: 153.6169 - val_output_z_loss: 408.6290 - val_output_x_msle: 380.7957 - val_output_y_msle: 153.6169 - val_output_z_msle: 408.6290 - lr: 1.0000e-08\n",
      "Epoch 110/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.9505 - output_x_loss: 379.1594 - output_y_loss: 151.4691 - output_z_loss: 408.4954 - output_x_msle: 379.1594 - output_y_msle: 151.4691 - output_z_msle: 408.4954 - val_loss: 295.4797 - val_output_x_loss: 380.7817 - val_output_y_loss: 153.6114 - val_output_z_loss: 408.6123 - val_output_x_msle: 380.7817 - val_output_y_msle: 153.6114 - val_output_z_msle: 408.6123 - lr: 1.0000e-08\n",
      "Epoch 111/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.9394 - output_x_loss: 379.1451 - output_y_loss: 151.4638 - output_z_loss: 408.4793 - output_x_msle: 379.1451 - output_y_msle: 151.4638 - output_z_msle: 408.4793 - val_loss: 295.4682 - val_output_x_loss: 380.7672 - val_output_y_loss: 153.6060 - val_output_z_loss: 408.5944 - val_output_x_msle: 380.7672 - val_output_y_msle: 153.6060 - val_output_z_msle: 408.5944 - lr: 1.0000e-08\n",
      "Epoch 112/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.9020 - output_x_loss: 379.1306 - output_y_loss: 151.3932 - output_z_loss: 408.4622 - output_x_msle: 379.1306 - output_y_msle: 151.3932 - output_z_msle: 408.4622 - val_loss: 295.4561 - val_output_x_loss: 380.7539 - val_output_y_loss: 153.5984 - val_output_z_loss: 408.5760 - val_output_x_msle: 380.7539 - val_output_y_msle: 153.5984 - val_output_z_msle: 408.5760 - lr: 1.0000e-08\n",
      "Epoch 113/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8891 - output_x_loss: 379.1176 - output_y_loss: 151.3828 - output_z_loss: 408.4447 - output_x_msle: 379.1176 - output_y_msle: 151.3828 - output_z_msle: 408.4447 - val_loss: 295.4435 - val_output_x_loss: 380.7406 - val_output_y_loss: 153.5902 - val_output_z_loss: 408.5557 - val_output_x_msle: 380.7406 - val_output_y_msle: 153.5902 - val_output_z_msle: 408.5557 - lr: 1.0000e-08\n",
      "Epoch 114/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8748 - output_x_loss: 379.1040 - output_y_loss: 151.3703 - output_z_loss: 408.4259 - output_x_msle: 379.1040 - output_y_msle: 151.3703 - output_z_msle: 408.4259 - val_loss: 295.3701 - val_output_x_loss: 380.5882 - val_output_y_loss: 153.5707 - val_output_z_loss: 408.5327 - val_output_x_msle: 380.5882 - val_output_y_msle: 153.5707 - val_output_z_msle: 408.5327 - lr: 1.0000e-08\n",
      "Epoch 115/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8499 - output_x_loss: 379.0898 - output_y_loss: 151.3314 - output_z_loss: 408.4067 - output_x_msle: 379.0898 - output_y_msle: 151.3314 - output_z_msle: 408.4067 - val_loss: 295.3535 - val_output_x_loss: 380.5682 - val_output_y_loss: 153.5626 - val_output_z_loss: 408.5060 - val_output_x_msle: 380.5682 - val_output_y_msle: 153.5626 - val_output_z_msle: 408.5060 - lr: 1.0000e-08\n",
      "Epoch 116/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8377 - output_x_loss: 379.0753 - output_y_loss: 151.3258 - output_z_loss: 408.3865 - output_x_msle: 379.0753 - output_y_msle: 151.3258 - output_z_msle: 408.3865 - val_loss: 295.3232 - val_output_x_loss: 380.5525 - val_output_y_loss: 153.5507 - val_output_z_loss: 408.4090 - val_output_x_msle: 380.5525 - val_output_y_msle: 153.5507 - val_output_z_msle: 408.4090 - lr: 1.0000e-08\n",
      "Epoch 117/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8248 - output_x_loss: 379.0603 - output_y_loss: 151.3195 - output_z_loss: 408.3649 - output_x_msle: 379.0603 - output_y_msle: 151.3195 - output_z_msle: 408.3649 - val_loss: 295.2226 - val_output_x_loss: 380.5386 - val_output_y_loss: 153.3239 - val_output_z_loss: 408.3878 - val_output_x_msle: 380.5386 - val_output_y_msle: 153.3239 - val_output_z_msle: 408.3878 - lr: 1.0000e-08\n",
      "Epoch 118/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.8110 - output_x_loss: 379.0445 - output_y_loss: 151.3120 - output_z_loss: 408.3415 - output_x_msle: 379.0445 - output_y_msle: 151.3120 - output_z_msle: 408.3415 - val_loss: 295.2060 - val_output_x_loss: 380.5226 - val_output_y_loss: 153.3100 - val_output_z_loss: 408.3646 - val_output_x_msle: 380.5226 - val_output_y_msle: 153.3100 - val_output_z_msle: 408.3646 - lr: 1.0000e-08\n",
      "Epoch 119/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.7839 - output_x_loss: 379.0287 - output_y_loss: 151.2731 - output_z_loss: 408.3165 - output_x_msle: 379.0287 - output_y_msle: 151.2731 - output_z_msle: 408.3165 - val_loss: 295.1928 - val_output_x_loss: 380.5084 - val_output_y_loss: 153.3021 - val_output_z_loss: 408.3428 - val_output_x_msle: 380.5084 - val_output_y_msle: 153.3021 - val_output_z_msle: 408.3428 - lr: 1.0000e-08\n",
      "Epoch 120/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.7525 - output_x_loss: 379.0128 - output_y_loss: 151.2294 - output_z_loss: 408.2779 - output_x_msle: 379.0128 - output_y_msle: 151.2294 - output_z_msle: 408.2779 - val_loss: 295.1797 - val_output_x_loss: 380.4930 - val_output_y_loss: 153.2947 - val_output_z_loss: 408.3227 - val_output_x_msle: 380.4930 - val_output_y_msle: 153.2947 - val_output_z_msle: 408.3227 - lr: 1.0000e-08\n",
      "Epoch 121/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.7384 - output_x_loss: 378.9970 - output_y_loss: 151.2206 - output_z_loss: 408.2571 - output_x_msle: 378.9970 - output_y_msle: 151.2206 - output_z_msle: 408.2571 - val_loss: 295.1637 - val_output_x_loss: 380.4755 - val_output_y_loss: 153.2836 - val_output_z_loss: 408.3002 - val_output_x_msle: 380.4755 - val_output_y_msle: 153.2836 - val_output_z_msle: 408.3002 - lr: 1.0000e-08\n",
      "Epoch 122/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.7182 - output_x_loss: 378.9806 - output_y_loss: 151.1976 - output_z_loss: 408.2343 - output_x_msle: 378.9806 - output_y_msle: 151.1976 - output_z_msle: 408.2343 - val_loss: 295.1496 - val_output_x_loss: 380.4604 - val_output_y_loss: 153.2755 - val_output_z_loss: 408.2760 - val_output_x_msle: 380.4604 - val_output_y_msle: 153.2755 - val_output_z_msle: 408.2760 - lr: 1.0000e-08\n",
      "Epoch 123/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6999 - output_x_loss: 378.9639 - output_y_loss: 151.1892 - output_z_loss: 408.1931 - output_x_msle: 378.9639 - output_y_msle: 151.1892 - output_z_msle: 408.1931 - val_loss: 295.1420 - val_output_x_loss: 380.4675 - val_output_y_loss: 153.2633 - val_output_z_loss: 408.2486 - val_output_x_msle: 380.4675 - val_output_y_msle: 153.2633 - val_output_z_msle: 408.2486 - lr: 1.0000e-08\n",
      "Epoch 124/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6763 - output_x_loss: 378.9463 - output_y_loss: 151.1601 - output_z_loss: 408.1689 - output_x_msle: 378.9463 - output_y_msle: 151.1601 - output_z_msle: 408.1689 - val_loss: 295.1590 - val_output_x_loss: 380.5699 - val_output_y_loss: 153.2477 - val_output_z_loss: 408.1599 - val_output_x_msle: 380.5699 - val_output_y_msle: 153.2477 - val_output_z_msle: 408.1599 - lr: 1.0000e-08\n",
      "Epoch 125/500\n",
      "165/165 [==============================] - ETA: 0s - loss: 294.2824 - output_x_loss: 379.9804 - output_y_loss: 151.6008 - output_z_loss: 408.2497 - output_x_msle: 379.9804 - output_y_msle: 151.6008 - output_z_msle: 408.249 - 1s 5ms/step - loss: 293.6551 - output_x_loss: 378.9285 - output_y_loss: 151.1376 - output_z_loss: 408.1430 - output_x_msle: 378.9285 - output_y_msle: 151.1376 - output_z_msle: 408.1430 - val_loss: 295.1433 - val_output_x_loss: 380.5522 - val_output_y_loss: 153.2386 - val_output_z_loss: 408.1345 - val_output_x_msle: 380.5522 - val_output_y_msle: 153.2386 - val_output_z_msle: 408.1345 - lr: 1.0000e-08\n",
      "Epoch 126/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6382 - output_x_loss: 378.9106 - output_y_loss: 151.1302 - output_z_loss: 408.1097 - output_x_msle: 378.9106 - output_y_msle: 151.1302 - output_z_msle: 408.1097 - val_loss: 295.1246 - val_output_x_loss: 380.5350 - val_output_y_loss: 153.2257 - val_output_z_loss: 408.1018 - val_output_x_msle: 380.5350 - val_output_y_msle: 153.2257 - val_output_z_msle: 408.1018 - lr: 1.0000e-08\n",
      "Epoch 127/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6145 - output_x_loss: 378.8945 - output_y_loss: 151.1083 - output_z_loss: 408.0664 - output_x_msle: 378.8945 - output_y_msle: 151.1083 - output_z_msle: 408.0664 - val_loss: 295.0535 - val_output_x_loss: 380.3764 - val_output_y_loss: 153.2171 - val_output_z_loss: 408.0803 - val_output_x_msle: 380.3764 - val_output_y_msle: 153.2171 - val_output_z_msle: 408.0803 - lr: 1.0000e-08\n",
      "Epoch 128/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6012 - output_x_loss: 378.8786 - output_y_loss: 151.1030 - output_z_loss: 408.0432 - output_x_msle: 378.8786 - output_y_msle: 151.1030 - output_z_msle: 408.0432 - val_loss: 295.0389 - val_output_x_loss: 380.3630 - val_output_y_loss: 153.2060 - val_output_z_loss: 408.0566 - val_output_x_msle: 380.3630 - val_output_y_msle: 153.2060 - val_output_z_msle: 408.0566 - lr: 1.0000e-08\n",
      "Epoch 129/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.5682 - output_x_loss: 378.8640 - output_y_loss: 151.0463 - output_z_loss: 408.0202 - output_x_msle: 378.8640 - output_y_msle: 151.0463 - output_z_msle: 408.0202 - val_loss: 295.0154 - val_output_x_loss: 380.3419 - val_output_y_loss: 153.1791 - val_output_z_loss: 408.0350 - val_output_x_msle: 380.3419 - val_output_y_msle: 153.1791 - val_output_z_msle: 408.0350 - lr: 1.0000e-08\n",
      "Epoch 130/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.5483 - output_x_loss: 378.8519 - output_y_loss: 151.0187 - output_z_loss: 407.9998 - output_x_msle: 378.8519 - output_y_msle: 151.0187 - output_z_msle: 407.9998 - val_loss: 295.0034 - val_output_x_loss: 380.3284 - val_output_y_loss: 153.1716 - val_output_z_loss: 408.0169 - val_output_x_msle: 380.3284 - val_output_y_msle: 153.1716 - val_output_z_msle: 408.0169 - lr: 1.0000e-08\n",
      "Epoch 131/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.5371 - output_x_loss: 378.8397 - output_y_loss: 151.0149 - output_z_loss: 407.9759 - output_x_msle: 378.8397 - output_y_msle: 151.0149 - output_z_msle: 407.9759 - val_loss: 294.9846 - val_output_x_loss: 380.3157 - val_output_y_loss: 153.1509 - val_output_z_loss: 407.9904 - val_output_x_msle: 380.3157 - val_output_y_msle: 153.1509 - val_output_z_msle: 407.9904 - lr: 1.0000e-08\n",
      "Epoch 132/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.5097 - output_x_loss: 378.8274 - output_y_loss: 150.9768 - output_z_loss: 407.9399 - output_x_msle: 378.8274 - output_y_msle: 150.9768 - output_z_msle: 407.9399 - val_loss: 294.9528 - val_output_x_loss: 380.3023 - val_output_y_loss: 153.0943 - val_output_z_loss: 407.9706 - val_output_x_msle: 380.3023 - val_output_y_msle: 153.0943 - val_output_z_msle: 407.9706 - lr: 1.0000e-08\n",
      "Epoch 133/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.4345 - output_x_loss: 378.6908 - output_y_loss: 150.9355 - output_z_loss: 407.9200 - output_x_msle: 378.6908 - output_y_msle: 150.9355 - output_z_msle: 407.9200 - val_loss: 294.9421 - val_output_x_loss: 380.2914 - val_output_y_loss: 153.0884 - val_output_z_loss: 407.9512 - val_output_x_msle: 380.2914 - val_output_y_msle: 153.0884 - val_output_z_msle: 407.9512 - lr: 1.0000e-08\n",
      "Epoch 134/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3966 - output_x_loss: 378.6787 - output_y_loss: 150.8620 - output_z_loss: 407.9013 - output_x_msle: 378.6787 - output_y_msle: 150.8620 - output_z_msle: 407.9013 - val_loss: 294.9340 - val_output_x_loss: 380.2861 - val_output_y_loss: 153.0831 - val_output_z_loss: 407.9319 - val_output_x_msle: 380.2861 - val_output_y_msle: 153.0831 - val_output_z_msle: 407.9319 - lr: 1.0000e-08\n",
      "Epoch 135/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3710 - output_x_loss: 378.6732 - output_y_loss: 150.8202 - output_z_loss: 407.8681 - output_x_msle: 378.6732 - output_y_msle: 150.8202 - output_z_msle: 407.8681 - val_loss: 294.9249 - val_output_x_loss: 380.2806 - val_output_y_loss: 153.0758 - val_output_z_loss: 407.9117 - val_output_x_msle: 380.2806 - val_output_y_msle: 153.0758 - val_output_z_msle: 407.9117 - lr: 1.0000e-08\n",
      "Epoch 136/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3631 - output_x_loss: 378.6674 - output_y_loss: 150.8151 - output_z_loss: 407.8507 - output_x_msle: 378.6674 - output_y_msle: 150.8151 - output_z_msle: 407.8507 - val_loss: 294.9139 - val_output_x_loss: 380.2747 - val_output_y_loss: 153.0664 - val_output_z_loss: 407.8873 - val_output_x_msle: 380.2747 - val_output_y_msle: 153.0664 - val_output_z_msle: 407.8873 - lr: 1.0000e-08\n",
      "Epoch 137/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3550 - output_x_loss: 378.6613 - output_y_loss: 150.8105 - output_z_loss: 407.8315 - output_x_msle: 378.6613 - output_y_msle: 150.8105 - output_z_msle: 407.8315 - val_loss: 294.8639 - val_output_x_loss: 380.2687 - val_output_y_loss: 152.9917 - val_output_z_loss: 407.7984 - val_output_x_msle: 380.2687 - val_output_y_msle: 152.9917 - val_output_z_msle: 407.7984 - lr: 1.0000e-08\n",
      "Epoch 138/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3457 - output_x_loss: 378.6550 - output_y_loss: 150.8052 - output_z_loss: 407.8087 - output_x_msle: 378.6550 - output_y_msle: 150.8052 - output_z_msle: 407.8087 - val_loss: 294.8543 - val_output_x_loss: 380.2622 - val_output_y_loss: 152.9856 - val_output_z_loss: 407.7757 - val_output_x_msle: 380.2622 - val_output_y_msle: 152.9856 - val_output_z_msle: 407.7757 - lr: 1.0000e-08\n",
      "Epoch 139/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3358 - output_x_loss: 378.6482 - output_y_loss: 150.7993 - output_z_loss: 407.7838 - output_x_msle: 378.6482 - output_y_msle: 150.7993 - output_z_msle: 407.7838 - val_loss: 294.8431 - val_output_x_loss: 380.2554 - val_output_y_loss: 152.9774 - val_output_z_loss: 407.7499 - val_output_x_msle: 380.2554 - val_output_y_msle: 152.9774 - val_output_z_msle: 407.7499 - lr: 1.0000e-08\n",
      "Epoch 140/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3236 - output_x_loss: 378.6411 - output_y_loss: 150.7922 - output_z_loss: 407.7518 - output_x_msle: 378.6411 - output_y_msle: 150.7922 - output_z_msle: 407.7518 - val_loss: 294.8293 - val_output_x_loss: 380.2483 - val_output_y_loss: 152.9659 - val_output_z_loss: 407.7185 - val_output_x_msle: 380.2483 - val_output_y_msle: 152.9659 - val_output_z_msle: 407.7185 - lr: 1.0000e-08\n",
      "Epoch 141/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.3065 - output_x_loss: 378.6334 - output_y_loss: 150.7827 - output_z_loss: 407.7005 - output_x_msle: 378.6334 - output_y_msle: 150.7827 - output_z_msle: 407.7005 - val_loss: 294.8118 - val_output_x_loss: 380.2406 - val_output_y_loss: 152.9462 - val_output_z_loss: 407.6850 - val_output_x_msle: 380.2406 - val_output_y_msle: 152.9462 - val_output_z_msle: 407.6850 - lr: 1.0000e-08\n",
      "Epoch 142/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.2810 - output_x_loss: 378.6254 - output_y_loss: 150.7529 - output_z_loss: 407.6488 - output_x_msle: 378.6254 - output_y_msle: 150.7529 - output_z_msle: 407.6488 - val_loss: 294.7653 - val_output_x_loss: 380.2326 - val_output_y_loss: 152.8555 - val_output_z_loss: 407.6506 - val_output_x_msle: 380.2326 - val_output_y_msle: 152.8555 - val_output_z_msle: 407.6506 - lr: 1.0000e-08\n",
      "Epoch 143/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.2628 - output_x_loss: 378.6170 - output_y_loss: 150.7372 - output_z_loss: 407.6057 - output_x_msle: 378.6170 - output_y_msle: 150.7372 - output_z_msle: 407.6057 - val_loss: 294.7126 - val_output_x_loss: 380.2241 - val_output_y_loss: 152.7583 - val_output_z_loss: 407.5988 - val_output_x_msle: 380.2241 - val_output_y_msle: 152.7583 - val_output_z_msle: 407.5988 - lr: 1.0000e-08\n",
      "Epoch 144/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.2302 - output_x_loss: 378.6081 - output_y_loss: 150.6950 - output_z_loss: 407.5442 - output_x_msle: 378.6081 - output_y_msle: 150.6950 - output_z_msle: 407.5442 - val_loss: 294.6984 - val_output_x_loss: 380.2153 - val_output_y_loss: 152.7492 - val_output_z_loss: 407.5629 - val_output_x_msle: 380.2153 - val_output_y_msle: 152.7492 - val_output_z_msle: 407.5629 - lr: 1.0000e-08\n",
      "Epoch 145/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.2148 - output_x_loss: 378.5988 - output_y_loss: 150.6856 - output_z_loss: 407.5055 - output_x_msle: 378.5988 - output_y_msle: 150.6856 - output_z_msle: 407.5055 - val_loss: 294.6809 - val_output_x_loss: 380.2058 - val_output_y_loss: 152.7357 - val_output_z_loss: 407.5213 - val_output_x_msle: 380.2058 - val_output_y_msle: 152.7357 - val_output_z_msle: 407.5213 - lr: 1.0000e-08\n",
      "Epoch 146/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.1185 - output_x_loss: 378.5889 - output_y_loss: 150.4753 - output_z_loss: 407.4643 - output_x_msle: 378.5889 - output_y_msle: 150.4753 - output_z_msle: 407.4643 - val_loss: 294.5374 - val_output_x_loss: 380.1961 - val_output_y_loss: 152.4038 - val_output_z_loss: 407.4868 - val_output_x_msle: 380.1961 - val_output_y_msle: 152.4038 - val_output_z_msle: 407.4868 - lr: 1.0000e-08\n",
      "Epoch 147/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.0294 - output_x_loss: 378.5793 - output_y_loss: 150.2871 - output_z_loss: 407.4141 - output_x_msle: 378.5793 - output_y_msle: 150.2871 - output_z_msle: 407.4141 - val_loss: 294.5048 - val_output_x_loss: 380.1875 - val_output_y_loss: 152.3973 - val_output_z_loss: 407.3542 - val_output_x_msle: 380.1875 - val_output_y_msle: 152.3973 - val_output_z_msle: 407.3542 - lr: 1.0000e-08\n",
      "Epoch 148/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9972 - output_x_loss: 378.5710 - output_y_loss: 150.2468 - output_z_loss: 407.3509 - output_x_msle: 378.5710 - output_y_msle: 150.2468 - output_z_msle: 407.3509 - val_loss: 294.4966 - val_output_x_loss: 380.1791 - val_output_y_loss: 152.3923 - val_output_z_loss: 407.3403 - val_output_x_msle: 380.1791 - val_output_y_msle: 152.3923 - val_output_z_msle: 407.3403 - lr: 1.0000e-08\n",
      "Epoch 149/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9882 - output_x_loss: 378.5623 - output_y_loss: 150.2409 - output_z_loss: 407.3343 - output_x_msle: 378.5623 - output_y_msle: 150.2409 - output_z_msle: 407.3343 - val_loss: 294.4874 - val_output_x_loss: 380.1704 - val_output_y_loss: 152.3858 - val_output_z_loss: 407.3246 - val_output_x_msle: 380.1704 - val_output_y_msle: 152.3858 - val_output_z_msle: 407.3246 - lr: 1.0000e-08\n",
      "Epoch 150/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9776 - output_x_loss: 378.5532 - output_y_loss: 150.2356 - output_z_loss: 407.3102 - output_x_msle: 378.5532 - output_y_msle: 150.2356 - output_z_msle: 407.3102 - val_loss: 294.4746 - val_output_x_loss: 380.1611 - val_output_y_loss: 152.3740 - val_output_z_loss: 407.3029 - val_output_x_msle: 380.1611 - val_output_y_msle: 152.3740 - val_output_z_msle: 407.3029 - lr: 1.0000e-08\n",
      "Epoch 151/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9644 - output_x_loss: 378.5436 - output_y_loss: 150.2289 - output_z_loss: 407.2770 - output_x_msle: 378.5436 - output_y_msle: 150.2289 - output_z_msle: 407.2770 - val_loss: 294.4373 - val_output_x_loss: 380.1514 - val_output_y_loss: 152.3001 - val_output_z_loss: 407.2835 - val_output_x_msle: 380.1514 - val_output_y_msle: 152.3001 - val_output_z_msle: 407.2835 - lr: 1.0000e-08\n",
      "Epoch 152/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9457 - output_x_loss: 378.5343 - output_y_loss: 150.2071 - output_z_loss: 407.2455 - output_x_msle: 378.5343 - output_y_msle: 150.2071 - output_z_msle: 407.2455 - val_loss: 294.4270 - val_output_x_loss: 380.1429 - val_output_y_loss: 152.2969 - val_output_z_loss: 407.2559 - val_output_x_msle: 380.1429 - val_output_y_msle: 152.2969 - val_output_z_msle: 407.2559 - lr: 1.0000e-08\n",
      "Epoch 153/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9287 - output_x_loss: 378.5254 - output_y_loss: 150.2018 - output_z_loss: 407.1894 - output_x_msle: 378.5254 - output_y_msle: 150.2018 - output_z_msle: 407.1894 - val_loss: 294.4174 - val_output_x_loss: 380.1342 - val_output_y_loss: 152.2935 - val_output_z_loss: 407.2309 - val_output_x_msle: 380.1342 - val_output_y_msle: 152.2935 - val_output_z_msle: 407.2309 - lr: 1.0000e-08\n",
      "Epoch 154/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9164 - output_x_loss: 378.5165 - output_y_loss: 150.1958 - output_z_loss: 407.1579 - output_x_msle: 378.5165 - output_y_msle: 150.1958 - output_z_msle: 407.1579 - val_loss: 294.4093 - val_output_x_loss: 380.1252 - val_output_y_loss: 152.2899 - val_output_z_loss: 407.2167 - val_output_x_msle: 380.1252 - val_output_y_msle: 152.2899 - val_output_z_msle: 407.2167 - lr: 1.0000e-08\n",
      "Epoch 155/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9068 - output_x_loss: 378.5069 - output_y_loss: 150.1882 - output_z_loss: 407.1437 - output_x_msle: 378.5069 - output_y_msle: 150.1882 - output_z_msle: 407.1437 - val_loss: 294.4003 - val_output_x_loss: 380.1155 - val_output_y_loss: 152.2852 - val_output_z_loss: 407.2005 - val_output_x_msle: 380.1155 - val_output_y_msle: 152.2852 - val_output_z_msle: 407.2005 - lr: 1.0000e-08\n",
      "Epoch 156/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.8900 - output_x_loss: 378.4970 - output_y_loss: 150.1640 - output_z_loss: 407.1276 - output_x_msle: 378.4970 - output_y_msle: 150.1640 - output_z_msle: 407.1276 - val_loss: 294.3910 - val_output_x_loss: 380.1052 - val_output_y_loss: 152.2811 - val_output_z_loss: 407.1821 - val_output_x_msle: 380.1052 - val_output_y_msle: 152.2811 - val_output_z_msle: 407.1821 - lr: 1.0000e-08\n",
      "Epoch 157/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.8397 - output_x_loss: 378.4863 - output_y_loss: 150.0577 - output_z_loss: 407.1107 - output_x_msle: 378.4863 - output_y_msle: 150.0577 - output_z_msle: 407.1107 - val_loss: 294.3192 - val_output_x_loss: 380.0945 - val_output_y_loss: 152.1226 - val_output_z_loss: 407.1617 - val_output_x_msle: 380.0945 - val_output_y_msle: 152.1226 - val_output_z_msle: 407.1617 - lr: 1.0000e-08\n",
      "Epoch 158/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.7862 - output_x_loss: 378.4749 - output_y_loss: 149.9448 - output_z_loss: 407.0915 - output_x_msle: 378.4749 - output_y_msle: 149.9448 - output_z_msle: 407.0915 - val_loss: 294.2378 - val_output_x_loss: 380.0841 - val_output_y_loss: 151.9404 - val_output_z_loss: 407.1400 - val_output_x_msle: 380.0841 - val_output_y_msle: 151.9404 - val_output_z_msle: 407.1400 - lr: 1.0000e-08\n",
      "Epoch 159/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.7438 - output_x_loss: 378.4660 - output_y_loss: 149.8556 - output_z_loss: 407.0761 - output_x_msle: 378.4660 - output_y_msle: 149.8556 - output_z_msle: 407.0761 - val_loss: 294.2274 - val_output_x_loss: 380.0763 - val_output_y_loss: 151.9367 - val_output_z_loss: 407.1112 - val_output_x_msle: 380.0763 - val_output_y_msle: 151.9367 - val_output_z_msle: 407.1112 - lr: 1.0000e-08\n",
      "Epoch 160/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.7271 - output_x_loss: 378.4578 - output_y_loss: 149.8313 - output_z_loss: 407.0580 - output_x_msle: 378.4578 - output_y_msle: 149.8313 - output_z_msle: 407.0580 - val_loss: 294.2067 - val_output_x_loss: 380.0680 - val_output_y_loss: 151.9328 - val_output_z_loss: 407.0318 - val_output_x_msle: 380.0680 - val_output_y_msle: 151.9328 - val_output_z_msle: 407.0318 - lr: 1.0000e-08\n",
      "Epoch 161/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.7104 - output_x_loss: 378.4492 - output_y_loss: 149.8099 - output_z_loss: 407.0339 - output_x_msle: 378.4492 - output_y_msle: 149.8099 - output_z_msle: 407.0339 - val_loss: 294.1977 - val_output_x_loss: 380.0594 - val_output_y_loss: 151.9295 - val_output_z_loss: 407.0108 - val_output_x_msle: 380.0594 - val_output_y_msle: 151.9295 - val_output_z_msle: 407.0108 - lr: 1.0000e-08\n",
      "Epoch 162/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6978 - output_x_loss: 378.4404 - output_y_loss: 149.8049 - output_z_loss: 406.9986 - output_x_msle: 378.4404 - output_y_msle: 149.8049 - output_z_msle: 406.9986 - val_loss: 294.1889 - val_output_x_loss: 380.0505 - val_output_y_loss: 151.9259 - val_output_z_loss: 406.9916 - val_output_x_msle: 380.0505 - val_output_y_msle: 151.9259 - val_output_z_msle: 406.9916 - lr: 1.0000e-08\n",
      "Epoch 163/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6870 - output_x_loss: 378.4309 - output_y_loss: 149.7985 - output_z_loss: 406.9767 - output_x_msle: 378.4309 - output_y_msle: 149.7985 - output_z_msle: 406.9767 - val_loss: 294.1790 - val_output_x_loss: 380.0410 - val_output_y_loss: 151.9214 - val_output_z_loss: 406.9702 - val_output_x_msle: 380.0410 - val_output_y_msle: 151.9214 - val_output_z_msle: 406.9702 - lr: 1.0000e-08\n",
      "Epoch 164/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6738 - output_x_loss: 378.4211 - output_y_loss: 149.7884 - output_z_loss: 406.9499 - output_x_msle: 378.4211 - output_y_msle: 149.7884 - output_z_msle: 406.9499 - val_loss: 294.1664 - val_output_x_loss: 380.0309 - val_output_y_loss: 151.9118 - val_output_z_loss: 406.9468 - val_output_x_msle: 380.0309 - val_output_y_msle: 151.9118 - val_output_z_msle: 406.9468 - lr: 1.0000e-08\n",
      "Epoch 165/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6543 - output_x_loss: 378.4107 - output_y_loss: 149.7630 - output_z_loss: 406.9236 - output_x_msle: 378.4107 - output_y_msle: 149.7630 - output_z_msle: 406.9236 - val_loss: 294.1554 - val_output_x_loss: 380.0207 - val_output_y_loss: 151.9078 - val_output_z_loss: 406.9202 - val_output_x_msle: 380.0207 - val_output_y_msle: 151.9078 - val_output_z_msle: 406.9202 - lr: 1.0000e-08\n",
      "Epoch 166/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6368 - output_x_loss: 378.4000 - output_y_loss: 149.7517 - output_z_loss: 406.8811 - output_x_msle: 378.4000 - output_y_msle: 149.7517 - output_z_msle: 406.8811 - val_loss: 294.1407 - val_output_x_loss: 380.0100 - val_output_y_loss: 151.9017 - val_output_z_loss: 406.8802 - val_output_x_msle: 380.0100 - val_output_y_msle: 151.9017 - val_output_z_msle: 406.8802 - lr: 1.0000e-08\n",
      "Epoch 167/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.5851 - output_x_loss: 378.3891 - output_y_loss: 149.6938 - output_z_loss: 406.7590 - output_x_msle: 378.3891 - output_y_msle: 149.6938 - output_z_msle: 406.7590 - val_loss: 294.1292 - val_output_x_loss: 379.9991 - val_output_y_loss: 151.8981 - val_output_z_loss: 406.8515 - val_output_x_msle: 379.9991 - val_output_y_msle: 151.8981 - val_output_z_msle: 406.8515 - lr: 1.0000e-08\n",
      "Epoch 168/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.5732 - output_x_loss: 378.3777 - output_y_loss: 149.6893 - output_z_loss: 406.7321 - output_x_msle: 378.3777 - output_y_msle: 149.6893 - output_z_msle: 406.7321 - val_loss: 294.1177 - val_output_x_loss: 379.9877 - val_output_y_loss: 151.8946 - val_output_z_loss: 406.8240 - val_output_x_msle: 379.9877 - val_output_y_msle: 151.8946 - val_output_z_msle: 406.8240 - lr: 1.0000e-08\n",
      "Epoch 169/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.5599 - output_x_loss: 378.3660 - output_y_loss: 149.6829 - output_z_loss: 406.7022 - output_x_msle: 378.3660 - output_y_msle: 149.6829 - output_z_msle: 406.7022 - val_loss: 294.1049 - val_output_x_loss: 379.9757 - val_output_y_loss: 151.8898 - val_output_z_loss: 406.7933 - val_output_x_msle: 379.9757 - val_output_y_msle: 151.8898 - val_output_z_msle: 406.7933 - lr: 1.0000e-08\n",
      "Epoch 170/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.5424 - output_x_loss: 378.3535 - output_y_loss: 149.6784 - output_z_loss: 406.6485 - output_x_msle: 378.3535 - output_y_msle: 149.6784 - output_z_msle: 406.6485 - val_loss: 294.0890 - val_output_x_loss: 379.9637 - val_output_y_loss: 151.8799 - val_output_z_loss: 406.7579 - val_output_x_msle: 379.9637 - val_output_y_msle: 151.8799 - val_output_z_msle: 406.7579 - lr: 1.0000e-08\n",
      "Epoch 171/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.5164 - output_x_loss: 378.3410 - output_y_loss: 149.6424 - output_z_loss: 406.6151 - output_x_msle: 378.3410 - output_y_msle: 149.6424 - output_z_msle: 406.6151 - val_loss: 294.0758 - val_output_x_loss: 379.9511 - val_output_y_loss: 151.8759 - val_output_z_loss: 406.7249 - val_output_x_msle: 379.9511 - val_output_y_msle: 151.8759 - val_output_z_msle: 406.7249 - lr: 1.0000e-08\n",
      "Epoch 172/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.4981 - output_x_loss: 378.3282 - output_y_loss: 149.6287 - output_z_loss: 406.5769 - output_x_msle: 378.3282 - output_y_msle: 149.6287 - output_z_msle: 406.5769 - val_loss: 294.0594 - val_output_x_loss: 379.9384 - val_output_y_loss: 151.8676 - val_output_z_loss: 406.6847 - val_output_x_msle: 379.9384 - val_output_y_msle: 151.8676 - val_output_z_msle: 406.6847 - lr: 1.0000e-08\n",
      "Epoch 173/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.4612 - output_x_loss: 378.3152 - output_y_loss: 149.5707 - output_z_loss: 406.5338 - output_x_msle: 378.3152 - output_y_msle: 149.5707 - output_z_msle: 406.5338 - val_loss: 294.0439 - val_output_x_loss: 379.9256 - val_output_y_loss: 151.8615 - val_output_z_loss: 406.6450 - val_output_x_msle: 379.9256 - val_output_y_msle: 151.8615 - val_output_z_msle: 406.6450 - lr: 1.0000e-08\n",
      "Epoch 174/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.4346 - output_x_loss: 378.3018 - output_y_loss: 149.5490 - output_z_loss: 406.4710 - output_x_msle: 378.3018 - output_y_msle: 149.5490 - output_z_msle: 406.4710 - val_loss: 294.0279 - val_output_x_loss: 379.9124 - val_output_y_loss: 151.8561 - val_output_z_loss: 406.6023 - val_output_x_msle: 379.9124 - val_output_y_msle: 151.8561 - val_output_z_msle: 406.6023 - lr: 1.0000e-08\n",
      "Epoch 175/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.4148 - output_x_loss: 378.2882 - output_y_loss: 149.5433 - output_z_loss: 406.4103 - output_x_msle: 378.2882 - output_y_msle: 149.5433 - output_z_msle: 406.4103 - val_loss: 294.0112 - val_output_x_loss: 379.8989 - val_output_y_loss: 151.8506 - val_output_z_loss: 406.5572 - val_output_x_msle: 379.8989 - val_output_y_msle: 151.8506 - val_output_z_msle: 406.5572 - lr: 1.0000e-08\n",
      "Epoch 176/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.3853 - output_x_loss: 378.2742 - output_y_loss: 149.5179 - output_z_loss: 406.3419 - output_x_msle: 378.2742 - output_y_msle: 149.5179 - output_z_msle: 406.3419 - val_loss: 293.9910 - val_output_x_loss: 379.8848 - val_output_y_loss: 151.8393 - val_output_z_loss: 406.5068 - val_output_x_msle: 379.8848 - val_output_y_msle: 151.8393 - val_output_z_msle: 406.5068 - lr: 1.0000e-08\n",
      "Epoch 177/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.3490 - output_x_loss: 378.2604 - output_y_loss: 149.4787 - output_z_loss: 406.2671 - output_x_msle: 378.2604 - output_y_msle: 149.4787 - output_z_msle: 406.2671 - val_loss: 293.9708 - val_output_x_loss: 379.8722 - val_output_y_loss: 151.8299 - val_output_z_loss: 406.4495 - val_output_x_msle: 379.8722 - val_output_y_msle: 151.8299 - val_output_z_msle: 406.4495 - lr: 1.0000e-08\n",
      "Epoch 178/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.3239 - output_x_loss: 378.2477 - output_y_loss: 149.4586 - output_z_loss: 406.2066 - output_x_msle: 378.2477 - output_y_msle: 149.4586 - output_z_msle: 406.2066 - val_loss: 293.9559 - val_output_x_loss: 379.8599 - val_output_y_loss: 151.8248 - val_output_z_loss: 406.4102 - val_output_x_msle: 379.8599 - val_output_y_msle: 151.8248 - val_output_z_msle: 406.4102 - lr: 1.0000e-08\n",
      "Epoch 179/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.3093 - output_x_loss: 378.2352 - output_y_loss: 149.4543 - output_z_loss: 406.1671 - output_x_msle: 378.2352 - output_y_msle: 149.4543 - output_z_msle: 406.1671 - val_loss: 293.9399 - val_output_x_loss: 379.8471 - val_output_y_loss: 151.8206 - val_output_z_loss: 406.3643 - val_output_x_msle: 379.8471 - val_output_y_msle: 151.8206 - val_output_z_msle: 406.3643 - lr: 1.0000e-08\n",
      "Epoch 180/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.2929 - output_x_loss: 378.2218 - output_y_loss: 149.4505 - output_z_loss: 406.1198 - output_x_msle: 378.2218 - output_y_msle: 149.4505 - output_z_msle: 406.1198 - val_loss: 293.9218 - val_output_x_loss: 379.8339 - val_output_y_loss: 151.8164 - val_output_z_loss: 406.3083 - val_output_x_msle: 379.8339 - val_output_y_msle: 151.8164 - val_output_z_msle: 406.3083 - lr: 1.0000e-08\n",
      "Epoch 181/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.2730 - output_x_loss: 378.2081 - output_y_loss: 149.4467 - output_z_loss: 406.0551 - output_x_msle: 378.2081 - output_y_msle: 149.4467 - output_z_msle: 406.0551 - val_loss: 293.8885 - val_output_x_loss: 379.8203 - val_output_y_loss: 151.8119 - val_output_z_loss: 406.1781 - val_output_x_msle: 379.8203 - val_output_y_msle: 151.8119 - val_output_z_msle: 406.1781 - lr: 1.0000e-08\n",
      "Epoch 182/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.2382 - output_x_loss: 378.1941 - output_y_loss: 149.4084 - output_z_loss: 405.9863 - output_x_msle: 378.1941 - output_y_msle: 149.4084 - output_z_msle: 405.9863 - val_loss: 293.8676 - val_output_x_loss: 379.8062 - val_output_y_loss: 151.8056 - val_output_z_loss: 406.1143 - val_output_x_msle: 379.8062 - val_output_y_msle: 151.8056 - val_output_z_msle: 406.1143 - lr: 1.0000e-08\n",
      "Epoch 183/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.2152 - output_x_loss: 378.1795 - output_y_loss: 149.4003 - output_z_loss: 405.9164 - output_x_msle: 378.1795 - output_y_msle: 149.4003 - output_z_msle: 405.9164 - val_loss: 293.8499 - val_output_x_loss: 379.7916 - val_output_y_loss: 151.8008 - val_output_z_loss: 406.0645 - val_output_x_msle: 379.7916 - val_output_y_msle: 151.8008 - val_output_z_msle: 406.0645 - lr: 1.0000e-08\n",
      "Epoch 184/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.1764 - output_x_loss: 378.1645 - output_y_loss: 149.3542 - output_z_loss: 405.8444 - output_x_msle: 378.1645 - output_y_msle: 149.3542 - output_z_msle: 405.8444 - val_loss: 293.8349 - val_output_x_loss: 379.7772 - val_output_y_loss: 151.8017 - val_output_z_loss: 406.0169 - val_output_x_msle: 379.7772 - val_output_y_msle: 151.8017 - val_output_z_msle: 406.0169 - lr: 1.0000e-08\n",
      "Epoch 185/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.1235 - output_x_loss: 378.1501 - output_y_loss: 149.2707 - output_z_loss: 405.7761 - output_x_msle: 378.1501 - output_y_msle: 149.2707 - output_z_msle: 405.7761 - val_loss: 293.7635 - val_output_x_loss: 379.7643 - val_output_y_loss: 151.6502 - val_output_z_loss: 405.9886 - val_output_x_msle: 379.7643 - val_output_y_msle: 151.6502 - val_output_z_msle: 405.9886 - lr: 1.0000e-08\n",
      "Epoch 186/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.1092 - output_x_loss: 378.1389 - output_y_loss: 149.2592 - output_z_loss: 405.7503 - output_x_msle: 378.1389 - output_y_msle: 149.2592 - output_z_msle: 405.7503 - val_loss: 293.7512 - val_output_x_loss: 379.7541 - val_output_y_loss: 151.6427 - val_output_z_loss: 405.9626 - val_output_x_msle: 379.7541 - val_output_y_msle: 151.6427 - val_output_z_msle: 405.9626 - lr: 1.0000e-08\n",
      "Epoch 187/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0943 - output_x_loss: 378.1284 - output_y_loss: 149.2448 - output_z_loss: 405.7254 - output_x_msle: 378.1284 - output_y_msle: 149.2448 - output_z_msle: 405.7254 - val_loss: 293.7411 - val_output_x_loss: 379.7435 - val_output_y_loss: 151.6411 - val_output_z_loss: 405.9366 - val_output_x_msle: 379.7435 - val_output_y_msle: 151.6411 - val_output_z_msle: 405.9366 - lr: 1.0000e-08\n",
      "Epoch 188/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0840 - output_x_loss: 378.1175 - output_y_loss: 149.2435 - output_z_loss: 405.6982 - output_x_msle: 378.1175 - output_y_msle: 149.2435 - output_z_msle: 405.6982 - val_loss: 293.7303 - val_output_x_loss: 379.7326 - val_output_y_loss: 151.6392 - val_output_z_loss: 405.9076 - val_output_x_msle: 379.7326 - val_output_y_msle: 151.6392 - val_output_z_msle: 405.9076 - lr: 1.0000e-08\n",
      "Epoch 189/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0725 - output_x_loss: 378.1062 - output_y_loss: 149.2420 - output_z_loss: 405.6660 - output_x_msle: 378.1062 - output_y_msle: 149.2420 - output_z_msle: 405.6660 - val_loss: 293.7179 - val_output_x_loss: 379.7213 - val_output_y_loss: 151.6371 - val_output_z_loss: 405.8731 - val_output_x_msle: 379.7213 - val_output_y_msle: 151.6371 - val_output_z_msle: 405.8731 - lr: 1.0000e-08\n",
      "Epoch 190/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0586 - output_x_loss: 378.0948 - output_y_loss: 149.2404 - output_z_loss: 405.6227 - output_x_msle: 378.0948 - output_y_msle: 149.2404 - output_z_msle: 405.6227 - val_loss: 293.7043 - val_output_x_loss: 379.7098 - val_output_y_loss: 151.6344 - val_output_z_loss: 405.8330 - val_output_x_msle: 379.7098 - val_output_y_msle: 151.6344 - val_output_z_msle: 405.8330 - lr: 1.0000e-08\n",
      "Epoch 191/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0308 - output_x_loss: 378.0829 - output_y_loss: 149.2053 - output_z_loss: 405.5774 - output_x_msle: 378.0829 - output_y_msle: 149.2053 - output_z_msle: 405.5774 - val_loss: 293.6928 - val_output_x_loss: 379.6980 - val_output_y_loss: 151.6320 - val_output_z_loss: 405.8041 - val_output_x_msle: 379.6980 - val_output_y_msle: 151.6320 - val_output_z_msle: 405.8041 - lr: 1.0000e-08\n",
      "Epoch 192/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0157 - output_x_loss: 378.0707 - output_y_loss: 149.2023 - output_z_loss: 405.5319 - output_x_msle: 378.0707 - output_y_msle: 149.2023 - output_z_msle: 405.5319 - val_loss: 293.6809 - val_output_x_loss: 379.6859 - val_output_y_loss: 151.6296 - val_output_z_loss: 405.7737 - val_output_x_msle: 379.6859 - val_output_y_msle: 151.6296 - val_output_z_msle: 405.7737 - lr: 1.0000e-08\n",
      "Epoch 193/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.0032 - output_x_loss: 378.0586 - output_y_loss: 149.2006 - output_z_loss: 405.4980 - output_x_msle: 378.0586 - output_y_msle: 149.2006 - output_z_msle: 405.4980 - val_loss: 293.6670 - val_output_x_loss: 379.6737 - val_output_y_loss: 151.6263 - val_output_z_loss: 405.7349 - val_output_x_msle: 379.6737 - val_output_y_msle: 151.6263 - val_output_z_msle: 405.7349 - lr: 1.0000e-08\n",
      "Epoch 194/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9853 - output_x_loss: 378.0459 - output_y_loss: 149.1986 - output_z_loss: 405.4373 - output_x_msle: 378.0459 - output_y_msle: 149.1986 - output_z_msle: 405.4373 - val_loss: 293.6489 - val_output_x_loss: 379.6613 - val_output_y_loss: 151.6215 - val_output_z_loss: 405.6788 - val_output_x_msle: 379.6613 - val_output_y_msle: 151.6215 - val_output_z_msle: 405.6788 - lr: 1.0000e-08\n",
      "Epoch 195/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9613 - output_x_loss: 378.0335 - output_y_loss: 149.1965 - output_z_loss: 405.3464 - output_x_msle: 378.0335 - output_y_msle: 149.1965 - output_z_msle: 405.3464 - val_loss: 293.6346 - val_output_x_loss: 379.6489 - val_output_y_loss: 151.6171 - val_output_z_loss: 405.6413 - val_output_x_msle: 379.6489 - val_output_y_msle: 151.6171 - val_output_z_msle: 405.6413 - lr: 1.0000e-08\n",
      "Epoch 196/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9472 - output_x_loss: 378.0208 - output_y_loss: 149.1944 - output_z_loss: 405.3048 - output_x_msle: 378.0208 - output_y_msle: 149.1944 - output_z_msle: 405.3048 - val_loss: 293.6206 - val_output_x_loss: 379.6360 - val_output_y_loss: 151.6125 - val_output_z_loss: 405.6060 - val_output_x_msle: 379.6360 - val_output_y_msle: 151.6125 - val_output_z_msle: 405.6060 - lr: 1.0000e-08\n",
      "Epoch 197/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9363 - output_x_loss: 378.0073 - output_y_loss: 149.1924 - output_z_loss: 405.2819 - output_x_msle: 378.0073 - output_y_msle: 149.1924 - output_z_msle: 405.2819 - val_loss: 293.5929 - val_output_x_loss: 379.6228 - val_output_y_loss: 151.6059 - val_output_z_loss: 405.5069 - val_output_x_msle: 379.6228 - val_output_y_msle: 151.6059 - val_output_z_msle: 405.5069 - lr: 1.0000e-08\n",
      "Epoch 198/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9247 - output_x_loss: 377.9937 - output_y_loss: 149.1902 - output_z_loss: 405.2561 - output_x_msle: 377.9937 - output_y_msle: 149.1902 - output_z_msle: 405.2561 - val_loss: 293.5737 - val_output_x_loss: 379.6089 - val_output_y_loss: 151.5893 - val_output_z_loss: 405.4722 - val_output_x_msle: 379.6089 - val_output_y_msle: 151.5893 - val_output_z_msle: 405.4722 - lr: 1.0000e-08\n",
      "Epoch 199/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9123 - output_x_loss: 377.9794 - output_y_loss: 149.1876 - output_z_loss: 405.2271 - output_x_msle: 377.9794 - output_y_msle: 149.1876 - output_z_msle: 405.2271 - val_loss: 293.5235 - val_output_x_loss: 379.5948 - val_output_y_loss: 151.5328 - val_output_z_loss: 405.3621 - val_output_x_msle: 379.5948 - val_output_y_msle: 151.5328 - val_output_z_msle: 405.3621 - lr: 1.0000e-08\n",
      "Epoch 200/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.8987 - output_x_loss: 377.9652 - output_y_loss: 149.1850 - output_z_loss: 405.1933 - output_x_msle: 377.9652 - output_y_msle: 149.1850 - output_z_msle: 405.1933 - val_loss: 293.5095 - val_output_x_loss: 379.5807 - val_output_y_loss: 151.5296 - val_output_z_loss: 405.3272 - val_output_x_msle: 379.5807 - val_output_y_msle: 151.5296 - val_output_z_msle: 405.3272 - lr: 1.0000e-08\n",
      "Epoch 201/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.8807 - output_x_loss: 377.9505 - output_y_loss: 149.1820 - output_z_loss: 405.1392 - output_x_msle: 377.9505 - output_y_msle: 149.1820 - output_z_msle: 405.1392 - val_loss: 293.4946 - val_output_x_loss: 379.5659 - val_output_y_loss: 151.5261 - val_output_z_loss: 405.2887 - val_output_x_msle: 379.5659 - val_output_y_msle: 151.5261 - val_output_z_msle: 405.2887 - lr: 1.0000e-08\n",
      "Epoch 202/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.8646 - output_x_loss: 377.9355 - output_y_loss: 149.1788 - output_z_loss: 405.0949 - output_x_msle: 377.9355 - output_y_msle: 149.1788 - output_z_msle: 405.0949 - val_loss: 293.4770 - val_output_x_loss: 379.5509 - val_output_y_loss: 151.5222 - val_output_z_loss: 405.2392 - val_output_x_msle: 379.5509 - val_output_y_msle: 151.5222 - val_output_z_msle: 405.2392 - lr: 1.0000e-08\n",
      "Epoch 203/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.8433 - output_x_loss: 377.9201 - output_y_loss: 149.1750 - output_z_loss: 405.0258 - output_x_msle: 377.9201 - output_y_msle: 149.1750 - output_z_msle: 405.0258 - val_loss: 293.4540 - val_output_x_loss: 379.5359 - val_output_y_loss: 151.5176 - val_output_z_loss: 405.1628 - val_output_x_msle: 379.5359 - val_output_y_msle: 151.5176 - val_output_z_msle: 405.1628 - lr: 1.0000e-08\n",
      "Epoch 204/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.8181 - output_x_loss: 377.9050 - output_y_loss: 149.1709 - output_z_loss: 404.9388 - output_x_msle: 377.9050 - output_y_msle: 149.1709 - output_z_msle: 404.9388 - val_loss: 293.4223 - val_output_x_loss: 379.5208 - val_output_y_loss: 151.5125 - val_output_z_loss: 405.0450 - val_output_x_msle: 379.5208 - val_output_y_msle: 151.5125 - val_output_z_msle: 405.0450 - lr: 1.0000e-08\n",
      "Epoch 205/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.7937 - output_x_loss: 377.8891 - output_y_loss: 149.1664 - output_z_loss: 404.8573 - output_x_msle: 377.8891 - output_y_msle: 149.1664 - output_z_msle: 404.8573 - val_loss: 293.3879 - val_output_x_loss: 379.5053 - val_output_y_loss: 151.5069 - val_output_z_loss: 404.9156 - val_output_x_msle: 379.5053 - val_output_y_msle: 151.5069 - val_output_z_msle: 404.9156 - lr: 1.0000e-08\n",
      "Epoch 206/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.7747 - output_x_loss: 377.8733 - output_y_loss: 149.1613 - output_z_loss: 404.8038 - output_x_msle: 377.8733 - output_y_msle: 149.1613 - output_z_msle: 404.8038 - val_loss: 293.3661 - val_output_x_loss: 379.4893 - val_output_y_loss: 151.5001 - val_output_z_loss: 404.8519 - val_output_x_msle: 379.4893 - val_output_y_msle: 151.5001 - val_output_z_msle: 404.8519 - lr: 1.0000e-08\n",
      "Epoch 207/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.7484 - output_x_loss: 377.8571 - output_y_loss: 149.1554 - output_z_loss: 404.7170 - output_x_msle: 377.8571 - output_y_msle: 149.1554 - output_z_msle: 404.7170 - val_loss: 293.3286 - val_output_x_loss: 379.4733 - val_output_y_loss: 151.4913 - val_output_z_loss: 404.7139 - val_output_x_msle: 379.4733 - val_output_y_msle: 151.4913 - val_output_z_msle: 404.7139 - lr: 1.0000e-08\n",
      "Epoch 208/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.7077 - output_x_loss: 377.8405 - output_y_loss: 149.1482 - output_z_loss: 404.5614 - output_x_msle: 377.8405 - output_y_msle: 149.1482 - output_z_msle: 404.5614 - val_loss: 293.3036 - val_output_x_loss: 379.4568 - val_output_y_loss: 151.4783 - val_output_z_loss: 404.6476 - val_output_x_msle: 379.4568 - val_output_y_msle: 151.4783 - val_output_z_msle: 404.6476 - lr: 1.0000e-08\n",
      "Epoch 209/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.6748 - output_x_loss: 377.8251 - output_y_loss: 149.1380 - output_z_loss: 404.4480 - output_x_msle: 377.8251 - output_y_msle: 149.1380 - output_z_msle: 404.4480 - val_loss: 293.2290 - val_output_x_loss: 379.4442 - val_output_y_loss: 151.3920 - val_output_z_loss: 404.4727 - val_output_x_msle: 379.4442 - val_output_y_msle: 151.3920 - val_output_z_msle: 404.4727 - lr: 1.0000e-08\n",
      "Epoch 210/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.6261 - output_x_loss: 377.8141 - output_y_loss: 149.0993 - output_z_loss: 404.3043 - output_x_msle: 377.8141 - output_y_msle: 149.0993 - output_z_msle: 404.3043 - val_loss: 293.2153 - val_output_x_loss: 379.4336 - val_output_y_loss: 151.3877 - val_output_z_loss: 404.4341 - val_output_x_msle: 379.4336 - val_output_y_msle: 151.3877 - val_output_z_msle: 404.4341 - lr: 1.0000e-08\n",
      "Epoch 211/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.6108 - output_x_loss: 377.8031 - output_y_loss: 149.0950 - output_z_loss: 404.2578 - output_x_msle: 377.8031 - output_y_msle: 149.0950 - output_z_msle: 404.2578 - val_loss: 293.1984 - val_output_x_loss: 379.4225 - val_output_y_loss: 151.3829 - val_output_z_loss: 404.3813 - val_output_x_msle: 379.4225 - val_output_y_msle: 151.3829 - val_output_z_msle: 404.3813 - lr: 1.0000e-08\n",
      "Epoch 212/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.5815 - output_x_loss: 377.7919 - output_y_loss: 149.0900 - output_z_loss: 404.1440 - output_x_msle: 377.7919 - output_y_msle: 149.0900 - output_z_msle: 404.1440 - val_loss: 293.1832 - val_output_x_loss: 379.4114 - val_output_y_loss: 151.3779 - val_output_z_loss: 404.3372 - val_output_x_msle: 379.4114 - val_output_y_msle: 151.3779 - val_output_z_msle: 404.3372 - lr: 1.0000e-08\n",
      "Epoch 213/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.5665 - output_x_loss: 377.7804 - output_y_loss: 149.0849 - output_z_loss: 404.1021 - output_x_msle: 377.7804 - output_y_msle: 149.0849 - output_z_msle: 404.1021 - val_loss: 293.1656 - val_output_x_loss: 379.3999 - val_output_y_loss: 151.3723 - val_output_z_loss: 404.2838 - val_output_x_msle: 379.3999 - val_output_y_msle: 151.3723 - val_output_z_msle: 404.2838 - lr: 1.0000e-08\n",
      "Epoch 214/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.5219 - output_x_loss: 377.7685 - output_y_loss: 149.0167 - output_z_loss: 404.0399 - output_x_msle: 377.7685 - output_y_msle: 149.0167 - output_z_msle: 404.0399 - val_loss: 293.1335 - val_output_x_loss: 379.3879 - val_output_y_loss: 151.3660 - val_output_z_loss: 404.1598 - val_output_x_msle: 379.3879 - val_output_y_msle: 151.3660 - val_output_z_msle: 404.1598 - lr: 1.0000e-08\n",
      "Epoch 215/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.5028 - output_x_loss: 377.7560 - output_y_loss: 149.0048 - output_z_loss: 403.9925 - output_x_msle: 377.7560 - output_y_msle: 149.0048 - output_z_msle: 403.9925 - val_loss: 293.1172 - val_output_x_loss: 379.3758 - val_output_y_loss: 151.3614 - val_output_z_loss: 404.1117 - val_output_x_msle: 379.3758 - val_output_y_msle: 151.3614 - val_output_z_msle: 404.1117 - lr: 1.0000e-08\n",
      "Epoch 216/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.4809 - output_x_loss: 377.7438 - output_y_loss: 149.0002 - output_z_loss: 403.9167 - output_x_msle: 377.7438 - output_y_msle: 149.0002 - output_z_msle: 403.9167 - val_loss: 293.1022 - val_output_x_loss: 379.3634 - val_output_y_loss: 151.3568 - val_output_z_loss: 404.0708 - val_output_x_msle: 379.3634 - val_output_y_msle: 151.3568 - val_output_z_msle: 404.0708 - lr: 1.0000e-08\n",
      "Epoch 217/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.4617 - output_x_loss: 377.7307 - output_y_loss: 148.9949 - output_z_loss: 403.8574 - output_x_msle: 377.7307 - output_y_msle: 148.9949 - output_z_msle: 403.8574 - val_loss: 293.0843 - val_output_x_loss: 379.3504 - val_output_y_loss: 151.3512 - val_output_z_loss: 404.0183 - val_output_x_msle: 379.3504 - val_output_y_msle: 151.3512 - val_output_z_msle: 404.0183 - lr: 1.0000e-08\n",
      "Epoch 218/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.4240 - output_x_loss: 377.7173 - output_y_loss: 148.9428 - output_z_loss: 403.7996 - output_x_msle: 377.7173 - output_y_msle: 148.9428 - output_z_msle: 403.7996 - val_loss: 293.0006 - val_output_x_loss: 379.2031 - val_output_y_loss: 151.3465 - val_output_z_loss: 403.9040 - val_output_x_msle: 379.2031 - val_output_y_msle: 151.3465 - val_output_z_msle: 403.9040 - lr: 1.0000e-08\n",
      "Epoch 219/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.4060 - output_x_loss: 377.7031 - output_y_loss: 148.9344 - output_z_loss: 403.7545 - output_x_msle: 377.7031 - output_y_msle: 148.9344 - output_z_msle: 403.7545 - val_loss: 293.0361 - val_output_x_loss: 379.3227 - val_output_y_loss: 151.3414 - val_output_z_loss: 403.8526 - val_output_x_msle: 379.3227 - val_output_y_msle: 151.3414 - val_output_z_msle: 403.8526 - lr: 1.0000e-08\n",
      "Epoch 220/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.3845 - output_x_loss: 377.6887 - output_y_loss: 148.9297 - output_z_loss: 403.6862 - output_x_msle: 377.6887 - output_y_msle: 148.9297 - output_z_msle: 403.6862 - val_loss: 293.0166 - val_output_x_loss: 379.3082 - val_output_y_loss: 151.3352 - val_output_z_loss: 403.7959 - val_output_x_msle: 379.3082 - val_output_y_msle: 151.3352 - val_output_z_msle: 403.7959 - lr: 1.0000e-08\n",
      "Epoch 221/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.3615 - output_x_loss: 377.6736 - output_y_loss: 148.9243 - output_z_loss: 403.6118 - output_x_msle: 377.6736 - output_y_msle: 148.9243 - output_z_msle: 403.6118 - val_loss: 292.9796 - val_output_x_loss: 379.2931 - val_output_y_loss: 151.3281 - val_output_z_loss: 403.6552 - val_output_x_msle: 379.2931 - val_output_y_msle: 151.3281 - val_output_z_msle: 403.6552 - lr: 1.0000e-08\n",
      "Epoch 222/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.3352 - output_x_loss: 377.6579 - output_y_loss: 148.9183 - output_z_loss: 403.5233 - output_x_msle: 377.6579 - output_y_msle: 148.9183 - output_z_msle: 403.5233 - val_loss: 292.9596 - val_output_x_loss: 379.2776 - val_output_y_loss: 151.3203 - val_output_z_loss: 403.6023 - val_output_x_msle: 379.2776 - val_output_y_msle: 151.3203 - val_output_z_msle: 403.6023 - lr: 1.0000e-08\n",
      "Epoch 223/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.3121 - output_x_loss: 377.6416 - output_y_loss: 148.9104 - output_z_loss: 403.4565 - output_x_msle: 377.6416 - output_y_msle: 148.9104 - output_z_msle: 403.4565 - val_loss: 292.9388 - val_output_x_loss: 379.2615 - val_output_y_loss: 151.3092 - val_output_z_loss: 403.5524 - val_output_x_msle: 379.2615 - val_output_y_msle: 151.3092 - val_output_z_msle: 403.5524 - lr: 1.0000e-08\n",
      "Epoch 224/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.2877 - output_x_loss: 377.6253 - output_y_loss: 148.8897 - output_z_loss: 403.4081 - output_x_msle: 377.6253 - output_y_msle: 148.8897 - output_z_msle: 403.4081 - val_loss: 292.9189 - val_output_x_loss: 379.2452 - val_output_y_loss: 151.3026 - val_output_z_loss: 403.4990 - val_output_x_msle: 379.2452 - val_output_y_msle: 151.3026 - val_output_z_msle: 403.4990 - lr: 1.0000e-08\n",
      "Epoch 225/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.2678 - output_x_loss: 377.6083 - output_y_loss: 148.8857 - output_z_loss: 403.3507 - output_x_msle: 377.6083 - output_y_msle: 148.8857 - output_z_msle: 403.3507 - val_loss: 292.8938 - val_output_x_loss: 379.2281 - val_output_y_loss: 151.2907 - val_output_z_loss: 403.4314 - val_output_x_msle: 379.2281 - val_output_y_msle: 151.2907 - val_output_z_msle: 403.4314 - lr: 1.0000e-08\n",
      "Epoch 226/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.2424 - output_x_loss: 377.5905 - output_y_loss: 148.8811 - output_z_loss: 403.2682 - output_x_msle: 377.5905 - output_y_msle: 148.8811 - output_z_msle: 403.2682 - val_loss: 292.8409 - val_output_x_loss: 379.2106 - val_output_y_loss: 151.2127 - val_output_z_loss: 403.3578 - val_output_x_msle: 379.2106 - val_output_y_msle: 151.2127 - val_output_z_msle: 403.3578 - lr: 1.0000e-08\n",
      "Epoch 227/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.2139 - output_x_loss: 377.5724 - output_y_loss: 148.8762 - output_z_loss: 403.1721 - output_x_msle: 377.5724 - output_y_msle: 148.8762 - output_z_msle: 403.1721 - val_loss: 292.8024 - val_output_x_loss: 379.1925 - val_output_y_loss: 151.2079 - val_output_z_loss: 403.2110 - val_output_x_msle: 379.1925 - val_output_y_msle: 151.2079 - val_output_z_msle: 403.2110 - lr: 1.0000e-08\n",
      "Epoch 228/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.1893 - output_x_loss: 377.5536 - output_y_loss: 148.8705 - output_z_loss: 403.0987 - output_x_msle: 377.5536 - output_y_msle: 148.8705 - output_z_msle: 403.0987 - val_loss: 292.7748 - val_output_x_loss: 379.1740 - val_output_y_loss: 151.2022 - val_output_z_loss: 403.1217 - val_output_x_msle: 379.1740 - val_output_y_msle: 151.2022 - val_output_z_msle: 403.1217 - lr: 1.0000e-08\n",
      "Epoch 229/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.1575 - output_x_loss: 377.5345 - output_y_loss: 148.8639 - output_z_loss: 402.9909 - output_x_msle: 377.5345 - output_y_msle: 148.8639 - output_z_msle: 402.9909 - val_loss: 292.7331 - val_output_x_loss: 379.1552 - val_output_y_loss: 151.1963 - val_output_z_loss: 402.9622 - val_output_x_msle: 379.1552 - val_output_y_msle: 151.1963 - val_output_z_msle: 402.9622 - lr: 1.0000e-08\n",
      "Epoch 230/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.1306 - output_x_loss: 377.5152 - output_y_loss: 148.8555 - output_z_loss: 402.9115 - output_x_msle: 377.5152 - output_y_msle: 148.8555 - output_z_msle: 402.9115 - val_loss: 292.7053 - val_output_x_loss: 379.1365 - val_output_y_loss: 151.1892 - val_output_z_loss: 402.8752 - val_output_x_msle: 379.1365 - val_output_y_msle: 151.1892 - val_output_z_msle: 402.8752 - lr: 1.0000e-08\n",
      "Epoch 231/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.0923 - output_x_loss: 377.4967 - output_y_loss: 148.8333 - output_z_loss: 402.8014 - output_x_msle: 377.4967 - output_y_msle: 148.8333 - output_z_msle: 402.8014 - val_loss: 292.6818 - val_output_x_loss: 379.1184 - val_output_y_loss: 151.1870 - val_output_z_loss: 402.7981 - val_output_x_msle: 379.1184 - val_output_y_msle: 151.1870 - val_output_z_msle: 402.7981 - lr: 1.0000e-08\n",
      "Epoch 232/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.0616 - output_x_loss: 377.4783 - output_y_loss: 148.8302 - output_z_loss: 402.6908 - output_x_msle: 377.4783 - output_y_msle: 148.8302 - output_z_msle: 402.6908 - val_loss: 292.6340 - val_output_x_loss: 379.1022 - val_output_y_loss: 151.1836 - val_output_z_loss: 402.5980 - val_output_x_msle: 379.1022 - val_output_y_msle: 151.1836 - val_output_z_msle: 402.5980 - lr: 1.0000e-08\n",
      "Epoch 233/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.0188 - output_x_loss: 377.4630 - output_y_loss: 148.8271 - output_z_loss: 402.5147 - output_x_msle: 377.4630 - output_y_msle: 148.8271 - output_z_msle: 402.5147 - val_loss: 292.5941 - val_output_x_loss: 379.0896 - val_output_y_loss: 151.1808 - val_output_z_loss: 402.4295 - val_output_x_msle: 379.0896 - val_output_y_msle: 151.1808 - val_output_z_msle: 402.4295 - lr: 1.0000e-08\n",
      "Epoch 234/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.0007 - output_x_loss: 377.4522 - output_y_loss: 148.8248 - output_z_loss: 402.4490 - output_x_msle: 377.4522 - output_y_msle: 148.8248 - output_z_msle: 402.4490 - val_loss: 292.5865 - val_output_x_loss: 379.0800 - val_output_y_loss: 151.1790 - val_output_z_loss: 402.4145 - val_output_x_msle: 379.0800 - val_output_y_msle: 151.1790 - val_output_z_msle: 402.4145 - lr: 1.0000e-08\n",
      "Epoch 235/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9933 - output_x_loss: 377.4426 - output_y_loss: 148.8229 - output_z_loss: 402.4358 - output_x_msle: 377.4426 - output_y_msle: 148.8229 - output_z_msle: 402.4358 - val_loss: 292.5786 - val_output_x_loss: 379.0703 - val_output_y_loss: 151.1770 - val_output_z_loss: 402.3981 - val_output_x_msle: 379.0703 - val_output_y_msle: 151.1770 - val_output_z_msle: 402.3981 - lr: 1.0000e-08\n",
      "Epoch 236/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9855 - output_x_loss: 377.4326 - output_y_loss: 148.8205 - output_z_loss: 402.4211 - output_x_msle: 377.4326 - output_y_msle: 148.8205 - output_z_msle: 402.4211 - val_loss: 292.5694 - val_output_x_loss: 379.0602 - val_output_y_loss: 151.1747 - val_output_z_loss: 402.3773 - val_output_x_msle: 379.0602 - val_output_y_msle: 151.1747 - val_output_z_msle: 402.3773 - lr: 1.0000e-08\n",
      "Epoch 237/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9770 - output_x_loss: 377.4225 - output_y_loss: 148.8180 - output_z_loss: 402.4037 - output_x_msle: 377.4225 - output_y_msle: 148.8180 - output_z_msle: 402.4037 - val_loss: 292.5088 - val_output_x_loss: 378.9298 - val_output_y_loss: 151.1725 - val_output_z_loss: 402.3391 - val_output_x_msle: 378.9298 - val_output_y_msle: 151.1725 - val_output_z_msle: 402.3391 - lr: 1.0000e-08\n",
      "Epoch 238/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9628 - output_x_loss: 377.4121 - output_y_loss: 148.8154 - output_z_loss: 402.3596 - output_x_msle: 377.4121 - output_y_msle: 148.8154 - output_z_msle: 402.3596 - val_loss: 292.4820 - val_output_x_loss: 378.9001 - val_output_y_loss: 151.1698 - val_output_z_loss: 402.2700 - val_output_x_msle: 378.9001 - val_output_y_msle: 151.1698 - val_output_z_msle: 402.2700 - lr: 1.0000e-08\n",
      "Epoch 239/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9430 - output_x_loss: 377.4016 - output_y_loss: 148.7822 - output_z_loss: 402.3474 - output_x_msle: 377.4016 - output_y_msle: 148.7822 - output_z_msle: 402.3474 - val_loss: 292.4731 - val_output_x_loss: 378.8893 - val_output_y_loss: 151.1666 - val_output_z_loss: 402.2539 - val_output_x_msle: 378.8893 - val_output_y_msle: 151.1666 - val_output_z_msle: 402.2539 - lr: 1.0000e-08\n",
      "Epoch 240/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9344 - output_x_loss: 377.3916 - output_y_loss: 148.7772 - output_z_loss: 402.3344 - output_x_msle: 377.3916 - output_y_msle: 148.7772 - output_z_msle: 402.3344 - val_loss: 292.4635 - val_output_x_loss: 378.8770 - val_output_y_loss: 151.1641 - val_output_z_loss: 402.2351 - val_output_x_msle: 378.8770 - val_output_y_msle: 151.1641 - val_output_z_msle: 402.2351 - lr: 1.0000e-08\n",
      "Epoch 241/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9263 - output_x_loss: 377.3810 - output_y_loss: 148.7741 - output_z_loss: 402.3209 - output_x_msle: 377.3810 - output_y_msle: 148.7741 - output_z_msle: 402.3209 - val_loss: 292.4403 - val_output_x_loss: 378.8651 - val_output_y_loss: 151.1613 - val_output_z_loss: 402.1487 - val_output_x_msle: 378.8651 - val_output_y_msle: 151.1613 - val_output_z_msle: 402.1487 - lr: 1.0000e-08\n",
      "Epoch 242/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9176 - output_x_loss: 377.3703 - output_y_loss: 148.7704 - output_z_loss: 402.3062 - output_x_msle: 377.3703 - output_y_msle: 148.7704 - output_z_msle: 402.3062 - val_loss: 292.4309 - val_output_x_loss: 378.8522 - val_output_y_loss: 151.1579 - val_output_z_loss: 402.1339 - val_output_x_msle: 378.8522 - val_output_y_msle: 151.1579 - val_output_z_msle: 402.1339 - lr: 1.0000e-08\n",
      "Epoch 243/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.9081 - output_x_loss: 377.3595 - output_y_loss: 148.7656 - output_z_loss: 402.2901 - output_x_msle: 377.3595 - output_y_msle: 148.7656 - output_z_msle: 402.2901 - val_loss: 292.4225 - val_output_x_loss: 378.8426 - val_output_y_loss: 151.1549 - val_output_z_loss: 402.1177 - val_output_x_msle: 378.8426 - val_output_y_msle: 151.1549 - val_output_z_msle: 402.1177 - lr: 1.0000e-08\n",
      "Epoch 244/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8965 - output_x_loss: 377.3485 - output_y_loss: 148.7576 - output_z_loss: 402.2708 - output_x_msle: 377.3485 - output_y_msle: 148.7576 - output_z_msle: 402.2708 - val_loss: 292.4106 - val_output_x_loss: 378.8297 - val_output_y_loss: 151.1476 - val_output_z_loss: 402.0987 - val_output_x_msle: 378.8297 - val_output_y_msle: 151.1476 - val_output_z_msle: 402.0987 - lr: 1.0000e-08\n",
      "Epoch 245/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8778 - output_x_loss: 377.3372 - output_y_loss: 148.7397 - output_z_loss: 402.2352 - output_x_msle: 377.3372 - output_y_msle: 148.7397 - output_z_msle: 402.2352 - val_loss: 292.4024 - val_output_x_loss: 378.8197 - val_output_y_loss: 151.1457 - val_output_z_loss: 402.0813 - val_output_x_msle: 378.8197 - val_output_y_msle: 151.1457 - val_output_z_msle: 402.0813 - lr: 1.0000e-08\n",
      "Epoch 246/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8686 - output_x_loss: 377.3264 - output_y_loss: 148.7363 - output_z_loss: 402.2177 - output_x_msle: 377.3264 - output_y_msle: 148.7363 - output_z_msle: 402.2177 - val_loss: 292.3935 - val_output_x_loss: 378.8087 - val_output_y_loss: 151.1434 - val_output_z_loss: 402.0635 - val_output_x_msle: 378.8087 - val_output_y_msle: 151.1434 - val_output_z_msle: 402.0635 - lr: 1.0000e-08\n",
      "Epoch 247/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8580 - output_x_loss: 377.3148 - output_y_loss: 148.7331 - output_z_loss: 402.1939 - output_x_msle: 377.3148 - output_y_msle: 148.7331 - output_z_msle: 402.1939 - val_loss: 292.3837 - val_output_x_loss: 378.7979 - val_output_y_loss: 151.1408 - val_output_z_loss: 402.0408 - val_output_x_msle: 378.7979 - val_output_y_msle: 151.1408 - val_output_z_msle: 402.0408 - lr: 1.0000e-08\n",
      "Epoch 248/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8433 - output_x_loss: 377.3029 - output_y_loss: 148.7295 - output_z_loss: 402.1520 - output_x_msle: 377.3029 - output_y_msle: 148.7295 - output_z_msle: 402.1520 - val_loss: 292.3726 - val_output_x_loss: 378.7870 - val_output_y_loss: 151.1374 - val_output_z_loss: 402.0142 - val_output_x_msle: 378.7870 - val_output_y_msle: 151.1374 - val_output_z_msle: 402.0142 - lr: 1.0000e-08\n",
      "Epoch 249/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8416 - output_x_loss: 377.2908 - output_y_loss: 148.7548 - output_z_loss: 402.1177 - output_x_msle: 377.2908 - output_y_msle: 148.7548 - output_z_msle: 402.1177 - val_loss: 292.3607 - val_output_x_loss: 378.7745 - val_output_y_loss: 151.1309 - val_output_z_loss: 401.9927 - val_output_x_msle: 378.7745 - val_output_y_msle: 151.1309 - val_output_z_msle: 401.9927 - lr: 1.0000e-08\n",
      "Epoch 250/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8260 - output_x_loss: 377.2783 - output_y_loss: 148.7379 - output_z_loss: 402.0975 - output_x_msle: 377.2783 - output_y_msle: 148.7379 - output_z_msle: 402.0975 - val_loss: 292.3507 - val_output_x_loss: 378.7611 - val_output_y_loss: 151.1291 - val_output_z_loss: 401.9732 - val_output_x_msle: 378.7611 - val_output_y_msle: 151.1291 - val_output_z_msle: 401.9732 - lr: 1.0000e-08\n",
      "Epoch 251/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8159 - output_x_loss: 377.2657 - output_y_loss: 148.7358 - output_z_loss: 402.0769 - output_x_msle: 377.2657 - output_y_msle: 148.7358 - output_z_msle: 402.0769 - val_loss: 292.2816 - val_output_x_loss: 378.7499 - val_output_y_loss: 150.9783 - val_output_z_loss: 401.9515 - val_output_x_msle: 378.7499 - val_output_y_msle: 150.9783 - val_output_z_msle: 401.9515 - lr: 1.0000e-08\n",
      "Epoch 252/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8048 - output_x_loss: 377.2527 - output_y_loss: 148.7336 - output_z_loss: 402.0516 - output_x_msle: 377.2527 - output_y_msle: 148.7336 - output_z_msle: 402.0516 - val_loss: 292.3258 - val_output_x_loss: 378.8820 - val_output_y_loss: 150.9695 - val_output_z_loss: 401.9261 - val_output_x_msle: 378.8820 - val_output_y_msle: 150.9695 - val_output_z_msle: 401.9261 - lr: 1.0000e-08\n",
      "Epoch 253/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.7896 - output_x_loss: 377.2392 - output_y_loss: 148.7311 - output_z_loss: 402.0077 - output_x_msle: 377.2392 - output_y_msle: 148.7311 - output_z_msle: 402.0077 - val_loss: 292.2619 - val_output_x_loss: 378.7424 - val_output_y_loss: 150.9647 - val_output_z_loss: 401.8949 - val_output_x_msle: 378.7424 - val_output_y_msle: 150.9647 - val_output_z_msle: 401.8949 - lr: 1.0000e-08\n",
      "Epoch 254/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.7738 - output_x_loss: 377.2255 - output_y_loss: 148.7284 - output_z_loss: 401.9617 - output_x_msle: 377.2255 - output_y_msle: 148.7284 - output_z_msle: 401.9617 - val_loss: 292.3004 - val_output_x_loss: 378.8549 - val_output_y_loss: 150.9608 - val_output_z_loss: 401.8700 - val_output_x_msle: 378.8549 - val_output_y_msle: 150.9608 - val_output_z_msle: 401.8700 - lr: 1.0000e-08\n",
      "Epoch 255/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.7598 - output_x_loss: 377.2113 - output_y_loss: 148.7258 - output_z_loss: 401.9247 - output_x_msle: 377.2113 - output_y_msle: 148.7258 - output_z_msle: 401.9247 - val_loss: 292.2886 - val_output_x_loss: 378.8410 - val_output_y_loss: 150.9572 - val_output_z_loss: 401.8467 - val_output_x_msle: 378.8410 - val_output_y_msle: 150.9572 - val_output_z_msle: 401.8467 - lr: 1.0000e-08\n",
      "Epoch 256/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.7480 - output_x_loss: 377.1968 - output_y_loss: 148.7230 - output_z_loss: 401.9007 - output_x_msle: 377.1968 - output_y_msle: 148.7230 - output_z_msle: 401.9007 - val_loss: 292.2761 - val_output_x_loss: 378.8266 - val_output_y_loss: 150.9536 - val_output_z_loss: 401.8200 - val_output_x_msle: 378.8266 - val_output_y_msle: 150.9536 - val_output_z_msle: 401.8200 - lr: 1.0000e-08\n",
      "Epoch 257/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.6929 - output_x_loss: 377.1823 - output_y_loss: 148.6204 - output_z_loss: 401.8592 - output_x_msle: 377.1823 - output_y_msle: 148.6204 - output_z_msle: 401.8592 - val_loss: 292.2633 - val_output_x_loss: 378.8122 - val_output_y_loss: 150.9491 - val_output_z_loss: 401.7937 - val_output_x_msle: 378.8122 - val_output_y_msle: 150.9491 - val_output_z_msle: 401.7937 - lr: 1.0000e-08\n",
      "Epoch 258/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.6276 - output_x_loss: 377.1692 - output_y_loss: 148.4820 - output_z_loss: 401.8354 - output_x_msle: 377.1692 - output_y_msle: 148.4820 - output_z_msle: 401.8354 - val_loss: 292.2023 - val_output_x_loss: 378.6802 - val_output_y_loss: 150.9439 - val_output_z_loss: 401.7635 - val_output_x_msle: 378.6802 - val_output_y_msle: 150.9439 - val_output_z_msle: 401.7635 - lr: 1.0000e-08\n",
      "Epoch 259/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.6129 - output_x_loss: 377.1593 - output_y_loss: 148.4743 - output_z_loss: 401.7968 - output_x_msle: 377.1593 - output_y_msle: 148.4743 - output_z_msle: 401.7968 - val_loss: 292.1695 - val_output_x_loss: 378.6479 - val_output_y_loss: 150.9419 - val_output_z_loss: 401.6674 - val_output_x_msle: 378.6479 - val_output_y_msle: 150.9419 - val_output_z_msle: 401.6674 - lr: 1.0000e-08\n",
      "Epoch 260/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.6021 - output_x_loss: 377.1491 - output_y_loss: 148.4712 - output_z_loss: 401.7694 - output_x_msle: 377.1491 - output_y_msle: 148.4712 - output_z_msle: 401.7694 - val_loss: 292.1577 - val_output_x_loss: 378.6368 - val_output_y_loss: 150.9395 - val_output_z_loss: 401.6357 - val_output_x_msle: 378.6368 - val_output_y_msle: 150.9395 - val_output_z_msle: 401.6357 - lr: 1.0000e-08\n",
      "Epoch 261/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5875 - output_x_loss: 377.1386 - output_y_loss: 148.4685 - output_z_loss: 401.7240 - output_x_msle: 377.1386 - output_y_msle: 148.4685 - output_z_msle: 401.7240 - val_loss: 292.1450 - val_output_x_loss: 378.6241 - val_output_y_loss: 150.9369 - val_output_z_loss: 401.6028 - val_output_x_msle: 378.6241 - val_output_y_msle: 150.9369 - val_output_z_msle: 401.6028 - lr: 1.0000e-08\n",
      "Epoch 262/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5726 - output_x_loss: 377.1275 - output_y_loss: 148.4651 - output_z_loss: 401.6779 - output_x_msle: 377.1275 - output_y_msle: 148.4651 - output_z_msle: 401.6779 - val_loss: 292.1319 - val_output_x_loss: 378.6125 - val_output_y_loss: 150.9341 - val_output_z_loss: 401.5662 - val_output_x_msle: 378.6125 - val_output_y_msle: 150.9341 - val_output_z_msle: 401.5662 - lr: 1.0000e-08\n",
      "Epoch 263/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5603 - output_x_loss: 377.1161 - output_y_loss: 148.4617 - output_z_loss: 401.6463 - output_x_msle: 377.1161 - output_y_msle: 148.4617 - output_z_msle: 401.6463 - val_loss: 292.1039 - val_output_x_loss: 378.6011 - val_output_y_loss: 150.9307 - val_output_z_loss: 401.4559 - val_output_x_msle: 378.6011 - val_output_y_msle: 150.9307 - val_output_z_msle: 401.4559 - lr: 1.0000e-08\n",
      "Epoch 264/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5448 - output_x_loss: 377.1043 - output_y_loss: 148.4578 - output_z_loss: 401.5999 - output_x_msle: 377.1043 - output_y_msle: 148.4578 - output_z_msle: 401.5999 - val_loss: 292.0857 - val_output_x_loss: 378.5892 - val_output_y_loss: 150.9265 - val_output_z_loss: 401.3971 - val_output_x_msle: 378.5892 - val_output_y_msle: 150.9265 - val_output_z_msle: 401.3971 - lr: 1.0000e-08\n",
      "Epoch 265/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5224 - output_x_loss: 377.0935 - output_y_loss: 148.4532 - output_z_loss: 401.5189 - output_x_msle: 377.0935 - output_y_msle: 148.4532 - output_z_msle: 401.5189 - val_loss: 292.0716 - val_output_x_loss: 378.5774 - val_output_y_loss: 150.9220 - val_output_z_loss: 401.3590 - val_output_x_msle: 378.5774 - val_output_y_msle: 150.9220 - val_output_z_msle: 401.3590 - lr: 1.0000e-08\n",
      "Epoch 266/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.5075 - output_x_loss: 377.0828 - output_y_loss: 148.4477 - output_z_loss: 401.4767 - output_x_msle: 377.0828 - output_y_msle: 148.4477 - output_z_msle: 401.4767 - val_loss: 292.0555 - val_output_x_loss: 378.5659 - val_output_y_loss: 150.9169 - val_output_z_loss: 401.3118 - val_output_x_msle: 378.5659 - val_output_y_msle: 150.9169 - val_output_z_msle: 401.3118 - lr: 1.0000e-08\n",
      "Epoch 267/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.4869 - output_x_loss: 377.0711 - output_y_loss: 148.4409 - output_z_loss: 401.4100 - output_x_msle: 377.0711 - output_y_msle: 148.4409 - output_z_msle: 401.4100 - val_loss: 292.0357 - val_output_x_loss: 378.5541 - val_output_y_loss: 150.9100 - val_output_z_loss: 401.2507 - val_output_x_msle: 378.5541 - val_output_y_msle: 150.9100 - val_output_z_msle: 401.2507 - lr: 1.0000e-08\n",
      "Epoch 268/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.4574 - output_x_loss: 377.0591 - output_y_loss: 148.4168 - output_z_loss: 401.3350 - output_x_msle: 377.0591 - output_y_msle: 148.4168 - output_z_msle: 401.3350 - val_loss: 292.0008 - val_output_x_loss: 378.5422 - val_output_y_loss: 150.9039 - val_output_z_loss: 401.1113 - val_output_x_msle: 378.5422 - val_output_y_msle: 150.9039 - val_output_z_msle: 401.1113 - lr: 1.0000e-08\n",
      "Epoch 269/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.4294 - output_x_loss: 377.0466 - output_y_loss: 148.4095 - output_z_loss: 401.2349 - output_x_msle: 377.0466 - output_y_msle: 148.4095 - output_z_msle: 401.2349 - val_loss: 291.9818 - val_output_x_loss: 378.5293 - val_output_y_loss: 150.8968 - val_output_z_loss: 401.0567 - val_output_x_msle: 378.5293 - val_output_y_msle: 150.8968 - val_output_z_msle: 401.0567 - lr: 1.0000e-08\n",
      "Epoch 270/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.4086 - output_x_loss: 377.0336 - output_y_loss: 148.3996 - output_z_loss: 401.1762 - output_x_msle: 377.0336 - output_y_msle: 148.3996 - output_z_msle: 401.1762 - val_loss: 291.9560 - val_output_x_loss: 378.5162 - val_output_y_loss: 150.8852 - val_output_z_loss: 400.9771 - val_output_x_msle: 378.5162 - val_output_y_msle: 150.8852 - val_output_z_msle: 400.9771 - lr: 1.0000e-08\n",
      "Epoch 271/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.3524 - output_x_loss: 377.0196 - output_y_loss: 148.3130 - output_z_loss: 401.0967 - output_x_msle: 377.0196 - output_y_msle: 148.3130 - output_z_msle: 401.0967 - val_loss: 291.9059 - val_output_x_loss: 378.5022 - val_output_y_loss: 150.8834 - val_output_z_loss: 400.7587 - val_output_x_msle: 378.5022 - val_output_y_msle: 150.8834 - val_output_z_msle: 400.7587 - lr: 1.0000e-08\n",
      "Epoch 272/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.2571 - output_x_loss: 377.0057 - output_y_loss: 148.1363 - output_z_loss: 401.0016 - output_x_msle: 377.0057 - output_y_msle: 148.1363 - output_z_msle: 401.0016 - val_loss: 291.8846 - val_output_x_loss: 378.4907 - val_output_y_loss: 150.8670 - val_output_z_loss: 400.7077 - val_output_x_msle: 378.4907 - val_output_y_msle: 150.8670 - val_output_z_msle: 400.7077 - lr: 1.0000e-08\n",
      "Epoch 273/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.2154 - output_x_loss: 376.9944 - output_y_loss: 148.0713 - output_z_loss: 400.9456 - output_x_msle: 376.9944 - output_y_msle: 148.0713 - output_z_msle: 400.9456 - val_loss: 291.8732 - val_output_x_loss: 378.4788 - val_output_y_loss: 150.8659 - val_output_z_loss: 400.6765 - val_output_x_msle: 378.4788 - val_output_y_msle: 150.8659 - val_output_z_msle: 400.6765 - lr: 1.0000e-08\n",
      "Epoch 274/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.2029 - output_x_loss: 376.9825 - output_y_loss: 148.0699 - output_z_loss: 400.9092 - output_x_msle: 376.9825 - output_y_msle: 148.0699 - output_z_msle: 400.9092 - val_loss: 291.8607 - val_output_x_loss: 378.4677 - val_output_y_loss: 150.8648 - val_output_z_loss: 400.6389 - val_output_x_msle: 378.4677 - val_output_y_msle: 150.8648 - val_output_z_msle: 400.6389 - lr: 1.0000e-08\n",
      "Epoch 275/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.1847 - output_x_loss: 376.9709 - output_y_loss: 148.0685 - output_z_loss: 400.8439 - output_x_msle: 376.9709 - output_y_msle: 148.0685 - output_z_msle: 400.8439 - val_loss: 291.8464 - val_output_x_loss: 378.4568 - val_output_y_loss: 150.8636 - val_output_z_loss: 400.5912 - val_output_x_msle: 378.4568 - val_output_y_msle: 150.8636 - val_output_z_msle: 400.5912 - lr: 1.0000e-08\n",
      "Epoch 276/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.1627 - output_x_loss: 376.9589 - output_y_loss: 148.0671 - output_z_loss: 400.7612 - output_x_msle: 376.9589 - output_y_msle: 148.0671 - output_z_msle: 400.7612 - val_loss: 291.8331 - val_output_x_loss: 378.4443 - val_output_y_loss: 150.8625 - val_output_z_loss: 400.5517 - val_output_x_msle: 378.4443 - val_output_y_msle: 150.8625 - val_output_z_msle: 400.5517 - lr: 1.0000e-08\n",
      "Epoch 277/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.1490 - output_x_loss: 376.9462 - output_y_loss: 148.0658 - output_z_loss: 400.7206 - output_x_msle: 376.9462 - output_y_msle: 148.0658 - output_z_msle: 400.7206 - val_loss: 291.8174 - val_output_x_loss: 378.4323 - val_output_y_loss: 150.8614 - val_output_z_loss: 400.4994 - val_output_x_msle: 378.4323 - val_output_y_msle: 150.8614 - val_output_z_msle: 400.4994 - lr: 1.0000e-08\n",
      "Epoch 278/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.1297 - output_x_loss: 376.9331 - output_y_loss: 148.0643 - output_z_loss: 400.6536 - output_x_msle: 376.9331 - output_y_msle: 148.0643 - output_z_msle: 400.6536 - val_loss: 291.7947 - val_output_x_loss: 378.4197 - val_output_y_loss: 150.8601 - val_output_z_loss: 400.4140 - val_output_x_msle: 378.4197 - val_output_y_msle: 150.8601 - val_output_z_msle: 400.4140 - lr: 1.0000e-08\n",
      "Epoch 279/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.1011 - output_x_loss: 376.9198 - output_y_loss: 148.0627 - output_z_loss: 400.5409 - output_x_msle: 376.9198 - output_y_msle: 148.0627 - output_z_msle: 400.5409 - val_loss: 291.7305 - val_output_x_loss: 378.4072 - val_output_y_loss: 150.8588 - val_output_z_loss: 400.1205 - val_output_x_msle: 378.4072 - val_output_y_msle: 150.8588 - val_output_z_msle: 400.1205 - lr: 1.0000e-08\n",
      "Epoch 280/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.0680 - output_x_loss: 376.9066 - output_y_loss: 148.0612 - output_z_loss: 400.4038 - output_x_msle: 376.9066 - output_y_msle: 148.0612 - output_z_msle: 400.4038 - val_loss: 291.7125 - val_output_x_loss: 378.3955 - val_output_y_loss: 150.8576 - val_output_z_loss: 400.0561 - val_output_x_msle: 378.3955 - val_output_y_msle: 150.8576 - val_output_z_msle: 400.0561 - lr: 1.0000e-08\n",
      "Epoch 281/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.0452 - output_x_loss: 376.8939 - output_y_loss: 148.0598 - output_z_loss: 400.3188 - output_x_msle: 376.8939 - output_y_msle: 148.0598 - output_z_msle: 400.3188 - val_loss: 291.6824 - val_output_x_loss: 378.3830 - val_output_y_loss: 150.8563 - val_output_z_loss: 399.9334 - val_output_x_msle: 378.3830 - val_output_y_msle: 150.8563 - val_output_z_msle: 399.9334 - lr: 1.0000e-08\n",
      "Epoch 282/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 290.0131 - output_x_loss: 376.8808 - output_y_loss: 148.0262 - output_z_loss: 400.2514 - output_x_msle: 376.8808 - output_y_msle: 148.0262 - output_z_msle: 400.2514 - val_loss: 291.6694 - val_output_x_loss: 378.3701 - val_output_y_loss: 150.8548 - val_output_z_loss: 399.8973 - val_output_x_msle: 378.3701 - val_output_y_msle: 150.8548 - val_output_z_msle: 399.8973 - lr: 1.0000e-08\n",
      "Epoch 283/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.9939 - output_x_loss: 376.8677 - output_y_loss: 148.0211 - output_z_loss: 400.1924 - output_x_msle: 376.8677 - output_y_msle: 148.0211 - output_z_msle: 400.1924 - val_loss: 291.6540 - val_output_x_loss: 378.3581 - val_output_y_loss: 150.8535 - val_output_z_loss: 399.8468 - val_output_x_msle: 378.3581 - val_output_y_msle: 150.8535 - val_output_z_msle: 399.8468 - lr: 1.0000e-08\n",
      "Epoch 284/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.9660 - output_x_loss: 376.8541 - output_y_loss: 148.0197 - output_z_loss: 400.0819 - output_x_msle: 376.8541 - output_y_msle: 148.0197 - output_z_msle: 400.0819 - val_loss: 291.6235 - val_output_x_loss: 378.3458 - val_output_y_loss: 150.8523 - val_output_z_loss: 399.7213 - val_output_x_msle: 378.3458 - val_output_y_msle: 150.8523 - val_output_z_msle: 399.7213 - lr: 1.0000e-08\n",
      "Epoch 285/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.9433 - output_x_loss: 376.8403 - output_y_loss: 148.0184 - output_z_loss: 399.9992 - output_x_msle: 376.8403 - output_y_msle: 148.0184 - output_z_msle: 399.9992 - val_loss: 291.6122 - val_output_x_loss: 378.3335 - val_output_y_loss: 150.8511 - val_output_z_loss: 399.6915 - val_output_x_msle: 378.3335 - val_output_y_msle: 150.8511 - val_output_z_msle: 399.6915 - lr: 1.0000e-08\n",
      "Epoch 286/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.9170 - output_x_loss: 376.8261 - output_y_loss: 147.9868 - output_z_loss: 399.9593 - output_x_msle: 376.8261 - output_y_msle: 147.9868 - output_z_msle: 399.9593 - val_loss: 291.6007 - val_output_x_loss: 378.3231 - val_output_y_loss: 150.8486 - val_output_z_loss: 399.6606 - val_output_x_msle: 378.3231 - val_output_y_msle: 150.8486 - val_output_z_msle: 399.6606 - lr: 1.0000e-08\n",
      "Epoch 287/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.9056 - output_x_loss: 376.8132 - output_y_loss: 147.9819 - output_z_loss: 399.9373 - output_x_msle: 376.8132 - output_y_msle: 147.9819 - output_z_msle: 399.9373 - val_loss: 291.6450 - val_output_x_loss: 378.4516 - val_output_y_loss: 150.8475 - val_output_z_loss: 399.6266 - val_output_x_msle: 378.4516 - val_output_y_msle: 150.8475 - val_output_z_msle: 399.6266 - lr: 1.0000e-08\n",
      "Epoch 288/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8954 - output_x_loss: 376.8000 - output_y_loss: 147.9807 - output_z_loss: 399.9149 - output_x_msle: 376.8000 - output_y_msle: 147.9807 - output_z_msle: 399.9149 - val_loss: 291.5616 - val_output_x_loss: 378.2952 - val_output_y_loss: 150.8465 - val_output_z_loss: 399.5243 - val_output_x_msle: 378.2952 - val_output_y_msle: 150.8465 - val_output_z_msle: 399.5243 - lr: 1.0000e-08\n",
      "Epoch 289/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8845 - output_x_loss: 376.7870 - output_y_loss: 147.9794 - output_z_loss: 399.8899 - output_x_msle: 376.7870 - output_y_msle: 147.9794 - output_z_msle: 399.8899 - val_loss: 291.5482 - val_output_x_loss: 378.2841 - val_output_y_loss: 150.8454 - val_output_z_loss: 399.4822 - val_output_x_msle: 378.2841 - val_output_y_msle: 150.8454 - val_output_z_msle: 399.4822 - lr: 1.0000e-08\n",
      "Epoch 290/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8725 - output_x_loss: 376.7733 - output_y_loss: 147.9782 - output_z_loss: 399.8595 - output_x_msle: 376.7733 - output_y_msle: 147.9782 - output_z_msle: 399.8595 - val_loss: 291.5162 - val_output_x_loss: 378.2757 - val_output_y_loss: 150.8443 - val_output_z_loss: 399.3412 - val_output_x_msle: 378.2757 - val_output_y_msle: 150.8443 - val_output_z_msle: 399.3412 - lr: 1.0000e-08\n",
      "Epoch 291/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8586 - output_x_loss: 376.7592 - output_y_loss: 147.9767 - output_z_loss: 399.8209 - output_x_msle: 376.7592 - output_y_msle: 147.9767 - output_z_msle: 399.8209 - val_loss: 291.5319 - val_output_x_loss: 378.3981 - val_output_y_loss: 150.8430 - val_output_z_loss: 399.1774 - val_output_x_msle: 378.3981 - val_output_y_msle: 150.8430 - val_output_z_msle: 399.1774 - lr: 1.0000e-08\n",
      "Epoch 292/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8403 - output_x_loss: 376.7447 - output_y_loss: 147.9752 - output_z_loss: 399.7610 - output_x_msle: 376.7447 - output_y_msle: 147.9752 - output_z_msle: 399.7610 - val_loss: 291.5176 - val_output_x_loss: 378.3838 - val_output_y_loss: 150.8418 - val_output_z_loss: 399.1368 - val_output_x_msle: 378.3838 - val_output_y_msle: 150.8418 - val_output_z_msle: 399.1368 - lr: 1.0000e-08\n",
      "Epoch 293/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.8190 - output_x_loss: 376.7298 - output_y_loss: 147.9736 - output_z_loss: 399.6880 - output_x_msle: 376.7298 - output_y_msle: 147.9736 - output_z_msle: 399.6880 - val_loss: 291.5009 - val_output_x_loss: 378.3691 - val_output_y_loss: 150.8404 - val_output_z_loss: 399.0854 - val_output_x_msle: 378.3691 - val_output_y_msle: 150.8404 - val_output_z_msle: 399.0854 - lr: 1.0000e-08\n",
      "Epoch 294/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.7921 - output_x_loss: 376.7149 - output_y_loss: 147.9718 - output_z_loss: 399.5865 - output_x_msle: 376.7149 - output_y_msle: 147.9718 - output_z_msle: 399.5865 - val_loss: 291.4850 - val_output_x_loss: 378.3543 - val_output_y_loss: 150.8390 - val_output_z_loss: 399.0385 - val_output_x_msle: 378.3543 - val_output_y_msle: 150.8390 - val_output_z_msle: 399.0385 - lr: 1.0000e-08\n",
      "Epoch 295/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.7683 - output_x_loss: 376.6994 - output_y_loss: 147.9701 - output_z_loss: 399.5027 - output_x_msle: 376.6994 - output_y_msle: 147.9701 - output_z_msle: 399.5027 - val_loss: 291.4680 - val_output_x_loss: 378.3392 - val_output_y_loss: 150.8375 - val_output_z_loss: 398.9865 - val_output_x_msle: 378.3392 - val_output_y_msle: 150.8375 - val_output_z_msle: 398.9865 - lr: 1.0000e-08\n",
      "Epoch 296/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.7340 - output_x_loss: 376.6842 - output_y_loss: 147.9412 - output_z_loss: 399.4193 - output_x_msle: 376.6842 - output_y_msle: 147.9412 - output_z_msle: 399.4193 - val_loss: 291.4336 - val_output_x_loss: 378.3250 - val_output_y_loss: 150.8368 - val_output_z_loss: 398.8445 - val_output_x_msle: 378.3250 - val_output_y_msle: 150.8368 - val_output_z_msle: 398.8445 - lr: 1.0000e-08\n",
      "Epoch 297/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6889 - output_x_loss: 376.6733 - output_y_loss: 147.8985 - output_z_loss: 399.3014 - output_x_msle: 376.6733 - output_y_msle: 147.8985 - output_z_msle: 399.3014 - val_loss: 291.3655 - val_output_x_loss: 378.3180 - val_output_y_loss: 150.6914 - val_output_z_loss: 398.8085 - val_output_x_msle: 378.3180 - val_output_y_msle: 150.6914 - val_output_z_msle: 398.8085 - lr: 1.0000e-08\n",
      "Epoch 298/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6748 - output_x_loss: 376.6664 - output_y_loss: 147.8974 - output_z_loss: 399.2470 - output_x_msle: 376.6664 - output_y_msle: 147.8974 - output_z_msle: 399.2470 - val_loss: 291.3000 - val_output_x_loss: 378.1756 - val_output_y_loss: 150.6866 - val_output_z_loss: 398.7755 - val_output_x_msle: 378.1756 - val_output_y_msle: 150.6866 - val_output_z_msle: 398.7755 - lr: 1.0000e-08\n",
      "Epoch 299/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6611 - output_x_loss: 376.6595 - output_y_loss: 147.8961 - output_z_loss: 399.1937 - output_x_msle: 376.6595 - output_y_msle: 147.8961 - output_z_msle: 399.1937 - val_loss: 291.2858 - val_output_x_loss: 378.1611 - val_output_y_loss: 150.6832 - val_output_z_loss: 398.7402 - val_output_x_msle: 378.1611 - val_output_y_msle: 150.6832 - val_output_z_msle: 398.7402 - lr: 1.0000e-08\n",
      "Epoch 300/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6492 - output_x_loss: 376.6523 - output_y_loss: 147.8948 - output_z_loss: 399.1512 - output_x_msle: 376.6523 - output_y_msle: 147.8948 - output_z_msle: 399.1512 - val_loss: 291.2726 - val_output_x_loss: 378.1517 - val_output_y_loss: 150.6801 - val_output_z_loss: 398.6992 - val_output_x_msle: 378.1517 - val_output_y_msle: 150.6801 - val_output_z_msle: 398.6992 - lr: 1.0000e-08\n",
      "Epoch 301/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6289 - output_x_loss: 376.6450 - output_y_loss: 147.8935 - output_z_loss: 399.0678 - output_x_msle: 376.6450 - output_y_msle: 147.8935 - output_z_msle: 399.0678 - val_loss: 291.2542 - val_output_x_loss: 378.1434 - val_output_y_loss: 150.6777 - val_output_z_loss: 398.6291 - val_output_x_msle: 378.1434 - val_output_y_msle: 150.6777 - val_output_z_msle: 398.6291 - lr: 1.0000e-08\n",
      "Epoch 302/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.6031 - output_x_loss: 376.6378 - output_y_loss: 147.8921 - output_z_loss: 398.9554 - output_x_msle: 376.6378 - output_y_msle: 147.8921 - output_z_msle: 398.9554 - val_loss: 291.2454 - val_output_x_loss: 378.1353 - val_output_y_loss: 150.6754 - val_output_z_loss: 398.6052 - val_output_x_msle: 378.1353 - val_output_y_msle: 150.6754 - val_output_z_msle: 398.6052 - lr: 1.0000e-08\n",
      "Epoch 303/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5924 - output_x_loss: 376.6309 - output_y_loss: 147.8907 - output_z_loss: 398.9185 - output_x_msle: 376.6309 - output_y_msle: 147.8907 - output_z_msle: 398.9185 - val_loss: 291.2341 - val_output_x_loss: 378.1278 - val_output_y_loss: 150.6732 - val_output_z_loss: 398.5687 - val_output_x_msle: 378.1278 - val_output_y_msle: 150.6732 - val_output_z_msle: 398.5687 - lr: 1.0000e-08\n",
      "Epoch 304/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5811 - output_x_loss: 376.6237 - output_y_loss: 147.8893 - output_z_loss: 398.8789 - output_x_msle: 376.6237 - output_y_msle: 147.8893 - output_z_msle: 398.8789 - val_loss: 291.2251 - val_output_x_loss: 378.1201 - val_output_y_loss: 150.6712 - val_output_z_loss: 398.5427 - val_output_x_msle: 378.1201 - val_output_y_msle: 150.6712 - val_output_z_msle: 398.5427 - lr: 1.0000e-08\n",
      "Epoch 305/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5717 - output_x_loss: 376.6167 - output_y_loss: 147.8879 - output_z_loss: 398.8493 - output_x_msle: 376.6167 - output_y_msle: 147.8879 - output_z_msle: 398.8493 - val_loss: 291.2151 - val_output_x_loss: 378.1125 - val_output_y_loss: 150.6692 - val_output_z_loss: 398.5118 - val_output_x_msle: 378.1125 - val_output_y_msle: 150.6692 - val_output_z_msle: 398.5118 - lr: 1.0000e-08\n",
      "Epoch 306/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5590 - output_x_loss: 376.6093 - output_y_loss: 147.8862 - output_z_loss: 398.8041 - output_x_msle: 376.6093 - output_y_msle: 147.8862 - output_z_msle: 398.8041 - val_loss: 291.2048 - val_output_x_loss: 378.1055 - val_output_y_loss: 150.6668 - val_output_z_loss: 398.4794 - val_output_x_msle: 378.1055 - val_output_y_msle: 150.6668 - val_output_z_msle: 398.4794 - lr: 1.0000e-08\n",
      "Epoch 307/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5321 - output_x_loss: 376.6019 - output_y_loss: 147.8842 - output_z_loss: 398.6881 - output_x_msle: 376.6019 - output_y_msle: 147.8842 - output_z_msle: 398.6881 - val_loss: 291.1810 - val_output_x_loss: 378.0972 - val_output_y_loss: 150.6640 - val_output_z_loss: 398.3829 - val_output_x_msle: 378.0972 - val_output_y_msle: 150.6640 - val_output_z_msle: 398.3829 - lr: 1.0000e-08\n",
      "Epoch 308/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.5163 - output_x_loss: 376.5949 - output_y_loss: 147.8824 - output_z_loss: 398.6269 - output_x_msle: 376.5949 - output_y_msle: 147.8824 - output_z_msle: 398.6269 - val_loss: 291.1755 - val_output_x_loss: 378.0898 - val_output_y_loss: 150.6622 - val_output_z_loss: 398.3739 - val_output_x_msle: 378.0898 - val_output_y_msle: 150.6622 - val_output_z_msle: 398.3739 - lr: 1.0000e-08\n",
      "Epoch 309/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4982 - output_x_loss: 376.5875 - output_y_loss: 147.8484 - output_z_loss: 398.6184 - output_x_msle: 376.5875 - output_y_msle: 147.8484 - output_z_msle: 398.6184 - val_loss: 291.1690 - val_output_x_loss: 378.0822 - val_output_y_loss: 150.6579 - val_output_z_loss: 398.3649 - val_output_x_msle: 378.0822 - val_output_y_msle: 150.6579 - val_output_z_msle: 398.3649 - lr: 1.0000e-08\n",
      "Epoch 310/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4914 - output_x_loss: 376.5800 - output_y_loss: 147.8436 - output_z_loss: 398.6099 - output_x_msle: 376.5800 - output_y_msle: 147.8436 - output_z_msle: 398.6099 - val_loss: 291.1634 - val_output_x_loss: 378.0743 - val_output_y_loss: 150.6568 - val_output_z_loss: 398.3546 - val_output_x_msle: 378.0743 - val_output_y_msle: 150.6568 - val_output_z_msle: 398.3546 - lr: 1.0000e-08\n",
      "Epoch 311/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4854 - output_x_loss: 376.5722 - output_y_loss: 147.8424 - output_z_loss: 398.5978 - output_x_msle: 376.5722 - output_y_msle: 147.8424 - output_z_msle: 398.5978 - val_loss: 291.1015 - val_output_x_loss: 378.0663 - val_output_y_loss: 150.5170 - val_output_z_loss: 398.3412 - val_output_x_msle: 378.0663 - val_output_y_msle: 150.5170 - val_output_z_msle: 398.3412 - lr: 1.0000e-08\n",
      "Epoch 312/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4651 - output_x_loss: 376.5645 - output_y_loss: 147.8094 - output_z_loss: 398.5774 - output_x_msle: 376.5645 - output_y_msle: 147.8094 - output_z_msle: 398.5774 - val_loss: 291.0318 - val_output_x_loss: 378.0585 - val_output_y_loss: 150.3549 - val_output_z_loss: 398.3326 - val_output_x_msle: 378.0585 - val_output_y_msle: 150.3549 - val_output_z_msle: 398.3326 - lr: 1.0000e-08\n",
      "Epoch 313/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4457 - output_x_loss: 376.5566 - output_y_loss: 147.7726 - output_z_loss: 398.5700 - output_x_msle: 376.5566 - output_y_msle: 147.7726 - output_z_msle: 398.5700 - val_loss: 291.0188 - val_output_x_loss: 378.0504 - val_output_y_loss: 150.3347 - val_output_z_loss: 398.3237 - val_output_x_msle: 378.0504 - val_output_y_msle: 150.3347 - val_output_z_msle: 398.3237 - lr: 1.0000e-08\n",
      "Epoch 314/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4398 - output_x_loss: 376.5486 - output_y_loss: 147.7698 - output_z_loss: 398.5619 - output_x_msle: 376.5486 - output_y_msle: 147.7698 - output_z_msle: 398.5619 - val_loss: 290.9548 - val_output_x_loss: 378.0423 - val_output_y_loss: 150.1876 - val_output_z_loss: 398.3141 - val_output_x_msle: 378.0423 - val_output_y_msle: 150.1876 - val_output_z_msle: 398.3141 - lr: 1.0000e-08\n",
      "Epoch 315/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4342 - output_x_loss: 376.5404 - output_y_loss: 147.7683 - output_z_loss: 398.5533 - output_x_msle: 376.5404 - output_y_msle: 147.7683 - output_z_msle: 398.5533 - val_loss: 290.9465 - val_output_x_loss: 378.0338 - val_output_y_loss: 150.1806 - val_output_z_loss: 398.3037 - val_output_x_msle: 378.0338 - val_output_y_msle: 150.1806 - val_output_z_msle: 398.3037 - lr: 1.0000e-08\n",
      "Epoch 316/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4284 - output_x_loss: 376.5319 - output_y_loss: 147.7669 - output_z_loss: 398.5444 - output_x_msle: 376.5319 - output_y_msle: 147.7669 - output_z_msle: 398.5444 - val_loss: 290.9392 - val_output_x_loss: 378.0253 - val_output_y_loss: 150.1765 - val_output_z_loss: 398.2925 - val_output_x_msle: 378.0253 - val_output_y_msle: 150.1765 - val_output_z_msle: 398.2925 - lr: 1.0000e-08\n",
      "Epoch 317/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4226 - output_x_loss: 376.5234 - output_y_loss: 147.7655 - output_z_loss: 398.5350 - output_x_msle: 376.5234 - output_y_msle: 147.7655 - output_z_msle: 398.5350 - val_loss: 290.9319 - val_output_x_loss: 378.0165 - val_output_y_loss: 150.1732 - val_output_z_loss: 398.2799 - val_output_x_msle: 378.0165 - val_output_y_msle: 150.1732 - val_output_z_msle: 398.2799 - lr: 1.0000e-08\n",
      "Epoch 318/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.3767 - output_x_loss: 376.5145 - output_y_loss: 147.6643 - output_z_loss: 398.5255 - output_x_msle: 376.5145 - output_y_msle: 147.6643 - output_z_msle: 398.5255 - val_loss: 290.9197 - val_output_x_loss: 378.0075 - val_output_y_loss: 150.1580 - val_output_z_loss: 398.2675 - val_output_x_msle: 378.0075 - val_output_y_msle: 150.1580 - val_output_z_msle: 398.2675 - lr: 1.0000e-08\n",
      "Epoch 319/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.3146 - output_x_loss: 376.5056 - output_y_loss: 147.5225 - output_z_loss: 398.5164 - output_x_msle: 376.5056 - output_y_msle: 147.5225 - output_z_msle: 398.5164 - val_loss: 290.8517 - val_output_x_loss: 377.9982 - val_output_y_loss: 150.0047 - val_output_z_loss: 398.2521 - val_output_x_msle: 377.9982 - val_output_y_msle: 150.0047 - val_output_z_msle: 398.2521 - lr: 1.0000e-08\n",
      "Epoch 320/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.3073 - output_x_loss: 376.4966 - output_y_loss: 147.5183 - output_z_loss: 398.5064 - output_x_msle: 376.4966 - output_y_msle: 147.5183 - output_z_msle: 398.5064 - val_loss: 290.8315 - val_output_x_loss: 377.9893 - val_output_y_loss: 150.0006 - val_output_z_loss: 398.1776 - val_output_x_msle: 377.9893 - val_output_y_msle: 150.0006 - val_output_z_msle: 398.1776 - lr: 1.0000e-08\n",
      "Epoch 321/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.3004 - output_x_loss: 376.4873 - output_y_loss: 147.5159 - output_z_loss: 398.4953 - output_x_msle: 376.4873 - output_y_msle: 147.5159 - output_z_msle: 398.4953 - val_loss: 290.8243 - val_output_x_loss: 377.9802 - val_output_y_loss: 149.9980 - val_output_z_loss: 398.1650 - val_output_x_msle: 377.9802 - val_output_y_msle: 149.9980 - val_output_z_msle: 398.1650 - lr: 1.0000e-08\n",
      "Epoch 322/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.2805 - output_x_loss: 376.4776 - output_y_loss: 147.4813 - output_z_loss: 398.4836 - output_x_msle: 376.4776 - output_y_msle: 147.4813 - output_z_msle: 398.4836 - val_loss: 290.8148 - val_output_x_loss: 377.9705 - val_output_y_loss: 149.9909 - val_output_z_loss: 398.1511 - val_output_x_msle: 377.9705 - val_output_y_msle: 149.9909 - val_output_z_msle: 398.1511 - lr: 1.0000e-08\n",
      "Epoch 323/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.2578 - output_x_loss: 376.4679 - output_y_loss: 147.4415 - output_z_loss: 398.4700 - output_x_msle: 376.4679 - output_y_msle: 147.4415 - output_z_msle: 398.4700 - val_loss: 290.8065 - val_output_x_loss: 377.9608 - val_output_y_loss: 149.9880 - val_output_z_loss: 398.1344 - val_output_x_msle: 377.9608 - val_output_y_msle: 149.9880 - val_output_z_msle: 398.1344 - lr: 1.0000e-08\n",
      "Epoch 324/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.2475 - output_x_loss: 376.4583 - output_y_loss: 147.4385 - output_z_loss: 398.4444 - output_x_msle: 376.4583 - output_y_msle: 147.4385 - output_z_msle: 398.4444 - val_loss: 290.7986 - val_output_x_loss: 377.9509 - val_output_y_loss: 149.9854 - val_output_z_loss: 398.1202 - val_output_x_msle: 377.9509 - val_output_y_msle: 149.9854 - val_output_z_msle: 398.1202 - lr: 1.0000e-08\n",
      "Epoch 325/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.2400 - output_x_loss: 376.4480 - output_y_loss: 147.4357 - output_z_loss: 398.4319 - output_x_msle: 376.4480 - output_y_msle: 147.4357 - output_z_msle: 398.4319 - val_loss: 290.7905 - val_output_x_loss: 377.9409 - val_output_y_loss: 149.9830 - val_output_z_loss: 398.1046 - val_output_x_msle: 377.9409 - val_output_y_msle: 149.9830 - val_output_z_msle: 398.1046 - lr: 1.0000e-08\n",
      "Epoch 326/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.2319 - output_x_loss: 376.4374 - output_y_loss: 147.4330 - output_z_loss: 398.4186 - output_x_msle: 376.4374 - output_y_msle: 147.4330 - output_z_msle: 398.4186 - val_loss: 290.7818 - val_output_x_loss: 377.9305 - val_output_y_loss: 149.9804 - val_output_z_loss: 398.0870 - val_output_x_msle: 377.9305 - val_output_y_msle: 149.9804 - val_output_z_msle: 398.0870 - lr: 1.0000e-08\n",
      "Epoch 327/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.1977 - output_x_loss: 376.4268 - output_y_loss: 147.3652 - output_z_loss: 398.4044 - output_x_msle: 376.4268 - output_y_msle: 147.3652 - output_z_msle: 398.4044 - val_loss: 290.6498 - val_output_x_loss: 377.9198 - val_output_y_loss: 149.6713 - val_output_z_loss: 398.0668 - val_output_x_msle: 377.9198 - val_output_y_msle: 149.6713 - val_output_z_msle: 398.0668 - lr: 1.0000e-08\n",
      "Epoch 328/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.1308 - output_x_loss: 376.4156 - output_y_loss: 147.2167 - output_z_loss: 398.3898 - output_x_msle: 376.4156 - output_y_msle: 147.2167 - output_z_msle: 398.3898 - val_loss: 290.6316 - val_output_x_loss: 377.9090 - val_output_y_loss: 149.6500 - val_output_z_loss: 398.0396 - val_output_x_msle: 377.9090 - val_output_y_msle: 149.6500 - val_output_z_msle: 398.0396 - lr: 1.0000e-08\n",
      "Epoch 329/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.1212 - output_x_loss: 376.4045 - output_y_loss: 147.2115 - output_z_loss: 398.3739 - output_x_msle: 376.4045 - output_y_msle: 147.2115 - output_z_msle: 398.3739 - val_loss: 290.6071 - val_output_x_loss: 377.8975 - val_output_y_loss: 149.6440 - val_output_z_loss: 397.9524 - val_output_x_msle: 377.8975 - val_output_y_msle: 149.6440 - val_output_z_msle: 397.9524 - lr: 1.0000e-08\n",
      "Epoch 330/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.0707 - output_x_loss: 376.3929 - output_y_loss: 147.1046 - output_z_loss: 398.3585 - output_x_msle: 376.3929 - output_y_msle: 147.1046 - output_z_msle: 398.3585 - val_loss: 290.5904 - val_output_x_loss: 377.8863 - val_output_y_loss: 149.6287 - val_output_z_loss: 397.9218 - val_output_x_msle: 377.8863 - val_output_y_msle: 149.6287 - val_output_z_msle: 397.9218 - lr: 1.0000e-08\n",
      "Epoch 331/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.0306 - output_x_loss: 376.3816 - output_y_loss: 147.0233 - output_z_loss: 398.3434 - output_x_msle: 376.3816 - output_y_msle: 147.0233 - output_z_msle: 398.3434 - val_loss: 290.5731 - val_output_x_loss: 377.8751 - val_output_y_loss: 149.6259 - val_output_z_loss: 397.8639 - val_output_x_msle: 377.8751 - val_output_y_msle: 149.6259 - val_output_z_msle: 397.8639 - lr: 1.0000e-08\n",
      "Epoch 332/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.0217 - output_x_loss: 376.3699 - output_y_loss: 147.0210 - output_z_loss: 398.3265 - output_x_msle: 376.3699 - output_y_msle: 147.0210 - output_z_msle: 398.3265 - val_loss: 290.5641 - val_output_x_loss: 377.8635 - val_output_y_loss: 149.6234 - val_output_z_loss: 397.8464 - val_output_x_msle: 377.8635 - val_output_y_msle: 149.6234 - val_output_z_msle: 397.8464 - lr: 1.0000e-08\n",
      "Epoch 333/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.0117 - output_x_loss: 376.3578 - output_y_loss: 147.0184 - output_z_loss: 398.3062 - output_x_msle: 376.3578 - output_y_msle: 147.0184 - output_z_msle: 398.3062 - val_loss: 290.5540 - val_output_x_loss: 377.8517 - val_output_y_loss: 149.6205 - val_output_z_loss: 397.8258 - val_output_x_msle: 377.8517 - val_output_y_msle: 149.6205 - val_output_z_msle: 397.8258 - lr: 1.0000e-08\n",
      "Epoch 334/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9970 - output_x_loss: 376.3454 - output_y_loss: 147.0158 - output_z_loss: 398.2623 - output_x_msle: 376.3454 - output_y_msle: 147.0158 - output_z_msle: 398.2623 - val_loss: 290.5423 - val_output_x_loss: 377.8394 - val_output_y_loss: 149.6174 - val_output_z_loss: 397.7979 - val_output_x_msle: 377.8394 - val_output_y_msle: 149.6174 - val_output_z_msle: 397.7979 - lr: 1.0000e-08\n",
      "Epoch 335/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9809 - output_x_loss: 376.3331 - output_y_loss: 147.0124 - output_z_loss: 398.2135 - output_x_msle: 376.3331 - output_y_msle: 147.0124 - output_z_msle: 398.2135 - val_loss: 290.5312 - val_output_x_loss: 377.8271 - val_output_y_loss: 149.6139 - val_output_z_loss: 397.7742 - val_output_x_msle: 377.8271 - val_output_y_msle: 149.6139 - val_output_z_msle: 397.7742 - lr: 1.0000e-08\n",
      "Epoch 336/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9688 - output_x_loss: 376.3205 - output_y_loss: 147.0086 - output_z_loss: 398.1859 - output_x_msle: 376.3205 - output_y_msle: 147.0086 - output_z_msle: 398.1859 - val_loss: 290.5166 - val_output_x_loss: 377.8145 - val_output_y_loss: 149.6099 - val_output_z_loss: 397.7340 - val_output_x_msle: 377.8145 - val_output_y_msle: 149.6099 - val_output_z_msle: 397.7340 - lr: 1.0000e-08\n",
      "Epoch 337/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9446 - output_x_loss: 376.3079 - output_y_loss: 147.0039 - output_z_loss: 398.0997 - output_x_msle: 376.3079 - output_y_msle: 147.0039 - output_z_msle: 398.0997 - val_loss: 290.4906 - val_output_x_loss: 377.8030 - val_output_y_loss: 149.6052 - val_output_z_loss: 397.6368 - val_output_x_msle: 377.8030 - val_output_y_msle: 149.6052 - val_output_z_msle: 397.6368 - lr: 1.0000e-08\n",
      "Epoch 338/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9257 - output_x_loss: 376.2968 - output_y_loss: 146.9828 - output_z_loss: 398.0694 - output_x_msle: 376.2968 - output_y_msle: 146.9828 - output_z_msle: 398.0694 - val_loss: 290.4815 - val_output_x_loss: 377.7919 - val_output_y_loss: 149.6010 - val_output_z_loss: 397.6214 - val_output_x_msle: 377.7919 - val_output_y_msle: 149.6010 - val_output_z_msle: 397.6214 - lr: 1.0000e-08\n",
      "Epoch 339/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9160 - output_x_loss: 376.2855 - output_y_loss: 146.9775 - output_z_loss: 398.0546 - output_x_msle: 376.2855 - output_y_msle: 146.9775 - output_z_msle: 398.0546 - val_loss: 290.4710 - val_output_x_loss: 377.7807 - val_output_y_loss: 149.5950 - val_output_z_loss: 397.6033 - val_output_x_msle: 377.7807 - val_output_y_msle: 149.5950 - val_output_z_msle: 397.6033 - lr: 1.0000e-08\n",
      "Epoch 340/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.9014 - output_x_loss: 376.2740 - output_y_loss: 146.9601 - output_z_loss: 398.0387 - output_x_msle: 376.2740 - output_y_msle: 146.9601 - output_z_msle: 398.0387 - val_loss: 290.4616 - val_output_x_loss: 377.7693 - val_output_y_loss: 149.5926 - val_output_z_loss: 397.5843 - val_output_x_msle: 377.7693 - val_output_y_msle: 149.5926 - val_output_z_msle: 397.5843 - lr: 1.0000e-08\n",
      "Epoch 341/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.8464 - output_x_loss: 376.2621 - output_y_loss: 146.8423 - output_z_loss: 398.0232 - output_x_msle: 376.2621 - output_y_msle: 146.8423 - output_z_msle: 398.0232 - val_loss: 290.3899 - val_output_x_loss: 377.7573 - val_output_y_loss: 149.4328 - val_output_z_loss: 397.5692 - val_output_x_msle: 377.7573 - val_output_y_msle: 149.4328 - val_output_z_msle: 397.5692 - lr: 1.0000e-08\n",
      "Epoch 342/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7843 - output_x_loss: 376.2495 - output_y_loss: 146.7071 - output_z_loss: 398.0081 - output_x_msle: 376.2495 - output_y_msle: 146.7071 - output_z_msle: 398.0081 - val_loss: 290.3773 - val_output_x_loss: 377.7451 - val_output_y_loss: 149.4279 - val_output_z_loss: 397.5406 - val_output_x_msle: 377.7451 - val_output_y_msle: 149.4279 - val_output_z_msle: 397.5406 - lr: 1.0000e-08\n",
      "Epoch 343/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7667 - output_x_loss: 376.2373 - output_y_loss: 146.6850 - output_z_loss: 397.9887 - output_x_msle: 376.2373 - output_y_msle: 146.6850 - output_z_msle: 397.9887 - val_loss: 290.3550 - val_output_x_loss: 377.7328 - val_output_y_loss: 149.4230 - val_output_z_loss: 397.4637 - val_output_x_msle: 377.7328 - val_output_y_msle: 149.4230 - val_output_z_msle: 397.4637 - lr: 1.0000e-08\n",
      "Epoch 344/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7469 - output_x_loss: 376.2247 - output_y_loss: 146.6676 - output_z_loss: 397.9492 - output_x_msle: 376.2247 - output_y_msle: 146.6676 - output_z_msle: 397.9492 - val_loss: 290.3448 - val_output_x_loss: 377.7203 - val_output_y_loss: 149.4210 - val_output_z_loss: 397.4416 - val_output_x_msle: 377.7203 - val_output_y_msle: 149.4210 - val_output_z_msle: 397.4416 - lr: 1.0000e-08\n",
      "Epoch 345/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7341 - output_x_loss: 376.2115 - output_y_loss: 146.6653 - output_z_loss: 397.9165 - output_x_msle: 376.2115 - output_y_msle: 146.6653 - output_z_msle: 397.9165 - val_loss: 290.3348 - val_output_x_loss: 377.7076 - val_output_y_loss: 149.4191 - val_output_z_loss: 397.4207 - val_output_x_msle: 377.7076 - val_output_y_msle: 149.4191 - val_output_z_msle: 397.4207 - lr: 1.0000e-08\n",
      "Epoch 346/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7119 - output_x_loss: 376.1984 - output_y_loss: 146.6325 - output_z_loss: 397.8979 - output_x_msle: 376.1984 - output_y_msle: 146.6325 - output_z_msle: 397.8979 - val_loss: 290.3234 - val_output_x_loss: 377.6946 - val_output_y_loss: 149.4168 - val_output_z_loss: 397.3938 - val_output_x_msle: 377.6946 - val_output_y_msle: 149.4168 - val_output_z_msle: 397.3938 - lr: 1.0000e-08\n",
      "Epoch 347/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.7003 - output_x_loss: 376.1851 - output_y_loss: 146.6272 - output_z_loss: 397.8768 - output_x_msle: 376.1851 - output_y_msle: 146.6272 - output_z_msle: 397.8768 - val_loss: 290.3111 - val_output_x_loss: 377.6816 - val_output_y_loss: 149.4149 - val_output_z_loss: 397.3626 - val_output_x_msle: 377.6816 - val_output_y_msle: 149.4149 - val_output_z_msle: 397.3626 - lr: 1.0000e-08\n",
      "Epoch 348/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.6895 - output_x_loss: 376.1713 - output_y_loss: 146.6250 - output_z_loss: 397.8549 - output_x_msle: 376.1713 - output_y_msle: 146.6250 - output_z_msle: 397.8549 - val_loss: 290.2826 - val_output_x_loss: 377.6680 - val_output_y_loss: 149.4127 - val_output_z_loss: 397.2511 - val_output_x_msle: 377.6680 - val_output_y_msle: 149.4127 - val_output_z_msle: 397.2511 - lr: 1.0000e-08\n",
      "Epoch 349/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.6773 - output_x_loss: 376.1566 - output_y_loss: 146.6227 - output_z_loss: 397.8281 - output_x_msle: 376.1566 - output_y_msle: 146.6227 - output_z_msle: 397.8281 - val_loss: 290.2588 - val_output_x_loss: 377.6537 - val_output_y_loss: 149.4103 - val_output_z_loss: 397.1657 - val_output_x_msle: 377.6537 - val_output_y_msle: 149.4103 - val_output_z_msle: 397.1657 - lr: 1.0000e-08\n",
      "Epoch 350/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.6614 - output_x_loss: 376.1415 - output_y_loss: 146.6203 - output_z_loss: 397.7836 - output_x_msle: 376.1415 - output_y_msle: 146.6203 - output_z_msle: 397.7836 - val_loss: 290.1860 - val_output_x_loss: 377.6388 - val_output_y_loss: 149.2572 - val_output_z_loss: 397.1379 - val_output_x_msle: 377.6388 - val_output_y_msle: 149.2572 - val_output_z_msle: 397.1379 - lr: 1.0000e-08\n",
      "Epoch 351/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.6470 - output_x_loss: 376.1257 - output_y_loss: 146.6176 - output_z_loss: 397.7478 - output_x_msle: 376.1257 - output_y_msle: 146.6176 - output_z_msle: 397.7478 - val_loss: 290.1699 - val_output_x_loss: 377.6233 - val_output_y_loss: 149.2504 - val_output_z_loss: 397.1022 - val_output_x_msle: 377.6233 - val_output_y_msle: 149.2504 - val_output_z_msle: 397.1022 - lr: 1.0000e-08\n",
      "Epoch 352/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.6255 - output_x_loss: 376.1092 - output_y_loss: 146.6144 - output_z_loss: 397.6803 - output_x_msle: 376.1092 - output_y_msle: 146.6144 - output_z_msle: 397.6803 - val_loss: 290.1507 - val_output_x_loss: 377.6075 - val_output_y_loss: 149.2444 - val_output_z_loss: 397.0497 - val_output_x_msle: 377.6075 - val_output_y_msle: 149.2444 - val_output_z_msle: 397.0497 - lr: 1.0000e-08\n",
      "Epoch 353/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.5781 - output_x_loss: 376.0927 - output_y_loss: 146.6110 - output_z_loss: 397.4831 - output_x_msle: 376.0927 - output_y_msle: 146.6110 - output_z_msle: 397.4831 - val_loss: 290.1047 - val_output_x_loss: 377.5920 - val_output_y_loss: 149.2389 - val_output_z_loss: 396.8622 - val_output_x_msle: 377.5920 - val_output_y_msle: 149.2389 - val_output_z_msle: 396.8622 - lr: 1.0000e-08\n",
      "Epoch 354/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.5519 - output_x_loss: 376.0777 - output_y_loss: 146.6079 - output_z_loss: 397.3881 - output_x_msle: 376.0777 - output_y_msle: 146.6079 - output_z_msle: 397.3881 - val_loss: 290.0924 - val_output_x_loss: 377.5786 - val_output_y_loss: 149.2341 - val_output_z_loss: 396.8366 - val_output_x_msle: 377.5786 - val_output_y_msle: 149.2341 - val_output_z_msle: 396.8366 - lr: 1.0000e-08\n",
      "Epoch 355/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.5295 - output_x_loss: 376.0639 - output_y_loss: 146.5754 - output_z_loss: 397.3690 - output_x_msle: 376.0639 - output_y_msle: 146.5754 - output_z_msle: 397.3690 - val_loss: 290.0805 - val_output_x_loss: 377.5655 - val_output_y_loss: 149.2291 - val_output_z_loss: 396.8137 - val_output_x_msle: 377.5655 - val_output_y_msle: 149.2291 - val_output_z_msle: 396.8137 - lr: 1.0000e-08\n",
      "Epoch 356/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.5034 - output_x_loss: 376.0508 - output_y_loss: 146.5343 - output_z_loss: 397.3469 - output_x_msle: 376.0508 - output_y_msle: 146.5343 - output_z_msle: 397.3469 - val_loss: 290.0662 - val_output_x_loss: 377.5526 - val_output_y_loss: 149.2235 - val_output_z_loss: 396.7784 - val_output_x_msle: 377.5526 - val_output_y_msle: 149.2235 - val_output_z_msle: 396.7784 - lr: 1.0000e-08\n",
      "Epoch 357/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.4883 - output_x_loss: 376.0375 - output_y_loss: 146.5297 - output_z_loss: 397.3069 - output_x_msle: 376.0375 - output_y_msle: 146.5297 - output_z_msle: 397.3069 - val_loss: 290.0429 - val_output_x_loss: 377.5392 - val_output_y_loss: 149.2189 - val_output_z_loss: 396.6983 - val_output_x_msle: 377.5392 - val_output_y_msle: 149.2189 - val_output_z_msle: 396.6983 - lr: 1.0000e-08\n",
      "Epoch 358/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.4729 - output_x_loss: 376.0233 - output_y_loss: 146.5261 - output_z_loss: 397.2649 - output_x_msle: 376.0233 - output_y_msle: 146.5261 - output_z_msle: 397.2649 - val_loss: 290.0311 - val_output_x_loss: 377.5264 - val_output_y_loss: 149.2142 - val_output_z_loss: 396.6742 - val_output_x_msle: 377.5264 - val_output_y_msle: 149.2142 - val_output_z_msle: 396.6742 - lr: 1.0000e-08\n",
      "Epoch 359/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.4575 - output_x_loss: 376.0095 - output_y_loss: 146.5222 - output_z_loss: 397.2234 - output_x_msle: 376.0095 - output_y_msle: 146.5222 - output_z_msle: 397.2234 - val_loss: 290.0183 - val_output_x_loss: 377.5120 - val_output_y_loss: 149.2090 - val_output_z_loss: 396.6496 - val_output_x_msle: 377.5120 - val_output_y_msle: 149.2090 - val_output_z_msle: 396.6496 - lr: 1.0000e-08\n",
      "Epoch 360/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.4427 - output_x_loss: 375.9953 - output_y_loss: 146.5183 - output_z_loss: 397.1868 - output_x_msle: 375.9953 - output_y_msle: 146.5183 - output_z_msle: 397.1868 - val_loss: 289.9962 - val_output_x_loss: 377.4981 - val_output_y_loss: 149.2023 - val_output_z_loss: 396.5799 - val_output_x_msle: 377.4981 - val_output_y_msle: 149.2023 - val_output_z_msle: 396.5799 - lr: 1.0000e-08\n",
      "Epoch 361/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.4020 - output_x_loss: 375.9805 - output_y_loss: 146.4794 - output_z_loss: 397.0898 - output_x_msle: 375.9805 - output_y_msle: 146.4794 - output_z_msle: 397.0898 - val_loss: 289.9803 - val_output_x_loss: 377.4841 - val_output_y_loss: 149.1948 - val_output_z_loss: 396.5434 - val_output_x_msle: 377.4841 - val_output_y_msle: 149.1948 - val_output_z_msle: 396.5434 - lr: 1.0000e-08\n",
      "Epoch 362/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.3313 - output_x_loss: 375.9656 - output_y_loss: 146.3364 - output_z_loss: 397.0527 - output_x_msle: 375.9656 - output_y_msle: 146.3364 - output_z_msle: 397.0527 - val_loss: 289.8844 - val_output_x_loss: 377.4691 - val_output_y_loss: 149.0260 - val_output_z_loss: 396.4318 - val_output_x_msle: 377.4691 - val_output_y_msle: 149.0260 - val_output_z_msle: 396.4318 - lr: 1.0000e-08\n",
      "Epoch 363/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.2693 - output_x_loss: 375.9503 - output_y_loss: 146.2225 - output_z_loss: 397.0007 - output_x_msle: 375.9503 - output_y_msle: 146.2225 - output_z_msle: 397.0007 - val_loss: 289.8669 - val_output_x_loss: 377.4546 - val_output_y_loss: 149.0160 - val_output_z_loss: 396.3934 - val_output_x_msle: 377.4546 - val_output_y_msle: 149.0160 - val_output_z_msle: 396.3934 - lr: 1.0000e-08\n",
      "Epoch 364/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 288.2466 - output_x_loss: 375.9345 - output_y_loss: 146.2130 - output_z_loss: 396.9382 - output_x_msle: 375.9345 - output_y_msle: 146.2130 - output_z_msle: 396.9382 - val_loss: 289.8387 - val_output_x_loss: 377.4398 - val_output_y_loss: 149.0076 - val_output_z_loss: 396.2987 - val_output_x_msle: 377.4398 - val_output_y_msle: 149.0076 - val_output_z_msle: 396.2987 - lr: 1.0000e-08\n",
      "Epoch 365/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.2161 - output_x_loss: 375.9182 - output_y_loss: 146.1714 - output_z_loss: 396.9005 - output_x_msle: 375.9182 - output_y_msle: 146.1714 - output_z_msle: 396.9005 - val_loss: 289.6994 - val_output_x_loss: 377.4247 - val_output_y_loss: 148.6926 - val_output_z_loss: 396.2622 - val_output_x_msle: 377.4247 - val_output_y_msle: 148.6926 - val_output_z_msle: 396.2622 - lr: 1.0000e-08\n",
      "Epoch 366/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.1916 - output_x_loss: 375.9022 - output_y_loss: 146.1602 - output_z_loss: 396.8334 - output_x_msle: 375.9022 - output_y_msle: 146.1602 - output_z_msle: 396.8334 - val_loss: 289.6788 - val_output_x_loss: 377.4071 - val_output_y_loss: 148.6770 - val_output_z_loss: 396.2258 - val_output_x_msle: 377.4071 - val_output_y_msle: 148.6770 - val_output_z_msle: 396.2258 - lr: 1.0000e-08\n",
      "Epoch 367/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.1566 - output_x_loss: 375.8853 - output_y_loss: 146.1189 - output_z_loss: 396.7746 - output_x_msle: 375.8853 - output_y_msle: 146.1189 - output_z_msle: 396.7746 - val_loss: 289.6482 - val_output_x_loss: 377.3914 - val_output_y_loss: 148.6508 - val_output_z_loss: 396.1568 - val_output_x_msle: 377.3914 - val_output_y_msle: 148.6508 - val_output_z_msle: 396.1568 - lr: 1.0000e-08\n",
      "Epoch 368/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.9937 - output_x_loss: 375.8687 - output_y_loss: 145.7649 - output_z_loss: 396.7010 - output_x_msle: 375.8687 - output_y_msle: 145.7649 - output_z_msle: 396.7010 - val_loss: 289.5553 - val_output_x_loss: 377.3761 - val_output_y_loss: 148.4766 - val_output_z_loss: 396.0710 - val_output_x_msle: 377.3761 - val_output_y_msle: 148.4766 - val_output_z_msle: 396.0710 - lr: 1.0000e-08\n",
      "Epoch 369/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.8546 - output_x_loss: 375.8518 - output_y_loss: 145.4676 - output_z_loss: 396.6340 - output_x_msle: 375.8518 - output_y_msle: 145.4676 - output_z_msle: 396.6340 - val_loss: 289.4175 - val_output_x_loss: 377.3613 - val_output_y_loss: 148.1624 - val_output_z_loss: 396.0401 - val_output_x_msle: 377.3613 - val_output_y_msle: 148.1624 - val_output_z_msle: 396.0401 - lr: 1.0000e-08\n",
      "Epoch 370/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.7939 - output_x_loss: 375.8351 - output_y_loss: 145.3508 - output_z_loss: 396.5977 - output_x_msle: 375.8351 - output_y_msle: 145.3508 - output_z_msle: 396.5977 - val_loss: 289.3314 - val_output_x_loss: 377.3438 - val_output_y_loss: 147.9835 - val_output_z_loss: 396.0022 - val_output_x_msle: 377.3438 - val_output_y_msle: 147.9835 - val_output_z_msle: 396.0022 - lr: 1.0000e-08\n",
      "Epoch 371/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.6895 - output_x_loss: 375.8170 - output_y_loss: 145.1377 - output_z_loss: 396.5380 - output_x_msle: 375.8170 - output_y_msle: 145.1377 - output_z_msle: 396.5380 - val_loss: 289.0099 - val_output_x_loss: 377.3276 - val_output_y_loss: 147.2172 - val_output_z_loss: 395.9600 - val_output_x_msle: 377.3276 - val_output_y_msle: 147.2172 - val_output_z_msle: 395.9600 - lr: 1.0000e-08\n",
      "Epoch 372/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.5437 - output_x_loss: 375.8000 - output_y_loss: 144.8383 - output_z_loss: 396.4417 - output_x_msle: 375.8000 - output_y_msle: 144.8383 - output_z_msle: 396.4417 - val_loss: 288.9657 - val_output_x_loss: 377.3079 - val_output_y_loss: 147.1612 - val_output_z_loss: 395.8899 - val_output_x_msle: 377.3079 - val_output_y_msle: 147.1612 - val_output_z_msle: 395.8899 - lr: 1.0000e-08\n",
      "Epoch 373/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.4511 - output_x_loss: 375.7831 - output_y_loss: 144.6884 - output_z_loss: 396.3123 - output_x_msle: 375.7831 - output_y_msle: 144.6884 - output_z_msle: 396.3123 - val_loss: 288.9418 - val_output_x_loss: 377.2932 - val_output_y_loss: 147.1352 - val_output_z_loss: 395.8522 - val_output_x_msle: 377.2932 - val_output_y_msle: 147.1352 - val_output_z_msle: 395.8522 - lr: 1.0000e-08\n",
      "Epoch 374/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.4054 - output_x_loss: 375.7662 - output_y_loss: 144.6094 - output_z_loss: 396.2757 - output_x_msle: 375.7662 - output_y_msle: 144.6094 - output_z_msle: 396.2757 - val_loss: 288.9208 - val_output_x_loss: 377.2786 - val_output_y_loss: 147.1207 - val_output_z_loss: 395.8054 - val_output_x_msle: 377.2786 - val_output_y_msle: 147.1207 - val_output_z_msle: 395.8054 - lr: 1.0000e-08\n",
      "Epoch 375/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.3179 - output_x_loss: 375.7506 - output_y_loss: 144.4264 - output_z_loss: 396.2357 - output_x_msle: 375.7506 - output_y_msle: 144.4264 - output_z_msle: 396.2357 - val_loss: 288.7046 - val_output_x_loss: 377.2607 - val_output_y_loss: 146.6246 - val_output_z_loss: 395.7523 - val_output_x_msle: 377.2607 - val_output_y_msle: 146.6246 - val_output_z_msle: 395.7523 - lr: 1.0000e-08\n",
      "Epoch 376/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.2931 - output_x_loss: 375.7347 - output_y_loss: 144.4120 - output_z_loss: 396.1726 - output_x_msle: 375.7347 - output_y_msle: 144.4120 - output_z_msle: 396.1726 - val_loss: 288.6658 - val_output_x_loss: 377.2462 - val_output_y_loss: 146.6120 - val_output_z_loss: 395.6124 - val_output_x_msle: 377.2462 - val_output_y_msle: 146.6120 - val_output_z_msle: 395.6124 - lr: 1.0000e-08\n",
      "Epoch 377/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.2540 - output_x_loss: 375.7180 - output_y_loss: 144.3705 - output_z_loss: 396.0933 - output_x_msle: 375.7180 - output_y_msle: 144.3705 - output_z_msle: 396.0933 - val_loss: 288.5516 - val_output_x_loss: 377.2312 - val_output_y_loss: 146.4375 - val_output_z_loss: 395.4207 - val_output_x_msle: 377.2312 - val_output_y_msle: 146.4375 - val_output_z_msle: 395.4207 - lr: 1.0000e-08\n",
      "Epoch 378/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.1600 - output_x_loss: 375.7003 - output_y_loss: 144.1887 - output_z_loss: 396.0219 - output_x_msle: 375.7003 - output_y_msle: 144.1887 - output_z_msle: 396.0219 - val_loss: 288.4492 - val_output_x_loss: 377.2150 - val_output_y_loss: 146.2577 - val_output_z_loss: 395.3009 - val_output_x_msle: 377.2150 - val_output_y_msle: 146.2577 - val_output_z_msle: 395.3009 - lr: 1.0000e-08\n",
      "Epoch 379/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.1108 - output_x_loss: 375.6830 - output_y_loss: 144.1407 - output_z_loss: 395.9072 - output_x_msle: 375.6830 - output_y_msle: 144.1407 - output_z_msle: 395.9072 - val_loss: 288.3967 - val_output_x_loss: 377.1960 - val_output_y_loss: 146.2460 - val_output_z_loss: 395.0992 - val_output_x_msle: 377.1960 - val_output_y_msle: 146.2460 - val_output_z_msle: 395.0992 - lr: 1.0000e-08\n",
      "Epoch 380/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.0807 - output_x_loss: 375.6647 - output_y_loss: 144.1343 - output_z_loss: 395.8055 - output_x_msle: 375.6647 - output_y_msle: 144.1343 - output_z_msle: 395.8055 - val_loss: 288.3593 - val_output_x_loss: 377.1800 - val_output_y_loss: 146.2304 - val_output_z_loss: 394.9758 - val_output_x_msle: 377.1800 - val_output_y_msle: 146.2304 - val_output_z_msle: 394.9758 - lr: 1.0000e-08\n",
      "Epoch 381/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.0418 - output_x_loss: 375.6460 - output_y_loss: 144.0942 - output_z_loss: 395.7292 - output_x_msle: 375.6460 - output_y_msle: 144.0942 - output_z_msle: 395.7292 - val_loss: 288.2438 - val_output_x_loss: 377.1620 - val_output_y_loss: 145.9854 - val_output_z_loss: 394.9242 - val_output_x_msle: 377.1620 - val_output_y_msle: 145.9854 - val_output_z_msle: 394.9242 - lr: 1.0000e-08\n",
      "Epoch 382/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.9500 - output_x_loss: 375.6274 - output_y_loss: 143.9441 - output_z_loss: 395.6069 - output_x_msle: 375.6274 - output_y_msle: 143.9441 - output_z_msle: 395.6069 - val_loss: 288.2177 - val_output_x_loss: 377.1411 - val_output_y_loss: 145.9722 - val_output_z_loss: 394.8615 - val_output_x_msle: 377.1411 - val_output_y_msle: 145.9722 - val_output_z_msle: 394.8615 - lr: 1.0000e-08\n",
      "Epoch 383/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.8962 - output_x_loss: 375.6085 - output_y_loss: 143.8966 - output_z_loss: 395.4707 - output_x_msle: 375.6085 - output_y_msle: 143.8966 - output_z_msle: 395.4707 - val_loss: 288.1914 - val_output_x_loss: 377.1255 - val_output_y_loss: 145.9642 - val_output_z_loss: 394.7776 - val_output_x_msle: 377.1255 - val_output_y_msle: 145.9642 - val_output_z_msle: 394.7776 - lr: 1.0000e-08\n",
      "Epoch 384/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 286.8633 - output_x_loss: 375.5906 - output_y_loss: 143.8861 - output_z_loss: 395.3626 - output_x_msle: 375.5906 - output_y_msle: 143.8861 - output_z_msle: 395.3626 - val_loss: 288.1509 - val_output_x_loss: 377.1082 - val_output_y_loss: 145.9534 - val_output_z_loss: 394.6313 - val_output_x_msle: 377.1082 - val_output_y_msle: 145.9534 - val_output_z_msle: 394.6313 - lr: 1.0000e-08\n",
      "Epoch 385/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.8168 - output_x_loss: 375.5722 - output_y_loss: 143.8596 - output_z_loss: 395.2209 - output_x_msle: 375.5722 - output_y_msle: 143.8596 - output_z_msle: 395.2209 - val_loss: 288.1244 - val_output_x_loss: 377.0877 - val_output_y_loss: 145.9422 - val_output_z_loss: 394.5622 - val_output_x_msle: 377.0877 - val_output_y_msle: 145.9422 - val_output_z_msle: 394.5622 - lr: 1.0000e-08\n",
      "Epoch 386/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.7667 - output_x_loss: 375.5544 - output_y_loss: 143.8379 - output_z_loss: 395.0491 - output_x_msle: 375.5544 - output_y_msle: 143.8379 - output_z_msle: 395.0491 - val_loss: 288.0955 - val_output_x_loss: 377.0740 - val_output_y_loss: 145.9319 - val_output_z_loss: 394.4655 - val_output_x_msle: 377.0740 - val_output_y_msle: 145.9319 - val_output_z_msle: 394.4655 - lr: 1.0000e-08\n",
      "Epoch 387/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.7201 - output_x_loss: 375.5396 - output_y_loss: 143.8186 - output_z_loss: 394.8840 - output_x_msle: 375.5396 - output_y_msle: 143.8186 - output_z_msle: 394.8840 - val_loss: 288.0752 - val_output_x_loss: 377.0606 - val_output_y_loss: 145.9274 - val_output_z_loss: 394.3997 - val_output_x_msle: 377.0606 - val_output_y_msle: 145.9274 - val_output_z_msle: 394.3997 - lr: 1.0000e-08\n",
      "Epoch 388/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.7017 - output_x_loss: 375.5243 - output_y_loss: 143.8151 - output_z_loss: 394.8295 - output_x_msle: 375.5243 - output_y_msle: 143.8151 - output_z_msle: 394.8295 - val_loss: 288.0309 - val_output_x_loss: 377.0461 - val_output_y_loss: 145.9221 - val_output_z_loss: 394.2177 - val_output_x_msle: 377.0461 - val_output_y_msle: 145.9221 - val_output_z_msle: 394.2177 - lr: 1.0000e-08\n",
      "Epoch 389/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.6703 - output_x_loss: 375.5082 - output_y_loss: 143.8111 - output_z_loss: 394.7126 - output_x_msle: 375.5082 - output_y_msle: 143.8111 - output_z_msle: 394.7126 - val_loss: 287.9941 - val_output_x_loss: 377.0284 - val_output_y_loss: 145.9150 - val_output_z_loss: 394.0838 - val_output_x_msle: 377.0284 - val_output_y_msle: 145.9150 - val_output_z_msle: 394.0838 - lr: 1.0000e-08\n",
      "Epoch 390/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.6333 - output_x_loss: 375.4926 - output_y_loss: 143.8070 - output_z_loss: 394.5674 - output_x_msle: 375.4926 - output_y_msle: 143.8070 - output_z_msle: 394.5674 - val_loss: 287.9562 - val_output_x_loss: 377.0138 - val_output_y_loss: 145.9072 - val_output_z_loss: 393.9393 - val_output_x_msle: 377.0138 - val_output_y_msle: 145.9072 - val_output_z_msle: 393.9393 - lr: 1.0000e-08\n",
      "Epoch 391/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.6100 - output_x_loss: 375.4767 - output_y_loss: 143.8029 - output_z_loss: 394.4908 - output_x_msle: 375.4767 - output_y_msle: 143.8029 - output_z_msle: 394.4908 - val_loss: 287.9346 - val_output_x_loss: 376.9999 - val_output_y_loss: 145.8954 - val_output_z_loss: 393.8823 - val_output_x_msle: 376.9999 - val_output_y_msle: 145.8954 - val_output_z_msle: 393.8823 - lr: 1.0000e-08\n",
      "Epoch 392/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.5769 - output_x_loss: 375.4604 - output_y_loss: 143.7977 - output_z_loss: 394.3679 - output_x_msle: 375.4604 - output_y_msle: 143.7977 - output_z_msle: 394.3679 - val_loss: 287.8766 - val_output_x_loss: 376.9815 - val_output_y_loss: 145.8171 - val_output_z_loss: 393.7862 - val_output_x_msle: 376.9815 - val_output_y_msle: 145.8171 - val_output_z_msle: 393.7862 - lr: 1.0000e-08\n",
      "Epoch 393/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.5332 - output_x_loss: 375.4444 - output_y_loss: 143.7921 - output_z_loss: 394.1920 - output_x_msle: 375.4444 - output_y_msle: 143.7921 - output_z_msle: 394.1920 - val_loss: 287.7788 - val_output_x_loss: 376.9673 - val_output_y_loss: 145.6788 - val_output_z_loss: 393.6016 - val_output_x_msle: 376.9673 - val_output_y_msle: 145.6788 - val_output_z_msle: 393.6016 - lr: 1.0000e-08\n",
      "Epoch 394/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.5028 - output_x_loss: 375.4284 - output_y_loss: 143.7856 - output_z_loss: 394.0864 - output_x_msle: 375.4284 - output_y_msle: 143.7856 - output_z_msle: 394.0864 - val_loss: 287.7931 - val_output_x_loss: 376.9509 - val_output_y_loss: 145.7999 - val_output_z_loss: 393.4641 - val_output_x_msle: 376.9509 - val_output_y_msle: 145.7999 - val_output_z_msle: 393.4641 - lr: 1.0000e-08\n",
      "Epoch 395/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.4487 - output_x_loss: 375.4113 - output_y_loss: 143.7629 - output_z_loss: 393.8956 - output_x_msle: 375.4113 - output_y_msle: 143.7629 - output_z_msle: 393.8956 - val_loss: 287.7051 - val_output_x_loss: 376.9356 - val_output_y_loss: 145.6516 - val_output_z_loss: 393.3516 - val_output_x_msle: 376.9356 - val_output_y_msle: 145.6516 - val_output_z_msle: 393.3516 - lr: 1.0000e-08\n",
      "Epoch 396/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.4034 - output_x_loss: 375.3942 - output_y_loss: 143.7574 - output_z_loss: 393.7138 - output_x_msle: 375.3942 - output_y_msle: 143.7574 - output_z_msle: 393.7138 - val_loss: 287.6756 - val_output_x_loss: 376.9183 - val_output_y_loss: 145.6318 - val_output_z_loss: 393.2775 - val_output_x_msle: 376.9183 - val_output_y_msle: 145.6318 - val_output_z_msle: 393.2775 - lr: 1.0000e-08\n",
      "Epoch 397/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.3753 - output_x_loss: 375.3763 - output_y_loss: 143.7514 - output_z_loss: 393.6214 - output_x_msle: 375.3763 - output_y_msle: 143.7514 - output_z_msle: 393.6214 - val_loss: 287.6153 - val_output_x_loss: 376.9002 - val_output_y_loss: 145.6190 - val_output_z_loss: 393.0380 - val_output_x_msle: 376.9002 - val_output_y_msle: 145.6190 - val_output_z_msle: 393.0380 - lr: 1.0000e-08\n",
      "Epoch 398/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.3343 - output_x_loss: 375.3575 - output_y_loss: 143.7444 - output_z_loss: 393.4677 - output_x_msle: 375.3575 - output_y_msle: 143.7444 - output_z_msle: 393.4677 - val_loss: 287.5679 - val_output_x_loss: 376.8833 - val_output_y_loss: 145.6029 - val_output_z_loss: 392.8670 - val_output_x_msle: 376.8833 - val_output_y_msle: 145.6029 - val_output_z_msle: 392.8670 - lr: 1.0000e-08\n",
      "Epoch 399/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.2682 - output_x_loss: 375.3383 - output_y_loss: 143.7014 - output_z_loss: 393.2620 - output_x_msle: 375.3383 - output_y_msle: 143.7014 - output_z_msle: 393.2620 - val_loss: 287.5074 - val_output_x_loss: 376.8639 - val_output_y_loss: 145.5089 - val_output_z_loss: 392.7917 - val_output_x_msle: 376.8639 - val_output_y_msle: 145.5089 - val_output_z_msle: 392.7917 - lr: 1.0000e-08\n",
      "Epoch 400/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.1101 - output_x_loss: 375.3192 - output_y_loss: 143.3773 - output_z_loss: 393.1577 - output_x_msle: 375.3192 - output_y_msle: 143.3773 - output_z_msle: 393.1577 - val_loss: 287.2456 - val_output_x_loss: 376.8426 - val_output_y_loss: 144.9109 - val_output_z_loss: 392.7213 - val_output_x_msle: 376.8426 - val_output_y_msle: 144.9109 - val_output_z_msle: 392.7213 - lr: 1.0000e-08\n",
      "Epoch 401/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.9832 - output_x_loss: 375.3007 - output_y_loss: 143.1401 - output_z_loss: 393.0346 - output_x_msle: 375.3007 - output_y_msle: 143.1401 - output_z_msle: 393.0346 - val_loss: 287.1975 - val_output_x_loss: 376.8257 - val_output_y_loss: 144.8828 - val_output_z_loss: 392.5704 - val_output_x_msle: 376.8257 - val_output_y_msle: 144.8828 - val_output_z_msle: 392.5704 - lr: 1.0000e-08\n",
      "Epoch 402/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.9540 - output_x_loss: 375.2823 - output_y_loss: 143.1317 - output_z_loss: 392.9418 - output_x_msle: 375.2823 - output_y_msle: 143.1317 - output_z_msle: 392.9418 - val_loss: 287.1425 - val_output_x_loss: 376.8093 - val_output_y_loss: 144.8028 - val_output_z_loss: 392.4883 - val_output_x_msle: 376.8093 - val_output_y_msle: 144.8028 - val_output_z_msle: 392.4883 - lr: 1.0000e-08\n",
      "Epoch 403/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 285.9105 - output_x_loss: 375.2632 - output_y_loss: 143.1087 - output_z_loss: 392.8088 - output_x_msle: 375.2632 - output_y_msle: 143.1087 - output_z_msle: 392.8088 - val_loss: 287.0961 - val_output_x_loss: 376.7893 - val_output_y_loss: 144.7841 - val_output_z_loss: 392.3333 - val_output_x_msle: 376.7893 - val_output_y_msle: 144.7841 - val_output_z_msle: 392.3333 - lr: 1.0000e-08\n",
      "Epoch 404/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.8817 - output_x_loss: 375.2433 - output_y_loss: 143.1023 - output_z_loss: 392.7179 - output_x_msle: 375.2433 - output_y_msle: 143.1023 - output_z_msle: 392.7179 - val_loss: 287.0115 - val_output_x_loss: 376.7728 - val_output_y_loss: 144.7109 - val_output_z_loss: 392.0901 - val_output_x_msle: 376.7728 - val_output_y_msle: 144.7109 - val_output_z_msle: 392.0901 - lr: 1.0000e-08\n",
      "Epoch 405/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.8416 - output_x_loss: 375.2239 - output_y_loss: 143.0939 - output_z_loss: 392.5725 - output_x_msle: 375.2239 - output_y_msle: 143.0939 - output_z_msle: 392.5725 - val_loss: 286.9839 - val_output_x_loss: 376.7491 - val_output_y_loss: 144.7023 - val_output_z_loss: 392.0169 - val_output_x_msle: 376.7491 - val_output_y_msle: 144.7023 - val_output_z_msle: 392.0169 - lr: 1.0000e-08\n",
      "Epoch 406/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.8049 - output_x_loss: 375.2059 - output_y_loss: 143.0809 - output_z_loss: 392.4504 - output_x_msle: 375.2059 - output_y_msle: 143.0809 - output_z_msle: 392.4504 - val_loss: 286.9441 - val_output_x_loss: 376.7350 - val_output_y_loss: 144.6953 - val_output_z_loss: 391.8596 - val_output_x_msle: 376.7350 - val_output_y_msle: 144.6953 - val_output_z_msle: 391.8596 - lr: 1.0000e-08\n",
      "Epoch 407/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.7703 - output_x_loss: 375.1913 - output_y_loss: 143.0449 - output_z_loss: 392.3789 - output_x_msle: 375.1913 - output_y_msle: 143.0449 - output_z_msle: 392.3789 - val_loss: 286.9307 - val_output_x_loss: 376.7231 - val_output_y_loss: 144.6880 - val_output_z_loss: 391.8311 - val_output_x_msle: 376.7231 - val_output_y_msle: 144.6880 - val_output_z_msle: 391.8311 - lr: 1.0000e-08\n",
      "Epoch 408/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.7549 - output_x_loss: 375.1777 - output_y_loss: 143.0397 - output_z_loss: 392.3394 - output_x_msle: 375.1777 - output_y_msle: 143.0397 - output_z_msle: 392.3394 - val_loss: 286.9196 - val_output_x_loss: 376.7110 - val_output_y_loss: 144.6817 - val_output_z_loss: 391.8127 - val_output_x_msle: 376.7110 - val_output_y_msle: 144.6817 - val_output_z_msle: 391.8127 - lr: 1.0000e-08\n",
      "Epoch 409/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.7260 - output_x_loss: 375.1639 - output_y_loss: 143.0005 - output_z_loss: 392.3018 - output_x_msle: 375.1639 - output_y_msle: 143.0005 - output_z_msle: 392.3018 - val_loss: 286.9056 - val_output_x_loss: 376.6962 - val_output_y_loss: 144.6720 - val_output_z_loss: 391.7916 - val_output_x_msle: 376.6962 - val_output_y_msle: 144.6720 - val_output_z_msle: 391.7916 - lr: 1.0000e-08\n",
      "Epoch 410/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.6828 - output_x_loss: 375.1488 - output_y_loss: 142.9230 - output_z_loss: 392.2707 - output_x_msle: 375.1488 - output_y_msle: 142.9230 - output_z_msle: 392.2707 - val_loss: 286.8927 - val_output_x_loss: 376.6812 - val_output_y_loss: 144.6633 - val_output_z_loss: 391.7744 - val_output_x_msle: 376.6812 - val_output_y_msle: 144.6633 - val_output_z_msle: 391.7744 - lr: 1.0000e-08\n",
      "Epoch 411/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.6686 - output_x_loss: 375.1332 - output_y_loss: 142.9135 - output_z_loss: 392.2497 - output_x_msle: 375.1332 - output_y_msle: 142.9135 - output_z_msle: 392.2497 - val_loss: 286.8475 - val_output_x_loss: 376.6657 - val_output_y_loss: 144.5764 - val_output_z_loss: 391.7533 - val_output_x_msle: 376.6657 - val_output_y_msle: 144.5764 - val_output_z_msle: 391.7533 - lr: 1.0000e-08\n",
      "Epoch 412/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.6499 - output_x_loss: 375.1173 - output_y_loss: 142.8941 - output_z_loss: 392.2267 - output_x_msle: 375.1173 - output_y_msle: 142.8941 - output_z_msle: 392.2267 - val_loss: 286.8347 - val_output_x_loss: 376.6502 - val_output_y_loss: 144.5704 - val_output_z_loss: 391.7319 - val_output_x_msle: 376.6502 - val_output_y_msle: 144.5704 - val_output_z_msle: 391.7319 - lr: 1.0000e-08\n",
      "Epoch 413/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.5492 - output_x_loss: 375.1013 - output_y_loss: 142.6779 - output_z_loss: 392.1876 - output_x_msle: 375.1013 - output_y_msle: 142.6779 - output_z_msle: 392.1876 - val_loss: 286.7145 - val_output_x_loss: 376.6350 - val_output_y_loss: 144.3025 - val_output_z_loss: 391.6976 - val_output_x_msle: 376.6350 - val_output_y_msle: 144.3025 - val_output_z_msle: 391.6976 - lr: 1.0000e-08\n",
      "Epoch 414/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.5003 - output_x_loss: 375.0868 - output_y_loss: 142.5995 - output_z_loss: 392.1289 - output_x_msle: 375.0868 - output_y_msle: 142.5995 - output_z_msle: 392.1289 - val_loss: 286.6402 - val_output_x_loss: 376.6218 - val_output_y_loss: 144.1377 - val_output_z_loss: 391.6823 - val_output_x_msle: 376.6218 - val_output_y_msle: 144.1377 - val_output_z_msle: 391.6823 - lr: 1.0000e-08\n",
      "Epoch 415/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3980 - output_x_loss: 375.0743 - output_y_loss: 142.3629 - output_z_loss: 392.1159 - output_x_msle: 375.0743 - output_y_msle: 142.3629 - output_z_msle: 392.1159 - val_loss: 286.6292 - val_output_x_loss: 376.6103 - val_output_y_loss: 144.1289 - val_output_z_loss: 391.6680 - val_output_x_msle: 376.6103 - val_output_y_msle: 144.1289 - val_output_z_msle: 391.6680 - lr: 1.0000e-08\n",
      "Epoch 416/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3849 - output_x_loss: 375.0613 - output_y_loss: 142.3505 - output_z_loss: 392.1004 - output_x_msle: 375.0613 - output_y_msle: 142.3505 - output_z_msle: 392.1004 - val_loss: 286.6187 - val_output_x_loss: 376.5984 - val_output_y_loss: 144.1230 - val_output_z_loss: 391.6507 - val_output_x_msle: 376.5984 - val_output_y_msle: 144.1230 - val_output_z_msle: 391.6507 - lr: 1.0000e-08\n",
      "Epoch 417/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3614 - output_x_loss: 375.0475 - output_y_loss: 142.3139 - output_z_loss: 392.0838 - output_x_msle: 375.0475 - output_y_msle: 142.3139 - output_z_msle: 392.0838 - val_loss: 286.5460 - val_output_x_loss: 376.5864 - val_output_y_loss: 143.9618 - val_output_z_loss: 391.6336 - val_output_x_msle: 376.5864 - val_output_y_msle: 143.9618 - val_output_z_msle: 391.6336 - lr: 1.0000e-08\n",
      "Epoch 418/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3450 - output_x_loss: 375.0334 - output_y_loss: 142.2982 - output_z_loss: 392.0618 - output_x_msle: 375.0334 - output_y_msle: 142.2982 - output_z_msle: 392.0618 - val_loss: 286.5638 - val_output_x_loss: 376.5713 - val_output_y_loss: 144.0332 - val_output_z_loss: 391.6100 - val_output_x_msle: 376.5713 - val_output_y_msle: 144.0332 - val_output_z_msle: 391.6100 - lr: 1.0000e-08\n",
      "Epoch 419/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3287 - output_x_loss: 375.0190 - output_y_loss: 142.2808 - output_z_loss: 392.0437 - output_x_msle: 375.0190 - output_y_msle: 142.2808 - output_z_msle: 392.0437 - val_loss: 286.5532 - val_output_x_loss: 376.5579 - val_output_y_loss: 144.0299 - val_output_z_loss: 391.5902 - val_output_x_msle: 376.5579 - val_output_y_msle: 144.0299 - val_output_z_msle: 391.5902 - lr: 1.0000e-08\n",
      "Epoch 420/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.3061 - output_x_loss: 375.0042 - output_y_loss: 142.2489 - output_z_loss: 392.0242 - output_x_msle: 375.0042 - output_y_msle: 142.2489 - output_z_msle: 392.0242 - val_loss: 286.4733 - val_output_x_loss: 376.5417 - val_output_y_loss: 143.8553 - val_output_z_loss: 391.5726 - val_output_x_msle: 376.5417 - val_output_y_msle: 143.8553 - val_output_z_msle: 391.5726 - lr: 1.0000e-08\n",
      "Epoch 421/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.2323 - output_x_loss: 374.9888 - output_y_loss: 142.0919 - output_z_loss: 391.9999 - output_x_msle: 374.9888 - output_y_msle: 142.0919 - output_z_msle: 391.9999 - val_loss: 286.4598 - val_output_x_loss: 376.5252 - val_output_y_loss: 143.8535 - val_output_z_loss: 391.5415 - val_output_x_msle: 376.5252 - val_output_y_msle: 143.8535 - val_output_z_msle: 391.5415 - lr: 1.0000e-08\n",
      "Epoch 422/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.2189 - output_x_loss: 374.9742 - output_y_loss: 142.0904 - output_z_loss: 391.9653 - output_x_msle: 374.9742 - output_y_msle: 142.0904 - output_z_msle: 391.9653 - val_loss: 286.4501 - val_output_x_loss: 376.5117 - val_output_y_loss: 143.8520 - val_output_z_loss: 391.5233 - val_output_x_msle: 376.5117 - val_output_y_msle: 143.8520 - val_output_z_msle: 391.5233 - lr: 1.0000e-08\n",
      "Epoch 423/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.1826 - output_x_loss: 374.9590 - output_y_loss: 142.0233 - output_z_loss: 391.9486 - output_x_msle: 374.9590 - output_y_msle: 142.0233 - output_z_msle: 391.9486 - val_loss: 286.4042 - val_output_x_loss: 376.4988 - val_output_y_loss: 143.7591 - val_output_z_loss: 391.5052 - val_output_x_msle: 376.4988 - val_output_y_msle: 143.7591 - val_output_z_msle: 391.5052 - lr: 1.0000e-08\n",
      "Epoch 424/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0862 - output_x_loss: 374.9431 - output_y_loss: 141.8063 - output_z_loss: 391.9321 - output_x_msle: 374.9431 - output_y_msle: 141.8063 - output_z_msle: 391.9321 - val_loss: 286.3924 - val_output_x_loss: 376.4828 - val_output_y_loss: 143.7568 - val_output_z_loss: 391.4828 - val_output_x_msle: 376.4828 - val_output_y_msle: 143.7568 - val_output_z_msle: 391.4828 - lr: 1.0000e-08\n",
      "Epoch 425/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0724 - output_x_loss: 374.9270 - output_y_loss: 141.7986 - output_z_loss: 391.9108 - output_x_msle: 374.9270 - output_y_msle: 141.7986 - output_z_msle: 391.9108 - val_loss: 286.3798 - val_output_x_loss: 376.4672 - val_output_y_loss: 143.7553 - val_output_z_loss: 391.4540 - val_output_x_msle: 376.4672 - val_output_y_msle: 143.7553 - val_output_z_msle: 391.4540 - lr: 1.0000e-08\n",
      "Epoch 426/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0497 - output_x_loss: 374.9110 - output_y_loss: 141.7975 - output_z_loss: 391.8322 - output_x_msle: 374.9110 - output_y_msle: 141.7975 - output_z_msle: 391.8322 - val_loss: 286.3450 - val_output_x_loss: 376.4500 - val_output_y_loss: 143.7529 - val_output_z_loss: 391.3194 - val_output_x_msle: 376.4500 - val_output_y_msle: 143.7529 - val_output_z_msle: 391.3194 - lr: 1.0000e-08\n",
      "Epoch 427/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0356 - output_x_loss: 374.8980 - output_y_loss: 141.7959 - output_z_loss: 391.7895 - output_x_msle: 374.8980 - output_y_msle: 141.7959 - output_z_msle: 391.7895 - val_loss: 286.3376 - val_output_x_loss: 376.4387 - val_output_y_loss: 143.7514 - val_output_z_loss: 391.3079 - val_output_x_msle: 376.4387 - val_output_y_msle: 143.7514 - val_output_z_msle: 391.3079 - lr: 1.0000e-08\n",
      "Epoch 428/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0275 - output_x_loss: 374.8850 - output_y_loss: 141.7945 - output_z_loss: 391.7780 - output_x_msle: 374.8850 - output_y_msle: 141.7945 - output_z_msle: 391.7780 - val_loss: 286.3299 - val_output_x_loss: 376.4275 - val_output_y_loss: 143.7499 - val_output_z_loss: 391.2950 - val_output_x_msle: 376.4275 - val_output_y_msle: 143.7499 - val_output_z_msle: 391.2950 - lr: 1.0000e-08\n",
      "Epoch 429/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0189 - output_x_loss: 374.8719 - output_y_loss: 141.7930 - output_z_loss: 391.7637 - output_x_msle: 374.8719 - output_y_msle: 141.7930 - output_z_msle: 391.7637 - val_loss: 286.3208 - val_output_x_loss: 376.4139 - val_output_y_loss: 143.7483 - val_output_z_loss: 391.2794 - val_output_x_msle: 376.4139 - val_output_y_msle: 143.7483 - val_output_z_msle: 391.2794 - lr: 1.0000e-08\n",
      "Epoch 430/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.0070 - output_x_loss: 374.8587 - output_y_loss: 141.7916 - output_z_loss: 391.7346 - output_x_msle: 374.8587 - output_y_msle: 141.7916 - output_z_msle: 391.7346 - val_loss: 286.3124 - val_output_x_loss: 376.4016 - val_output_y_loss: 143.7467 - val_output_z_loss: 391.2658 - val_output_x_msle: 376.4016 - val_output_y_msle: 143.7467 - val_output_z_msle: 391.2658 - lr: 1.0000e-08\n",
      "Epoch 431/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.9983 - output_x_loss: 374.8448 - output_y_loss: 141.7903 - output_z_loss: 391.7220 - output_x_msle: 374.8448 - output_y_msle: 141.7903 - output_z_msle: 391.7220 - val_loss: 286.3033 - val_output_x_loss: 376.3882 - val_output_y_loss: 143.7448 - val_output_z_loss: 391.2505 - val_output_x_msle: 376.3882 - val_output_y_msle: 143.7448 - val_output_z_msle: 391.2505 - lr: 1.0000e-08\n",
      "Epoch 432/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.9892 - output_x_loss: 374.8301 - output_y_loss: 141.7889 - output_z_loss: 391.7077 - output_x_msle: 374.8301 - output_y_msle: 141.7889 - output_z_msle: 391.7077 - val_loss: 286.2926 - val_output_x_loss: 376.3722 - val_output_y_loss: 143.7425 - val_output_z_loss: 391.2336 - val_output_x_msle: 376.3722 - val_output_y_msle: 143.7425 - val_output_z_msle: 391.2336 - lr: 1.0000e-08\n",
      "Epoch 433/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.9275 - output_x_loss: 374.8156 - output_y_loss: 141.6553 - output_z_loss: 391.6951 - output_x_msle: 374.8156 - output_y_msle: 141.6553 - output_z_msle: 391.6951 - val_loss: 286.2863 - val_output_x_loss: 376.3599 - val_output_y_loss: 143.7439 - val_output_z_loss: 391.2238 - val_output_x_msle: 376.3599 - val_output_y_msle: 143.7439 - val_output_z_msle: 391.2238 - lr: 1.0000e-08\n",
      "Epoch 434/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.8938 - output_x_loss: 374.8041 - output_y_loss: 141.5876 - output_z_loss: 391.6848 - output_x_msle: 374.8041 - output_y_msle: 141.5876 - output_z_msle: 391.6848 - val_loss: 286.2784 - val_output_x_loss: 376.3491 - val_output_y_loss: 143.7427 - val_output_z_loss: 391.2084 - val_output_x_msle: 376.3491 - val_output_y_msle: 143.7427 - val_output_z_msle: 391.2084 - lr: 1.0000e-08\n",
      "Epoch 435/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.8859 - output_x_loss: 374.7926 - output_y_loss: 141.5864 - output_z_loss: 391.6711 - output_x_msle: 374.7926 - output_y_msle: 141.5864 - output_z_msle: 391.6711 - val_loss: 286.2690 - val_output_x_loss: 376.3356 - val_output_y_loss: 143.7413 - val_output_z_loss: 391.1907 - val_output_x_msle: 376.3356 - val_output_y_msle: 143.7413 - val_output_z_msle: 391.1907 - lr: 1.0000e-08\n",
      "Epoch 436/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.8767 - output_x_loss: 374.7799 - output_y_loss: 141.5847 - output_z_loss: 391.6541 - output_x_msle: 374.7799 - output_y_msle: 141.5847 - output_z_msle: 391.6541 - val_loss: 286.2592 - val_output_x_loss: 376.3246 - val_output_y_loss: 143.7397 - val_output_z_loss: 391.1680 - val_output_x_msle: 376.3246 - val_output_y_msle: 143.7397 - val_output_z_msle: 391.1680 - lr: 1.0000e-08\n",
      "Epoch 437/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.8126 - output_x_loss: 374.7673 - output_y_loss: 141.4448 - output_z_loss: 391.6391 - output_x_msle: 374.7673 - output_y_msle: 141.4448 - output_z_msle: 391.6391 - val_loss: 286.1821 - val_output_x_loss: 376.3119 - val_output_y_loss: 143.5791 - val_output_z_loss: 391.1285 - val_output_x_msle: 376.3119 - val_output_y_msle: 143.5791 - val_output_z_msle: 391.1285 - lr: 1.0000e-08\n",
      "Epoch 438/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7980 - output_x_loss: 374.7544 - output_y_loss: 141.4346 - output_z_loss: 391.6120 - output_x_msle: 374.7544 - output_y_msle: 141.4346 - output_z_msle: 391.6120 - val_loss: 286.1601 - val_output_x_loss: 376.2986 - val_output_y_loss: 143.5776 - val_output_z_loss: 391.0481 - val_output_x_msle: 376.2986 - val_output_y_msle: 143.5776 - val_output_z_msle: 391.0481 - lr: 1.0000e-08\n",
      "Epoch 439/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7818 - output_x_loss: 374.7412 - output_y_loss: 141.4332 - output_z_loss: 391.5602 - output_x_msle: 374.7412 - output_y_msle: 141.4332 - output_z_msle: 391.5602 - val_loss: 286.1508 - val_output_x_loss: 376.2868 - val_output_y_loss: 143.5762 - val_output_z_loss: 391.0276 - val_output_x_msle: 376.2868 - val_output_y_msle: 143.5762 - val_output_z_msle: 391.0276 - lr: 1.0000e-08\n",
      "Epoch 440/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7720 - output_x_loss: 374.7276 - output_y_loss: 141.4319 - output_z_loss: 391.5399 - output_x_msle: 374.7276 - output_y_msle: 141.4319 - output_z_msle: 391.5399 - val_loss: 286.1396 - val_output_x_loss: 376.2726 - val_output_y_loss: 143.5746 - val_output_z_loss: 391.0033 - val_output_x_msle: 376.2726 - val_output_y_msle: 143.5746 - val_output_z_msle: 391.0033 - lr: 1.0000e-08\n",
      "Epoch 441/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7603 - output_x_loss: 374.7137 - output_y_loss: 141.4302 - output_z_loss: 391.5139 - output_x_msle: 374.7137 - output_y_msle: 141.4302 - output_z_msle: 391.5139 - val_loss: 286.1264 - val_output_x_loss: 376.2585 - val_output_y_loss: 143.5728 - val_output_z_loss: 390.9695 - val_output_x_msle: 376.2585 - val_output_y_msle: 143.5728 - val_output_z_msle: 390.9695 - lr: 1.0000e-08\n",
      "Epoch 442/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 284.7419 - output_x_loss: 374.6990 - output_y_loss: 141.4284 - output_z_loss: 391.4553 - output_x_msle: 374.6990 - output_y_msle: 141.4284 - output_z_msle: 391.4553 - val_loss: 286.1122 - val_output_x_loss: 376.2436 - val_output_y_loss: 143.5706 - val_output_z_loss: 390.9325 - val_output_x_msle: 376.2436 - val_output_y_msle: 143.5706 - val_output_z_msle: 390.9325 - lr: 1.0000e-08\n",
      "Epoch 443/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7291 - output_x_loss: 374.6844 - output_y_loss: 141.4260 - output_z_loss: 391.4247 - output_x_msle: 374.6844 - output_y_msle: 141.4260 - output_z_msle: 391.4247 - val_loss: 286.0800 - val_output_x_loss: 376.2300 - val_output_y_loss: 143.5678 - val_output_z_loss: 390.8041 - val_output_x_msle: 376.2300 - val_output_y_msle: 143.5678 - val_output_z_msle: 390.8041 - lr: 1.0000e-08\n",
      "Epoch 444/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.7104 - output_x_loss: 374.6693 - output_y_loss: 141.4223 - output_z_loss: 391.3681 - output_x_msle: 374.6693 - output_y_msle: 141.4223 - output_z_msle: 391.3681 - val_loss: 286.0334 - val_output_x_loss: 376.2163 - val_output_y_loss: 143.5627 - val_output_z_loss: 390.6090 - val_output_x_msle: 376.2163 - val_output_y_msle: 143.5627 - val_output_z_msle: 390.6090 - lr: 1.0000e-08\n",
      "Epoch 445/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.6852 - output_x_loss: 374.6537 - output_y_loss: 141.4054 - output_z_loss: 391.3076 - output_x_msle: 374.6537 - output_y_msle: 141.4054 - output_z_msle: 391.3076 - val_loss: 286.0195 - val_output_x_loss: 376.1982 - val_output_y_loss: 143.5603 - val_output_z_loss: 390.5807 - val_output_x_msle: 376.1982 - val_output_y_msle: 143.5603 - val_output_z_msle: 390.5807 - lr: 1.0000e-08\n",
      "Epoch 446/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.6729 - output_x_loss: 374.6378 - output_y_loss: 141.4039 - output_z_loss: 391.2808 - output_x_msle: 374.6378 - output_y_msle: 141.4039 - output_z_msle: 391.2808 - val_loss: 286.0074 - val_output_x_loss: 376.1835 - val_output_y_loss: 143.5580 - val_output_z_loss: 390.5538 - val_output_x_msle: 376.1835 - val_output_y_msle: 143.5580 - val_output_z_msle: 390.5538 - lr: 1.0000e-08\n",
      "Epoch 447/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.6538 - output_x_loss: 374.6212 - output_y_loss: 141.4022 - output_z_loss: 391.2218 - output_x_msle: 374.6212 - output_y_msle: 141.4022 - output_z_msle: 391.2218 - val_loss: 285.9951 - val_output_x_loss: 376.1686 - val_output_y_loss: 143.5555 - val_output_z_loss: 390.5275 - val_output_x_msle: 376.1686 - val_output_y_msle: 143.5555 - val_output_z_msle: 390.5275 - lr: 1.0000e-08\n",
      "Epoch 448/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.6371 - output_x_loss: 374.6041 - output_y_loss: 141.4005 - output_z_loss: 391.1765 - output_x_msle: 374.6041 - output_y_msle: 141.4005 - output_z_msle: 391.1765 - val_loss: 285.9799 - val_output_x_loss: 376.1501 - val_output_y_loss: 143.5525 - val_output_z_loss: 390.4943 - val_output_x_msle: 376.1501 - val_output_y_msle: 143.5525 - val_output_z_msle: 390.4943 - lr: 1.0000e-08\n",
      "Epoch 449/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.6197 - output_x_loss: 374.5860 - output_y_loss: 141.3987 - output_z_loss: 391.1293 - output_x_msle: 374.5860 - output_y_msle: 141.3987 - output_z_msle: 391.1293 - val_loss: 285.9583 - val_output_x_loss: 376.1345 - val_output_y_loss: 143.5480 - val_output_z_loss: 390.4258 - val_output_x_msle: 376.1345 - val_output_y_msle: 143.5480 - val_output_z_msle: 390.4258 - lr: 1.0000e-08\n",
      "Epoch 450/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.5531 - output_x_loss: 374.5675 - output_y_loss: 141.2938 - output_z_loss: 391.0426 - output_x_msle: 374.5675 - output_y_msle: 141.2938 - output_z_msle: 391.0426 - val_loss: 285.7512 - val_output_x_loss: 376.1187 - val_output_y_loss: 143.0579 - val_output_z_loss: 390.4025 - val_output_x_msle: 376.1187 - val_output_y_msle: 143.0579 - val_output_z_msle: 390.4025 - lr: 1.0000e-08\n",
      "Epoch 451/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.5153 - output_x_loss: 374.5503 - output_y_loss: 141.2302 - output_z_loss: 391.0161 - output_x_msle: 374.5503 - output_y_msle: 141.2302 - output_z_msle: 391.0161 - val_loss: 285.7191 - val_output_x_loss: 376.0989 - val_output_y_loss: 143.0544 - val_output_z_loss: 390.2884 - val_output_x_msle: 376.0989 - val_output_y_msle: 143.0544 - val_output_z_msle: 390.2884 - lr: 1.0000e-08\n",
      "Epoch 452/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4967 - output_x_loss: 374.5317 - output_y_loss: 141.2226 - output_z_loss: 390.9746 - output_x_msle: 374.5317 - output_y_msle: 141.2226 - output_z_msle: 390.9746 - val_loss: 285.7025 - val_output_x_loss: 376.0821 - val_output_y_loss: 143.0455 - val_output_z_loss: 390.2573 - val_output_x_msle: 376.0821 - val_output_y_msle: 143.0455 - val_output_z_msle: 390.2573 - lr: 1.0000e-08\n",
      "Epoch 453/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.5055 - output_x_loss: 374.5141 - output_y_loss: 141.2772 - output_z_loss: 390.9447 - output_x_msle: 374.5141 - output_y_msle: 141.2772 - output_z_msle: 390.9447 - val_loss: 285.6609 - val_output_x_loss: 376.0670 - val_output_y_loss: 142.9720 - val_output_z_loss: 390.2265 - val_output_x_msle: 376.0670 - val_output_y_msle: 142.9720 - val_output_z_msle: 390.2265 - lr: 1.0000e-08\n",
      "Epoch 454/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4806 - output_x_loss: 374.4978 - output_y_loss: 141.2430 - output_z_loss: 390.9207 - output_x_msle: 374.4978 - output_y_msle: 141.2430 - output_z_msle: 390.9207 - val_loss: 285.6425 - val_output_x_loss: 376.0470 - val_output_y_loss: 142.9608 - val_output_z_loss: 390.1967 - val_output_x_msle: 376.0470 - val_output_y_msle: 142.9608 - val_output_z_msle: 390.1967 - lr: 1.0000e-08\n",
      "Epoch 455/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4627 - output_x_loss: 374.4797 - output_y_loss: 141.2358 - output_z_loss: 390.8827 - output_x_msle: 374.4797 - output_y_msle: 141.2358 - output_z_msle: 390.8827 - val_loss: 285.6293 - val_output_x_loss: 376.0312 - val_output_y_loss: 142.9600 - val_output_z_loss: 390.1642 - val_output_x_msle: 376.0312 - val_output_y_msle: 142.9600 - val_output_z_msle: 390.1642 - lr: 1.0000e-08\n",
      "Epoch 456/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4502 - output_x_loss: 374.4618 - output_y_loss: 141.2350 - output_z_loss: 390.8571 - output_x_msle: 374.4618 - output_y_msle: 141.2350 - output_z_msle: 390.8571 - val_loss: 285.6091 - val_output_x_loss: 376.0143 - val_output_y_loss: 142.9591 - val_output_z_loss: 390.0990 - val_output_x_msle: 376.0143 - val_output_y_msle: 142.9591 - val_output_z_msle: 390.0990 - lr: 1.0000e-08\n",
      "Epoch 457/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4227 - output_x_loss: 374.4435 - output_y_loss: 141.2016 - output_z_loss: 390.8235 - output_x_msle: 374.4435 - output_y_msle: 141.2016 - output_z_msle: 390.8235 - val_loss: 285.5647 - val_output_x_loss: 375.9948 - val_output_y_loss: 142.9570 - val_output_z_loss: 389.9200 - val_output_x_msle: 375.9948 - val_output_y_msle: 142.9570 - val_output_z_msle: 389.9200 - lr: 1.0000e-08\n",
      "Epoch 458/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4036 - output_x_loss: 374.4259 - output_y_loss: 141.1974 - output_z_loss: 390.7711 - output_x_msle: 374.4259 - output_y_msle: 141.1974 - output_z_msle: 390.7711 - val_loss: 285.5386 - val_output_x_loss: 375.9803 - val_output_y_loss: 142.9556 - val_output_z_loss: 389.8212 - val_output_x_msle: 375.9803 - val_output_y_msle: 142.9556 - val_output_z_msle: 389.8212 - lr: 1.0000e-08\n",
      "Epoch 459/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.3899 - output_x_loss: 374.4086 - output_y_loss: 141.1965 - output_z_loss: 390.7400 - output_x_msle: 374.4086 - output_y_msle: 141.1965 - output_z_msle: 390.7400 - val_loss: 285.5257 - val_output_x_loss: 375.9660 - val_output_y_loss: 142.9547 - val_output_z_loss: 389.7866 - val_output_x_msle: 375.9660 - val_output_y_msle: 142.9547 - val_output_z_msle: 389.7866 - lr: 1.0000e-08\n",
      "Epoch 460/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.3725 - output_x_loss: 374.3918 - output_y_loss: 141.1954 - output_z_loss: 390.6879 - output_x_msle: 374.3918 - output_y_msle: 141.1954 - output_z_msle: 390.6879 - val_loss: 285.5078 - val_output_x_loss: 375.9436 - val_output_y_loss: 142.9537 - val_output_z_loss: 389.7446 - val_output_x_msle: 375.9436 - val_output_y_msle: 142.9537 - val_output_z_msle: 389.7446 - lr: 1.0000e-08\n",
      "Epoch 461/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.3577 - output_x_loss: 374.3761 - output_y_loss: 141.1941 - output_z_loss: 390.6476 - output_x_msle: 374.3761 - output_y_msle: 141.1941 - output_z_msle: 390.6476 - val_loss: 285.4233 - val_output_x_loss: 375.9291 - val_output_y_loss: 142.8140 - val_output_z_loss: 389.6306 - val_output_x_msle: 375.9291 - val_output_y_msle: 142.8140 - val_output_z_msle: 389.6306 - lr: 1.0000e-08\n",
      "Epoch 462/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.3351 - output_x_loss: 374.3601 - output_y_loss: 141.1931 - output_z_loss: 390.5694 - output_x_msle: 374.3601 - output_y_msle: 141.1931 - output_z_msle: 390.5694 - val_loss: 285.4029 - val_output_x_loss: 375.9138 - val_output_y_loss: 142.7989 - val_output_z_loss: 389.5895 - val_output_x_msle: 375.9138 - val_output_y_msle: 142.7989 - val_output_z_msle: 389.5895 - lr: 1.0000e-08\n",
      "Epoch 463/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.3118 - output_x_loss: 374.3430 - output_y_loss: 141.1920 - output_z_loss: 390.4887 - output_x_msle: 374.3430 - output_y_msle: 141.1920 - output_z_msle: 390.4887 - val_loss: 285.3818 - val_output_x_loss: 375.8984 - val_output_y_loss: 142.7948 - val_output_z_loss: 389.5222 - val_output_x_msle: 375.8984 - val_output_y_msle: 142.7948 - val_output_z_msle: 389.5222 - lr: 1.0000e-08\n",
      "Epoch 464/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.2880 - output_x_loss: 374.3254 - output_y_loss: 141.1907 - output_z_loss: 390.4069 - output_x_msle: 374.3254 - output_y_msle: 141.1907 - output_z_msle: 390.4069 - val_loss: 285.3678 - val_output_x_loss: 375.8829 - val_output_y_loss: 142.7915 - val_output_z_loss: 389.4905 - val_output_x_msle: 375.8829 - val_output_y_msle: 142.7915 - val_output_z_msle: 389.4905 - lr: 1.0000e-08\n",
      "Epoch 465/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.2690 - output_x_loss: 374.3071 - output_y_loss: 141.1894 - output_z_loss: 390.3522 - output_x_msle: 374.3071 - output_y_msle: 141.1894 - output_z_msle: 390.3522 - val_loss: 285.3532 - val_output_x_loss: 375.8677 - val_output_y_loss: 142.7886 - val_output_z_loss: 389.4532 - val_output_x_msle: 375.8677 - val_output_y_msle: 142.7886 - val_output_z_msle: 389.4532 - lr: 1.0000e-08\n",
      "Epoch 466/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.2447 - output_x_loss: 374.2880 - output_y_loss: 141.1880 - output_z_loss: 390.2714 - output_x_msle: 374.2880 - output_y_msle: 141.1880 - output_z_msle: 390.2714 - val_loss: 285.3359 - val_output_x_loss: 375.8558 - val_output_y_loss: 142.7861 - val_output_z_loss: 389.3955 - val_output_x_msle: 375.8558 - val_output_y_msle: 142.7861 - val_output_z_msle: 389.3955 - lr: 1.0000e-08\n",
      "Epoch 467/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.2255 - output_x_loss: 374.2694 - output_y_loss: 141.1866 - output_z_loss: 390.2155 - output_x_msle: 374.2694 - output_y_msle: 141.1866 - output_z_msle: 390.2155 - val_loss: 285.3194 - val_output_x_loss: 375.8321 - val_output_y_loss: 142.7836 - val_output_z_loss: 389.3655 - val_output_x_msle: 375.8321 - val_output_y_msle: 142.7836 - val_output_z_msle: 389.3655 - lr: 1.0000e-08\n",
      "Epoch 468/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.2109 - output_x_loss: 374.2502 - output_y_loss: 141.1850 - output_z_loss: 390.1834 - output_x_msle: 374.2502 - output_y_msle: 141.1850 - output_z_msle: 390.1834 - val_loss: 285.3044 - val_output_x_loss: 375.8163 - val_output_y_loss: 142.7812 - val_output_z_loss: 389.3273 - val_output_x_msle: 375.8163 - val_output_y_msle: 142.7812 - val_output_z_msle: 389.3273 - lr: 1.0000e-08\n",
      "Epoch 469/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.1240 - output_x_loss: 374.2295 - output_y_loss: 141.0141 - output_z_loss: 390.1319 - output_x_msle: 374.2295 - output_y_msle: 141.0141 - output_z_msle: 390.1319 - val_loss: 285.2216 - val_output_x_loss: 375.8024 - val_output_y_loss: 142.6098 - val_output_z_loss: 389.2841 - val_output_x_msle: 375.8024 - val_output_y_msle: 142.6098 - val_output_z_msle: 389.2841 - lr: 1.0000e-08\n",
      "Epoch 470/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.0877 - output_x_loss: 374.2078 - output_y_loss: 140.9720 - output_z_loss: 390.0791 - output_x_msle: 374.2078 - output_y_msle: 140.9720 - output_z_msle: 390.0791 - val_loss: 285.2148 - val_output_x_loss: 375.9160 - val_output_y_loss: 142.5009 - val_output_z_loss: 389.2404 - val_output_x_msle: 375.9160 - val_output_y_msle: 142.5009 - val_output_z_msle: 389.2404 - lr: 1.0000e-08\n",
      "Epoch 471/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.0697 - output_x_loss: 374.1873 - output_y_loss: 140.9659 - output_z_loss: 390.0421 - output_x_msle: 374.1873 - output_y_msle: 140.9659 - output_z_msle: 390.0421 - val_loss: 285.1170 - val_output_x_loss: 375.7447 - val_output_y_loss: 142.4924 - val_output_z_loss: 389.1105 - val_output_x_msle: 375.7447 - val_output_y_msle: 142.4924 - val_output_z_msle: 389.1105 - lr: 1.0000e-08\n",
      "Epoch 472/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.0390 - output_x_loss: 374.1685 - output_y_loss: 140.9307 - output_z_loss: 389.9970 - output_x_msle: 374.1685 - output_y_msle: 140.9307 - output_z_msle: 389.9970 - val_loss: 285.0250 - val_output_x_loss: 375.7263 - val_output_y_loss: 142.3415 - val_output_z_loss: 388.9895 - val_output_x_msle: 375.7263 - val_output_y_msle: 142.3415 - val_output_z_msle: 388.9895 - lr: 1.0000e-08\n",
      "Epoch 473/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.9850 - output_x_loss: 374.1480 - output_y_loss: 140.8523 - output_z_loss: 389.9253 - output_x_msle: 374.1480 - output_y_msle: 140.8523 - output_z_msle: 389.9253 - val_loss: 285.0013 - val_output_x_loss: 375.7066 - val_output_y_loss: 142.3369 - val_output_z_loss: 388.9196 - val_output_x_msle: 375.7066 - val_output_y_msle: 142.3369 - val_output_z_msle: 388.9196 - lr: 1.0000e-08\n",
      "Epoch 474/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.9578 - output_x_loss: 374.1266 - output_y_loss: 140.8498 - output_z_loss: 389.8363 - output_x_msle: 374.1266 - output_y_msle: 140.8498 - output_z_msle: 389.8363 - val_loss: 284.9651 - val_output_x_loss: 375.6862 - val_output_y_loss: 142.3327 - val_output_z_loss: 388.7878 - val_output_x_msle: 375.6862 - val_output_y_msle: 142.3327 - val_output_z_msle: 388.7878 - lr: 1.0000e-08\n",
      "Epoch 475/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.9310 - output_x_loss: 374.1035 - output_y_loss: 140.8475 - output_z_loss: 389.7529 - output_x_msle: 374.1035 - output_y_msle: 140.8475 - output_z_msle: 389.7529 - val_loss: 284.9289 - val_output_x_loss: 375.6645 - val_output_y_loss: 142.3280 - val_output_z_loss: 388.6599 - val_output_x_msle: 375.6645 - val_output_y_msle: 142.3280 - val_output_z_msle: 388.6599 - lr: 1.0000e-08\n",
      "Epoch 476/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.9056 - output_x_loss: 374.0798 - output_y_loss: 140.8450 - output_z_loss: 389.6782 - output_x_msle: 374.0798 - output_y_msle: 140.8450 - output_z_msle: 389.6782 - val_loss: 284.9058 - val_output_x_loss: 375.6432 - val_output_y_loss: 142.3217 - val_output_z_loss: 388.5994 - val_output_x_msle: 375.6432 - val_output_y_msle: 142.3217 - val_output_z_msle: 388.5994 - lr: 1.0000e-08\n",
      "Epoch 477/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.8796 - output_x_loss: 374.0556 - output_y_loss: 140.8424 - output_z_loss: 389.6012 - output_x_msle: 374.0556 - output_y_msle: 140.8424 - output_z_msle: 389.6012 - val_loss: 284.8803 - val_output_x_loss: 375.6217 - val_output_y_loss: 142.3100 - val_output_z_loss: 388.5381 - val_output_x_msle: 375.6217 - val_output_y_msle: 142.3100 - val_output_z_msle: 388.5381 - lr: 1.0000e-08\n",
      "Epoch 478/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.8511 - output_x_loss: 374.0300 - output_y_loss: 140.8400 - output_z_loss: 389.5153 - output_x_msle: 374.0300 - output_y_msle: 140.8400 - output_z_msle: 389.5153 - val_loss: 284.8317 - val_output_x_loss: 375.6039 - val_output_y_loss: 142.2495 - val_output_z_loss: 388.4518 - val_output_x_msle: 375.6039 - val_output_y_msle: 142.2495 - val_output_z_msle: 388.4518 - lr: 1.0000e-08\n",
      "Epoch 479/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.8154 - output_x_loss: 374.0025 - output_y_loss: 140.8369 - output_z_loss: 389.3976 - output_x_msle: 374.0025 - output_y_msle: 140.8369 - output_z_msle: 389.3976 - val_loss: 284.8422 - val_output_x_loss: 375.7158 - val_output_y_loss: 142.2461 - val_output_z_loss: 388.2870 - val_output_x_msle: 375.7158 - val_output_y_msle: 142.2461 - val_output_z_msle: 388.2870 - lr: 1.0000e-08\n",
      "Epoch 480/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.7600 - output_x_loss: 373.9735 - output_y_loss: 140.7976 - output_z_loss: 389.2579 - output_x_msle: 373.9735 - output_y_msle: 140.7976 - output_z_msle: 389.2579 - val_loss: 284.6717 - val_output_x_loss: 375.6869 - val_output_y_loss: 141.9326 - val_output_z_loss: 388.1196 - val_output_x_msle: 375.6869 - val_output_y_msle: 141.9326 - val_output_z_msle: 388.1196 - lr: 1.0000e-08\n",
      "Epoch 481/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.6888 - output_x_loss: 373.9430 - output_y_loss: 140.7226 - output_z_loss: 389.1131 - output_x_msle: 373.9430 - output_y_msle: 140.7226 - output_z_msle: 389.1131 - val_loss: 284.6197 - val_output_x_loss: 375.6562 - val_output_y_loss: 141.9185 - val_output_z_loss: 387.9491 - val_output_x_msle: 375.6562 - val_output_y_msle: 141.9185 - val_output_z_msle: 387.9491 - lr: 1.0000e-08\n",
      "Epoch 482/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.6513 - output_x_loss: 373.9104 - output_y_loss: 140.7175 - output_z_loss: 389.0005 - output_x_msle: 373.9104 - output_y_msle: 140.7175 - output_z_msle: 389.0005 - val_loss: 284.5091 - val_output_x_loss: 375.4809 - val_output_y_loss: 141.9118 - val_output_z_loss: 387.7599 - val_output_x_msle: 375.4809 - val_output_y_msle: 141.9118 - val_output_z_msle: 387.7599 - lr: 1.0000e-08\n",
      "Epoch 483/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.5451 - output_x_loss: 373.8796 - output_y_loss: 140.5487 - output_z_loss: 388.8693 - output_x_msle: 373.8796 - output_y_msle: 140.5487 - output_z_msle: 388.8693 - val_loss: 284.5080 - val_output_x_loss: 375.6016 - val_output_y_loss: 141.8311 - val_output_z_loss: 387.6746 - val_output_x_msle: 375.6016 - val_output_y_msle: 141.8311 - val_output_z_msle: 387.6746 - lr: 1.0000e-08\n",
      "Epoch 484/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.4874 - output_x_loss: 373.8607 - output_y_loss: 140.5043 - output_z_loss: 388.7071 - output_x_msle: 373.8607 - output_y_msle: 140.5043 - output_z_msle: 388.7071 - val_loss: 284.4762 - val_output_x_loss: 375.5836 - val_output_y_loss: 141.8059 - val_output_z_loss: 387.6019 - val_output_x_msle: 375.5836 - val_output_y_msle: 141.8059 - val_output_z_msle: 387.6019 - lr: 1.0000e-08\n",
      "Epoch 485/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.4569 - output_x_loss: 373.8413 - output_y_loss: 140.4996 - output_z_loss: 388.6023 - output_x_msle: 373.8413 - output_y_msle: 140.4996 - output_z_msle: 388.6023 - val_loss: 284.4430 - val_output_x_loss: 375.5644 - val_output_y_loss: 141.7914 - val_output_z_loss: 387.5033 - val_output_x_msle: 375.5644 - val_output_y_msle: 141.7914 - val_output_z_msle: 387.5033 - lr: 1.0000e-08\n",
      "Epoch 486/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.4255 - output_x_loss: 373.8210 - output_y_loss: 140.4956 - output_z_loss: 388.4947 - output_x_msle: 373.8210 - output_y_msle: 140.4956 - output_z_msle: 388.4947 - val_loss: 284.3670 - val_output_x_loss: 375.5444 - val_output_y_loss: 141.7229 - val_output_z_loss: 387.3004 - val_output_x_msle: 375.5444 - val_output_y_msle: 141.7229 - val_output_z_msle: 387.3004 - lr: 1.0000e-08\n",
      "Epoch 487/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.3954 - output_x_loss: 373.7995 - output_y_loss: 140.4915 - output_z_loss: 388.3948 - output_x_msle: 373.7995 - output_y_msle: 140.4915 - output_z_msle: 388.3948 - val_loss: 284.3398 - val_output_x_loss: 375.5219 - val_output_y_loss: 141.7172 - val_output_z_loss: 387.2207 - val_output_x_msle: 375.5219 - val_output_y_msle: 141.7172 - val_output_z_msle: 387.2207 - lr: 1.0000e-08\n",
      "Epoch 488/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.3317 - output_x_loss: 373.7764 - output_y_loss: 140.4218 - output_z_loss: 388.2628 - output_x_msle: 373.7764 - output_y_msle: 140.4218 - output_z_msle: 388.2628 - val_loss: 284.2067 - val_output_x_loss: 375.4992 - val_output_y_loss: 141.4506 - val_output_z_loss: 387.1339 - val_output_x_msle: 375.4992 - val_output_y_msle: 141.4506 - val_output_z_msle: 387.1339 - lr: 1.0000e-08\n",
      "Epoch 489/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.2319 - output_x_loss: 373.7522 - output_y_loss: 140.2828 - output_z_loss: 388.0896 - output_x_msle: 373.7522 - output_y_msle: 140.2828 - output_z_msle: 388.0896 - val_loss: 284.1821 - val_output_x_loss: 375.4754 - val_output_y_loss: 141.4459 - val_output_z_loss: 387.0675 - val_output_x_msle: 375.4754 - val_output_y_msle: 141.4459 - val_output_z_msle: 387.0675 - lr: 1.0000e-08\n",
      "Epoch 490/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.0899 - output_x_loss: 373.7289 - output_y_loss: 140.0017 - output_z_loss: 387.9882 - output_x_msle: 373.7289 - output_y_msle: 140.0017 - output_z_msle: 387.9882 - val_loss: 284.1583 - val_output_x_loss: 375.4540 - val_output_y_loss: 141.4427 - val_output_z_loss: 386.9978 - val_output_x_msle: 375.4540 - val_output_y_msle: 141.4427 - val_output_z_msle: 386.9978 - lr: 1.0000e-08\n",
      "Epoch 491/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.0510 - output_x_loss: 373.7067 - output_y_loss: 139.9651 - output_z_loss: 387.9116 - output_x_msle: 373.7067 - output_y_msle: 139.9651 - output_z_msle: 387.9116 - val_loss: 284.1216 - val_output_x_loss: 375.4319 - val_output_y_loss: 141.4379 - val_output_z_loss: 386.8678 - val_output_x_msle: 375.4319 - val_output_y_msle: 141.4379 - val_output_z_msle: 386.8678 - lr: 1.0000e-08\n",
      "Epoch 492/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.0262 - output_x_loss: 373.6842 - output_y_loss: 139.9556 - output_z_loss: 387.8514 - output_x_msle: 373.6842 - output_y_msle: 139.9556 - output_z_msle: 387.8514 - val_loss: 284.1035 - val_output_x_loss: 375.4105 - val_output_y_loss: 141.4326 - val_output_z_loss: 386.8312 - val_output_x_msle: 375.4105 - val_output_y_msle: 141.4326 - val_output_z_msle: 386.8312 - lr: 1.0000e-08\n",
      "Epoch 493/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.0017 - output_x_loss: 373.6619 - output_y_loss: 139.9402 - output_z_loss: 387.8040 - output_x_msle: 373.6619 - output_y_msle: 139.9402 - output_z_msle: 387.8040 - val_loss: 284.0285 - val_output_x_loss: 375.2466 - val_output_y_loss: 141.4312 - val_output_z_loss: 386.7866 - val_output_x_msle: 375.2466 - val_output_y_msle: 141.4312 - val_output_z_msle: 386.7866 - lr: 1.0000e-08\n",
      "Epoch 494/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.9760 - output_x_loss: 373.6367 - output_y_loss: 139.9385 - output_z_loss: 387.7297 - output_x_msle: 373.6367 - output_y_msle: 139.9385 - output_z_msle: 387.7297 - val_loss: 284.0656 - val_output_x_loss: 375.3623 - val_output_y_loss: 141.4298 - val_output_z_loss: 386.7435 - val_output_x_msle: 375.3623 - val_output_y_msle: 141.4298 - val_output_z_msle: 386.7435 - lr: 1.0000e-08\n",
      "Epoch 495/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.9524 - output_x_loss: 373.6123 - output_y_loss: 139.9369 - output_z_loss: 387.6635 - output_x_msle: 373.6123 - output_y_msle: 139.9369 - output_z_msle: 387.6635 - val_loss: 283.9850 - val_output_x_loss: 375.1890 - val_output_y_loss: 141.4282 - val_output_z_loss: 386.6907 - val_output_x_msle: 375.1890 - val_output_y_msle: 141.4282 - val_output_z_msle: 386.6907 - lr: 1.0000e-08\n",
      "Epoch 496/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.9245 - output_x_loss: 373.5869 - output_y_loss: 139.9352 - output_z_loss: 387.5782 - output_x_msle: 373.5869 - output_y_msle: 139.9352 - output_z_msle: 387.5782 - val_loss: 283.9471 - val_output_x_loss: 375.1679 - val_output_y_loss: 141.4266 - val_output_z_loss: 386.5465 - val_output_x_msle: 375.1679 - val_output_y_msle: 141.4266 - val_output_z_msle: 386.5465 - lr: 1.0000e-08\n",
      "Epoch 497/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.8902 - output_x_loss: 373.5600 - output_y_loss: 139.9038 - output_z_loss: 387.5228 - output_x_msle: 373.5600 - output_y_msle: 139.9038 - output_z_msle: 387.5228 - val_loss: 283.9716 - val_output_x_loss: 375.2852 - val_output_y_loss: 141.4243 - val_output_z_loss: 386.4388 - val_output_x_msle: 375.2852 - val_output_y_msle: 141.4243 - val_output_z_msle: 386.4388 - lr: 1.0000e-08\n",
      "Epoch 498/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.8551 - output_x_loss: 373.5324 - output_y_loss: 139.8988 - output_z_loss: 387.4133 - output_x_msle: 373.5324 - output_y_msle: 139.8988 - output_z_msle: 387.4133 - val_loss: 283.9485 - val_output_x_loss: 375.2580 - val_output_y_loss: 141.4222 - val_output_z_loss: 386.3820 - val_output_x_msle: 375.2580 - val_output_y_msle: 141.4222 - val_output_z_msle: 386.3820 - lr: 1.0000e-08\n",
      "Epoch 499/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.8297 - output_x_loss: 373.5048 - output_y_loss: 139.8972 - output_z_loss: 387.3447 - output_x_msle: 373.5048 - output_y_msle: 139.8972 - output_z_msle: 387.3447 - val_loss: 283.8103 - val_output_x_loss: 375.0800 - val_output_y_loss: 141.2728 - val_output_z_loss: 386.3460 - val_output_x_msle: 375.0800 - val_output_y_msle: 141.2728 - val_output_z_msle: 386.3460 - lr: 1.0000e-08\n",
      "Epoch 500/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.8051 - output_x_loss: 373.4760 - output_y_loss: 139.8955 - output_z_loss: 387.2831 - output_x_msle: 373.4760 - output_y_msle: 139.8955 - output_z_msle: 387.2831 - val_loss: 283.7867 - val_output_x_loss: 375.0524 - val_output_y_loss: 141.2633 - val_output_z_loss: 386.3019 - val_output_x_msle: 375.0524 - val_output_y_msle: 141.2633 - val_output_z_msle: 386.3019 - lr: 1.0000e-08\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using numpy formatted training and validation data.\n",
    "history = model.fit(\n",
    "    [X_train], [y_train_x, y_train_y, y_train_z],\n",
    "    epochs=input_num_epochs,\n",
    "    validation_data=([X_valid], [y_valid_x, y_valid_y, y_valid_z]),\n",
    "    batch_size=input_batch_size,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>output_x_loss</th>\n",
       "      <th>output_y_loss</th>\n",
       "      <th>output_z_loss</th>\n",
       "      <th>output_x_msle</th>\n",
       "      <th>output_y_msle</th>\n",
       "      <th>output_z_msle</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_output_x_loss</th>\n",
       "      <th>val_output_y_loss</th>\n",
       "      <th>val_output_z_loss</th>\n",
       "      <th>val_output_x_msle</th>\n",
       "      <th>val_output_y_msle</th>\n",
       "      <th>val_output_z_msle</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.001129</td>\n",
       "      <td>380.847076</td>\n",
       "      <td>154.695129</td>\n",
       "      <td>413.921082</td>\n",
       "      <td>380.847076</td>\n",
       "      <td>154.695129</td>\n",
       "      <td>413.921082</td>\n",
       "      <td>298.272278</td>\n",
       "      <td>382.369446</td>\n",
       "      <td>156.654053</td>\n",
       "      <td>413.314301</td>\n",
       "      <td>382.369446</td>\n",
       "      <td>156.654053</td>\n",
       "      <td>413.314301</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296.889984</td>\n",
       "      <td>380.835571</td>\n",
       "      <td>154.479416</td>\n",
       "      <td>413.819519</td>\n",
       "      <td>380.835571</td>\n",
       "      <td>154.479416</td>\n",
       "      <td>413.819519</td>\n",
       "      <td>298.250458</td>\n",
       "      <td>382.361603</td>\n",
       "      <td>156.628052</td>\n",
       "      <td>413.272888</td>\n",
       "      <td>382.361603</td>\n",
       "      <td>156.628052</td>\n",
       "      <td>413.272888</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296.866028</td>\n",
       "      <td>380.828339</td>\n",
       "      <td>154.448181</td>\n",
       "      <td>413.777374</td>\n",
       "      <td>380.828339</td>\n",
       "      <td>154.448181</td>\n",
       "      <td>413.777374</td>\n",
       "      <td>298.230286</td>\n",
       "      <td>382.354370</td>\n",
       "      <td>156.605087</td>\n",
       "      <td>413.232422</td>\n",
       "      <td>382.354370</td>\n",
       "      <td>156.605087</td>\n",
       "      <td>413.232422</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296.842041</td>\n",
       "      <td>380.821136</td>\n",
       "      <td>154.418167</td>\n",
       "      <td>413.731506</td>\n",
       "      <td>380.821136</td>\n",
       "      <td>154.418167</td>\n",
       "      <td>413.731506</td>\n",
       "      <td>298.212585</td>\n",
       "      <td>382.347534</td>\n",
       "      <td>156.586380</td>\n",
       "      <td>413.194946</td>\n",
       "      <td>382.347534</td>\n",
       "      <td>156.586380</td>\n",
       "      <td>413.194946</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>296.817017</td>\n",
       "      <td>380.814240</td>\n",
       "      <td>154.390396</td>\n",
       "      <td>413.676422</td>\n",
       "      <td>380.814240</td>\n",
       "      <td>154.390396</td>\n",
       "      <td>413.676422</td>\n",
       "      <td>298.197632</td>\n",
       "      <td>382.340576</td>\n",
       "      <td>156.572922</td>\n",
       "      <td>413.161133</td>\n",
       "      <td>382.340576</td>\n",
       "      <td>156.572922</td>\n",
       "      <td>413.161133</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>283.395355</td>\n",
       "      <td>373.799500</td>\n",
       "      <td>140.491516</td>\n",
       "      <td>388.394806</td>\n",
       "      <td>373.799500</td>\n",
       "      <td>140.491516</td>\n",
       "      <td>388.394806</td>\n",
       "      <td>284.339783</td>\n",
       "      <td>375.521912</td>\n",
       "      <td>141.717239</td>\n",
       "      <td>387.220703</td>\n",
       "      <td>375.521912</td>\n",
       "      <td>141.717239</td>\n",
       "      <td>387.220703</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>283.331726</td>\n",
       "      <td>373.776367</td>\n",
       "      <td>140.421829</td>\n",
       "      <td>388.262817</td>\n",
       "      <td>373.776367</td>\n",
       "      <td>140.421829</td>\n",
       "      <td>388.262817</td>\n",
       "      <td>284.206726</td>\n",
       "      <td>375.499237</td>\n",
       "      <td>141.450607</td>\n",
       "      <td>387.133911</td>\n",
       "      <td>375.499237</td>\n",
       "      <td>141.450607</td>\n",
       "      <td>387.133911</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>283.231873</td>\n",
       "      <td>373.752167</td>\n",
       "      <td>140.282761</td>\n",
       "      <td>388.089600</td>\n",
       "      <td>373.752167</td>\n",
       "      <td>140.282761</td>\n",
       "      <td>388.089600</td>\n",
       "      <td>284.182068</td>\n",
       "      <td>375.475433</td>\n",
       "      <td>141.445923</td>\n",
       "      <td>387.067474</td>\n",
       "      <td>375.475433</td>\n",
       "      <td>141.445923</td>\n",
       "      <td>387.067474</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>283.089874</td>\n",
       "      <td>373.728851</td>\n",
       "      <td>140.001694</td>\n",
       "      <td>387.988159</td>\n",
       "      <td>373.728851</td>\n",
       "      <td>140.001694</td>\n",
       "      <td>387.988159</td>\n",
       "      <td>284.158295</td>\n",
       "      <td>375.454041</td>\n",
       "      <td>141.442657</td>\n",
       "      <td>386.997833</td>\n",
       "      <td>375.454041</td>\n",
       "      <td>141.442657</td>\n",
       "      <td>386.997833</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>283.050995</td>\n",
       "      <td>373.706665</td>\n",
       "      <td>139.965118</td>\n",
       "      <td>387.911591</td>\n",
       "      <td>373.706665</td>\n",
       "      <td>139.965118</td>\n",
       "      <td>387.911591</td>\n",
       "      <td>284.121582</td>\n",
       "      <td>375.431946</td>\n",
       "      <td>141.437912</td>\n",
       "      <td>386.867798</td>\n",
       "      <td>375.431946</td>\n",
       "      <td>141.437912</td>\n",
       "      <td>386.867798</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  output_x_loss  output_y_loss  output_z_loss  output_x_msle  \\\n",
       "0    297.001129     380.847076     154.695129     413.921082     380.847076   \n",
       "1    296.889984     380.835571     154.479416     413.819519     380.835571   \n",
       "2    296.866028     380.828339     154.448181     413.777374     380.828339   \n",
       "3    296.842041     380.821136     154.418167     413.731506     380.821136   \n",
       "4    296.817017     380.814240     154.390396     413.676422     380.814240   \n",
       "..          ...            ...            ...            ...            ...   \n",
       "486  283.395355     373.799500     140.491516     388.394806     373.799500   \n",
       "487  283.331726     373.776367     140.421829     388.262817     373.776367   \n",
       "488  283.231873     373.752167     140.282761     388.089600     373.752167   \n",
       "489  283.089874     373.728851     140.001694     387.988159     373.728851   \n",
       "490  283.050995     373.706665     139.965118     387.911591     373.706665   \n",
       "\n",
       "     output_y_msle  output_z_msle    val_loss  val_output_x_loss  \\\n",
       "0       154.695129     413.921082  298.272278         382.369446   \n",
       "1       154.479416     413.819519  298.250458         382.361603   \n",
       "2       154.448181     413.777374  298.230286         382.354370   \n",
       "3       154.418167     413.731506  298.212585         382.347534   \n",
       "4       154.390396     413.676422  298.197632         382.340576   \n",
       "..             ...            ...         ...                ...   \n",
       "486     140.491516     388.394806  284.339783         375.521912   \n",
       "487     140.421829     388.262817  284.206726         375.499237   \n",
       "488     140.282761     388.089600  284.182068         375.475433   \n",
       "489     140.001694     387.988159  284.158295         375.454041   \n",
       "490     139.965118     387.911591  284.121582         375.431946   \n",
       "\n",
       "     val_output_y_loss  val_output_z_loss  val_output_x_msle  \\\n",
       "0           156.654053         413.314301         382.369446   \n",
       "1           156.628052         413.272888         382.361603   \n",
       "2           156.605087         413.232422         382.354370   \n",
       "3           156.586380         413.194946         382.347534   \n",
       "4           156.572922         413.161133         382.340576   \n",
       "..                 ...                ...                ...   \n",
       "486         141.717239         387.220703         375.521912   \n",
       "487         141.450607         387.133911         375.499237   \n",
       "488         141.445923         387.067474         375.475433   \n",
       "489         141.442657         386.997833         375.454041   \n",
       "490         141.437912         386.867798         375.431946   \n",
       "\n",
       "     val_output_y_msle  val_output_z_msle            lr  \n",
       "0           156.654053         413.314301  1.000000e-08  \n",
       "1           156.628052         413.272888  1.000000e-08  \n",
       "2           156.605087         413.232422  1.000000e-08  \n",
       "3           156.586380         413.194946  1.000000e-08  \n",
       "4           156.572922         413.161133  1.000000e-08  \n",
       "..                 ...                ...           ...  \n",
       "486         141.717239         387.220703  1.000000e-08  \n",
       "487         141.450607         387.133911  1.000000e-08  \n",
       "488         141.445923         387.067474  1.000000e-08  \n",
       "489         141.442657         386.997833  1.000000e-08  \n",
       "490         141.437912         386.867798  1.000000e-08  \n",
       "\n",
       "[491 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training history to dataframe for analysis and plotting.\n",
    "complete_history_data = pd.DataFrame(history.history)\n",
    "complete_history_data.head(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5c0a61cce74af7b2f46f3af2867dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1732e383848>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a0e384be994371915eab2f2dad3571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate MSEs.\n",
    "fig2, mse_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "mse_plots[0][0].plot(complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]])\n",
    "#mse_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "mse_plots[0][1].plot(complete_history_data[[\"output_y_msle\", \"val_output_y_msle\"]])\n",
    "#mse_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "mse_plots[1][0].plot(complete_history_data[[\"output_z_msle\", \"val_output_z_msle\"]])\n",
    "#mse_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93df579c43a54b679138f4eff7313df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate loss.\n",
    "fig, loss_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "loss_plots[0][0].plot(complete_history_data[[\"loss\", \"val_loss\"]])\n",
    "#loss_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[0][1].plot(complete_history_data[[\"output_x_loss\", \"val_output_x_loss\"]])\n",
    "#loss_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][0].plot(complete_history_data[[\"output_y_loss\", \"val_output_y_loss\"]])\n",
    "#loss_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][1].plot(complete_history_data[[\"output_z_loss\", \"val_output_z_loss\"]])\n",
    "#loss_plots[1][1].set_ylim(0,1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4501,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 3ms/step - loss: 283.4539 - output_x_loss: 375.5742 - output_y_loss: 141.5419 - output_z_loss: 383.0372 - output_x_msle: 375.5742 - output_y_msle: 141.5419 - output_z_msle: 383.0372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[283.45391845703125,\n",
       " 375.57415771484375,\n",
       " 141.54188537597656,\n",
       " 383.0372009277344,\n",
       " 375.57415771484375,\n",
       " 141.54188537597656,\n",
       " 383.0372009277344]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test],[y_test_x, y_test_y, y_test_z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values and Inspect Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, z_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_x</th>\n",
       "      <th>model_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>model_y</th>\n",
       "      <th>pred_z</th>\n",
       "      <th>model_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.600022e+11</td>\n",
       "      <td>-1.422871e+12</td>\n",
       "      <td>8.570599e+11</td>\n",
       "      <td>3.081012e+12</td>\n",
       "      <td>-4.303639e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.411175e+11</td>\n",
       "      <td>2.071774e+12</td>\n",
       "      <td>3.787914e+10</td>\n",
       "      <td>2.493669e+12</td>\n",
       "      <td>3.568953e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.249756e+12</td>\n",
       "      <td>6.205357e+11</td>\n",
       "      <td>-4.821397e+11</td>\n",
       "      <td>-1.523855e+12</td>\n",
       "      <td>1.410745e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.305617e+12</td>\n",
       "      <td>2.345211e+12</td>\n",
       "      <td>2.547206e+11</td>\n",
       "      <td>1.626431e+11</td>\n",
       "      <td>4.110802e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.683005e+11</td>\n",
       "      <td>2.340551e+12</td>\n",
       "      <td>-4.118627e+10</td>\n",
       "      <td>1.906852e+12</td>\n",
       "      <td>4.733806e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.172332e+12</td>\n",
       "      <td>2.477813e+12</td>\n",
       "      <td>2.065746e+11</td>\n",
       "      <td>9.349509e+11</td>\n",
       "      <td>6.040747e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.371568e+11</td>\n",
       "      <td>1.381164e+11</td>\n",
       "      <td>2.050292e+11</td>\n",
       "      <td>3.695837e+12</td>\n",
       "      <td>2.744128e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.455776e+12</td>\n",
       "      <td>1.895708e+11</td>\n",
       "      <td>-4.333491e+11</td>\n",
       "      <td>-1.588522e+12</td>\n",
       "      <td>9.930585e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.785137e+11</td>\n",
       "      <td>2.443982e+12</td>\n",
       "      <td>7.295473e+10</td>\n",
       "      <td>1.474754e+12</td>\n",
       "      <td>6.659892e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.142234e+11</td>\n",
       "      <td>9.199301e+11</td>\n",
       "      <td>1.057904e+12</td>\n",
       "      <td>3.567643e+12</td>\n",
       "      <td>-1.522513e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_x       model_x        pred_y       model_y        pred_z  \\\n",
       "0  6.600022e+11 -1.422871e+12  8.570599e+11  3.081012e+12 -4.303639e+11   \n",
       "1  7.411175e+11  2.071774e+12  3.787914e+10  2.493669e+12  3.568953e+11   \n",
       "2  1.249756e+12  6.205357e+11 -4.821397e+11 -1.523855e+12  1.410745e+11   \n",
       "3  1.305617e+12  2.345211e+12  2.547206e+11  1.626431e+11  4.110802e+11   \n",
       "4  8.683005e+11  2.340551e+12 -4.118627e+10  1.906852e+12  4.733806e+11   \n",
       "5  1.172332e+12  2.477813e+12  2.065746e+11  9.349509e+11  6.040747e+11   \n",
       "6 -3.371568e+11  1.381164e+11  2.050292e+11  3.695837e+12  2.744128e+11   \n",
       "7  1.455776e+12  1.895708e+11 -4.333491e+11 -1.588522e+12  9.930585e+10   \n",
       "8  9.785137e+11  2.443982e+12  7.295473e+10  1.474754e+12  6.659892e+11   \n",
       "9  1.142234e+11  9.199301e+11  1.057904e+12  3.567643e+12 -1.522513e+12   \n",
       "\n",
       "   model_z  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      0.0  \n",
       "8      0.0  \n",
       "9      0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison = pd.DataFrame(data=np.concatenate((x_pred, y_test_x.reshape(-1,1), y_pred, y_test_y.reshape(-1,1), z_pred, y_test_z.reshape(-1,1)), axis=1),\n",
    "                                    columns=['pred_x', 'model_x', 'pred_y', 'model_y', 'pred_z', 'model_z'])\n",
    "pred_model_comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae005d2c0ca74636ac7f08a8e377f55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17496d0b048>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_x\", \"model_x\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a9a9a3daf44b6da297e505fb6ac703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17496d541c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_y\", \"model_y\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47405c532b0843d3aa244df95a3bd563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17496d54508>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_z\", \"model_z\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
