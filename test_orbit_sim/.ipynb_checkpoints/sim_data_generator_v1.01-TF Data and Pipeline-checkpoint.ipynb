{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet Simulator with Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Craig Boger\n",
    "06/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes the model prototyping and learning of v1.01 and tries to expand upon it in 2 key areas.\n",
    "\n",
    "1) Perform data normalization and processing in TF data libraries.\n",
    "2) Take predictions in normalized form and output them in their unormalized form for use in simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straight Up Just Stealing Someone's Code and Trying to Run It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to benrules2: https://gist.github.com/benrules2/220d56ea6fe9a85a4d762128b11adfba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class point:\n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class body:\n",
    "    def __init__(self, location, mass, velocity, name = \"\"):\n",
    "        self.location = location\n",
    "        self.mass = mass\n",
    "        self.velocity = velocity\n",
    "        self.name = name\n",
    "\n",
    "def calculate_single_body_acceleration(bodies, body_index):\n",
    "    G_const = 6.67408e-11 #m3 kg-1 s-2\n",
    "    acceleration = point(0,0,0)\n",
    "    target_body = bodies[body_index]\n",
    "    for index, external_body in enumerate(bodies):\n",
    "        if index != body_index:\n",
    "            r = (target_body.location.x - external_body.location.x)**2 + (target_body.location.y - external_body.location.y)**2 + (target_body.location.z - external_body.location.z)**2\n",
    "            r = math.sqrt(r)\n",
    "            tmp = G_const * external_body.mass / r**3\n",
    "            acceleration.x += tmp * (external_body.location.x - target_body.location.x)\n",
    "            acceleration.y += tmp * (external_body.location.y - target_body.location.y)\n",
    "            acceleration.z += tmp * (external_body.location.z - target_body.location.z)\n",
    "\n",
    "    return acceleration\n",
    "\n",
    "def compute_velocity(bodies, time_step = 1):\n",
    "    for body_index, target_body in enumerate(bodies):\n",
    "        acceleration = calculate_single_body_acceleration(bodies, body_index)\n",
    "\n",
    "        target_body.velocity.x += acceleration.x * time_step\n",
    "        target_body.velocity.y += acceleration.y * time_step\n",
    "        target_body.velocity.z += acceleration.z * time_step \n",
    "\n",
    "\n",
    "def update_location(bodies, time_step = 1):\n",
    "    for target_body in bodies:\n",
    "        target_body.location.x += target_body.velocity.x * time_step\n",
    "        target_body.location.y += target_body.velocity.y * time_step\n",
    "        target_body.location.z += target_body.velocity.z * time_step\n",
    "\n",
    "def compute_gravity_step(bodies, time_step = 1):\n",
    "    compute_velocity(bodies, time_step = time_step)\n",
    "    update_location(bodies, time_step = time_step)\n",
    "\n",
    "def plot_output(bodies, outfile = None):\n",
    "    fig = plot.figure()\n",
    "    colours = ['r','b','g','y','m','c']\n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "    max_range = 0\n",
    "    for current_body in bodies: \n",
    "        max_dim = max(max(current_body[\"x\"]),max(current_body[\"y\"]),max(current_body[\"z\"]))\n",
    "        if max_dim > max_range:\n",
    "            max_range = max_dim\n",
    "        ax.plot(current_body[\"x\"], current_body[\"y\"], current_body[\"z\"], c = random.choice(colours), label = current_body[\"name\"])        \n",
    "    \n",
    "    ax.set_xlim([-max_range,max_range])    \n",
    "    ax.set_ylim([-max_range,max_range])\n",
    "    ax.set_zlim([-max_range,max_range])\n",
    "    ax.legend()        \n",
    "\n",
    "    if outfile:\n",
    "        plot.savefig(outfile)\n",
    "    else:\n",
    "        plot.show()\n",
    "\n",
    "def run_simulation(bodies, names = None, time_step = 1, number_of_steps = 10000, report_freq = 100):\n",
    "\n",
    "    #create output container for each body\n",
    "    body_locations_hist = []\n",
    "    for current_body in bodies:\n",
    "        body_locations_hist.append({\"x\":[], \"y\":[], \"z\":[], \"name\":current_body.name})\n",
    "        \n",
    "    for i in range(1,number_of_steps):\n",
    "        compute_gravity_step(bodies, time_step = 1000)            \n",
    "        \n",
    "        if i % report_freq == 0:\n",
    "            for index, body_location in enumerate(body_locations_hist):\n",
    "                body_location[\"x\"].append(bodies[index].location.x)\n",
    "                body_location[\"y\"].append(bodies[index].location.y)           \n",
    "                body_location[\"z\"].append(bodies[index].location.z)       \n",
    "\n",
    "    return body_locations_hist        \n",
    "            \n",
    "#planet data (location (m), mass (kg), velocity (m/s)\n",
    "sun = {\"location\":point(0,0,0), \"mass\":2e30, \"velocity\":point(0,0,0)}\n",
    "mercury = {\"location\":point(0,5.7e10,0), \"mass\":3.285e23, \"velocity\":point(47000,0,0)}\n",
    "venus = {\"location\":point(0,1.1e11,0), \"mass\":4.8e24, \"velocity\":point(35000,0,0)}\n",
    "earth = {\"location\":point(0,1.5e11,0), \"mass\":6e24, \"velocity\":point(30000,0,0)}\n",
    "mars = {\"location\":point(0,2.2e11,0), \"mass\":2.4e24, \"velocity\":point(24000,0,0)}\n",
    "jupiter = {\"location\":point(0,7.7e11,0), \"mass\":1e28, \"velocity\":point(13000,0,0)}\n",
    "saturn = {\"location\":point(0,1.4e12,0), \"mass\":5.7e26, \"velocity\":point(9000,0,0)}\n",
    "uranus = {\"location\":point(0,2.8e12,0), \"mass\":8.7e25, \"velocity\":point(6835,0,0)}\n",
    "neptune = {\"location\":point(0,4.5e12,0), \"mass\":1e26, \"velocity\":point(5477,0,0)}\n",
    "pluto = {\"location\":point(0,3.7e12,0), \"mass\":1.3e22, \"velocity\":point(4748,0,0)}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #build list of planets in the simulation, or create your own\n",
    "    bodies = [\n",
    "        body( location = sun[\"location\"], mass = sun[\"mass\"], velocity = sun[\"velocity\"], name = \"sun\"),\n",
    "        body( location = mercury[\"location\"], mass = mercury[\"mass\"], velocity = mercury[\"velocity\"], name = \"mercury\"),\n",
    "        body( location = venus[\"location\"], mass = venus[\"mass\"], velocity = venus[\"velocity\"], name = \"venus\"),\n",
    "        body( location = earth[\"location\"], mass = earth[\"mass\"], velocity = earth[\"velocity\"], name = \"earth\"),\n",
    "        body( location = mars[\"location\"], mass = mars[\"mass\"], velocity = mars[\"velocity\"], name = \"mars\"),\n",
    "        body( location = jupiter[\"location\"], mass = jupiter[\"mass\"], velocity = jupiter[\"velocity\"], name = \"jupiter\"),\n",
    "        body( location = saturn[\"location\"], mass = saturn[\"mass\"], velocity = saturn[\"velocity\"], name = \"saturn\"),\n",
    "        body( location = uranus[\"location\"], mass = uranus[\"mass\"], velocity = uranus[\"velocity\"], name = \"uranus\"),\n",
    "        body( location = neptune[\"location\"], mass = neptune[\"mass\"], velocity = neptune[\"velocity\"], name = \"neptune\"),\n",
    "        body( location = pluto[\"location\"], mass = pluto[\"mass\"], velocity = pluto[\"velocity\"], name = \"pluto\")\n",
    "        ]\n",
    "    \n",
    "    # Original defaults of simulation\n",
    "    # motions = run_simulation(bodies, time_step = 100, number_of_steps = 80000, report_freq = 1000)\n",
    "    # Try messing with report frequency to get more data.\n",
    "    motions = run_simulation(bodies, time_step = 10, number_of_steps = 6000000, report_freq = 100)\n",
    "    plot_output(motions, outfile = 'orbits.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take motions data from the above simulation and convert it to a Pandas dataframe.  The \"motions\" output is a list of python dictionaries that can be converted into a dataframe and then manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.17261536148749, 49.37902931004262, 166.6238...</td>\n",
       "      <td>[6062.379510449177, 24129.08432936523, 54198.9...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4694355206.032213, 9354859805.615133, 1394777...</td>\n",
       "      <td>[56792631341.03519, 56175843290.39122, 5515329...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mercury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3499415066.4596167, 6995320910.098446, 104842...</td>\n",
       "      <td>[109944304443.26683, 109778376891.15071, 10950...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2999802268.7561436, 5998418130.146453, 899466...</td>\n",
       "      <td>[149970049806.4969, 149880804295.7356, 1497322...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2399949856.0031266, 4799598821.678605, 719864...</td>\n",
       "      <td>[219986083536.2445, 219944611164.44067, 219875...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1299999366.479779, 2599994931.4595885, 389998...</td>\n",
       "      <td>[769998863558.2162, 769995476739.6332, 7699898...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[899999928.8199571, 1799999430.5168397, 269999...</td>\n",
       "      <td>[1399999647604.3037, 1399998597395.4744, 13999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>saturn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[683499993.1607178, 1366999945.2816358, 205049...</td>\n",
       "      <td>[2799999913115.264, 2799999654181.5522, 279999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>uranus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[547699998.6801858, 1095399989.4406931, 164309...</td>\n",
       "      <td>[4499999966439.355, 4499999866422.006, 4499999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[474799997.95801955, 949599983.6629324, 142439...</td>\n",
       "      <td>[3699999950348.1753, 3699999802375.9053, 36999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>pluto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  [6.17261536148749, 49.37902931004262, 166.6238...   \n",
       "1  [4694355206.032213, 9354859805.615133, 1394777...   \n",
       "2  [3499415066.4596167, 6995320910.098446, 104842...   \n",
       "3  [2999802268.7561436, 5998418130.146453, 899466...   \n",
       "4  [2399949856.0031266, 4799598821.678605, 719864...   \n",
       "5  [1299999366.479779, 2599994931.4595885, 389998...   \n",
       "6  [899999928.8199571, 1799999430.5168397, 269999...   \n",
       "7  [683499993.1607178, 1366999945.2816358, 205049...   \n",
       "8  [547699998.6801858, 1095399989.4406931, 164309...   \n",
       "9  [474799997.95801955, 949599983.6629324, 142439...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [6062.379510449177, 24129.08432936523, 54198.9...   \n",
       "1  [56792631341.03519, 56175843290.39122, 5515329...   \n",
       "2  [109944304443.26683, 109778376891.15071, 10950...   \n",
       "3  [149970049806.4969, 149880804295.7356, 1497322...   \n",
       "4  [219986083536.2445, 219944611164.44067, 219875...   \n",
       "5  [769998863558.2162, 769995476739.6332, 7699898...   \n",
       "6  [1399999647604.3037, 1399998597395.4744, 13999...   \n",
       "7  [2799999913115.264, 2799999654181.5522, 279999...   \n",
       "8  [4499999966439.355, 4499999866422.006, 4499999...   \n",
       "9  [3699999950348.1753, 3699999802375.9053, 36999...   \n",
       "\n",
       "                                                   z     name  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      sun  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  mercury  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    venus  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    earth  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     mars  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  jupiter  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   saturn  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   uranus  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    pluto  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "motions_df = pd.DataFrame(motions)\n",
    "motions_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to separate out each row of list or dataframe into its own dataframe.\n",
    "# Will later put these dataframes back together into 1 large dataframe.\n",
    "\n",
    "motions_df_list = []\n",
    "for body in motions:\n",
    "    motions_df_list.append(pd.DataFrame(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>1.499700e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>1.498808e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>1.497323e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>1.495246e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>1.492578e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29994</th>\n",
       "      <td>3.365349e+11</td>\n",
       "      <td>-6.931279e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>3.350566e+11</td>\n",
       "      <td>-7.186066e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>3.335293e+11</td>\n",
       "      <td>-7.437856e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>3.319538e+11</td>\n",
       "      <td>-7.686557e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>3.303305e+11</td>\n",
       "      <td>-7.932077e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y    z   name\n",
       "0      2.999802e+09  1.499700e+11  0.0  earth\n",
       "1      5.998418e+09  1.498808e+11  0.0  earth\n",
       "2      8.994662e+09  1.497323e+11  0.0  earth\n",
       "3      1.198735e+10  1.495246e+11  0.0  earth\n",
       "4      1.497529e+10  1.492578e+11  0.0  earth\n",
       "...             ...           ...  ...    ...\n",
       "29994  3.365349e+11 -6.931279e+10  0.0  earth\n",
       "29995  3.350566e+11 -7.186066e+10  0.0  earth\n",
       "29996  3.335293e+11 -7.437856e+10  0.0  earth\n",
       "29997  3.319538e+11 -7.686557e+10  0.0  earth\n",
       "29998  3.303305e+11 -7.932077e+10  0.0  earth\n",
       "\n",
       "[29999 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions_df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.172615e+00</td>\n",
       "      <td>6.062380e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.694355e+09</td>\n",
       "      <td>5.679263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>1.099443e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.835000e+08</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.477000e+08</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.937903e+01</td>\n",
       "      <td>2.412908e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.354860e+09</td>\n",
       "      <td>5.617584e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>1.097784e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.367000e+09</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.095400e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.496000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666238e+02</td>\n",
       "      <td>5.419895e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394778e+10</td>\n",
       "      <td>5.515330e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>1.095024e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.050500e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643100e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424400e+09</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948516e+02</td>\n",
       "      <td>9.627002e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843961e+10</td>\n",
       "      <td>5.373113e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>1.091166e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.734000e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190800e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.899200e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.709150e+02</td>\n",
       "      <td>1.503396e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279721e+10</td>\n",
       "      <td>5.191794e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>1.086215e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.417499e+09</td>\n",
       "      <td>2.799998e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738500e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374000e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.138930e+06</td>\n",
       "      <td>5.399689e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.050288e+10</td>\n",
       "      <td>-4.133027e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578892e+10</td>\n",
       "      <td>-1.109137e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441446e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.560995e+10</td>\n",
       "      <td>2.799207e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.257803e+10</td>\n",
       "      <td>4.499694e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557899e+10</td>\n",
       "      <td>3.699547e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.259370e+06</td>\n",
       "      <td>5.511102e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606635e+10</td>\n",
       "      <td>-4.407848e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238219e+10</td>\n",
       "      <td>-1.113485e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431961e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.629326e+10</td>\n",
       "      <td>2.799191e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.312570e+10</td>\n",
       "      <td>4.499687e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.605374e+10</td>\n",
       "      <td>3.699537e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.381922e+06</td>\n",
       "      <td>5.623611e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137176e+10</td>\n",
       "      <td>-4.638955e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.963734e+09</td>\n",
       "      <td>-1.116778e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421936e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.697656e+10</td>\n",
       "      <td>2.799174e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.367336e+10</td>\n",
       "      <td>4.499681e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.652848e+10</td>\n",
       "      <td>3.699528e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.506591e+06</td>\n",
       "      <td>5.737214e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646399e+10</td>\n",
       "      <td>-4.823708e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536787e+09</td>\n",
       "      <td>-1.119012e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411373e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.765986e+10</td>\n",
       "      <td>2.799157e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.422102e+10</td>\n",
       "      <td>4.499674e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700322e+10</td>\n",
       "      <td>3.699518e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.633378e+06</td>\n",
       "      <td>5.851910e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139102e+10</td>\n",
       "      <td>-4.959972e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104599e+09</td>\n",
       "      <td>-1.120185e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400277e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.834316e+10</td>\n",
       "      <td>2.799140e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.476868e+10</td>\n",
       "      <td>4.499668e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747796e+10</td>\n",
       "      <td>3.699508e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0   6.172615e+00  6.062380e+03    0.0  4.694355e+09  5.679263e+10        0.0   \n",
       "1   4.937903e+01  2.412908e+04    0.0  9.354860e+09  5.617584e+10        0.0   \n",
       "2   1.666238e+02  5.419895e+04    0.0  1.394778e+10  5.515330e+10        0.0   \n",
       "3   3.948516e+02  9.627002e+04    0.0  1.843961e+10  5.373113e+10        0.0   \n",
       "4   7.709150e+02  1.503396e+05    0.0  2.279721e+10  5.191794e+10        0.0   \n",
       "..           ...           ...    ...           ...           ...        ...   \n",
       "95  4.138930e+06  5.399689e+07    0.0  3.050288e+10 -4.133027e+10        0.0   \n",
       "96  4.259370e+06  5.511102e+07    0.0  2.606635e+10 -4.407848e+10        0.0   \n",
       "97  4.381922e+06  5.623611e+07    0.0  2.137176e+10 -4.638955e+10        0.0   \n",
       "98  4.506591e+06  5.737214e+07    0.0  1.646399e+10 -4.823708e+10        0.0   \n",
       "99  4.633378e+06  5.851910e+07    0.0  1.139102e+10 -4.959972e+10        0.0   \n",
       "\n",
       "         venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0   3.499415e+09  1.099443e+11      0.0  2.999802e+09  ...       0.0   \n",
       "1   6.995321e+09  1.097784e+11      0.0  5.998418e+09  ...       0.0   \n",
       "2   1.048421e+10  1.095024e+11      0.0  8.994662e+09  ...       0.0   \n",
       "3   1.396259e+10  1.091166e+11      0.0  1.198735e+10  ...       0.0   \n",
       "4   1.742697e+10  1.086215e+11      0.0  1.497529e+10  ...       0.0   \n",
       "..           ...           ...      ...           ...  ...       ...   \n",
       "95  1.578892e+10 -1.109137e+11      0.0  1.441446e+11  ...       0.0   \n",
       "96  1.238219e+10 -1.113485e+11      0.0  1.431961e+11  ...       0.0   \n",
       "97  8.963734e+09 -1.116778e+11      0.0  1.421936e+11  ...       0.0   \n",
       "98  5.536787e+09 -1.119012e+11      0.0  1.411373e+11  ...       0.0   \n",
       "99  2.104599e+09 -1.120185e+11      0.0  1.400277e+11  ...       0.0   \n",
       "\n",
       "        uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0   6.835000e+08  2.800000e+12       0.0  5.477000e+08  4.500000e+12   \n",
       "1   1.367000e+09  2.800000e+12       0.0  1.095400e+09  4.500000e+12   \n",
       "2   2.050500e+09  2.799999e+12       0.0  1.643100e+09  4.500000e+12   \n",
       "3   2.734000e+09  2.799999e+12       0.0  2.190800e+09  4.499999e+12   \n",
       "4   3.417499e+09  2.799998e+12       0.0  2.738500e+09  4.499999e+12   \n",
       "..           ...           ...       ...           ...           ...   \n",
       "95  6.560995e+10  2.799207e+12       0.0  5.257803e+10  4.499694e+12   \n",
       "96  6.629326e+10  2.799191e+12       0.0  5.312570e+10  4.499687e+12   \n",
       "97  6.697656e+10  2.799174e+12       0.0  5.367336e+10  4.499681e+12   \n",
       "98  6.765986e+10  2.799157e+12       0.0  5.422102e+10  4.499674e+12   \n",
       "99  6.834316e+10  2.799140e+12       0.0  5.476868e+10  4.499668e+12   \n",
       "\n",
       "    neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0         0.0  4.748000e+08  3.700000e+12      0.0  \n",
       "1         0.0  9.496000e+08  3.700000e+12      0.0  \n",
       "2         0.0  1.424400e+09  3.700000e+12      0.0  \n",
       "3         0.0  1.899200e+09  3.699999e+12      0.0  \n",
       "4         0.0  2.374000e+09  3.699999e+12      0.0  \n",
       "..        ...           ...           ...      ...  \n",
       "95        0.0  4.557899e+10  3.699547e+12      0.0  \n",
       "96        0.0  4.605374e+10  3.699537e+12      0.0  \n",
       "97        0.0  4.652848e+10  3.699528e+12      0.0  \n",
       "98        0.0  4.700322e+10  3.699518e+12      0.0  \n",
       "99        0.0  4.747796e+10  3.699508e+12      0.0  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the dataframes into a single, large dataframe.\n",
    "# Can later choose a planet to be the target we train to predict.\n",
    "complete_motion_df = None\n",
    "\n",
    "for body in motions_df_list:\n",
    "    # Append name of body to each column and remove the name column\n",
    "    body_name = body.loc[0, \"name\"]\n",
    "    body.columns = [body_name + \"_x\",\n",
    "                    body_name + \"_y\",\n",
    "                    body_name + \"_z\",\n",
    "                    \"name\"]\n",
    "    # Add current body to the complete dataframe.\n",
    "    complete_motion_df = pd.concat([complete_motion_df, body.iloc[:, 0:3]], axis=1)\n",
    "\n",
    "complete_motion_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29999, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the simulation data for later loading and use\n",
    "complete_motion_df.to_csv(\"raw_model_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single dataframe with all bodies and all positions with each time step as the index of our rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Create a tf.data Dataset from the Constructed, Unrandomized, Unnormalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "# Probably not needed since not using regressor or doing any feature engineering.\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler  # Scaler for normalizing data.\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaler for normalizing data.\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "# Recommended to enable eager execution when developing model.\n",
    "# Processing data: https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Use sklearn for data processing\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here with Trying to Process Data with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the difficulties is using a mixture of numpy, pandas, and sklearn to take input data (influx), arrange it, split it out, normalize it, and then train a model.  With tf.data input pipelines (similar to sklearn pipelines), we can create data and machine learning pipelines for training or inference.  This allows us to encapsulate not only the machine learning into a Tensorflow model, but the necessary transformations to that data.  That allows us to deploy the model and data transformations as a single object to the later simulator. \\\n",
    "The input pipeline let's us take raw data from any source, like csv, numpy arrays, distributed file system, etc, and convert it into the tensors we will use to train our model.\n",
    "\n",
    "Intro to tensors:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "Good source on how data loading and preprocessing is usually done: https://stackoverflow.com/questions/55321905/want-to-split-train-and-test-data-gotten-from-a-csv-with-tensorflow\n",
    "1) Load the data into memory with numpy\n",
    "2) Split the data into train and validation\n",
    "\n",
    "Since we are not using a massive dataset, then we might be able to use tf.split to split an exsting tf dataset into train and validation.\n",
    "https://docs.w3cub.com/tensorflow~python/tf/split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Numpy Version of the Data as a Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of the complete dataframe and shuffle it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.184144e+11</td>\n",
       "      <td>2.106035e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.461203e+10</td>\n",
       "      <td>7.859856e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.527747e+10</td>\n",
       "      <td>8.464115e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.461007e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.528597e+12</td>\n",
       "      <td>-2.390377e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.871100e+12</td>\n",
       "      <td>-2.215471e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.223972e+12</td>\n",
       "      <td>1.756117e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.521656e+11</td>\n",
       "      <td>7.816288e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.057491e+11</td>\n",
       "      <td>3.824753e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.475399e+11</td>\n",
       "      <td>-5.006123e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.761581e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.742169e+11</td>\n",
       "      <td>2.698263e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.530463e+12</td>\n",
       "      <td>-4.095506e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.846527e+11</td>\n",
       "      <td>3.671363e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.236746e+11</td>\n",
       "      <td>6.260013e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.494716e+10</td>\n",
       "      <td>4.681467e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.592392e+10</td>\n",
       "      <td>-2.172987e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.787482e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.439836e+12</td>\n",
       "      <td>8.628876e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.350029e+12</td>\n",
       "      <td>-2.914202e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.832453e+12</td>\n",
       "      <td>2.613840e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.191820e+11</td>\n",
       "      <td>1.467521e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.763817e+10</td>\n",
       "      <td>2.020065e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.272503e+11</td>\n",
       "      <td>-2.500246e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.665635e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.546435e+12</td>\n",
       "      <td>2.456018e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.662203e+12</td>\n",
       "      <td>-2.531614e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.084206e+12</td>\n",
       "      <td>2.158683e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.562370e+10</td>\n",
       "      <td>1.824030e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.397105e+11</td>\n",
       "      <td>3.584029e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.904134e+11</td>\n",
       "      <td>5.857773e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.369232e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.701299e+12</td>\n",
       "      <td>-1.846983e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.391705e+12</td>\n",
       "      <td>-9.039650e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.092250e+12</td>\n",
       "      <td>-8.623793e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.148480e+10</td>\n",
       "      <td>8.089280e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.866136e+10</td>\n",
       "      <td>5.392533e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.909314e+11</td>\n",
       "      <td>2.570390e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.558976e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.182982e+11</td>\n",
       "      <td>-2.538111e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.477439e+12</td>\n",
       "      <td>4.150703e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.967221e+11</td>\n",
       "      <td>-1.539767e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.906394e+11</td>\n",
       "      <td>5.181714e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130946e+11</td>\n",
       "      <td>-4.544835e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.137327e+11</td>\n",
       "      <td>-8.067189e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.503266e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.602035e+12</td>\n",
       "      <td>1.276351e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.457287e+12</td>\n",
       "      <td>-3.996340e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.179592e+12</td>\n",
       "      <td>2.568917e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.201153e+10</td>\n",
       "      <td>7.431636e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.437798e+10</td>\n",
       "      <td>6.388905e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.431717e+10</td>\n",
       "      <td>-2.570730e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.942371e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.587185e+12</td>\n",
       "      <td>9.079828e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.562007e+12</td>\n",
       "      <td>3.702364e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.082499e+12</td>\n",
       "      <td>2.475915e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.542970e+11</td>\n",
       "      <td>8.044385e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.984892e+11</td>\n",
       "      <td>4.191462e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.328995e+11</td>\n",
       "      <td>8.539061e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.575585e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.688470e+11</td>\n",
       "      <td>2.725584e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.446341e+12</td>\n",
       "      <td>-4.122579e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.095110e+11</td>\n",
       "      <td>3.681460e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.433612e+11</td>\n",
       "      <td>1.710360e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.721680e+10</td>\n",
       "      <td>3.259985e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.826202e+10</td>\n",
       "      <td>9.709829e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000113e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.257482e+12</td>\n",
       "      <td>2.400290e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.089772e+12</td>\n",
       "      <td>-3.864323e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.908687e+11</td>\n",
       "      <td>3.534922e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0  1.184144e+11  2.106035e+09    0.0  6.461203e+10  7.859856e+09        0.0   \n",
       "1  1.521656e+11  7.816288e+09    0.0  1.057491e+11  3.824753e+10        0.0   \n",
       "2  1.236746e+11  6.260013e+09    0.0  8.494716e+10  4.681467e+10        0.0   \n",
       "3  1.191820e+11  1.467521e+09    0.0  6.763817e+10  2.020065e+10        0.0   \n",
       "4  9.562370e+10  1.824030e+09    0.0  1.397105e+11  3.584029e+10        0.0   \n",
       "5  8.148480e+10  8.089280e+09    0.0  4.866136e+10  5.392533e+10        0.0   \n",
       "6  1.906394e+11  5.181714e+08    0.0  2.130946e+11 -4.544835e+10        0.0   \n",
       "7  3.201153e+10  7.431636e+09    0.0  2.437798e+10  6.388905e+10        0.0   \n",
       "8  1.542970e+11  8.044385e+09    0.0  1.984892e+11  4.191462e+10        0.0   \n",
       "9  1.433612e+11  1.710360e+09    0.0  9.721680e+10  3.259985e+10        0.0   \n",
       "\n",
       "        venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0  4.527747e+10  8.464115e+10      0.0  2.461007e+11  ...       0.0   \n",
       "1  2.475399e+11 -5.006123e+10      0.0  2.761581e+11  ...       0.0   \n",
       "2  1.592392e+10 -2.172987e+10      0.0  1.787482e+11  ...       0.0   \n",
       "3  2.272503e+11 -2.500246e+10      0.0  2.665635e+11  ...       0.0   \n",
       "4  1.904134e+11  5.857773e+10      0.0  2.369232e+11  ...       0.0   \n",
       "5  1.909314e+11  2.570390e+10      0.0 -6.558976e+10  ...       0.0   \n",
       "6  1.137327e+11 -8.067189e+10      0.0  2.503266e+11  ...       0.0   \n",
       "7 -7.431717e+10 -2.570730e+10      0.0  5.942371e+10  ...       0.0   \n",
       "8  2.328995e+11  8.539061e+10      0.0  2.575585e+10  ...       0.0   \n",
       "9  8.826202e+10  9.709829e+10      0.0  1.000113e+11  ...       0.0   \n",
       "\n",
       "       uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0 -2.528597e+12 -2.390377e+11       0.0  3.871100e+12 -2.215471e+12   \n",
       "1 -5.742169e+11  2.698263e+12       0.0  1.530463e+12 -4.095506e+12   \n",
       "2 -2.439836e+12  8.628876e+11       0.0  3.350029e+12 -2.914202e+12   \n",
       "3 -2.546435e+12  2.456018e+11       0.0  3.662203e+12 -2.531614e+12   \n",
       "4 -1.701299e+12 -1.846983e+12       0.0  4.391705e+12 -9.039650e+11   \n",
       "5 -1.182982e+11 -2.538111e+12       0.0  4.477439e+12  4.150703e+11   \n",
       "6  2.602035e+12  1.276351e+12       0.0 -1.457287e+12 -3.996340e+12   \n",
       "7  2.587185e+12  9.079828e+11       0.0  2.562007e+12  3.702364e+12   \n",
       "8 -4.688470e+11  2.725584e+12       0.0  1.446341e+12 -4.122579e+12   \n",
       "9 -1.257482e+12  2.400290e+12       0.0  2.089772e+12 -3.864323e+12   \n",
       "\n",
       "   neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0        0.0 -2.223972e+12  1.756117e+12      0.0  \n",
       "1        0.0 -1.846527e+11  3.671363e+12      0.0  \n",
       "2        0.0 -1.832453e+12  2.613840e+12      0.0  \n",
       "3        0.0 -2.084206e+12  2.158683e+12      0.0  \n",
       "4        0.0 -2.092250e+12 -8.623793e+10      0.0  \n",
       "5        0.0 -3.967221e+11 -1.539767e+12      0.0  \n",
       "6        0.0  2.179592e+12  2.568917e+12      0.0  \n",
       "7        0.0  2.082499e+12  2.475915e+12      0.0  \n",
       "8        0.0 -1.095110e+11  3.681460e+12      0.0  \n",
       "9        0.0 -6.908687e+11  3.534922e+12      0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy1_complete_motion_df = complete_motion_df.copy()\n",
    "copy1_complete_motion_df = copy1_complete_motion_df.sample(frac=1).reset_index(drop=True)\n",
    "copy1_complete_motion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split out the target x,y,z columns as the last 3 columns in the dataframe.  Skipping scaling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.223972e+12</td>\n",
       "      <td>1.756117e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.846527e+11</td>\n",
       "      <td>3.671363e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.832453e+12</td>\n",
       "      <td>2.613840e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.084206e+12</td>\n",
       "      <td>2.158683e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.092250e+12</td>\n",
       "      <td>-8.623793e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pluto_x       pluto_y  pluto_z\n",
       "0 -2.223972e+12  1.756117e+12      0.0\n",
       "1 -1.846527e+11  3.671363e+12      0.0\n",
       "2 -1.832453e+12  2.613840e+12      0.0\n",
       "3 -2.084206e+12  2.158683e+12      0.0\n",
       "4 -2.092250e+12 -8.623793e+10      0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = copy1_complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "copy1_complete_motion_df.drop(copy1_complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = target.iloc[:,0]\n",
    "target_y = target.iloc[:,1]\n",
    "target_z = target.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all pandas dataframes to numpy arrays so they are compatible with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_motion_np = copy1_complete_motion_df.to_numpy()\n",
    "target_np = target.to_numpy()\n",
    "target_x_np = target_x.to_numpy()\n",
    "target_y_np = target_y.to_numpy()\n",
    "target_z_np = target_z.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "X_train, X_valid, X_test = complete_motion_np[:train_size], complete_motion_np[train_size:(train_size+val_size)], complete_motion_np[(train_size + val_size):]\n",
    "y_train_x, y_valid_x, y_test_x = target_x_np[:train_size], target_x_np[train_size:(train_size+val_size)], target_x_np[(train_size + val_size):]\n",
    "y_train_y, y_valid_y, y_test_y = target_y_np[:train_size], target_y_np[train_size:(train_size+val_size)], target_y_np[(train_size + val_size):]\n",
    "y_train_z, y_valid_z, y_test_z = target_z_np[:train_size], target_z_np[train_size:(train_size+val_size)], target_z_np[(train_size + val_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf dataset from slices (numpy array, pandas dataframe, etc). \n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "Probably one of the better articles on using tensorflow datasets: \\\n",
    "https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "\n",
    "TF documentation on tf.data: Building Tensorflow Input Pipelines: \\\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "Method for splitting tensorflow datasets into train, validation, and test: \\\n",
    "https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets/51126863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into input and targets for the x, y, and z coordinates.\n",
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "complete_motion_df.drop(complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "# Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output.\n",
    "# Convert targets to numpy arrays as well so we can use them in the model.\n",
    "target_x_np = target.iloc[:,0].to_numpy()\n",
    "target_y_np = target.iloc[:,1].to_numpy()\n",
    "target_z_np = target.iloc[:,2].to_numpy()\n",
    "# Usually training, validation, and test data would be coming from different CSV files or sources.\n",
    "# complete_motion_df only consists of input data at this point.\n",
    "complete_motion_np = complete_motion_df.to_numpy()\n",
    "\n",
    "#Create one large tensorflow dataset.\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((complete_motion_np, \n",
    "                                                   target_x_np, \n",
    "                                                   target_y_np,\n",
    "                                                   target_z_np)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [6.17261536e+00 6.06237951e+03 0.00000000e+00 4.69435521e+09\n",
      " 5.67926313e+10 0.00000000e+00 3.49941507e+09 1.09944304e+11\n",
      " 0.00000000e+00 2.99980227e+09 1.49970050e+11 0.00000000e+00\n",
      " 2.39994986e+09 2.19986084e+11 0.00000000e+00 1.29999937e+09\n",
      " 7.69998864e+11 0.00000000e+00 8.99999929e+08 1.39999965e+12\n",
      " 0.00000000e+00 6.83499993e+08 2.79999991e+12 0.00000000e+00\n",
      " 5.47699999e+08 4.49999997e+12 0.00000000e+00] Target_X: 474799997.95801955 Target_Y: 3699999950348.1753 Target_Z: 0.0\n",
      "Features: [4.93790293e+01 2.41290843e+04 0.00000000e+00 9.35485981e+09\n",
      " 5.61758433e+10 0.00000000e+00 6.99532091e+09 1.09778377e+11\n",
      " 0.00000000e+00 5.99841813e+09 1.49880804e+11 0.00000000e+00\n",
      " 4.79959882e+09 2.19944611e+11 0.00000000e+00 2.59999493e+09\n",
      " 7.69995477e+11 0.00000000e+00 1.79999943e+09 1.39999860e+12\n",
      " 0.00000000e+00 1.36699995e+09 2.79999965e+12 0.00000000e+00\n",
      " 1.09539999e+09 4.49999987e+12 0.00000000e+00] Target_X: 949599983.6629324 Target_Y: 3699999802375.9053 Target_Z: 0.0\n",
      "Features: [1.66623838e+02 5.41989476e+04 0.00000000e+00 1.39477770e+10\n",
      " 5.51532975e+10 0.00000000e+00 1.04842120e+10 1.09502387e+11\n",
      " 0.00000000e+00 8.99466168e+09 1.49732300e+11 0.00000000e+00\n",
      " 7.19864603e+09 2.19875587e+11 0.00000000e+00 3.89998289e+09\n",
      " 7.69989840e+11 0.00000000e+00 2.69999808e+09 1.39999685e+12\n",
      " 0.00000000e+00 2.05049982e+09 2.79999922e+12 0.00000000e+00\n",
      " 1.64309996e+09 4.49999970e+12 0.00000000e+00] Target_X: 1424399944.8616266 Target_Y: 3699999556083.186 Target_Z: 0.0\n",
      "Features: [3.94851583e+02 9.62700181e+04 0.00000000e+00 1.84396060e+10\n",
      " 5.37311252e+10 0.00000000e+00 1.39625905e+10 1.09116617e+11\n",
      " 0.00000000e+00 1.19873480e+10 1.49524596e+11 0.00000000e+00\n",
      " 9.59679064e+09 2.19779019e+11 0.00000000e+00 5.19995945e+09\n",
      " 7.69981952e+11 0.00000000e+00 3.59999544e+09 1.39999440e+12\n",
      " 0.00000000e+00 2.73399956e+09 2.79999862e+12 0.00000000e+00\n",
      " 2.19079992e+09 4.49999947e+12 0.00000000e+00] Target_X: 1899199869.3009844 Target_Y: 3699999211470.024 Target_Z: 0.0\n",
      "Features: [7.70915008e+02 1.50339559e+05 0.00000000e+00 2.27972101e+10\n",
      " 5.19179389e+10 0.00000000e+00 1.74269696e+10 1.08621464e+11\n",
      " 0.00000000e+00 1.49752939e+10 1.49257779e+11 0.00000000e+00\n",
      " 1.19937319e+10 2.19654917e+11 0.00000000e+00 6.49992080e+09\n",
      " 7.69971814e+11 0.00000000e+00 4.49999110e+09 1.39999126e+12\n",
      " 0.00000000e+00 3.41749915e+09 2.79999785e+12 0.00000000e+00\n",
      " 2.73849984e+09 4.49999917e+12 0.00000000e+00] Target_X: 2373999744.727879 Target_Y: 3699998768536.421 Target_Z: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataset and print the input and targets.\n",
    "# Will select top 5 to iterate through.\n",
    "for feat, targ_x, targ_y, targ_z in full_dataset.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the full dataset before splitting into train, validation, and test.\n",
    "# Since dataset can fit in memory, can set buffer to be the size of the data.\n",
    "full_dataset_num_samples = complete_motion_df.shape[0]  #Get the size of the dataset to set the randomize buffer\n",
    "#full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples).batch(1)\n",
    "full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(27,), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "# Take the shuffled dataset and split into train, validation, and test datasets.\n",
    "train_dataset = full_dataset.take(train_size)   # Take top of dataset for training data\n",
    "test_dataset = full_dataset.skip(train_size)    # Take the rest of the dataset for validation and test\n",
    "val_dataset = test_dataset.skip(test_size)      # Take a part of the test data for validation during training\n",
    "test_dataset = test_dataset.take(test_size)     # Get rid of the validation data from the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Quick Neural Net for Predicting Jupiter's Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \\\n",
    "<br>\n",
    "Instead of using sklearn to normalize or manually making a normalization and standardization layer like p. 431 of the book, try using at least 1 Batch normalization layer after the input layer.  Can also add after hidden layers. \\\n",
    "<br>\n",
    "Might need to add an activation function to the output layer later to help with scaling of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Creating Single Input, Multiple Output Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a regression NN where instead of designating an output layer of 3 nodes, 3 output layers of a single node are used to designate specific datasets and loss functions.  Still need to figure out later how to get a 3 node output to correspond to the input training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functional API to build basic NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions with different versions of the neural network.\n",
    "\n",
    "def get_model1(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_2(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"tanh\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"tanh\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_3(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    \n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=10, rho=0.9)\n",
    "    \n",
    "def get_model_4(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(normal1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=2, rho=0.9)\n",
    "    \n",
    "def get_model_5(input_shape):  #Best one yet.  Typically takes about 1500 epochs to get decend results.\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "    hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "    #Set \n",
    "    input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "    input_loss_weights = [0.4, 0.4, 0.2]\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=0.0000005, rho=0.01)\n",
    "    input_metrics = [\"mae\"]\n",
    "    input_num_epochs = 200\n",
    "    input_batch_size = 64\n",
    "\n",
    "    model.summary()\n",
    "    #Also can use and probably should use Adam\n",
    "    input_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with specified input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 300)          8400        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          90300       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_x (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_y (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output_z (Dense)                (None, 1)            301         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 99,603\n",
      "Trainable params: 99,603\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model with specified input and output layers.\n",
    "# Select which model to try.\n",
    "# Pass shape of input layer to the function.\n",
    "#model = get_model_2(complete_motion_np.shape[1:])\n",
    "\n",
    "# Use functional API to build basic NN architecture.\n",
    "input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "#Set \n",
    "input_losses = [\"msle\", \"msle\", \"msle\"]\n",
    "input_loss_weights = [0.4, 0.4, 0.2]\n",
    "input_optimizer = keras.optimizers.Adam(learning_rate=1e-7, beta_1=0.9, beta_2=0.999)\n",
    "input_metrics = [\"msle\"]\n",
    "input_num_epochs = 500\n",
    "input_batch_size = 128\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting the model, create callbacks for the various stages.\n",
    "\n",
    "# Callback to implement overfitting.  Helps with regularization.  \n",
    "# Keep from over-training.  Stops training when validation error starts increasing again.\n",
    "# https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping/\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                 min_delta=0.0001,\n",
    "                                                 patience=20)\n",
    "\n",
    "# Callback for learning rate scheduling.  This way we can start with a higher learning rate then reduce as we go.\n",
    "# Reducing the learning rate by a factor of \"factor\" every so many epochs or \"patience\".\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=50)\n",
    "\n",
    "#Create list of all callbacks.\n",
    "#callback_list = [early_stopping_cb, lr_scheduler]\n",
    "callback_list = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with specified loss functions for each output and specify weighting to provide each output.\n",
    "# Weighting X and Y output more than Z\n",
    "model.compile(loss=input_losses, \n",
    "              loss_weights=input_loss_weights, \n",
    "              optimizer=input_optimizer,\n",
    "              metrics=input_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with separate x, y, z training sets.  Choose either numpy data or tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 308.7949 - output_x_loss: 300.8155 - output_y_loss: 304.2582 - output_z_loss: 333.8279 - output_x_msle: 300.8155 - output_y_msle: 304.2582 - output_z_msle: 333.8279 - val_loss: 312.0705 - val_output_x_loss: 303.5751 - val_output_y_loss: 308.7294 - val_output_z_loss: 335.7434 - val_output_x_msle: 303.5751 - val_output_y_msle: 308.7294 - val_output_z_msle: 335.7434 - lr: 1.0000e-07\n",
      "Epoch 2/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 307.5116 - output_x_loss: 300.6783 - output_y_loss: 303.9241 - output_z_loss: 328.3526 - output_x_msle: 300.6783 - output_y_msle: 303.9241 - output_z_msle: 328.3526 - val_loss: 311.2049 - val_output_x_loss: 303.5564 - val_output_y_loss: 308.5372 - val_output_z_loss: 331.8367 - val_output_x_msle: 303.5564 - val_output_y_msle: 308.5372 - val_output_z_msle: 331.8367 - lr: 1.0000e-07\n",
      "Epoch 3/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 306.3521 - output_x_loss: 300.5210 - output_y_loss: 303.5587 - output_z_loss: 323.6004 - output_x_msle: 300.5210 - output_y_msle: 303.5587 - output_z_msle: 323.6004 - val_loss: 310.1568 - val_output_x_loss: 303.5111 - val_output_y_loss: 308.5511 - val_output_z_loss: 326.6595 - val_output_x_msle: 303.5111 - val_output_y_msle: 308.5511 - val_output_z_msle: 326.6595 - lr: 1.0000e-07\n",
      "Epoch 4/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 305.3055 - output_x_loss: 300.4135 - output_y_loss: 303.6152 - output_z_loss: 318.4702 - output_x_msle: 300.4135 - output_y_msle: 303.6152 - output_z_msle: 318.4702 - val_loss: 308.9423 - val_output_x_loss: 303.2530 - val_output_y_loss: 308.2289 - val_output_z_loss: 321.7478 - val_output_x_msle: 303.2530 - val_output_y_msle: 308.2289 - val_output_z_msle: 321.7478 - lr: 1.0000e-07\n",
      "Epoch 5/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 304.4926 - output_x_loss: 300.2827 - output_y_loss: 303.4848 - output_z_loss: 314.9281 - output_x_msle: 300.2827 - output_y_msle: 303.4848 - output_z_msle: 314.9281 - val_loss: 308.5397 - val_output_x_loss: 303.0381 - val_output_y_loss: 308.3994 - val_output_z_loss: 319.8233 - val_output_x_msle: 303.0381 - val_output_y_msle: 308.3994 - val_output_z_msle: 319.8233 - lr: 1.0000e-07\n",
      "Epoch 6/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 303.9929 - output_x_loss: 300.1305 - output_y_loss: 303.4265 - output_z_loss: 312.8498 - output_x_msle: 300.1305 - output_y_msle: 303.4265 - output_z_msle: 312.8498 - val_loss: 307.7899 - val_output_x_loss: 303.1024 - val_output_y_loss: 307.7728 - val_output_z_loss: 317.1987 - val_output_x_msle: 303.1024 - val_output_y_msle: 307.7728 - val_output_z_msle: 317.1987 - lr: 1.0000e-07\n",
      "Epoch 7/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 303.3220 - output_x_loss: 299.9696 - output_y_loss: 303.3916 - output_z_loss: 309.8869 - output_x_msle: 299.9696 - output_y_msle: 303.3916 - output_z_msle: 309.8869 - val_loss: 307.0731 - val_output_x_loss: 303.1707 - val_output_y_loss: 307.7306 - val_output_z_loss: 313.5626 - val_output_x_msle: 303.1707 - val_output_y_msle: 307.7306 - val_output_z_msle: 313.5626 - lr: 1.0000e-07\n",
      "Epoch 8/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 302.7185 - output_x_loss: 299.7694 - output_y_loss: 303.3759 - output_z_loss: 307.3017 - output_x_msle: 299.7694 - output_y_msle: 303.3759 - output_z_msle: 307.3017 - val_loss: 306.7036 - val_output_x_loss: 302.9339 - val_output_y_loss: 307.6656 - val_output_z_loss: 312.3190 - val_output_x_msle: 302.9339 - val_output_y_msle: 307.6656 - val_output_z_msle: 312.3190 - lr: 1.0000e-07\n",
      "Epoch 9/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 302.1636 - output_x_loss: 299.6765 - output_y_loss: 303.1016 - output_z_loss: 305.2618 - output_x_msle: 299.6765 - output_y_msle: 303.1016 - output_z_msle: 305.2618 - val_loss: 305.9795 - val_output_x_loss: 302.8086 - val_output_y_loss: 307.2594 - val_output_z_loss: 309.7615 - val_output_x_msle: 302.8086 - val_output_y_msle: 307.2594 - val_output_z_msle: 309.7615 - lr: 1.0000e-07\n",
      "Epoch 10/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 301.3477 - output_x_loss: 299.4991 - output_y_loss: 302.8357 - output_z_loss: 302.0688 - output_x_msle: 299.4991 - output_y_msle: 302.8357 - output_z_msle: 302.0688 - val_loss: 305.4360 - val_output_x_loss: 302.6901 - val_output_y_loss: 307.0549 - val_output_z_loss: 307.6902 - val_output_x_msle: 302.6901 - val_output_y_msle: 307.0549 - val_output_z_msle: 307.6902 - lr: 1.0000e-07\n",
      "Epoch 11/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 300.6787 - output_x_loss: 299.3329 - output_y_loss: 302.7540 - output_z_loss: 299.2199 - output_x_msle: 299.3329 - output_y_msle: 302.7540 - output_z_msle: 299.2199 - val_loss: 305.0079 - val_output_x_loss: 302.8819 - val_output_y_loss: 306.9837 - val_output_z_loss: 305.3085 - val_output_x_msle: 302.8819 - val_output_y_msle: 306.9837 - val_output_z_msle: 305.3085 - lr: 1.0000e-07\n",
      "Epoch 12/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 299.9830 - output_x_loss: 299.1750 - output_y_loss: 302.7737 - output_z_loss: 296.0177 - output_x_msle: 299.1750 - output_y_msle: 302.7737 - output_z_msle: 296.0177 - val_loss: 304.1431 - val_output_x_loss: 302.7415 - val_output_y_loss: 306.8991 - val_output_z_loss: 301.4343 - val_output_x_msle: 302.7415 - val_output_y_msle: 306.8991 - val_output_z_msle: 301.4343 - lr: 1.0000e-07\n",
      "Epoch 13/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 299.2837 - output_x_loss: 298.9983 - output_y_loss: 302.7990 - output_z_loss: 292.8238 - output_x_msle: 298.9983 - output_y_msle: 302.7990 - output_z_msle: 292.8238 - val_loss: 303.4774 - val_output_x_loss: 302.6258 - val_output_y_loss: 306.7303 - val_output_z_loss: 298.6750 - val_output_x_msle: 302.6258 - val_output_y_msle: 306.7303 - val_output_z_msle: 298.6750 - lr: 1.0000e-07\n",
      "Epoch 14/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 298.5880 - output_x_loss: 298.9289 - output_y_loss: 302.7402 - output_z_loss: 289.6015 - output_x_msle: 298.9289 - output_y_msle: 302.7402 - output_z_msle: 289.6015 - val_loss: 302.6098 - val_output_x_loss: 302.5940 - val_output_y_loss: 306.6121 - val_output_z_loss: 294.6369 - val_output_x_msle: 302.5940 - val_output_y_msle: 306.6121 - val_output_z_msle: 294.6369 - lr: 1.0000e-07\n",
      "Epoch 15/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 297.5659 - output_x_loss: 298.8019 - output_y_loss: 302.6903 - output_z_loss: 284.8449 - output_x_msle: 298.8019 - output_y_msle: 302.6903 - output_z_msle: 284.8449 - val_loss: 301.5891 - val_output_x_loss: 302.3873 - val_output_y_loss: 306.6597 - val_output_z_loss: 289.8514 - val_output_x_msle: 302.3873 - val_output_y_msle: 306.6597 - val_output_z_msle: 289.8514 - lr: 1.0000e-07\n",
      "Epoch 16/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 296.1833 - output_x_loss: 298.5734 - output_y_loss: 302.6491 - output_z_loss: 278.4711 - output_x_msle: 298.5734 - output_y_msle: 302.6491 - output_z_msle: 278.4711 - val_loss: 299.7817 - val_output_x_loss: 302.4232 - val_output_y_loss: 306.4786 - val_output_z_loss: 281.1052 - val_output_x_msle: 302.4232 - val_output_y_msle: 306.4786 - val_output_z_msle: 281.1052 - lr: 1.0000e-07\n",
      "Epoch 17/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 295.2315 - output_x_loss: 298.6048 - output_y_loss: 302.5832 - output_z_loss: 273.7817 - output_x_msle: 298.6048 - output_y_msle: 302.5832 - output_z_msle: 273.7817 - val_loss: 298.8824 - val_output_x_loss: 302.4651 - val_output_y_loss: 306.3895 - val_output_z_loss: 276.7033 - val_output_x_msle: 302.4651 - val_output_y_msle: 306.3895 - val_output_z_msle: 276.7033 - lr: 1.0000e-07\n",
      "Epoch 18/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.5164 - output_x_loss: 298.3146 - output_y_loss: 302.5311 - output_z_loss: 270.8903 - output_x_msle: 298.3146 - output_y_msle: 302.5311 - output_z_msle: 270.8903 - val_loss: 298.6322 - val_output_x_loss: 302.2984 - val_output_y_loss: 306.5910 - val_output_z_loss: 275.3820 - val_output_x_msle: 302.2984 - val_output_y_msle: 306.5910 - val_output_z_msle: 275.3820 - lr: 1.0000e-07\n",
      "Epoch 19/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 294.0723 - output_x_loss: 298.0588 - output_y_loss: 302.4864 - output_z_loss: 269.2715 - output_x_msle: 298.0588 - output_y_msle: 302.4864 - output_z_msle: 269.2715 - val_loss: 298.3053 - val_output_x_loss: 302.1146 - val_output_y_loss: 306.3773 - val_output_z_loss: 274.5427 - val_output_x_msle: 302.1146 - val_output_y_msle: 306.3773 - val_output_z_msle: 274.5427 - lr: 1.0000e-07\n",
      "Epoch 20/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 293.6728 - output_x_loss: 297.7382 - output_y_loss: 302.4263 - output_z_loss: 268.0349 - output_x_msle: 297.7382 - output_y_msle: 302.4263 - output_z_msle: 268.0349 - val_loss: 298.0729 - val_output_x_loss: 302.1679 - val_output_y_loss: 306.4575 - val_output_z_loss: 273.1140 - val_output_x_msle: 302.1679 - val_output_y_msle: 306.4575 - val_output_z_msle: 273.1140 - lr: 1.0000e-07\n",
      "Epoch 21/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 293.2817 - output_x_loss: 297.5009 - output_y_loss: 302.3975 - output_z_loss: 266.6117 - output_x_msle: 297.5009 - output_y_msle: 302.3975 - output_z_msle: 266.6117 - val_loss: 297.5102 - val_output_x_loss: 301.5735 - val_output_y_loss: 306.3667 - val_output_z_loss: 271.6704 - val_output_x_msle: 301.5735 - val_output_y_msle: 306.3667 - val_output_z_msle: 271.6704 - lr: 1.0000e-07\n",
      "Epoch 22/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.9032 - output_x_loss: 296.9941 - output_y_loss: 302.3628 - output_z_loss: 265.8022 - output_x_msle: 296.9941 - output_y_msle: 302.3628 - output_z_msle: 265.8022 - val_loss: 297.1546 - val_output_x_loss: 301.3570 - val_output_y_loss: 306.3438 - val_output_z_loss: 270.3714 - val_output_x_msle: 301.3570 - val_output_y_msle: 306.3438 - val_output_z_msle: 270.3714 - lr: 1.0000e-07\n",
      "Epoch 23/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 292.6210 - output_x_loss: 296.8756 - output_y_loss: 302.3076 - output_z_loss: 264.7385 - output_x_msle: 296.8756 - output_y_msle: 302.3076 - output_z_msle: 264.7385 - val_loss: 296.6310 - val_output_x_loss: 300.9183 - val_output_y_loss: 306.3204 - val_output_z_loss: 268.6775 - val_output_x_msle: 300.9183 - val_output_y_msle: 306.3204 - val_output_z_msle: 268.6775 - lr: 1.0000e-07\n",
      "Epoch 24/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 292.2150 - output_x_loss: 296.6753 - output_y_loss: 302.2879 - output_z_loss: 263.1494 - output_x_msle: 296.6753 - output_y_msle: 302.2879 - output_z_msle: 263.1494 - val_loss: 296.2737 - val_output_x_loss: 300.4316 - val_output_y_loss: 306.2986 - val_output_z_loss: 267.9081 - val_output_x_msle: 300.4316 - val_output_y_msle: 306.2986 - val_output_z_msle: 267.9081 - lr: 1.0000e-07\n",
      "Epoch 25/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.9969 - output_x_loss: 296.4704 - output_y_loss: 302.2325 - output_z_loss: 262.5784 - output_x_msle: 296.4704 - output_y_msle: 302.2325 - output_z_msle: 262.5784 - val_loss: 295.9697 - val_output_x_loss: 300.0988 - val_output_y_loss: 306.2750 - val_output_z_loss: 267.1005 - val_output_x_msle: 300.0988 - val_output_y_msle: 306.2750 - val_output_z_msle: 267.1005 - lr: 1.0000e-07\n",
      "Epoch 26/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.7487 - output_x_loss: 296.2549 - output_y_loss: 302.2127 - output_z_loss: 261.8080 - output_x_msle: 296.2549 - output_y_msle: 302.2127 - output_z_msle: 261.8080 - val_loss: 295.7082 - val_output_x_loss: 299.7379 - val_output_y_loss: 306.2534 - val_output_z_loss: 266.5582 - val_output_x_msle: 299.7379 - val_output_y_msle: 306.2534 - val_output_z_msle: 266.5582 - lr: 1.0000e-07\n",
      "Epoch 27/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.5303 - output_x_loss: 296.0295 - output_y_loss: 302.1923 - output_z_loss: 261.2077 - output_x_msle: 296.0295 - output_y_msle: 302.1923 - output_z_msle: 261.2077 - val_loss: 295.4525 - val_output_x_loss: 299.2907 - val_output_y_loss: 306.2294 - val_output_z_loss: 266.2224 - val_output_x_msle: 299.2907 - val_output_y_msle: 306.2294 - val_output_z_msle: 266.2224 - lr: 1.0000e-07\n",
      "Epoch 28/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 291.3288 - output_x_loss: 295.8286 - output_y_loss: 302.1743 - output_z_loss: 260.6383 - output_x_msle: 295.8286 - output_y_msle: 302.1743 - output_z_msle: 260.6383 - val_loss: 295.2637 - val_output_x_loss: 299.0880 - val_output_y_loss: 306.2140 - val_output_z_loss: 265.7146 - val_output_x_msle: 299.0880 - val_output_y_msle: 306.2140 - val_output_z_msle: 265.7146 - lr: 1.0000e-07\n",
      "Epoch 29/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 291.1590 - output_x_loss: 295.6846 - output_y_loss: 302.1574 - output_z_loss: 260.1109 - output_x_msle: 295.6846 - output_y_msle: 302.1574 - output_z_msle: 260.1109 - val_loss: 295.0237 - val_output_x_loss: 298.8150 - val_output_y_loss: 306.1915 - val_output_z_loss: 265.1052 - val_output_x_msle: 298.8150 - val_output_y_msle: 306.1915 - val_output_z_msle: 265.1052 - lr: 1.0000e-07\n",
      "Epoch 30/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.8962 - output_x_loss: 295.4096 - output_y_loss: 302.1396 - output_z_loss: 259.3827 - output_x_msle: 295.4096 - output_y_msle: 302.1396 - output_z_msle: 259.3827 - val_loss: 294.7090 - val_output_x_loss: 298.6206 - val_output_y_loss: 306.0085 - val_output_z_loss: 264.2867 - val_output_x_msle: 298.6206 - val_output_y_msle: 306.0085 - val_output_z_msle: 264.2867 - lr: 1.0000e-07\n",
      "Epoch 31/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.6512 - output_x_loss: 295.1629 - output_y_loss: 302.1242 - output_z_loss: 258.6819 - output_x_msle: 295.1629 - output_y_msle: 302.1242 - output_z_msle: 258.6819 - val_loss: 294.4114 - val_output_x_loss: 298.3280 - val_output_y_loss: 305.9841 - val_output_z_loss: 263.4326 - val_output_x_msle: 298.3280 - val_output_y_msle: 305.9841 - val_output_z_msle: 263.4326 - lr: 1.0000e-07\n",
      "Epoch 32/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.3513 - output_x_loss: 294.9949 - output_y_loss: 302.1638 - output_z_loss: 257.4395 - output_x_msle: 294.9949 - output_y_msle: 302.1638 - output_z_msle: 257.4395 - val_loss: 294.0200 - val_output_x_loss: 298.1447 - val_output_y_loss: 305.9488 - val_output_z_loss: 261.9131 - val_output_x_msle: 298.1447 - val_output_y_msle: 305.9488 - val_output_z_msle: 261.9131 - lr: 1.0000e-07\n",
      "Epoch 33/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 290.0392 - output_x_loss: 294.9810 - output_y_loss: 302.1440 - output_z_loss: 255.9466 - output_x_msle: 294.9810 - output_y_msle: 302.1440 - output_z_msle: 255.9466 - val_loss: 293.7672 - val_output_x_loss: 298.0739 - val_output_y_loss: 305.9186 - val_output_z_loss: 260.8511 - val_output_x_msle: 298.0739 - val_output_y_msle: 305.9186 - val_output_z_msle: 260.8511 - lr: 1.0000e-07\n",
      "Epoch 34/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 289.7803 - output_x_loss: 295.0682 - output_y_loss: 302.1842 - output_z_loss: 254.3974 - output_x_msle: 295.0682 - output_y_msle: 302.1842 - output_z_msle: 254.3974 - val_loss: 293.4361 - val_output_x_loss: 298.1237 - val_output_y_loss: 305.8178 - val_output_z_loss: 259.2975 - val_output_x_msle: 298.1237 - val_output_y_msle: 305.8178 - val_output_z_msle: 259.2975 - lr: 1.0000e-07\n",
      "Epoch 35/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.4159 - output_x_loss: 294.9616 - output_y_loss: 302.1310 - output_z_loss: 252.8947 - output_x_msle: 294.9616 - output_y_msle: 302.1310 - output_z_msle: 252.8947 - val_loss: 293.1884 - val_output_x_loss: 298.2783 - val_output_y_loss: 305.7952 - val_output_z_loss: 257.7947 - val_output_x_msle: 298.2783 - val_output_y_msle: 305.7952 - val_output_z_msle: 257.7947 - lr: 1.0000e-07\n",
      "Epoch 36/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 289.0822 - output_x_loss: 294.8609 - output_y_loss: 302.1680 - output_z_loss: 251.3530 - output_x_msle: 294.8609 - output_y_msle: 302.1680 - output_z_msle: 251.3530 - val_loss: 292.6562 - val_output_x_loss: 298.1057 - val_output_y_loss: 305.7670 - val_output_z_loss: 255.5354 - val_output_x_msle: 298.1057 - val_output_y_msle: 305.7670 - val_output_z_msle: 255.5354 - lr: 1.0000e-07\n",
      "Epoch 37/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 288.5544 - output_x_loss: 294.7669 - output_y_loss: 302.1719 - output_z_loss: 248.8949 - output_x_msle: 294.7669 - output_y_msle: 302.1719 - output_z_msle: 248.8949 - val_loss: 292.0120 - val_output_x_loss: 297.4355 - val_output_y_loss: 305.7403 - val_output_z_loss: 253.7084 - val_output_x_msle: 297.4355 - val_output_y_msle: 305.7403 - val_output_z_msle: 253.7084 - lr: 1.0000e-07\n",
      "Epoch 38/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.9708 - output_x_loss: 294.2329 - output_y_loss: 302.1498 - output_z_loss: 247.0883 - output_x_msle: 294.2329 - output_y_msle: 302.1498 - output_z_msle: 247.0883 - val_loss: 291.5828 - val_output_x_loss: 297.2566 - val_output_y_loss: 305.7133 - val_output_z_loss: 251.9746 - val_output_x_msle: 297.2566 - val_output_y_msle: 305.7133 - val_output_z_msle: 251.9746 - lr: 1.0000e-07\n",
      "Epoch 39/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 287.5554 - output_x_loss: 294.1030 - output_y_loss: 302.1267 - output_z_loss: 245.3176 - output_x_msle: 294.1030 - output_y_msle: 302.1267 - output_z_msle: 245.3176 - val_loss: 291.2104 - val_output_x_loss: 297.2583 - val_output_y_loss: 305.7236 - val_output_z_loss: 250.0882 - val_output_x_msle: 297.2583 - val_output_y_msle: 305.7236 - val_output_z_msle: 250.0882 - lr: 1.0000e-07\n",
      "Epoch 40/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.9953 - output_x_loss: 293.9769 - output_y_loss: 301.9187 - output_z_loss: 243.1858 - output_x_msle: 293.9769 - output_y_msle: 301.9187 - output_z_msle: 243.1858 - val_loss: 290.6096 - val_output_x_loss: 297.0180 - val_output_y_loss: 305.7169 - val_output_z_loss: 247.5782 - val_output_x_msle: 297.0180 - val_output_y_msle: 305.7169 - val_output_z_msle: 247.5782 - lr: 1.0000e-07\n",
      "Epoch 41/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 286.4657 - output_x_loss: 293.8375 - output_y_loss: 301.7996 - output_z_loss: 241.0546 - output_x_msle: 293.8375 - output_y_msle: 301.7996 - output_z_msle: 241.0546 - val_loss: 289.9767 - val_output_x_loss: 296.8672 - val_output_y_loss: 305.6947 - val_output_z_loss: 244.7596 - val_output_x_msle: 296.8672 - val_output_y_msle: 305.6947 - val_output_z_msle: 244.7596 - lr: 1.0000e-07\n",
      "Epoch 42/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 285.8249 - output_x_loss: 293.7453 - output_y_loss: 301.8118 - output_z_loss: 238.0105 - output_x_msle: 293.7453 - output_y_msle: 301.8118 - output_z_msle: 238.0105 - val_loss: 289.4817 - val_output_x_loss: 296.5894 - val_output_y_loss: 305.6879 - val_output_z_loss: 242.8537 - val_output_x_msle: 296.5894 - val_output_y_msle: 305.6879 - val_output_z_msle: 242.8537 - lr: 1.0000e-07\n",
      "Epoch 43/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 285.0701 - output_x_loss: 293.5684 - output_y_loss: 301.7436 - output_z_loss: 234.7271 - output_x_msle: 293.5684 - output_y_msle: 301.7436 - output_z_msle: 234.7271 - val_loss: 288.6351 - val_output_x_loss: 296.5919 - val_output_y_loss: 305.6764 - val_output_z_loss: 238.6391 - val_output_x_msle: 296.5919 - val_output_y_msle: 305.6764 - val_output_z_msle: 238.6391 - lr: 1.0000e-07\n",
      "Epoch 44/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.4659 - output_x_loss: 293.4886 - output_y_loss: 301.7045 - output_z_loss: 231.9434 - output_x_msle: 293.4886 - output_y_msle: 301.7045 - output_z_msle: 231.9434 - val_loss: 288.2203 - val_output_x_loss: 296.4265 - val_output_y_loss: 305.7570 - val_output_z_loss: 236.7341 - val_output_x_msle: 296.4265 - val_output_y_msle: 305.7570 - val_output_z_msle: 236.7341 - lr: 1.0000e-07\n",
      "Epoch 45/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 284.0570 - output_x_loss: 293.3645 - output_y_loss: 301.6892 - output_z_loss: 230.1774 - output_x_msle: 293.3645 - output_y_msle: 301.6892 - output_z_msle: 230.1774 - val_loss: 287.7032 - val_output_x_loss: 296.2788 - val_output_y_loss: 305.6511 - val_output_z_loss: 234.6562 - val_output_x_msle: 296.2788 - val_output_y_msle: 305.6511 - val_output_z_msle: 234.6562 - lr: 1.0000e-07\n",
      "Epoch 46/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.8343 - output_x_loss: 293.3165 - output_y_loss: 301.7052 - output_z_loss: 229.1281 - output_x_msle: 293.3165 - output_y_msle: 301.7052 - output_z_msle: 229.1281 - val_loss: 287.5811 - val_output_x_loss: 296.3334 - val_output_y_loss: 305.7108 - val_output_z_loss: 233.8168 - val_output_x_msle: 296.3334 - val_output_y_msle: 305.7108 - val_output_z_msle: 233.8168 - lr: 1.0000e-07\n",
      "Epoch 47/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.6252 - output_x_loss: 293.1367 - output_y_loss: 301.6627 - output_z_loss: 228.5275 - output_x_msle: 293.1367 - output_y_msle: 301.6627 - output_z_msle: 228.5275 - val_loss: 287.1657 - val_output_x_loss: 296.1764 - val_output_y_loss: 305.6195 - val_output_z_loss: 232.2364 - val_output_x_msle: 296.1764 - val_output_y_msle: 305.6195 - val_output_z_msle: 232.2364 - lr: 1.0000e-07\n",
      "Epoch 48/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 283.2315 - output_x_loss: 292.9585 - output_y_loss: 301.6753 - output_z_loss: 226.8898 - output_x_msle: 292.9585 - output_y_msle: 301.6753 - output_z_msle: 226.8898 - val_loss: 287.1291 - val_output_x_loss: 296.2778 - val_output_y_loss: 305.6037 - val_output_z_loss: 231.8824 - val_output_x_msle: 296.2778 - val_output_y_msle: 305.6037 - val_output_z_msle: 231.8824 - lr: 1.0000e-07\n",
      "Epoch 49/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 283.1240 - output_x_loss: 292.8461 - output_y_loss: 301.7523 - output_z_loss: 226.4235 - output_x_msle: 292.8461 - output_y_msle: 301.7523 - output_z_msle: 226.4235 - val_loss: 287.0033 - val_output_x_loss: 296.2108 - val_output_y_loss: 305.5834 - val_output_z_loss: 231.4282 - val_output_x_msle: 296.2108 - val_output_y_msle: 305.5834 - val_output_z_msle: 231.4282 - lr: 1.0000e-07\n",
      "Epoch 50/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 282.9979 - output_x_loss: 292.8003 - output_y_loss: 301.8566 - output_z_loss: 225.6758 - output_x_msle: 292.8003 - output_y_msle: 301.8566 - output_z_msle: 225.6758 - val_loss: 286.7458 - val_output_x_loss: 295.8844 - val_output_y_loss: 305.5566 - val_output_z_loss: 230.8470 - val_output_x_msle: 295.8844 - val_output_y_msle: 305.5566 - val_output_z_msle: 230.8470 - lr: 1.0000e-07\n",
      "Epoch 51/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.8018 - output_x_loss: 292.6401 - output_y_loss: 301.8286 - output_z_loss: 225.0721 - output_x_msle: 292.6401 - output_y_msle: 301.8286 - output_z_msle: 225.0721 - val_loss: 286.5616 - val_output_x_loss: 295.5798 - val_output_y_loss: 305.5171 - val_output_z_loss: 230.6140 - val_output_x_msle: 295.5798 - val_output_y_msle: 305.5171 - val_output_z_msle: 230.6140 - lr: 1.0000e-07\n",
      "Epoch 52/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.6280 - output_x_loss: 292.4938 - output_y_loss: 301.8145 - output_z_loss: 224.5236 - output_x_msle: 292.4938 - output_y_msle: 301.8145 - output_z_msle: 224.5236 - val_loss: 286.3197 - val_output_x_loss: 295.2418 - val_output_y_loss: 305.4865 - val_output_z_loss: 230.1422 - val_output_x_msle: 295.2418 - val_output_y_msle: 305.4865 - val_output_z_msle: 230.1422 - lr: 1.0000e-07\n",
      "Epoch 53/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.3294 - output_x_loss: 292.0741 - output_y_loss: 301.7988 - output_z_loss: 223.9011 - output_x_msle: 292.0741 - output_y_msle: 301.7988 - output_z_msle: 223.9011 - val_loss: 286.1107 - val_output_x_loss: 295.0668 - val_output_y_loss: 305.4707 - val_output_z_loss: 229.4788 - val_output_x_msle: 295.0668 - val_output_y_msle: 305.4707 - val_output_z_msle: 229.4788 - lr: 1.0000e-07\n",
      "Epoch 54/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 282.0817 - output_x_loss: 291.8886 - output_y_loss: 301.8120 - output_z_loss: 223.0078 - output_x_msle: 291.8886 - output_y_msle: 301.8120 - output_z_msle: 223.0078 - val_loss: 285.9317 - val_output_x_loss: 294.9294 - val_output_y_loss: 305.4426 - val_output_z_loss: 228.9148 - val_output_x_msle: 294.9294 - val_output_y_msle: 305.4426 - val_output_z_msle: 228.9148 - lr: 1.0000e-07\n",
      "Epoch 55/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 281.8693 - output_x_loss: 291.7592 - output_y_loss: 301.7933 - output_z_loss: 222.2420 - output_x_msle: 291.7592 - output_y_msle: 301.7933 - output_z_msle: 222.2420 - val_loss: 285.5554 - val_output_x_loss: 294.7057 - val_output_y_loss: 305.3309 - val_output_z_loss: 227.7040 - val_output_x_msle: 294.7057 - val_output_y_msle: 305.3309 - val_output_z_msle: 227.7040 - lr: 1.0000e-07\n",
      "Epoch 56/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 281.5867 - output_x_loss: 291.6238 - output_y_loss: 301.7737 - output_z_loss: 221.1381 - output_x_msle: 291.6238 - output_y_msle: 301.7737 - output_z_msle: 221.1381 - val_loss: 285.4073 - val_output_x_loss: 294.5620 - val_output_y_loss: 305.3055 - val_output_z_loss: 227.3017 - val_output_x_msle: 294.5620 - val_output_y_msle: 305.3055 - val_output_z_msle: 227.3017 - lr: 1.0000e-07\n",
      "Epoch 57/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 281.3738 - output_x_loss: 291.4132 - output_y_loss: 301.8082 - output_z_loss: 220.4265 - output_x_msle: 291.4132 - output_y_msle: 301.8082 - output_z_msle: 220.4265 - val_loss: 285.1497 - val_output_x_loss: 294.3184 - val_output_y_loss: 305.2759 - val_output_z_loss: 226.5600 - val_output_x_msle: 294.3184 - val_output_y_msle: 305.2759 - val_output_z_msle: 226.5600 - lr: 1.0000e-07\n",
      "Epoch 58/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 281.1526 - output_x_loss: 291.2360 - output_y_loss: 301.7851 - output_z_loss: 219.7214 - output_x_msle: 291.2360 - output_y_msle: 301.7851 - output_z_msle: 219.7214 - val_loss: 285.0312 - val_output_x_loss: 294.2762 - val_output_y_loss: 305.2430 - val_output_z_loss: 226.1181 - val_output_x_msle: 294.2762 - val_output_y_msle: 305.2430 - val_output_z_msle: 226.1181 - lr: 1.0000e-07\n",
      "Epoch 59/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 280.9138 - output_x_loss: 291.0707 - output_y_loss: 301.7610 - output_z_loss: 218.9056 - output_x_msle: 291.0707 - output_y_msle: 301.7610 - output_z_msle: 218.9056 - val_loss: 284.7847 - val_output_x_loss: 294.0923 - val_output_y_loss: 305.1292 - val_output_z_loss: 225.4805 - val_output_x_msle: 294.0923 - val_output_y_msle: 305.1292 - val_output_z_msle: 225.4805 - lr: 1.0000e-07\n",
      "Epoch 60/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 280.6192 - output_x_loss: 290.8890 - output_y_loss: 301.7704 - output_z_loss: 217.7772 - output_x_msle: 290.8890 - output_y_msle: 301.7704 - output_z_msle: 217.7772 - val_loss: 284.4338 - val_output_x_loss: 293.8119 - val_output_y_loss: 305.2198 - val_output_z_loss: 224.1060 - val_output_x_msle: 293.8119 - val_output_y_msle: 305.2198 - val_output_z_msle: 224.1060 - lr: 1.0000e-07\n",
      "Epoch 61/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 280.3692 - output_x_loss: 290.6836 - output_y_loss: 301.7550 - output_z_loss: 216.9692 - output_x_msle: 290.6836 - output_y_msle: 301.7550 - output_z_msle: 216.9692 - val_loss: 284.1158 - val_output_x_loss: 293.6083 - val_output_y_loss: 305.2042 - val_output_z_loss: 222.9541 - val_output_x_msle: 293.6083 - val_output_y_msle: 305.2042 - val_output_z_msle: 222.9541 - lr: 1.0000e-07\n",
      "Epoch 62/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 280.2101 - output_x_loss: 290.5768 - output_y_loss: 301.7600 - output_z_loss: 216.3770 - output_x_msle: 290.5768 - output_y_msle: 301.7600 - output_z_msle: 216.3770 - val_loss: 283.8378 - val_output_x_loss: 293.3821 - val_output_y_loss: 305.1725 - val_output_z_loss: 222.0797 - val_output_x_msle: 293.3821 - val_output_y_msle: 305.1725 - val_output_z_msle: 222.0797 - lr: 1.0000e-07\n",
      "Epoch 63/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 280.0473 - output_x_loss: 290.3850 - output_y_loss: 301.8187 - output_z_loss: 215.8295 - output_x_msle: 290.3850 - output_y_msle: 301.8187 - output_z_msle: 215.8295 - val_loss: 283.7296 - val_output_x_loss: 293.2058 - val_output_y_loss: 305.3118 - val_output_z_loss: 221.6127 - val_output_x_msle: 293.2058 - val_output_y_msle: 305.3118 - val_output_z_msle: 221.6127 - lr: 1.0000e-07\n",
      "Epoch 64/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 279.8922 - output_x_loss: 290.1675 - output_y_loss: 301.8504 - output_z_loss: 215.4248 - output_x_msle: 290.1675 - output_y_msle: 301.8504 - output_z_msle: 215.4248 - val_loss: 283.5643 - val_output_x_loss: 293.0080 - val_output_y_loss: 305.2937 - val_output_z_loss: 221.2181 - val_output_x_msle: 293.0080 - val_output_y_msle: 305.2937 - val_output_z_msle: 221.2181 - lr: 1.0000e-07\n",
      "Epoch 65/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 279.6968 - output_x_loss: 289.9378 - output_y_loss: 301.8116 - output_z_loss: 214.9854 - output_x_msle: 289.9378 - output_y_msle: 301.8116 - output_z_msle: 214.9854 - val_loss: 283.3813 - val_output_x_loss: 292.7365 - val_output_y_loss: 305.2775 - val_output_z_loss: 220.8780 - val_output_x_msle: 292.7365 - val_output_y_msle: 305.2775 - val_output_z_msle: 220.8780 - lr: 1.0000e-07\n",
      "Epoch 66/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 279.4803 - output_x_loss: 289.6230 - output_y_loss: 301.8679 - output_z_loss: 214.4198 - output_x_msle: 289.6230 - output_y_msle: 301.8679 - output_z_msle: 214.4198 - val_loss: 282.9984 - val_output_x_loss: 292.1801 - val_output_y_loss: 305.2443 - val_output_z_loss: 220.1432 - val_output_x_msle: 292.1801 - val_output_y_msle: 305.2443 - val_output_z_msle: 220.1432 - lr: 1.0000e-07\n",
      "Epoch 67/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 279.2722 - output_x_loss: 289.3404 - output_y_loss: 301.9150 - output_z_loss: 213.8502 - output_x_msle: 289.3404 - output_y_msle: 301.9150 - output_z_msle: 213.8502 - val_loss: 282.7532 - val_output_x_loss: 291.9339 - val_output_y_loss: 305.3449 - val_output_z_loss: 219.2084 - val_output_x_msle: 291.9339 - val_output_y_msle: 305.3449 - val_output_z_msle: 219.2084 - lr: 1.0000e-07\n",
      "Epoch 68/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 279.0009 - output_x_loss: 289.0335 - output_y_loss: 301.9938 - output_z_loss: 212.9498 - output_x_msle: 289.0335 - output_y_msle: 301.9938 - output_z_msle: 212.9498 - val_loss: 282.5069 - val_output_x_loss: 291.4725 - val_output_y_loss: 305.5528 - val_output_z_loss: 218.4839 - val_output_x_msle: 291.4725 - val_output_y_msle: 305.5528 - val_output_z_msle: 218.4839 - lr: 1.0000e-07\n",
      "Epoch 69/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 278.7356 - output_x_loss: 288.6909 - output_y_loss: 302.0606 - output_z_loss: 212.1750 - output_x_msle: 288.6909 - output_y_msle: 302.0606 - output_z_msle: 212.1750 - val_loss: 282.1731 - val_output_x_loss: 291.1021 - val_output_y_loss: 305.6433 - val_output_z_loss: 217.3746 - val_output_x_msle: 291.1021 - val_output_y_msle: 305.6433 - val_output_z_msle: 217.3746 - lr: 1.0000e-07\n",
      "Epoch 70/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 278.4232 - output_x_loss: 288.3873 - output_y_loss: 302.0262 - output_z_loss: 211.2887 - output_x_msle: 288.3873 - output_y_msle: 302.0262 - output_z_msle: 211.2887 - val_loss: 281.8305 - val_output_x_loss: 290.9397 - val_output_y_loss: 305.6154 - val_output_z_loss: 216.0423 - val_output_x_msle: 290.9397 - val_output_y_msle: 305.6154 - val_output_z_msle: 216.0423 - lr: 1.0000e-07\n",
      "Epoch 71/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 278.1161 - output_x_loss: 288.0196 - output_y_loss: 302.1421 - output_z_loss: 210.2567 - output_x_msle: 288.0196 - output_y_msle: 302.1421 - output_z_msle: 210.2567 - val_loss: 281.6556 - val_output_x_loss: 290.7209 - val_output_y_loss: 305.6987 - val_output_z_loss: 215.4387 - val_output_x_msle: 290.7209 - val_output_y_msle: 305.6987 - val_output_z_msle: 215.4387 - lr: 1.0000e-07\n",
      "Epoch 72/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 277.9540 - output_x_loss: 287.8970 - output_y_loss: 302.1896 - output_z_loss: 209.5965 - output_x_msle: 287.8970 - output_y_msle: 302.1896 - output_z_msle: 209.5965 - val_loss: 281.3348 - val_output_x_loss: 290.1021 - val_output_y_loss: 305.7723 - val_output_z_loss: 214.9255 - val_output_x_msle: 290.1021 - val_output_y_msle: 305.7723 - val_output_z_msle: 214.9255 - lr: 1.0000e-07\n",
      "Epoch 73/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 277.7712 - output_x_loss: 287.5792 - output_y_loss: 302.2516 - output_z_loss: 209.1945 - output_x_msle: 287.5792 - output_y_msle: 302.2516 - output_z_msle: 209.1945 - val_loss: 281.1403 - val_output_x_loss: 289.6749 - val_output_y_loss: 305.8589 - val_output_z_loss: 214.6337 - val_output_x_msle: 289.6749 - val_output_y_msle: 305.8589 - val_output_z_msle: 214.6337 - lr: 1.0000e-07\n",
      "Epoch 74/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 277.4809 - output_x_loss: 287.2021 - output_y_loss: 302.2367 - output_z_loss: 208.5266 - output_x_msle: 287.2021 - output_y_msle: 302.2367 - output_z_msle: 208.5266 - val_loss: 280.8264 - val_output_x_loss: 289.4117 - val_output_y_loss: 305.8056 - val_output_z_loss: 213.6974 - val_output_x_msle: 289.4117 - val_output_y_msle: 305.8056 - val_output_z_msle: 213.6974 - lr: 1.0000e-07\n",
      "Epoch 75/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 277.0119 - output_x_loss: 286.4223 - output_y_loss: 302.2612 - output_z_loss: 207.6930 - output_x_msle: 286.4223 - output_y_msle: 302.2612 - output_z_msle: 207.6930 - val_loss: 280.5193 - val_output_x_loss: 288.9795 - val_output_y_loss: 305.7758 - val_output_z_loss: 213.0861 - val_output_x_msle: 288.9795 - val_output_y_msle: 305.7758 - val_output_z_msle: 213.0861 - lr: 1.0000e-07\n",
      "Epoch 76/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 276.6362 - output_x_loss: 285.8501 - output_y_loss: 302.3172 - output_z_loss: 206.8467 - output_x_msle: 285.8501 - output_y_msle: 302.3172 - output_z_msle: 206.8467 - val_loss: 279.6187 - val_output_x_loss: 287.2099 - val_output_y_loss: 305.8435 - val_output_z_loss: 211.9865 - val_output_x_msle: 287.2099 - val_output_y_msle: 305.8435 - val_output_z_msle: 211.9865 - lr: 1.0000e-07\n",
      "Epoch 77/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 276.1169 - output_x_loss: 285.2126 - output_y_loss: 302.3246 - output_z_loss: 205.5105 - output_x_msle: 285.2126 - output_y_msle: 302.3246 - output_z_msle: 205.5105 - val_loss: 279.1722 - val_output_x_loss: 286.7069 - val_output_y_loss: 305.7827 - val_output_z_loss: 210.8818 - val_output_x_msle: 286.7069 - val_output_y_msle: 305.7827 - val_output_z_msle: 210.8818 - lr: 1.0000e-07\n",
      "Epoch 78/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 275.8481 - output_x_loss: 284.9167 - output_y_loss: 302.3560 - output_z_loss: 204.6949 - output_x_msle: 284.9167 - output_y_msle: 302.3560 - output_z_msle: 204.6949 - val_loss: 278.6857 - val_output_x_loss: 286.1253 - val_output_y_loss: 305.7253 - val_output_z_loss: 209.7274 - val_output_x_msle: 286.1253 - val_output_y_msle: 305.7253 - val_output_z_msle: 209.7274 - lr: 1.0000e-07\n",
      "Epoch 79/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 275.5314 - output_x_loss: 284.5978 - output_y_loss: 302.3908 - output_z_loss: 203.6806 - output_x_msle: 284.5978 - output_y_msle: 302.3908 - output_z_msle: 203.6806 - val_loss: 278.3232 - val_output_x_loss: 285.7120 - val_output_y_loss: 305.6503 - val_output_z_loss: 208.8915 - val_output_x_msle: 285.7120 - val_output_y_msle: 305.6503 - val_output_z_msle: 208.8915 - lr: 1.0000e-07\n",
      "Epoch 80/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 275.1730 - output_x_loss: 284.2368 - output_y_loss: 302.4397 - output_z_loss: 202.5123 - output_x_msle: 284.2368 - output_y_msle: 302.4397 - output_z_msle: 202.5123 - val_loss: 277.9131 - val_output_x_loss: 285.2373 - val_output_y_loss: 305.7093 - val_output_z_loss: 207.6724 - val_output_x_msle: 285.2373 - val_output_y_msle: 305.7093 - val_output_z_msle: 207.6724 - lr: 1.0000e-07\n",
      "Epoch 81/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 274.8992 - output_x_loss: 283.8282 - output_y_loss: 302.7471 - output_z_loss: 201.3459 - output_x_msle: 283.8282 - output_y_msle: 302.7471 - output_z_msle: 201.3459 - val_loss: 277.4494 - val_output_x_loss: 284.8609 - val_output_y_loss: 305.5248 - val_output_z_loss: 206.4756 - val_output_x_msle: 284.8609 - val_output_y_msle: 305.5248 - val_output_z_msle: 206.4756 - lr: 1.0000e-07\n",
      "Epoch 82/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 274.3782 - output_x_loss: 283.3893 - output_y_loss: 302.8405 - output_z_loss: 199.4317 - output_x_msle: 283.3893 - output_y_msle: 302.8405 - output_z_msle: 199.4317 - val_loss: 276.8315 - val_output_x_loss: 284.2450 - val_output_y_loss: 305.8641 - val_output_z_loss: 203.9391 - val_output_x_msle: 284.2450 - val_output_y_msle: 305.8641 - val_output_z_msle: 203.9391 - lr: 1.0000e-07\n",
      "Epoch 83/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 273.8106 - output_x_loss: 282.7551 - output_y_loss: 303.0122 - output_z_loss: 197.5180 - output_x_msle: 282.7551 - output_y_msle: 303.0122 - output_z_msle: 197.5180 - val_loss: 276.4818 - val_output_x_loss: 283.7340 - val_output_y_loss: 305.9456 - val_output_z_loss: 203.0498 - val_output_x_msle: 283.7340 - val_output_y_msle: 305.9456 - val_output_z_msle: 203.0498 - lr: 1.0000e-07\n",
      "Epoch 84/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 273.4358 - output_x_loss: 282.2758 - output_y_loss: 302.9195 - output_z_loss: 196.7881 - output_x_msle: 282.2758 - output_y_msle: 302.9195 - output_z_msle: 196.7881 - val_loss: 276.2954 - val_output_x_loss: 283.3221 - val_output_y_loss: 306.1452 - val_output_z_loss: 202.5423 - val_output_x_msle: 283.3221 - val_output_y_msle: 306.1452 - val_output_z_msle: 202.5423 - lr: 1.0000e-07\n",
      "Epoch 85/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 273.1346 - output_x_loss: 282.0124 - output_y_loss: 302.8795 - output_z_loss: 195.8895 - output_x_msle: 282.0124 - output_y_msle: 302.8795 - output_z_msle: 195.8895 - val_loss: 276.0238 - val_output_x_loss: 283.0120 - val_output_y_loss: 306.1816 - val_output_z_loss: 201.7319 - val_output_x_msle: 283.0120 - val_output_y_msle: 306.1816 - val_output_z_msle: 201.7319 - lr: 1.0000e-07\n",
      "Epoch 86/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 272.6328 - output_x_loss: 281.3033 - output_y_loss: 302.7605 - output_z_loss: 195.0366 - output_x_msle: 281.3033 - output_y_msle: 302.7605 - output_z_msle: 195.0366 - val_loss: 275.6732 - val_output_x_loss: 282.4642 - val_output_y_loss: 306.2126 - val_output_z_loss: 201.0128 - val_output_x_msle: 282.4642 - val_output_y_msle: 306.2126 - val_output_z_msle: 201.0128 - lr: 1.0000e-07\n",
      "Epoch 87/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 272.1000 - output_x_loss: 280.5210 - output_y_loss: 302.5559 - output_z_loss: 194.3456 - output_x_msle: 280.5210 - output_y_msle: 302.5559 - output_z_msle: 194.3456 - val_loss: 275.2075 - val_output_x_loss: 281.5308 - val_output_y_loss: 306.2790 - val_output_z_loss: 200.4180 - val_output_x_msle: 281.5308 - val_output_y_msle: 306.2790 - val_output_z_msle: 200.4180 - lr: 1.0000e-07\n",
      "Epoch 88/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 271.4118 - output_x_loss: 279.4673 - output_y_loss: 302.4213 - output_z_loss: 193.2825 - output_x_msle: 279.4673 - output_y_msle: 302.4213 - output_z_msle: 193.2825 - val_loss: 274.4884 - val_output_x_loss: 280.8154 - val_output_y_loss: 305.9991 - val_output_z_loss: 198.8130 - val_output_x_msle: 280.8154 - val_output_y_msle: 305.9991 - val_output_z_msle: 198.8130 - lr: 1.0000e-07\n",
      "Epoch 89/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 270.6769 - output_x_loss: 278.7126 - output_y_loss: 302.3011 - output_z_loss: 191.3573 - output_x_msle: 278.7126 - output_y_msle: 302.3011 - output_z_msle: 191.3573 - val_loss: 273.4667 - val_output_x_loss: 279.8510 - val_output_y_loss: 305.9085 - val_output_z_loss: 195.8143 - val_output_x_msle: 279.8510 - val_output_y_msle: 305.9085 - val_output_z_msle: 195.8143 - lr: 1.0000e-07\n",
      "Epoch 90/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 269.7400 - output_x_loss: 277.7614 - output_y_loss: 302.0334 - output_z_loss: 189.1096 - output_x_msle: 277.7614 - output_y_msle: 302.0334 - output_z_msle: 189.1096 - val_loss: 272.6341 - val_output_x_loss: 278.4780 - val_output_y_loss: 305.7356 - val_output_z_loss: 194.7429 - val_output_x_msle: 278.4780 - val_output_y_msle: 305.7356 - val_output_z_msle: 194.7429 - lr: 1.0000e-07\n",
      "Epoch 91/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 268.6542 - output_x_loss: 275.6104 - output_y_loss: 301.9499 - output_z_loss: 188.1505 - output_x_msle: 275.6104 - output_y_msle: 301.9499 - output_z_msle: 188.1505 - val_loss: 271.7841 - val_output_x_loss: 276.7658 - val_output_y_loss: 305.7162 - val_output_z_loss: 193.9566 - val_output_x_msle: 276.7658 - val_output_y_msle: 305.7162 - val_output_z_msle: 193.9566 - lr: 1.0000e-07\n",
      "Epoch 92/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 267.2941 - output_x_loss: 272.8932 - output_y_loss: 301.7887 - output_z_loss: 187.1070 - output_x_msle: 272.8932 - output_y_msle: 301.7887 - output_z_msle: 187.1070 - val_loss: 270.4604 - val_output_x_loss: 273.9371 - val_output_y_loss: 305.8575 - val_output_z_loss: 192.7127 - val_output_x_msle: 273.9371 - val_output_y_msle: 305.8575 - val_output_z_msle: 192.7127 - lr: 1.0000e-07\n",
      "Epoch 93/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 266.1560 - output_x_loss: 271.1078 - output_y_loss: 301.4686 - output_z_loss: 185.6271 - output_x_msle: 271.1078 - output_y_msle: 301.4686 - output_z_msle: 185.6271 - val_loss: 268.5137 - val_output_x_loss: 270.8611 - val_output_y_loss: 305.2773 - val_output_z_loss: 190.2915 - val_output_x_msle: 270.8611 - val_output_y_msle: 305.2773 - val_output_z_msle: 190.2915 - lr: 1.0000e-07\n",
      "Epoch 94/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 264.6472 - output_x_loss: 268.5503 - output_y_loss: 301.1927 - output_z_loss: 183.7499 - output_x_msle: 268.5503 - output_y_msle: 301.1927 - output_z_msle: 183.7499 - val_loss: 267.1441 - val_output_x_loss: 268.1165 - val_output_y_loss: 304.9214 - val_output_z_loss: 189.6448 - val_output_x_msle: 268.1165 - val_output_y_msle: 304.9214 - val_output_z_msle: 189.6448 - lr: 1.0000e-07\n",
      "Epoch 95/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 262.6519 - output_x_loss: 264.2191 - output_y_loss: 300.7653 - output_z_loss: 183.2908 - output_x_msle: 264.2191 - output_y_msle: 300.7653 - output_z_msle: 183.2908 - val_loss: 264.0748 - val_output_x_loss: 261.1274 - val_output_y_loss: 304.3340 - val_output_z_loss: 189.4511 - val_output_x_msle: 261.1274 - val_output_y_msle: 304.3340 - val_output_z_msle: 189.4511 - lr: 1.0000e-07\n",
      "Epoch 96/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 259.1065 - output_x_loss: 256.0344 - output_y_loss: 300.1802 - output_z_loss: 183.1040 - output_x_msle: 256.0344 - output_y_msle: 300.1802 - output_z_msle: 183.1040 - val_loss: 261.3805 - val_output_x_loss: 255.2254 - val_output_y_loss: 303.5283 - val_output_z_loss: 189.3949 - val_output_x_msle: 255.2254 - val_output_y_msle: 303.5283 - val_output_z_msle: 189.3949 - lr: 1.0000e-07\n",
      "Epoch 97/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 257.2437 - output_x_loss: 252.1970 - output_y_loss: 299.4237 - output_z_loss: 182.9766 - output_x_msle: 252.1970 - output_y_msle: 299.4237 - output_z_msle: 182.9766 - val_loss: 259.4648 - val_output_x_loss: 251.3751 - val_output_y_loss: 302.6326 - val_output_z_loss: 189.3085 - val_output_x_msle: 251.3751 - val_output_y_msle: 302.6326 - val_output_z_msle: 189.3085 - lr: 1.0000e-07\n",
      "Epoch 98/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 255.6396 - output_x_loss: 248.8222 - output_y_loss: 298.8576 - output_z_loss: 182.8386 - output_x_msle: 248.8222 - output_y_msle: 298.8576 - output_z_msle: 182.8386 - val_loss: 257.8068 - val_output_x_loss: 247.7593 - val_output_y_loss: 302.2322 - val_output_z_loss: 189.0513 - val_output_x_msle: 247.7593 - val_output_y_msle: 302.2322 - val_output_z_msle: 189.0513 - lr: 1.0000e-07\n",
      "Epoch 99/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 254.5692 - output_x_loss: 246.3561 - output_y_loss: 298.7215 - output_z_loss: 182.6899 - output_x_msle: 246.3561 - output_y_msle: 298.7215 - output_z_msle: 182.6899 - val_loss: 256.7081 - val_output_x_loss: 245.2798 - val_output_y_loss: 302.0662 - val_output_z_loss: 188.8486 - val_output_x_msle: 245.2798 - val_output_y_msle: 302.0662 - val_output_z_msle: 188.8486 - lr: 1.0000e-07\n",
      "Epoch 100/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 253.5890 - output_x_loss: 244.1654 - output_y_loss: 298.5897 - output_z_loss: 182.4345 - output_x_msle: 244.1654 - output_y_msle: 298.5897 - output_z_msle: 182.4345 - val_loss: 255.7627 - val_output_x_loss: 243.1907 - val_output_y_loss: 301.9223 - val_output_z_loss: 188.5872 - val_output_x_msle: 243.1907 - val_output_y_msle: 301.9223 - val_output_z_msle: 188.5872 - lr: 1.0000e-07\n",
      "Epoch 101/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 251.9326 - output_x_loss: 240.2203 - output_y_loss: 298.4659 - output_z_loss: 182.2902 - output_x_msle: 240.2203 - output_y_msle: 298.4659 - output_z_msle: 182.2902 - val_loss: 254.2206 - val_output_x_loss: 239.3478 - val_output_y_loss: 301.9977 - val_output_z_loss: 188.4118 - val_output_x_msle: 239.3478 - val_output_y_msle: 301.9977 - val_output_z_msle: 188.4118 - lr: 1.0000e-07\n",
      "Epoch 102/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 250.9538 - output_x_loss: 238.0626 - output_y_loss: 298.2894 - output_z_loss: 182.0652 - output_x_msle: 238.0626 - output_y_msle: 298.2894 - output_z_msle: 182.0652 - val_loss: 253.6054 - val_output_x_loss: 238.1860 - val_output_y_loss: 301.7598 - val_output_z_loss: 188.1358 - val_output_x_msle: 238.1860 - val_output_y_msle: 301.7598 - val_output_z_msle: 188.1358 - lr: 1.0000e-07\n",
      "Epoch 103/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 250.2813 - output_x_loss: 236.6497 - output_y_loss: 298.1291 - output_z_loss: 181.8485 - output_x_msle: 236.6497 - output_y_msle: 298.1291 - output_z_msle: 181.8485 - val_loss: 253.0617 - val_output_x_loss: 237.0827 - val_output_y_loss: 301.5797 - val_output_z_loss: 187.9834 - val_output_x_msle: 237.0827 - val_output_y_msle: 301.5797 - val_output_z_msle: 187.9834 - lr: 1.0000e-07\n",
      "Epoch 104/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 249.5648 - output_x_loss: 235.1096 - output_y_loss: 298.0859 - output_z_loss: 181.4334 - output_x_msle: 235.1096 - output_y_msle: 298.0859 - output_z_msle: 181.4334 - val_loss: 252.1947 - val_output_x_loss: 235.5590 - val_output_y_loss: 301.2520 - val_output_z_loss: 187.3514 - val_output_x_msle: 235.5590 - val_output_y_msle: 301.2520 - val_output_z_msle: 187.3514 - lr: 1.0000e-07\n",
      "Epoch 105/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 248.7055 - output_x_loss: 233.4582 - output_y_loss: 297.9016 - output_z_loss: 180.8078 - output_x_msle: 233.4582 - output_y_msle: 297.9016 - output_z_msle: 180.8078 - val_loss: 251.5000 - val_output_x_loss: 234.0130 - val_output_y_loss: 301.1820 - val_output_z_loss: 187.1099 - val_output_x_msle: 234.0130 - val_output_y_msle: 301.1820 - val_output_z_msle: 187.1099 - lr: 1.0000e-07\n",
      "Epoch 106/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 247.8122 - output_x_loss: 231.5204 - output_y_loss: 297.7798 - output_z_loss: 180.4607 - output_x_msle: 231.5204 - output_y_msle: 297.7798 - output_z_msle: 180.4607 - val_loss: 250.4789 - val_output_x_loss: 231.8068 - val_output_y_loss: 301.0113 - val_output_z_loss: 186.7583 - val_output_x_msle: 231.8068 - val_output_y_msle: 301.0113 - val_output_z_msle: 186.7583 - lr: 1.0000e-07\n",
      "Epoch 107/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 246.8062 - output_x_loss: 229.3125 - output_y_loss: 297.6935 - output_z_loss: 180.0187 - output_x_msle: 229.3125 - output_y_msle: 297.6935 - output_z_msle: 180.0187 - val_loss: 249.0114 - val_output_x_loss: 228.4818 - val_output_y_loss: 300.8326 - val_output_z_loss: 186.4280 - val_output_x_msle: 228.4818 - val_output_y_msle: 300.8326 - val_output_z_msle: 186.4280 - lr: 1.0000e-07\n",
      "Epoch 108/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 244.8111 - output_x_loss: 224.6366 - output_y_loss: 297.5946 - output_z_loss: 179.5930 - output_x_msle: 224.6366 - output_y_msle: 297.5946 - output_z_msle: 179.5930 - val_loss: 246.7014 - val_output_x_loss: 223.1248 - val_output_y_loss: 300.6716 - val_output_z_loss: 185.9142 - val_output_x_msle: 223.1248 - val_output_y_msle: 300.6716 - val_output_z_msle: 185.9142 - lr: 1.0000e-07\n",
      "Epoch 109/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 242.9638 - output_x_loss: 220.4470 - output_y_loss: 297.3880 - output_z_loss: 179.1485 - output_x_msle: 220.4470 - output_y_msle: 297.3880 - output_z_msle: 179.1485 - val_loss: 245.3337 - val_output_x_loss: 220.1369 - val_output_y_loss: 300.5064 - val_output_z_loss: 185.3819 - val_output_x_msle: 220.1369 - val_output_y_msle: 300.5064 - val_output_z_msle: 185.3819 - lr: 1.0000e-07\n",
      "Epoch 110/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 241.2135 - output_x_loss: 216.5404 - output_y_loss: 297.2632 - output_z_loss: 178.4597 - output_x_msle: 216.5404 - output_y_msle: 297.2632 - output_z_msle: 178.4597 - val_loss: 243.2228 - val_output_x_loss: 215.2138 - val_output_y_loss: 300.4223 - val_output_z_loss: 184.8419 - val_output_x_msle: 215.2138 - val_output_y_msle: 300.4223 - val_output_z_msle: 184.8419 - lr: 1.0000e-07\n",
      "Epoch 111/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 238.6420 - output_x_loss: 210.6742 - output_y_loss: 296.9468 - output_z_loss: 177.9685 - output_x_msle: 210.6742 - output_y_msle: 296.9468 - output_z_msle: 177.9685 - val_loss: 241.0580 - val_output_x_loss: 210.1620 - val_output_y_loss: 300.1567 - val_output_z_loss: 184.6523 - val_output_x_msle: 210.1620 - val_output_y_msle: 300.1567 - val_output_z_msle: 184.6523 - lr: 1.0000e-07\n",
      "Epoch 112/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 237.1966 - output_x_loss: 207.3603 - output_y_loss: 296.7291 - output_z_loss: 177.8042 - output_x_msle: 207.3603 - output_y_msle: 296.7291 - output_z_msle: 177.8042 - val_loss: 239.8670 - val_output_x_loss: 207.4187 - val_output_y_loss: 299.9760 - val_output_z_loss: 184.5456 - val_output_x_msle: 207.4187 - val_output_y_msle: 299.9760 - val_output_z_msle: 184.5456 - lr: 1.0000e-07\n",
      "Epoch 113/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 235.8876 - output_x_loss: 204.4627 - output_y_loss: 296.4352 - output_z_loss: 177.6423 - output_x_msle: 204.4627 - output_y_msle: 296.4352 - output_z_msle: 177.6423 - val_loss: 238.2520 - val_output_x_loss: 204.1057 - val_output_y_loss: 299.4577 - val_output_z_loss: 184.1333 - val_output_x_msle: 204.1057 - val_output_y_msle: 299.4577 - val_output_z_msle: 184.1333 - lr: 1.0000e-07\n",
      "Epoch 114/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 234.6368 - output_x_loss: 201.6548 - output_y_loss: 296.2553 - output_z_loss: 177.3632 - output_x_msle: 201.6548 - output_y_msle: 296.2553 - output_z_msle: 177.3632 - val_loss: 236.7032 - val_output_x_loss: 200.5176 - val_output_y_loss: 299.3035 - val_output_z_loss: 183.8740 - val_output_x_msle: 200.5176 - val_output_y_msle: 299.3035 - val_output_z_msle: 183.8740 - lr: 1.0000e-07\n",
      "Epoch 115/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 232.8079 - output_x_loss: 197.5865 - output_y_loss: 295.9799 - output_z_loss: 176.9063 - output_x_msle: 197.5865 - output_y_msle: 295.9799 - output_z_msle: 176.9063 - val_loss: 235.0555 - val_output_x_loss: 197.0090 - val_output_y_loss: 298.9882 - val_output_z_loss: 183.2827 - val_output_x_msle: 197.0090 - val_output_y_msle: 298.9882 - val_output_z_msle: 183.2827 - lr: 1.0000e-07\n",
      "Epoch 116/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 230.7182 - output_x_loss: 192.7478 - output_y_loss: 295.7923 - output_z_loss: 176.5106 - output_x_msle: 192.7478 - output_y_msle: 295.7923 - output_z_msle: 176.5106 - val_loss: 232.4810 - val_output_x_loss: 190.9824 - val_output_y_loss: 298.8197 - val_output_z_loss: 182.8009 - val_output_x_msle: 190.9824 - val_output_y_msle: 298.8197 - val_output_z_msle: 182.8009 - lr: 1.0000e-07\n",
      "Epoch 117/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 226.6018 - output_x_loss: 182.6957 - output_y_loss: 295.7047 - output_z_loss: 176.2082 - output_x_msle: 182.6957 - output_y_msle: 295.7047 - output_z_msle: 176.2082 - val_loss: 227.3784 - val_output_x_loss: 178.5809 - val_output_y_loss: 298.5793 - val_output_z_loss: 182.5720 - val_output_x_msle: 178.5809 - val_output_y_msle: 298.5793 - val_output_z_msle: 182.5720 - lr: 1.0000e-07\n",
      "Epoch 118/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 223.3726 - output_x_loss: 174.8489 - output_y_loss: 295.5569 - output_z_loss: 176.0503 - output_x_msle: 174.8489 - output_y_msle: 295.5569 - output_z_msle: 176.0503 - val_loss: 224.4730 - val_output_x_loss: 171.4890 - val_output_y_loss: 298.5135 - val_output_z_loss: 182.3598 - val_output_x_msle: 171.4890 - val_output_y_msle: 298.5135 - val_output_z_msle: 182.3598 - lr: 1.0000e-07\n",
      "Epoch 119/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 220.0248 - output_x_loss: 166.7241 - output_y_loss: 295.4233 - output_z_loss: 175.8296 - output_x_msle: 166.7241 - output_y_msle: 295.4233 - output_z_msle: 175.8296 - val_loss: 220.0003 - val_output_x_loss: 160.5306 - val_output_y_loss: 298.4437 - val_output_z_loss: 182.0528 - val_output_x_msle: 160.5306 - val_output_y_msle: 298.4437 - val_output_z_msle: 182.0528 - lr: 1.0000e-07\n",
      "Epoch 120/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 214.8720 - output_x_loss: 153.9979 - output_y_loss: 295.3251 - output_z_loss: 175.7139 - output_x_msle: 153.9979 - output_y_msle: 295.3251 - output_z_msle: 175.7139 - val_loss: 216.2478 - val_output_x_loss: 151.4278 - val_output_y_loss: 298.3491 - val_output_z_loss: 181.6850 - val_output_x_msle: 151.4278 - val_output_y_msle: 298.3491 - val_output_z_msle: 181.6850 - lr: 1.0000e-07\n",
      "Epoch 121/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 211.5983 - output_x_loss: 146.0787 - output_y_loss: 295.1866 - output_z_loss: 175.4609 - output_x_msle: 146.0787 - output_y_msle: 295.1866 - output_z_msle: 175.4609 - val_loss: 213.5776 - val_output_x_loss: 145.2242 - val_output_y_loss: 298.1667 - val_output_z_loss: 181.1062 - val_output_x_msle: 145.2242 - val_output_y_msle: 298.1667 - val_output_z_msle: 181.1062 - lr: 1.0000e-07\n",
      "Epoch 122/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 208.8730 - output_x_loss: 139.6704 - output_y_loss: 294.9115 - output_z_loss: 175.2012 - output_x_msle: 139.6704 - output_y_msle: 294.9115 - output_z_msle: 175.2012 - val_loss: 210.4501 - val_output_x_loss: 137.8500 - val_output_y_loss: 297.8415 - val_output_z_loss: 180.8678 - val_output_x_msle: 137.8500 - val_output_y_msle: 297.8415 - val_output_z_msle: 180.8678 - lr: 1.0000e-07\n",
      "Epoch 123/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 206.3552 - output_x_loss: 133.9353 - output_y_loss: 294.4742 - output_z_loss: 174.9573 - output_x_msle: 133.9353 - output_y_msle: 294.4742 - output_z_msle: 174.9573 - val_loss: 208.6066 - val_output_x_loss: 133.7865 - val_output_y_loss: 297.3734 - val_output_z_loss: 180.7130 - val_output_x_msle: 133.7865 - val_output_y_msle: 297.3734 - val_output_z_msle: 180.7130 - lr: 1.0000e-07\n",
      "Epoch 124/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 204.8201 - output_x_loss: 130.5950 - output_y_loss: 294.1861 - output_z_loss: 174.5388 - output_x_msle: 130.5950 - output_y_msle: 294.1861 - output_z_msle: 174.5388 - val_loss: 206.6749 - val_output_x_loss: 129.5067 - val_output_y_loss: 296.8871 - val_output_z_loss: 180.5867 - val_output_x_msle: 129.5067 - val_output_y_msle: 296.8871 - val_output_z_msle: 180.5867 - lr: 1.0000e-07\n",
      "Epoch 125/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 202.2906 - output_x_loss: 125.2085 - output_y_loss: 293.6615 - output_z_loss: 173.7133 - output_x_msle: 125.2085 - output_y_msle: 293.6615 - output_z_msle: 173.7133 - val_loss: 203.8642 - val_output_x_loss: 123.1510 - val_output_y_loss: 296.5466 - val_output_z_loss: 179.9261 - val_output_x_msle: 123.1510 - val_output_y_msle: 296.5466 - val_output_z_msle: 179.9261 - lr: 1.0000e-07\n",
      "Epoch 126/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 198.9194 - output_x_loss: 117.9917 - output_y_loss: 292.7686 - output_z_loss: 173.0765 - output_x_msle: 117.9917 - output_y_msle: 292.7686 - output_z_msle: 173.0765 - val_loss: 201.1350 - val_output_x_loss: 117.6412 - val_output_y_loss: 295.4638 - val_output_z_loss: 179.4651 - val_output_x_msle: 117.6412 - val_output_y_msle: 295.4638 - val_output_z_msle: 179.4651 - lr: 1.0000e-07\n",
      "Epoch 127/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 196.2347 - output_x_loss: 111.8603 - output_y_loss: 292.3280 - output_z_loss: 172.7964 - output_x_msle: 111.8603 - output_y_msle: 292.3280 - output_z_msle: 172.7964 - val_loss: 197.8248 - val_output_x_loss: 109.5999 - val_output_y_loss: 295.3586 - val_output_z_loss: 179.2073 - val_output_x_msle: 109.5999 - val_output_y_msle: 295.3586 - val_output_z_msle: 179.2073 - lr: 1.0000e-07\n",
      "Epoch 128/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 193.7723 - output_x_loss: 106.1423 - output_y_loss: 291.9957 - output_z_loss: 172.5853 - output_x_msle: 106.1423 - output_y_msle: 291.9957 - output_z_msle: 172.5853 - val_loss: 196.7809 - val_output_x_loss: 107.4344 - val_output_y_loss: 295.0665 - val_output_z_loss: 178.9029 - val_output_x_msle: 107.4344 - val_output_y_msle: 295.0665 - val_output_z_msle: 178.9029 - lr: 1.0000e-07\n",
      "Epoch 129/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 192.2085 - output_x_loss: 102.6437 - output_y_loss: 291.7188 - output_z_loss: 172.3177 - output_x_msle: 102.6437 - output_y_msle: 291.7188 - output_z_msle: 172.3177 - val_loss: 195.2841 - val_output_x_loss: 103.9514 - val_output_y_loss: 294.8880 - val_output_z_loss: 178.7415 - val_output_x_msle: 103.9514 - val_output_y_msle: 294.8880 - val_output_z_msle: 178.7415 - lr: 1.0000e-07\n",
      "Epoch 130/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 190.2592 - output_x_loss: 98.1379 - output_y_loss: 291.5380 - output_z_loss: 171.9447 - output_x_msle: 98.1379 - output_y_msle: 291.5380 - output_z_msle: 171.9447 - val_loss: 193.0153 - val_output_x_loss: 98.6571 - val_output_y_loss: 294.7846 - val_output_z_loss: 178.1929 - val_output_x_msle: 98.6571 - val_output_y_msle: 294.7846 - val_output_z_msle: 178.1929 - lr: 1.0000e-07\n",
      "Epoch 131/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 187.3771 - output_x_loss: 91.2104 - output_y_loss: 291.4348 - output_z_loss: 171.5951 - output_x_msle: 91.2104 - output_y_msle: 291.4348 - output_z_msle: 171.5951 - val_loss: 191.0998 - val_output_x_loss: 94.1301 - val_output_y_loss: 294.6150 - val_output_z_loss: 178.0085 - val_output_x_msle: 94.1301 - val_output_y_msle: 294.6150 - val_output_z_msle: 178.0085 - lr: 1.0000e-07\n",
      "Epoch 132/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 186.5894 - output_x_loss: 89.5356 - output_y_loss: 291.2334 - output_z_loss: 171.4087 - output_x_msle: 89.5356 - output_y_msle: 291.2334 - output_z_msle: 171.4087 - val_loss: 190.4847 - val_output_x_loss: 93.1186 - val_output_y_loss: 294.3918 - val_output_z_loss: 177.4030 - val_output_x_msle: 93.1186 - val_output_y_msle: 294.3918 - val_output_z_msle: 177.4030 - lr: 1.0000e-07\n",
      "Epoch 133/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 186.0756 - output_x_loss: 88.4642 - output_y_loss: 291.1407 - output_z_loss: 171.1685 - output_x_msle: 88.4642 - output_y_msle: 291.1407 - output_z_msle: 171.1685 - val_loss: 189.7079 - val_output_x_loss: 91.3603 - val_output_y_loss: 294.3007 - val_output_z_loss: 177.2174 - val_output_x_msle: 91.3603 - val_output_y_msle: 294.3007 - val_output_z_msle: 177.2174 - lr: 1.0000e-07\n",
      "Epoch 134/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 185.3594 - output_x_loss: 86.9304 - output_y_loss: 290.9708 - output_z_loss: 170.9943 - output_x_msle: 86.9304 - output_y_msle: 290.9708 - output_z_msle: 170.9943 - val_loss: 189.1311 - val_output_x_loss: 90.1848 - val_output_y_loss: 294.1361 - val_output_z_loss: 177.0136 - val_output_x_msle: 90.1848 - val_output_y_msle: 294.1361 - val_output_z_msle: 177.0136 - lr: 1.0000e-07\n",
      "Epoch 135/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 184.5316 - output_x_loss: 85.0286 - output_y_loss: 290.8857 - output_z_loss: 170.8290 - output_x_msle: 85.0286 - output_y_msle: 290.8857 - output_z_msle: 170.8290 - val_loss: 188.2336 - val_output_x_loss: 88.1321 - val_output_y_loss: 294.0307 - val_output_z_loss: 176.8424 - val_output_x_msle: 88.1321 - val_output_y_msle: 294.0307 - val_output_z_msle: 176.8424 - lr: 1.0000e-07\n",
      "Epoch 136/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 183.4859 - output_x_loss: 82.6877 - output_y_loss: 290.7129 - output_z_loss: 170.6286 - output_x_msle: 82.6877 - output_y_msle: 290.7129 - output_z_msle: 170.6286 - val_loss: 187.3194 - val_output_x_loss: 86.0575 - val_output_y_loss: 293.9247 - val_output_z_loss: 176.6328 - val_output_x_msle: 86.0575 - val_output_y_msle: 293.9247 - val_output_z_msle: 176.6328 - lr: 1.0000e-07\n",
      "Epoch 137/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 182.6516 - output_x_loss: 80.8370 - output_y_loss: 290.6273 - output_z_loss: 170.3293 - output_x_msle: 80.8370 - output_y_msle: 290.6273 - output_z_msle: 170.3293 - val_loss: 185.7791 - val_output_x_loss: 82.5674 - val_output_y_loss: 293.6131 - val_output_z_loss: 176.5343 - val_output_x_msle: 82.5674 - val_output_y_msle: 293.6131 - val_output_z_msle: 176.5343 - lr: 1.0000e-07\n",
      "Epoch 138/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 180.9686 - output_x_loss: 76.9135 - output_y_loss: 290.4782 - output_z_loss: 170.0597 - output_x_msle: 76.9135 - output_y_msle: 290.4782 - output_z_msle: 170.0597 - val_loss: 184.4077 - val_output_x_loss: 79.4490 - val_output_y_loss: 293.4006 - val_output_z_loss: 176.3397 - val_output_x_msle: 79.4490 - val_output_y_msle: 293.4006 - val_output_z_msle: 176.3397 - lr: 1.0000e-07\n",
      "Epoch 139/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 180.1424 - output_x_loss: 75.2344 - output_y_loss: 290.3490 - output_z_loss: 169.5448 - output_x_msle: 75.2344 - output_y_msle: 290.3490 - output_z_msle: 169.5448 - val_loss: 183.8826 - val_output_x_loss: 78.4521 - val_output_y_loss: 293.3451 - val_output_z_loss: 175.8186 - val_output_x_msle: 78.4521 - val_output_y_msle: 293.3451 - val_output_z_msle: 175.8186 - lr: 1.0000e-07\n",
      "Epoch 140/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 179.0698 - output_x_loss: 72.8347 - output_y_loss: 290.1823 - output_z_loss: 169.3150 - output_x_msle: 72.8347 - output_y_msle: 290.1823 - output_z_msle: 169.3150 - val_loss: 182.4756 - val_output_x_loss: 75.0855 - val_output_y_loss: 293.2255 - val_output_z_loss: 175.7561 - val_output_x_msle: 75.0855 - val_output_y_msle: 293.2255 - val_output_z_msle: 175.7561 - lr: 1.0000e-07\n",
      "Epoch 141/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 178.3252 - output_x_loss: 71.1504 - output_y_loss: 290.0468 - output_z_loss: 169.2315 - output_x_msle: 71.1504 - output_y_msle: 290.0468 - output_z_msle: 169.2315 - val_loss: 181.4350 - val_output_x_loss: 72.8427 - val_output_y_loss: 293.0054 - val_output_z_loss: 175.4788 - val_output_x_msle: 72.8427 - val_output_y_msle: 293.0054 - val_output_z_msle: 175.4788 - lr: 1.0000e-07\n",
      "Epoch 142/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 177.2290 - output_x_loss: 68.7734 - output_y_loss: 289.7487 - output_z_loss: 169.1006 - output_x_msle: 68.7734 - output_y_msle: 289.7487 - output_z_msle: 169.1006 - val_loss: 179.9195 - val_output_x_loss: 70.0804 - val_output_y_loss: 292.0511 - val_output_z_loss: 175.3345 - val_output_x_msle: 70.0804 - val_output_y_msle: 292.0511 - val_output_z_msle: 175.3345 - lr: 1.0000e-07\n",
      "Epoch 143/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 175.4836 - output_x_loss: 65.8569 - output_y_loss: 288.3322 - output_z_loss: 169.0397 - output_x_msle: 65.8569 - output_y_msle: 288.3322 - output_z_msle: 169.0397 - val_loss: 179.1373 - val_output_x_loss: 69.1911 - val_output_y_loss: 291.0913 - val_output_z_loss: 175.1216 - val_output_x_msle: 69.1911 - val_output_y_msle: 291.0913 - val_output_z_msle: 175.1216 - lr: 1.0000e-07\n",
      "Epoch 144/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 174.9818 - output_x_loss: 65.2865 - output_y_loss: 287.7291 - output_z_loss: 168.8778 - output_x_msle: 65.2865 - output_y_msle: 287.7291 - output_z_msle: 168.8778 - val_loss: 178.6051 - val_output_x_loss: 68.3392 - val_output_y_loss: 290.7209 - val_output_z_loss: 174.9055 - val_output_x_msle: 68.3392 - val_output_y_msle: 290.7209 - val_output_z_msle: 174.9055 - lr: 1.0000e-07\n",
      "Epoch 145/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 174.5392 - output_x_loss: 64.8690 - output_y_loss: 287.1317 - output_z_loss: 168.6948 - output_x_msle: 64.8690 - output_y_msle: 287.1317 - output_z_msle: 168.6948 - val_loss: 178.1375 - val_output_x_loss: 67.8111 - val_output_y_loss: 290.2360 - val_output_z_loss: 174.5932 - val_output_x_msle: 67.8111 - val_output_y_msle: 290.2360 - val_output_z_msle: 174.5932 - lr: 1.0000e-07\n",
      "Epoch 146/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 174.2256 - output_x_loss: 64.6323 - output_y_loss: 286.6870 - output_z_loss: 168.4894 - output_x_msle: 64.6323 - output_y_msle: 286.6870 - output_z_msle: 168.4894 - val_loss: 177.7340 - val_output_x_loss: 67.4155 - val_output_y_loss: 289.7961 - val_output_z_loss: 174.2470 - val_output_x_msle: 67.4155 - val_output_y_msle: 289.7961 - val_output_z_msle: 174.2470 - lr: 1.0000e-07\n",
      "Epoch 147/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 173.8646 - output_x_loss: 64.1502 - output_y_loss: 286.3694 - output_z_loss: 168.2839 - output_x_msle: 64.1502 - output_y_msle: 286.3694 - output_z_msle: 168.2839 - val_loss: 177.2840 - val_output_x_loss: 66.8627 - val_output_y_loss: 289.3418 - val_output_z_loss: 174.0108 - val_output_x_msle: 66.8627 - val_output_y_msle: 289.3418 - val_output_z_msle: 174.0108 - lr: 1.0000e-07\n",
      "Epoch 148/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 173.5878 - output_x_loss: 64.0308 - output_y_loss: 285.9294 - output_z_loss: 168.0188 - output_x_msle: 64.0308 - output_y_msle: 285.9294 - output_z_msle: 168.0188 - val_loss: 177.0099 - val_output_x_loss: 66.6493 - val_output_y_loss: 288.9956 - val_output_z_loss: 173.7594 - val_output_x_msle: 66.6493 - val_output_y_msle: 288.9956 - val_output_z_msle: 173.7594 - lr: 1.0000e-07\n",
      "Epoch 149/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 173.1681 - output_x_loss: 63.6115 - output_y_loss: 285.4445 - output_z_loss: 167.7283 - output_x_msle: 63.6115 - output_y_msle: 285.4445 - output_z_msle: 167.7283 - val_loss: 176.5479 - val_output_x_loss: 66.4837 - val_output_y_loss: 288.1382 - val_output_z_loss: 173.4955 - val_output_x_msle: 66.4837 - val_output_y_msle: 288.1382 - val_output_z_msle: 173.4955 - lr: 1.0000e-07\n",
      "Epoch 150/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 172.7077 - output_x_loss: 63.4902 - output_y_loss: 284.5422 - output_z_loss: 167.4739 - output_x_msle: 63.4902 - output_y_msle: 284.5422 - output_z_msle: 167.4739 - val_loss: 176.0807 - val_output_x_loss: 66.4987 - val_output_y_loss: 287.1024 - val_output_z_loss: 173.2009 - val_output_x_msle: 66.4987 - val_output_y_msle: 287.1024 - val_output_z_msle: 173.2009 - lr: 1.0000e-07\n",
      "Epoch 151/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 172.1665 - output_x_loss: 63.3491 - output_y_loss: 283.4864 - output_z_loss: 167.1614 - output_x_msle: 63.3491 - output_y_msle: 283.4864 - output_z_msle: 167.1614 - val_loss: 175.5455 - val_output_x_loss: 66.1056 - val_output_y_loss: 286.4092 - val_output_z_loss: 172.6980 - val_output_x_msle: 66.1056 - val_output_y_msle: 286.4092 - val_output_z_msle: 172.6980 - lr: 1.0000e-07\n",
      "Epoch 152/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 171.9768 - output_x_loss: 63.1920 - output_y_loss: 283.3184 - output_z_loss: 166.8631 - output_x_msle: 63.1920 - output_y_msle: 283.3184 - output_z_msle: 166.8631 - val_loss: 175.2370 - val_output_x_loss: 65.8464 - val_output_y_loss: 286.1100 - val_output_z_loss: 172.2722 - val_output_x_msle: 65.8464 - val_output_y_msle: 286.1100 - val_output_z_msle: 172.2722 - lr: 1.0000e-07\n",
      "Epoch 153/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 171.7636 - output_x_loss: 63.0573 - output_y_loss: 283.0612 - output_z_loss: 166.5811 - output_x_msle: 63.0573 - output_y_msle: 283.0612 - output_z_msle: 166.5811 - val_loss: 174.9485 - val_output_x_loss: 65.8396 - val_output_y_loss: 285.6659 - val_output_z_loss: 171.7316 - val_output_x_msle: 65.8396 - val_output_y_msle: 285.6659 - val_output_z_msle: 171.7316 - lr: 1.0000e-07\n",
      "Epoch 154/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 171.4866 - output_x_loss: 63.0315 - output_y_loss: 282.5764 - output_z_loss: 166.2175 - output_x_msle: 63.0315 - output_y_msle: 282.5764 - output_z_msle: 166.2175 - val_loss: 174.6703 - val_output_x_loss: 65.5185 - val_output_y_loss: 285.4313 - val_output_z_loss: 171.4518 - val_output_x_msle: 65.5185 - val_output_y_msle: 285.4313 - val_output_z_msle: 171.4518 - lr: 1.0000e-07\n",
      "Epoch 155/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 171.3076 - output_x_loss: 62.9382 - output_y_loss: 282.4064 - output_z_loss: 165.8488 - output_x_msle: 62.9382 - output_y_msle: 282.4064 - output_z_msle: 165.8488 - val_loss: 174.4132 - val_output_x_loss: 65.3159 - val_output_y_loss: 285.3442 - val_output_z_loss: 170.7460 - val_output_x_msle: 65.3159 - val_output_y_msle: 285.3442 - val_output_z_msle: 170.7460 - lr: 1.0000e-07\n",
      "Epoch 156/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 171.0961 - output_x_loss: 62.7897 - output_y_loss: 282.2625 - output_z_loss: 165.3760 - output_x_msle: 62.7897 - output_y_msle: 282.2625 - output_z_msle: 165.3760 - val_loss: 174.2604 - val_output_x_loss: 65.2761 - val_output_y_loss: 285.2476 - val_output_z_loss: 170.2550 - val_output_x_msle: 65.2761 - val_output_y_msle: 285.2476 - val_output_z_msle: 170.2550 - lr: 1.0000e-07\n",
      "Epoch 157/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 170.9377 - output_x_loss: 62.7731 - output_y_loss: 282.1285 - output_z_loss: 164.8853 - output_x_msle: 62.7731 - output_y_msle: 282.1285 - output_z_msle: 164.8853 - val_loss: 173.9107 - val_output_x_loss: 65.2189 - val_output_y_loss: 285.0490 - val_output_z_loss: 169.0175 - val_output_x_msle: 65.2189 - val_output_y_msle: 285.0490 - val_output_z_msle: 169.0175 - lr: 1.0000e-07\n",
      "Epoch 158/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 170.5771 - output_x_loss: 62.5105 - output_y_loss: 282.0214 - output_z_loss: 163.8219 - output_x_msle: 62.5105 - output_y_msle: 282.0214 - output_z_msle: 163.8219 - val_loss: 173.6045 - val_output_x_loss: 64.9655 - val_output_y_loss: 284.8550 - val_output_z_loss: 168.3815 - val_output_x_msle: 64.9655 - val_output_y_msle: 284.8550 - val_output_z_msle: 168.3815 - lr: 1.0000e-07\n",
      "Epoch 159/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 170.2865 - output_x_loss: 62.3233 - output_y_loss: 281.8331 - output_z_loss: 163.1199 - output_x_msle: 62.3233 - output_y_msle: 281.8331 - output_z_msle: 163.1199 - val_loss: 173.3800 - val_output_x_loss: 64.8447 - val_output_y_loss: 284.7350 - val_output_z_loss: 167.7402 - val_output_x_msle: 64.8447 - val_output_y_msle: 284.7350 - val_output_z_msle: 167.7402 - lr: 1.0000e-07\n",
      "Epoch 160/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 169.9890 - output_x_loss: 62.0606 - output_y_loss: 281.6721 - output_z_loss: 162.4794 - output_x_msle: 62.0606 - output_y_msle: 281.6721 - output_z_msle: 162.4794 - val_loss: 172.7666 - val_output_x_loss: 64.0603 - val_output_y_loss: 284.5142 - val_output_z_loss: 166.6839 - val_output_x_msle: 64.0603 - val_output_y_msle: 284.5142 - val_output_z_msle: 166.6839 - lr: 1.0000e-07\n",
      "Epoch 161/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 169.6360 - output_x_loss: 61.6771 - output_y_loss: 281.4735 - output_z_loss: 161.8786 - output_x_msle: 61.6771 - output_y_msle: 281.4735 - output_z_msle: 161.8786 - val_loss: 172.1212 - val_output_x_loss: 63.0810 - val_output_y_loss: 284.1508 - val_output_z_loss: 166.1421 - val_output_x_msle: 63.0810 - val_output_y_msle: 284.1508 - val_output_z_msle: 166.1421 - lr: 1.0000e-07\n",
      "Epoch 162/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 169.3287 - output_x_loss: 61.3858 - output_y_loss: 281.2754 - output_z_loss: 161.3216 - output_x_msle: 61.3858 - output_y_msle: 281.2754 - output_z_msle: 161.3216 - val_loss: 171.8756 - val_output_x_loss: 63.1809 - val_output_y_loss: 283.9272 - val_output_z_loss: 165.1618 - val_output_x_msle: 63.1809 - val_output_y_msle: 283.9272 - val_output_z_msle: 165.1618 - lr: 1.0000e-07\n",
      "Epoch 163/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 168.7783 - output_x_loss: 60.8383 - output_y_loss: 280.9881 - output_z_loss: 160.2387 - output_x_msle: 60.8383 - output_y_msle: 280.9881 - output_z_msle: 160.2387 - val_loss: 171.2132 - val_output_x_loss: 62.4661 - val_output_y_loss: 283.6687 - val_output_z_loss: 163.7966 - val_output_x_msle: 62.4661 - val_output_y_msle: 283.6687 - val_output_z_msle: 163.7966 - lr: 1.0000e-07\n",
      "Epoch 164/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 168.0003 - output_x_loss: 59.7056 - output_y_loss: 280.7577 - output_z_loss: 159.0749 - output_x_msle: 59.7056 - output_y_msle: 280.7577 - output_z_msle: 159.0749 - val_loss: 170.5956 - val_output_x_loss: 61.5290 - val_output_y_loss: 283.4124 - val_output_z_loss: 163.0953 - val_output_x_msle: 61.5290 - val_output_y_msle: 283.4124 - val_output_z_msle: 163.0953 - lr: 1.0000e-07\n",
      "Epoch 165/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 167.5097 - output_x_loss: 59.2865 - output_y_loss: 280.1945 - output_z_loss: 158.5867 - output_x_msle: 59.2865 - output_y_msle: 280.1945 - output_z_msle: 158.5867 - val_loss: 169.8565 - val_output_x_loss: 60.7105 - val_output_y_loss: 282.7513 - val_output_z_loss: 162.3590 - val_output_x_msle: 60.7105 - val_output_y_msle: 282.7513 - val_output_z_msle: 162.3590 - lr: 1.0000e-07\n",
      "Epoch 166/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 166.7923 - output_x_loss: 58.4874 - output_y_loss: 279.6886 - output_z_loss: 157.6096 - output_x_msle: 58.4874 - output_y_msle: 279.6886 - output_z_msle: 157.6096 - val_loss: 169.0520 - val_output_x_loss: 59.7481 - val_output_y_loss: 282.4566 - val_output_z_loss: 160.8509 - val_output_x_msle: 59.7481 - val_output_y_msle: 282.4566 - val_output_z_msle: 160.8509 - lr: 1.0000e-07\n",
      "Epoch 167/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 166.2760 - output_x_loss: 58.1287 - output_y_loss: 279.4284 - output_z_loss: 156.2660 - output_x_msle: 58.1287 - output_y_msle: 279.4284 - output_z_msle: 156.2660 - val_loss: 168.9832 - val_output_x_loss: 59.8281 - val_output_y_loss: 282.3475 - val_output_z_loss: 160.5648 - val_output_x_msle: 59.8281 - val_output_y_msle: 282.3475 - val_output_z_msle: 160.5648 - lr: 1.0000e-07\n",
      "Epoch 168/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 165.9775 - output_x_loss: 57.7752 - output_y_loss: 279.1710 - output_z_loss: 155.9952 - output_x_msle: 57.7752 - output_y_msle: 279.1710 - output_z_msle: 155.9952 - val_loss: 168.7919 - val_output_x_loss: 59.6056 - val_output_y_loss: 282.1524 - val_output_z_loss: 160.4436 - val_output_x_msle: 59.6056 - val_output_y_msle: 282.1524 - val_output_z_msle: 160.4436 - lr: 1.0000e-07\n",
      "Epoch 169/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 165.4759 - output_x_loss: 56.8725 - output_y_loss: 278.9964 - output_z_loss: 155.6417 - output_x_msle: 56.8725 - output_y_msle: 278.9964 - output_z_msle: 155.6417 - val_loss: 167.9412 - val_output_x_loss: 57.8952 - val_output_y_loss: 282.0053 - val_output_z_loss: 159.9050 - val_output_x_msle: 57.8952 - val_output_y_msle: 282.0053 - val_output_z_msle: 159.9050 - lr: 1.0000e-07\n",
      "Epoch 170/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 164.6294 - output_x_loss: 55.2647 - output_y_loss: 278.6965 - output_z_loss: 155.2243 - output_x_msle: 55.2647 - output_y_msle: 278.6965 - output_z_msle: 155.2243 - val_loss: 167.5199 - val_output_x_loss: 57.1378 - val_output_y_loss: 281.7588 - val_output_z_loss: 159.8065 - val_output_x_msle: 57.1378 - val_output_y_msle: 281.7588 - val_output_z_msle: 159.8065 - lr: 1.0000e-07\n",
      "Epoch 171/500\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 163.6061 - output_x_loss: 52.9209 - output_y_loss: 278.5425 - output_z_loss: 155.1036 - output_x_msle: 52.9209 - output_y_msle: 278.5425 - output_z_msle: 155.1036 - val_loss: 166.1860 - val_output_x_loss: 53.9354 - val_output_y_loss: 281.6754 - val_output_z_loss: 159.7082 - val_output_x_msle: 53.9354 - val_output_y_msle: 281.6754 - val_output_z_msle: 159.7082 - lr: 1.0000e-07\n",
      "Epoch 172/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 162.8506 - output_x_loss: 51.2529 - output_y_loss: 278.3792 - output_z_loss: 154.9889 - output_x_msle: 51.2529 - output_y_msle: 278.3792 - output_z_msle: 154.9889 - val_loss: 166.1666 - val_output_x_loss: 54.0860 - val_output_y_loss: 281.5535 - val_output_z_loss: 159.5542 - val_output_x_msle: 54.0860 - val_output_y_msle: 281.5535 - val_output_z_msle: 159.5542 - lr: 1.0000e-07\n",
      "Epoch 173/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 162.6302 - output_x_loss: 51.0984 - output_y_loss: 278.0558 - output_z_loss: 154.8428 - output_x_msle: 51.0984 - output_y_msle: 278.0558 - output_z_msle: 154.8428 - val_loss: 165.8606 - val_output_x_loss: 54.0244 - val_output_y_loss: 280.9113 - val_output_z_loss: 159.4318 - val_output_x_msle: 54.0244 - val_output_y_msle: 280.9113 - val_output_z_msle: 159.4318 - lr: 1.0000e-07\n",
      "Epoch 174/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 162.0879 - output_x_loss: 50.4056 - output_y_loss: 277.4719 - output_z_loss: 154.6849 - output_x_msle: 50.4056 - output_y_msle: 277.4719 - output_z_msle: 154.6849 - val_loss: 164.9763 - val_output_x_loss: 52.6022 - val_output_y_loss: 280.2222 - val_output_z_loss: 159.2329 - val_output_x_msle: 52.6022 - val_output_y_msle: 280.2222 - val_output_z_msle: 159.2329 - lr: 1.0000e-07\n",
      "Epoch 175/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 161.4453 - output_x_loss: 49.4708 - output_y_loss: 276.8994 - output_z_loss: 154.4862 - output_x_msle: 49.4708 - output_y_msle: 276.8994 - output_z_msle: 154.4862 - val_loss: 164.7678 - val_output_x_loss: 52.2701 - val_output_y_loss: 280.1471 - val_output_z_loss: 159.0045 - val_output_x_msle: 52.2701 - val_output_y_msle: 280.1471 - val_output_z_msle: 159.0045 - lr: 1.0000e-07\n",
      "Epoch 176/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 161.3203 - output_x_loss: 49.3916 - output_y_loss: 276.7832 - output_z_loss: 154.2514 - output_x_msle: 49.3916 - output_y_msle: 276.7832 - output_z_msle: 154.2514 - val_loss: 164.7070 - val_output_x_loss: 52.2575 - val_output_y_loss: 280.0872 - val_output_z_loss: 158.8453 - val_output_x_msle: 52.2575 - val_output_y_msle: 280.0872 - val_output_z_msle: 158.8453 - lr: 1.0000e-07\n",
      "Epoch 177/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 161.2201 - output_x_loss: 49.3769 - output_y_loss: 276.6870 - output_z_loss: 153.9725 - output_x_msle: 49.3769 - output_y_msle: 276.6870 - output_z_msle: 153.9725 - val_loss: 164.5919 - val_output_x_loss: 52.2481 - val_output_y_loss: 279.9896 - val_output_z_loss: 158.4842 - val_output_x_msle: 52.2481 - val_output_y_msle: 279.9896 - val_output_z_msle: 158.4842 - lr: 1.0000e-07\n",
      "Epoch 178/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 161.0985 - output_x_loss: 49.3483 - output_y_loss: 276.5461 - output_z_loss: 153.7041 - output_x_msle: 49.3483 - output_y_msle: 276.5461 - output_z_msle: 153.7041 - val_loss: 164.4643 - val_output_x_loss: 52.2388 - val_output_y_loss: 279.9007 - val_output_z_loss: 158.0425 - val_output_x_msle: 52.2388 - val_output_y_msle: 279.9007 - val_output_z_msle: 158.0425 - lr: 1.0000e-07\n",
      "Epoch 179/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.9817 - output_x_loss: 49.2970 - output_y_loss: 276.4477 - output_z_loss: 153.4186 - output_x_msle: 49.2970 - output_y_msle: 276.4477 - output_z_msle: 153.4186 - val_loss: 164.3290 - val_output_x_loss: 52.2202 - val_output_y_loss: 279.7355 - val_output_z_loss: 157.7339 - val_output_x_msle: 52.2202 - val_output_y_msle: 279.7355 - val_output_z_msle: 157.7339 - lr: 1.0000e-07\n",
      "Epoch 180/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.8603 - output_x_loss: 49.2210 - output_y_loss: 276.3273 - output_z_loss: 153.2051 - output_x_msle: 49.2210 - output_y_msle: 276.3273 - output_z_msle: 153.2051 - val_loss: 164.2287 - val_output_x_loss: 52.2054 - val_output_y_loss: 279.6512 - val_output_z_loss: 157.4303 - val_output_x_msle: 52.2054 - val_output_y_msle: 279.6512 - val_output_z_msle: 157.4303 - lr: 1.0000e-07\n",
      "Epoch 181/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.7280 - output_x_loss: 49.1750 - output_y_loss: 276.2650 - output_z_loss: 152.7603 - output_x_msle: 49.1750 - output_y_msle: 276.2650 - output_z_msle: 152.7603 - val_loss: 164.0360 - val_output_x_loss: 52.0390 - val_output_y_loss: 279.5382 - val_output_z_loss: 157.0257 - val_output_x_msle: 52.0390 - val_output_y_msle: 279.5382 - val_output_z_msle: 157.0257 - lr: 1.0000e-07\n",
      "Epoch 182/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.5833 - output_x_loss: 49.1621 - output_y_loss: 276.0744 - output_z_loss: 152.4432 - output_x_msle: 49.1621 - output_y_msle: 276.0744 - output_z_msle: 152.4432 - val_loss: 163.8607 - val_output_x_loss: 52.0248 - val_output_y_loss: 279.2869 - val_output_z_loss: 156.6803 - val_output_x_msle: 52.0248 - val_output_y_msle: 279.2869 - val_output_z_msle: 156.6803 - lr: 1.0000e-07\n",
      "Epoch 183/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.3053 - output_x_loss: 48.7674 - output_y_loss: 275.9198 - output_z_loss: 152.1517 - output_x_msle: 48.7674 - output_y_msle: 275.9198 - output_z_msle: 152.1517 - val_loss: 163.4734 - val_output_x_loss: 51.3401 - val_output_y_loss: 279.1602 - val_output_z_loss: 156.3660 - val_output_x_msle: 51.3401 - val_output_y_msle: 279.1602 - val_output_z_msle: 156.3660 - lr: 1.0000e-07\n",
      "Epoch 184/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 160.1277 - output_x_loss: 48.6743 - output_y_loss: 275.7214 - output_z_loss: 151.8465 - output_x_msle: 48.6743 - output_y_msle: 275.7214 - output_z_msle: 151.8465 - val_loss: 163.4141 - val_output_x_loss: 51.4416 - val_output_y_loss: 278.9947 - val_output_z_loss: 156.1975 - val_output_x_msle: 51.4416 - val_output_y_msle: 278.9947 - val_output_z_msle: 156.1975 - lr: 1.0000e-07\n",
      "Epoch 185/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 159.9174 - output_x_loss: 48.5574 - output_y_loss: 275.4353 - output_z_loss: 151.6012 - output_x_msle: 48.5574 - output_y_msle: 275.4353 - output_z_msle: 151.6012 - val_loss: 163.1432 - val_output_x_loss: 51.2730 - val_output_y_loss: 278.5864 - val_output_z_loss: 155.9970 - val_output_x_msle: 51.2730 - val_output_y_msle: 278.5864 - val_output_z_msle: 155.9970 - lr: 1.0000e-07\n",
      "Epoch 186/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 159.6119 - output_x_loss: 48.3607 - output_y_loss: 275.0276 - output_z_loss: 151.2829 - output_x_msle: 48.3607 - output_y_msle: 275.0276 - output_z_msle: 151.2829 - val_loss: 162.3936 - val_output_x_loss: 49.9669 - val_output_y_loss: 278.1618 - val_output_z_loss: 155.7108 - val_output_x_msle: 49.9669 - val_output_y_msle: 278.1618 - val_output_z_msle: 155.7108 - lr: 1.0000e-07\n",
      "Epoch 187/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 159.3916 - output_x_loss: 48.2760 - output_y_loss: 274.7228 - output_z_loss: 150.9602 - output_x_msle: 48.2760 - output_y_msle: 274.7228 - output_z_msle: 150.9602 - val_loss: 162.2016 - val_output_x_loss: 49.9544 - val_output_y_loss: 277.8727 - val_output_z_loss: 155.3537 - val_output_x_msle: 49.9544 - val_output_y_msle: 277.8727 - val_output_z_msle: 155.3537 - lr: 1.0000e-07\n",
      "Epoch 188/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 159.0843 - output_x_loss: 48.2289 - output_y_loss: 274.1437 - output_z_loss: 150.6762 - output_x_msle: 48.2289 - output_y_msle: 274.1437 - output_z_msle: 150.6762 - val_loss: 161.7436 - val_output_x_loss: 49.8409 - val_output_y_loss: 277.0203 - val_output_z_loss: 154.9957 - val_output_x_msle: 49.8409 - val_output_y_msle: 277.0203 - val_output_z_msle: 154.9957 - lr: 1.0000e-07\n",
      "Epoch 189/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 158.6639 - output_x_loss: 48.1688 - output_y_loss: 273.3089 - output_z_loss: 150.3644 - output_x_msle: 48.1688 - output_y_msle: 273.3089 - output_z_msle: 150.3644 - val_loss: 161.1036 - val_output_x_loss: 49.8295 - val_output_y_loss: 275.6410 - val_output_z_loss: 154.5770 - val_output_x_msle: 49.8295 - val_output_y_msle: 275.6410 - val_output_z_msle: 154.5770 - lr: 1.0000e-07\n",
      "Epoch 190/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 158.3087 - output_x_loss: 48.1226 - output_y_loss: 272.6424 - output_z_loss: 150.0134 - output_x_msle: 48.1226 - output_y_msle: 272.6424 - output_z_msle: 150.0134 - val_loss: 160.7456 - val_output_x_loss: 49.8196 - val_output_y_loss: 274.8820 - val_output_z_loss: 154.3249 - val_output_x_msle: 49.8196 - val_output_y_msle: 274.8820 - val_output_z_msle: 154.3249 - lr: 1.0000e-07\n",
      "Epoch 191/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 157.9921 - output_x_loss: 48.1147 - output_y_loss: 272.0468 - output_z_loss: 149.6376 - output_x_msle: 48.1147 - output_y_msle: 272.0468 - output_z_msle: 149.6376 - val_loss: 160.2098 - val_output_x_loss: 49.8109 - val_output_y_loss: 273.7581 - val_output_z_loss: 153.9114 - val_output_x_msle: 49.8109 - val_output_y_msle: 273.7581 - val_output_z_msle: 153.9114 - lr: 1.0000e-07\n",
      "Epoch 192/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 157.5618 - output_x_loss: 48.0734 - output_y_loss: 271.2823 - output_z_loss: 149.0982 - output_x_msle: 48.0734 - output_y_msle: 271.2823 - output_z_msle: 149.0982 - val_loss: 159.8869 - val_output_x_loss: 49.6680 - val_output_y_loss: 273.4266 - val_output_z_loss: 153.2450 - val_output_x_msle: 49.6680 - val_output_y_msle: 273.4266 - val_output_z_msle: 153.2450 - lr: 1.0000e-07\n",
      "Epoch 193/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 157.1981 - output_x_loss: 48.0350 - output_y_loss: 270.7037 - output_z_loss: 148.5129 - output_x_msle: 48.0350 - output_y_msle: 270.7037 - output_z_msle: 148.5129 - val_loss: 159.5944 - val_output_x_loss: 49.6489 - val_output_y_loss: 273.0976 - val_output_z_loss: 152.4789 - val_output_x_msle: 49.6489 - val_output_y_msle: 273.0976 - val_output_z_msle: 152.4789 - lr: 1.0000e-07\n",
      "Epoch 194/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 156.8453 - output_x_loss: 47.9969 - output_y_loss: 270.2925 - output_z_loss: 147.6477 - output_x_msle: 47.9969 - output_y_msle: 270.2925 - output_z_msle: 147.6477 - val_loss: 159.2400 - val_output_x_loss: 49.6347 - val_output_y_loss: 272.7235 - val_output_z_loss: 151.4836 - val_output_x_msle: 49.6347 - val_output_y_msle: 272.7235 - val_output_z_msle: 151.4836 - lr: 1.0000e-07\n",
      "Epoch 195/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 156.4674 - output_x_loss: 47.9557 - output_y_loss: 269.8510 - output_z_loss: 146.7243 - output_x_msle: 47.9557 - output_y_msle: 269.8510 - output_z_msle: 146.7243 - val_loss: 158.8807 - val_output_x_loss: 49.6219 - val_output_y_loss: 272.3403 - val_output_z_loss: 150.4790 - val_output_x_msle: 49.6219 - val_output_y_msle: 272.3403 - val_output_z_msle: 150.4790 - lr: 1.0000e-07\n",
      "Epoch 196/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 156.0951 - output_x_loss: 47.8572 - output_y_loss: 269.6066 - output_z_loss: 145.5482 - output_x_msle: 47.8572 - output_y_msle: 269.6066 - output_z_msle: 145.5482 - val_loss: 158.2945 - val_output_x_loss: 49.0505 - val_output_y_loss: 271.8503 - val_output_z_loss: 149.6708 - val_output_x_msle: 49.0505 - val_output_y_msle: 271.8503 - val_output_z_msle: 149.6708 - lr: 1.0000e-07\n",
      "Epoch 197/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 155.6396 - output_x_loss: 47.3930 - output_y_loss: 269.4272 - output_z_loss: 144.5573 - output_x_msle: 47.3930 - output_y_msle: 269.4272 - output_z_msle: 144.5573 - val_loss: 157.8610 - val_output_x_loss: 48.7687 - val_output_y_loss: 271.6462 - val_output_z_loss: 148.4750 - val_output_x_msle: 48.7687 - val_output_y_msle: 271.6462 - val_output_z_msle: 148.4750 - lr: 1.0000e-07\n",
      "Epoch 198/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 155.1431 - output_x_loss: 47.2368 - output_y_loss: 269.2617 - output_z_loss: 142.7182 - output_x_msle: 47.2368 - output_y_msle: 269.2617 - output_z_msle: 142.7182 - val_loss: 157.2276 - val_output_x_loss: 48.4691 - val_output_y_loss: 271.4070 - val_output_z_loss: 146.3853 - val_output_x_msle: 48.4691 - val_output_y_msle: 271.4070 - val_output_z_msle: 146.3853 - lr: 1.0000e-07\n",
      "Epoch 199/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 154.6072 - output_x_loss: 47.0711 - output_y_loss: 269.1155 - output_z_loss: 140.6625 - output_x_msle: 47.0711 - output_y_msle: 269.1155 - output_z_msle: 140.6625 - val_loss: 156.7000 - val_output_x_loss: 48.3139 - val_output_y_loss: 270.9975 - val_output_z_loss: 144.8772 - val_output_x_msle: 48.3139 - val_output_y_msle: 270.9975 - val_output_z_msle: 144.8772 - lr: 1.0000e-07\n",
      "Epoch 200/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 154.1933 - output_x_loss: 46.9078 - output_y_loss: 268.9104 - output_z_loss: 139.3301 - output_x_msle: 46.9078 - output_y_msle: 268.9104 - output_z_msle: 139.3301 - val_loss: 156.1538 - val_output_x_loss: 47.8604 - val_output_y_loss: 270.7092 - val_output_z_loss: 143.6300 - val_output_x_msle: 47.8604 - val_output_y_msle: 270.7092 - val_output_z_msle: 143.6300 - lr: 1.0000e-07\n",
      "Epoch 201/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 153.7301 - output_x_loss: 46.8447 - output_y_loss: 268.5898 - output_z_loss: 137.7816 - output_x_msle: 46.8447 - output_y_msle: 268.5898 - output_z_msle: 137.7816 - val_loss: 155.7774 - val_output_x_loss: 48.1635 - val_output_y_loss: 270.2631 - val_output_z_loss: 142.0342 - val_output_x_msle: 48.1635 - val_output_y_msle: 270.2631 - val_output_z_msle: 142.0342 - lr: 1.0000e-07\n",
      "Epoch 202/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 152.9725 - output_x_loss: 46.3063 - output_y_loss: 268.3307 - output_z_loss: 135.5885 - output_x_msle: 46.3063 - output_y_msle: 268.3307 - output_z_msle: 135.5885 - val_loss: 154.6053 - val_output_x_loss: 47.5579 - val_output_y_loss: 269.8792 - val_output_z_loss: 138.1521 - val_output_x_msle: 47.5579 - val_output_y_msle: 269.8792 - val_output_z_msle: 138.1521 - lr: 1.0000e-07\n",
      "Epoch 203/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 151.8291 - output_x_loss: 46.2133 - output_y_loss: 267.9207 - output_z_loss: 130.8773 - output_x_msle: 46.2133 - output_y_msle: 267.9207 - output_z_msle: 130.8773 - val_loss: 153.3789 - val_output_x_loss: 47.5418 - val_output_y_loss: 269.6459 - val_output_z_loss: 132.5193 - val_output_x_msle: 47.5418 - val_output_y_msle: 269.6459 - val_output_z_msle: 132.5193 - lr: 1.0000e-07\n",
      "Epoch 204/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 150.8601 - output_x_loss: 46.1179 - output_y_loss: 267.7746 - output_z_loss: 126.5153 - output_x_msle: 46.1179 - output_y_msle: 267.7746 - output_z_msle: 126.5153 - val_loss: 152.6859 - val_output_x_loss: 47.5258 - val_output_y_loss: 269.4754 - val_output_z_loss: 129.4269 - val_output_x_msle: 47.5258 - val_output_y_msle: 269.4754 - val_output_z_msle: 129.4269 - lr: 1.0000e-07\n",
      "Epoch 205/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 150.2657 - output_x_loss: 46.0346 - output_y_loss: 267.6341 - output_z_loss: 123.9912 - output_x_msle: 46.0346 - output_y_msle: 267.6341 - output_z_msle: 123.9912 - val_loss: 151.9758 - val_output_x_loss: 47.5146 - val_output_y_loss: 269.1719 - val_output_z_loss: 126.5059 - val_output_x_msle: 47.5146 - val_output_y_msle: 269.1719 - val_output_z_msle: 126.5059 - lr: 1.0000e-07\n",
      "Epoch 206/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 149.6392 - output_x_loss: 46.0351 - output_y_loss: 267.4010 - output_z_loss: 121.3234 - output_x_msle: 46.0351 - output_y_msle: 267.4010 - output_z_msle: 121.3234 - val_loss: 151.2904 - val_output_x_loss: 47.4886 - val_output_y_loss: 268.9878 - val_output_z_loss: 123.4991 - val_output_x_msle: 47.4886 - val_output_y_msle: 268.9878 - val_output_z_msle: 123.4991 - lr: 1.0000e-07\n",
      "Epoch 207/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 149.0416 - output_x_loss: 45.9975 - output_y_loss: 267.1677 - output_z_loss: 118.8776 - output_x_msle: 45.9975 - output_y_msle: 267.1677 - output_z_msle: 118.8776 - val_loss: 150.8229 - val_output_x_loss: 47.3967 - val_output_y_loss: 268.7818 - val_output_z_loss: 121.7576 - val_output_x_msle: 47.3967 - val_output_y_msle: 268.7818 - val_output_z_msle: 121.7576 - lr: 1.0000e-07\n",
      "Epoch 208/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 148.5657 - output_x_loss: 45.9385 - output_y_loss: 266.7346 - output_z_loss: 117.4822 - output_x_msle: 45.9385 - output_y_msle: 266.7346 - output_z_msle: 117.4822 - val_loss: 150.4427 - val_output_x_loss: 47.3865 - val_output_y_loss: 268.5582 - val_output_z_loss: 120.3243 - val_output_x_msle: 47.3865 - val_output_y_msle: 268.5582 - val_output_z_msle: 120.3243 - lr: 1.0000e-07\n",
      "Epoch 209/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 148.1430 - output_x_loss: 45.8893 - output_y_loss: 266.3342 - output_z_loss: 116.2683 - output_x_msle: 45.8893 - output_y_msle: 266.3342 - output_z_msle: 116.2683 - val_loss: 150.0671 - val_output_x_loss: 47.3726 - val_output_y_loss: 268.4221 - val_output_z_loss: 118.7462 - val_output_x_msle: 47.3726 - val_output_y_msle: 268.4221 - val_output_z_msle: 118.7462 - lr: 1.0000e-07\n",
      "Epoch 210/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 147.6049 - output_x_loss: 45.8045 - output_y_loss: 265.9725 - output_z_loss: 114.4706 - output_x_msle: 45.8045 - output_y_msle: 265.9725 - output_z_msle: 114.4706 - val_loss: 149.4654 - val_output_x_loss: 47.3606 - val_output_y_loss: 268.0943 - val_output_z_loss: 116.4168 - val_output_x_msle: 47.3606 - val_output_y_msle: 268.0943 - val_output_z_msle: 116.4168 - lr: 1.0000e-07\n",
      "Epoch 211/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 146.8061 - output_x_loss: 45.7376 - output_y_loss: 265.6273 - output_z_loss: 111.3006 - output_x_msle: 45.7376 - output_y_msle: 265.6273 - output_z_msle: 111.3006 - val_loss: 148.6406 - val_output_x_loss: 47.2251 - val_output_y_loss: 267.6312 - val_output_z_loss: 113.4902 - val_output_x_msle: 47.2251 - val_output_y_msle: 267.6312 - val_output_z_msle: 113.4902 - lr: 1.0000e-07\n",
      "Epoch 212/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 146.0674 - output_x_loss: 45.6353 - output_y_loss: 265.3236 - output_z_loss: 108.4191 - output_x_msle: 45.6353 - output_y_msle: 265.3236 - output_z_msle: 108.4191 - val_loss: 147.6777 - val_output_x_loss: 47.2049 - val_output_y_loss: 267.3663 - val_output_z_loss: 109.2461 - val_output_x_msle: 47.2049 - val_output_y_msle: 267.3663 - val_output_z_msle: 109.2461 - lr: 1.0000e-07\n",
      "Epoch 213/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 145.1347 - output_x_loss: 45.4846 - output_y_loss: 264.8690 - output_z_loss: 104.9663 - output_x_msle: 45.4846 - output_y_msle: 264.8690 - output_z_msle: 104.9663 - val_loss: 146.7999 - val_output_x_loss: 47.1953 - val_output_y_loss: 266.8510 - val_output_z_loss: 105.9067 - val_output_x_msle: 47.1953 - val_output_y_msle: 266.8510 - val_output_z_msle: 105.9067 - lr: 1.0000e-07\n",
      "Epoch 214/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 144.5121 - output_x_loss: 45.4678 - output_y_loss: 264.5371 - output_z_loss: 102.5509 - output_x_msle: 45.4678 - output_y_msle: 264.5371 - output_z_msle: 102.5509 - val_loss: 146.3032 - val_output_x_loss: 47.1803 - val_output_y_loss: 266.6362 - val_output_z_loss: 103.8828 - val_output_x_msle: 47.1803 - val_output_y_msle: 266.6362 - val_output_z_msle: 103.8828 - lr: 1.0000e-07\n",
      "Epoch 215/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 143.9256 - output_x_loss: 45.3889 - output_y_loss: 264.2993 - output_z_loss: 100.2517 - output_x_msle: 45.3889 - output_y_msle: 264.2993 - output_z_msle: 100.2517 - val_loss: 145.5687 - val_output_x_loss: 47.1681 - val_output_y_loss: 266.3433 - val_output_z_loss: 100.8204 - val_output_x_msle: 47.1681 - val_output_y_msle: 266.3433 - val_output_z_msle: 100.8204 - lr: 1.0000e-07\n",
      "Epoch 216/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 143.2540 - output_x_loss: 45.3724 - output_y_loss: 263.9878 - output_z_loss: 97.5494 - output_x_msle: 45.3724 - output_y_msle: 263.9878 - output_z_msle: 97.5494 - val_loss: 145.1499 - val_output_x_loss: 47.1529 - val_output_y_loss: 266.1719 - val_output_z_loss: 99.0999 - val_output_x_msle: 47.1529 - val_output_y_msle: 266.1719 - val_output_z_msle: 99.0999 - lr: 1.0000e-07\n",
      "Epoch 217/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 142.5684 - output_x_loss: 45.3115 - output_y_loss: 263.6953 - output_z_loss: 94.8284 - output_x_msle: 45.3115 - output_y_msle: 263.6953 - output_z_msle: 94.8284 - val_loss: 144.1877 - val_output_x_loss: 46.9741 - val_output_y_loss: 265.9163 - val_output_z_loss: 95.1576 - val_output_x_msle: 46.9741 - val_output_y_msle: 265.9163 - val_output_z_msle: 95.1576 - lr: 1.0000e-07\n",
      "Epoch 218/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 141.8611 - output_x_loss: 45.3658 - output_y_loss: 263.5288 - output_z_loss: 91.5159 - output_x_msle: 45.3658 - output_y_msle: 263.5288 - output_z_msle: 91.5159 - val_loss: 143.3154 - val_output_x_loss: 46.8681 - val_output_y_loss: 265.5504 - val_output_z_loss: 91.7399 - val_output_x_msle: 46.8681 - val_output_y_msle: 265.5504 - val_output_z_msle: 91.7399 - lr: 1.0000e-07\n",
      "Epoch 219/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 141.0576 - output_x_loss: 45.2652 - output_y_loss: 263.0315 - output_z_loss: 88.6947 - output_x_msle: 45.2652 - output_y_msle: 263.0315 - output_z_msle: 88.6947 - val_loss: 142.6138 - val_output_x_loss: 46.8484 - val_output_y_loss: 264.9859 - val_output_z_loss: 89.4001 - val_output_x_msle: 46.8484 - val_output_y_msle: 264.9859 - val_output_z_msle: 89.4001 - lr: 1.0000e-07\n",
      "Epoch 220/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 140.5312 - output_x_loss: 45.1594 - output_y_loss: 262.3429 - output_z_loss: 87.6513 - output_x_msle: 45.1594 - output_y_msle: 262.3429 - output_z_msle: 87.6513 - val_loss: 142.2988 - val_output_x_loss: 46.8719 - val_output_y_loss: 264.8105 - val_output_z_loss: 88.1289 - val_output_x_msle: 46.8719 - val_output_y_msle: 264.8105 - val_output_z_msle: 88.1289 - lr: 1.0000e-07\n",
      "Epoch 221/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 140.2476 - output_x_loss: 45.1304 - output_y_loss: 262.1226 - output_z_loss: 86.7321 - output_x_msle: 45.1304 - output_y_msle: 262.1226 - output_z_msle: 86.7321 - val_loss: 141.9002 - val_output_x_loss: 46.8490 - val_output_y_loss: 264.4301 - val_output_z_loss: 86.9427 - val_output_x_msle: 46.8490 - val_output_y_msle: 264.4301 - val_output_z_msle: 86.9427 - lr: 1.0000e-07\n",
      "Epoch 222/500\n",
      "165/165 [==============================] - ETA: 0s - loss: 139.9088 - output_x_loss: 45.0842 - output_y_loss: 261.8788 - output_z_loss: 85.6177 - output_x_msle: 45.0842 - output_y_msle: 261.8788 - output_z_msle: 85.617 - 1s 5ms/step - loss: 139.9079 - output_x_loss: 45.0700 - output_y_loss: 261.8917 - output_z_loss: 85.6158 - output_x_msle: 45.0700 - output_y_msle: 261.8917 - output_z_msle: 85.6158 - val_loss: 141.4915 - val_output_x_loss: 46.7175 - val_output_y_loss: 264.3354 - val_output_z_loss: 85.3516 - val_output_x_msle: 46.7175 - val_output_y_msle: 264.3354 - val_output_z_msle: 85.3516 - lr: 1.0000e-07\n",
      "Epoch 223/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 139.6416 - output_x_loss: 45.0106 - output_y_loss: 261.7189 - output_z_loss: 84.7492 - output_x_msle: 45.0106 - output_y_msle: 261.7189 - output_z_msle: 84.7492 - val_loss: 141.2698 - val_output_x_loss: 46.5752 - val_output_y_loss: 264.2457 - val_output_z_loss: 84.7073 - val_output_x_msle: 46.5752 - val_output_y_msle: 264.2457 - val_output_z_msle: 84.7073 - lr: 1.0000e-07\n",
      "Epoch 224/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 139.2448 - output_x_loss: 44.9026 - output_y_loss: 261.4871 - output_z_loss: 83.4446 - output_x_msle: 44.9026 - output_y_msle: 261.4871 - output_z_msle: 83.4446 - val_loss: 140.6019 - val_output_x_loss: 46.3707 - val_output_y_loss: 264.0411 - val_output_z_loss: 82.1857 - val_output_x_msle: 46.3707 - val_output_y_msle: 264.0411 - val_output_z_msle: 82.1857 - lr: 1.0000e-07\n",
      "Epoch 225/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 138.6565 - output_x_loss: 44.6777 - output_y_loss: 261.0372 - output_z_loss: 81.8529 - output_x_msle: 44.6777 - output_y_msle: 261.0372 - output_z_msle: 81.8529 - val_loss: 140.0376 - val_output_x_loss: 45.8990 - val_output_y_loss: 263.5305 - val_output_z_loss: 81.3288 - val_output_x_msle: 45.8990 - val_output_y_msle: 263.5305 - val_output_z_msle: 81.3288 - lr: 1.0000e-07\n",
      "Epoch 226/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 138.2023 - output_x_loss: 44.2946 - output_y_loss: 260.7214 - output_z_loss: 80.9790 - output_x_msle: 44.2946 - output_y_msle: 260.7214 - output_z_msle: 80.9790 - val_loss: 139.6492 - val_output_x_loss: 45.7421 - val_output_y_loss: 263.3170 - val_output_z_loss: 80.1280 - val_output_x_msle: 45.7421 - val_output_y_msle: 263.3170 - val_output_z_msle: 80.1280 - lr: 1.0000e-07\n",
      "Epoch 227/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 137.8822 - output_x_loss: 44.3245 - output_y_loss: 260.5035 - output_z_loss: 79.7551 - output_x_msle: 44.3245 - output_y_msle: 260.5035 - output_z_msle: 79.7551 - val_loss: 139.4989 - val_output_x_loss: 45.8951 - val_output_y_loss: 263.1341 - val_output_z_loss: 79.4363 - val_output_x_msle: 45.8951 - val_output_y_msle: 263.1341 - val_output_z_msle: 79.4363 - lr: 1.0000e-07\n",
      "Epoch 228/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 137.5732 - output_x_loss: 44.3831 - output_y_loss: 260.0350 - output_z_loss: 79.0294 - output_x_msle: 44.3831 - output_y_msle: 260.0350 - output_z_msle: 79.0294 - val_loss: 139.1994 - val_output_x_loss: 45.8883 - val_output_y_loss: 262.8136 - val_output_z_loss: 78.5929 - val_output_x_msle: 45.8883 - val_output_y_msle: 262.8136 - val_output_z_msle: 78.5929 - lr: 1.0000e-07\n",
      "Epoch 229/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 137.2201 - output_x_loss: 44.3125 - output_y_loss: 259.6367 - output_z_loss: 78.2019 - output_x_msle: 44.3125 - output_y_msle: 259.6367 - output_z_msle: 78.2019 - val_loss: 138.9146 - val_output_x_loss: 45.8796 - val_output_y_loss: 262.5337 - val_output_z_loss: 77.7466 - val_output_x_msle: 45.8796 - val_output_y_msle: 262.5337 - val_output_z_msle: 77.7466 - lr: 1.0000e-07\n",
      "Epoch 230/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 136.9286 - output_x_loss: 44.3024 - output_y_loss: 259.4699 - output_z_loss: 77.0987 - output_x_msle: 44.3024 - output_y_msle: 259.4699 - output_z_msle: 77.0987 - val_loss: 138.6263 - val_output_x_loss: 45.8726 - val_output_y_loss: 262.2285 - val_output_z_loss: 76.9292 - val_output_x_msle: 45.8726 - val_output_y_msle: 262.2285 - val_output_z_msle: 76.9292 - lr: 1.0000e-07\n",
      "Epoch 231/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 136.5690 - output_x_loss: 44.2954 - output_y_loss: 259.1659 - output_z_loss: 75.9228 - output_x_msle: 44.2954 - output_y_msle: 259.1659 - output_z_msle: 75.9228 - val_loss: 138.0724 - val_output_x_loss: 45.7292 - val_output_y_loss: 261.8023 - val_output_z_loss: 75.2993 - val_output_x_msle: 45.7292 - val_output_y_msle: 261.8023 - val_output_z_msle: 75.2993 - lr: 1.0000e-07\n",
      "Epoch 232/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 135.9587 - output_x_loss: 44.1981 - output_y_loss: 258.4505 - output_z_loss: 74.4966 - output_x_msle: 44.1981 - output_y_msle: 258.4505 - output_z_msle: 74.4966 - val_loss: 137.6346 - val_output_x_loss: 45.7146 - val_output_y_loss: 261.4139 - val_output_z_loss: 73.9158 - val_output_x_msle: 45.7146 - val_output_y_msle: 261.4139 - val_output_z_msle: 73.9158 - lr: 1.0000e-07\n",
      "Epoch 233/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 135.5973 - output_x_loss: 44.1375 - output_y_loss: 258.1709 - output_z_loss: 73.3696 - output_x_msle: 44.1375 - output_y_msle: 258.1709 - output_z_msle: 73.3696 - val_loss: 137.0129 - val_output_x_loss: 45.5588 - val_output_y_loss: 260.7639 - val_output_z_loss: 72.4189 - val_output_x_msle: 45.5588 - val_output_y_msle: 260.7639 - val_output_z_msle: 72.4189 - lr: 1.0000e-07\n",
      "Epoch 234/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 134.9572 - output_x_loss: 44.0870 - output_y_loss: 257.0279 - output_z_loss: 72.5564 - output_x_msle: 44.0870 - output_y_msle: 257.0279 - output_z_msle: 72.5564 - val_loss: 136.6415 - val_output_x_loss: 45.5447 - val_output_y_loss: 260.0720 - val_output_z_loss: 71.9739 - val_output_x_msle: 45.5447 - val_output_y_msle: 260.0720 - val_output_z_msle: 71.9739 - lr: 1.0000e-07\n",
      "Epoch 235/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 134.5020 - output_x_loss: 44.1246 - output_y_loss: 256.1058 - output_z_loss: 72.0490 - output_x_msle: 44.1246 - output_y_msle: 256.1058 - output_z_msle: 72.0490 - val_loss: 136.3015 - val_output_x_loss: 45.5477 - val_output_y_loss: 259.6678 - val_output_z_loss: 71.0762 - val_output_x_msle: 45.5477 - val_output_y_msle: 259.6678 - val_output_z_msle: 71.0762 - lr: 1.0000e-07\n",
      "Epoch 236/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 134.0894 - output_x_loss: 44.1338 - output_y_loss: 255.3455 - output_z_loss: 71.4887 - output_x_msle: 44.1338 - output_y_msle: 255.3455 - output_z_msle: 71.4887 - val_loss: 135.7390 - val_output_x_loss: 45.5317 - val_output_y_loss: 258.7001 - val_output_z_loss: 70.2314 - val_output_x_msle: 45.5317 - val_output_y_msle: 258.7001 - val_output_z_msle: 70.2314 - lr: 1.0000e-07\n",
      "Epoch 237/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 133.6844 - output_x_loss: 44.0301 - output_y_loss: 254.7645 - output_z_loss: 70.8326 - output_x_msle: 44.0301 - output_y_msle: 254.7645 - output_z_msle: 70.8326 - val_loss: 135.5283 - val_output_x_loss: 45.5216 - val_output_y_loss: 258.5188 - val_output_z_loss: 69.5604 - val_output_x_msle: 45.5216 - val_output_y_msle: 258.5188 - val_output_z_msle: 69.5604 - lr: 1.0000e-07\n",
      "Epoch 238/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 133.3343 - output_x_loss: 43.9916 - output_y_loss: 254.3330 - output_z_loss: 70.0227 - output_x_msle: 43.9916 - output_y_msle: 254.3330 - output_z_msle: 70.0227 - val_loss: 135.2605 - val_output_x_loss: 45.5139 - val_output_y_loss: 258.0910 - val_output_z_loss: 69.0926 - val_output_x_msle: 45.5139 - val_output_y_msle: 258.0910 - val_output_z_msle: 69.0926 - lr: 1.0000e-07\n",
      "Epoch 239/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 132.9058 - output_x_loss: 43.9488 - output_y_loss: 253.8045 - output_z_loss: 69.0223 - output_x_msle: 43.9488 - output_y_msle: 253.8045 - output_z_msle: 69.0223 - val_loss: 134.7067 - val_output_x_loss: 45.1983 - val_output_y_loss: 257.5878 - val_output_z_loss: 67.9616 - val_output_x_msle: 45.1983 - val_output_y_msle: 257.5878 - val_output_z_msle: 67.9616 - lr: 1.0000e-07\n",
      "Epoch 240/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 132.5075 - output_x_loss: 43.9432 - output_y_loss: 253.5595 - output_z_loss: 67.5320 - output_x_msle: 43.9432 - output_y_msle: 253.5595 - output_z_msle: 67.5320 - val_loss: 134.2347 - val_output_x_loss: 45.2502 - val_output_y_loss: 257.4772 - val_output_z_loss: 65.7188 - val_output_x_msle: 45.2502 - val_output_y_msle: 257.4772 - val_output_z_msle: 65.7188 - lr: 1.0000e-07\n",
      "Epoch 241/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 132.0212 - output_x_loss: 44.0093 - output_y_loss: 253.3277 - output_z_loss: 65.4320 - output_x_msle: 44.0093 - output_y_msle: 253.3277 - output_z_msle: 65.4320 - val_loss: 133.8909 - val_output_x_loss: 45.1737 - val_output_y_loss: 257.1794 - val_output_z_loss: 64.7482 - val_output_x_msle: 45.1737 - val_output_y_msle: 257.1794 - val_output_z_msle: 64.7482 - lr: 1.0000e-07\n",
      "Epoch 242/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 131.3336 - output_x_loss: 43.9913 - output_y_loss: 253.1023 - output_z_loss: 62.4810 - output_x_msle: 43.9913 - output_y_msle: 253.1023 - output_z_msle: 62.4810 - val_loss: 133.1891 - val_output_x_loss: 45.1626 - val_output_y_loss: 257.2163 - val_output_z_loss: 61.1876 - val_output_x_msle: 45.1626 - val_output_y_msle: 257.2163 - val_output_z_msle: 61.1876 - lr: 1.0000e-07\n",
      "Epoch 243/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 130.6169 - output_x_loss: 43.8928 - output_y_loss: 252.9509 - output_z_loss: 59.3974 - output_x_msle: 43.8928 - output_y_msle: 252.9509 - output_z_msle: 59.3974 - val_loss: 132.3161 - val_output_x_loss: 45.1525 - val_output_y_loss: 256.9298 - val_output_z_loss: 57.4161 - val_output_x_msle: 45.1525 - val_output_y_msle: 256.9298 - val_output_z_msle: 57.4161 - lr: 1.0000e-07\n",
      "Epoch 244/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 129.8092 - output_x_loss: 43.8550 - output_y_loss: 252.8526 - output_z_loss: 55.6303 - output_x_msle: 43.8550 - output_y_msle: 252.8526 - output_z_msle: 55.6303 - val_loss: 131.3883 - val_output_x_loss: 45.1430 - val_output_y_loss: 256.6128 - val_output_z_loss: 53.4297 - val_output_x_msle: 45.1430 - val_output_y_msle: 256.6128 - val_output_z_msle: 53.4297 - lr: 1.0000e-07\n",
      "Epoch 245/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 129.3459 - output_x_loss: 43.7305 - output_y_loss: 252.7147 - output_z_loss: 53.8393 - output_x_msle: 43.7305 - output_y_msle: 252.7147 - output_z_msle: 53.8393 - val_loss: 130.8953 - val_output_x_loss: 45.1337 - val_output_y_loss: 256.4631 - val_output_z_loss: 51.2829 - val_output_x_msle: 45.1337 - val_output_y_msle: 256.4631 - val_output_z_msle: 51.2829 - lr: 1.0000e-07\n",
      "Epoch 246/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 128.7594 - output_x_loss: 43.6124 - output_y_loss: 252.5377 - output_z_loss: 51.4971 - output_x_msle: 43.6124 - output_y_msle: 252.5377 - output_z_msle: 51.4971 - val_loss: 130.2520 - val_output_x_loss: 45.1252 - val_output_y_loss: 255.9475 - val_output_z_loss: 49.1146 - val_output_x_msle: 45.1252 - val_output_y_msle: 255.9475 - val_output_z_msle: 49.1146 - lr: 1.0000e-07\n",
      "Epoch 247/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 128.1018 - output_x_loss: 43.4785 - output_y_loss: 252.3099 - output_z_loss: 48.9322 - output_x_msle: 43.4785 - output_y_msle: 252.3099 - output_z_msle: 48.9322 - val_loss: 129.2609 - val_output_x_loss: 43.9025 - val_output_y_loss: 255.7919 - val_output_z_loss: 46.9157 - val_output_x_msle: 43.9025 - val_output_y_msle: 255.7919 - val_output_z_msle: 46.9157 - lr: 1.0000e-07\n",
      "Epoch 248/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 127.4525 - output_x_loss: 42.8293 - output_y_loss: 252.0352 - output_z_loss: 47.5336 - output_x_msle: 42.8293 - output_y_msle: 252.0352 - output_z_msle: 47.5336 - val_loss: 128.9028 - val_output_x_loss: 43.8810 - val_output_y_loss: 255.4601 - val_output_z_loss: 45.8319 - val_output_x_msle: 43.8810 - val_output_y_msle: 255.4601 - val_output_z_msle: 45.8319 - lr: 1.0000e-07\n",
      "Epoch 249/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 127.0445 - output_x_loss: 42.5976 - output_y_loss: 251.7489 - output_z_loss: 46.5295 - output_x_msle: 42.5976 - output_y_msle: 251.7489 - output_z_msle: 46.5295 - val_loss: 128.6507 - val_output_x_loss: 43.8649 - val_output_y_loss: 255.3048 - val_output_z_loss: 44.9143 - val_output_x_msle: 43.8649 - val_output_y_msle: 255.3048 - val_output_z_msle: 44.9143 - lr: 1.0000e-07\n",
      "Epoch 250/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 126.6879 - output_x_loss: 42.5666 - output_y_loss: 251.5827 - output_z_loss: 45.1405 - output_x_msle: 42.5666 - output_y_msle: 251.5827 - output_z_msle: 45.1405 - val_loss: 128.3300 - val_output_x_loss: 43.9049 - val_output_y_loss: 255.0412 - val_output_z_loss: 43.7578 - val_output_x_msle: 43.9049 - val_output_y_msle: 255.0412 - val_output_z_msle: 43.7578 - lr: 1.0000e-07\n",
      "Epoch 251/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 126.2581 - output_x_loss: 42.5407 - output_y_loss: 251.3945 - output_z_loss: 43.4197 - output_x_msle: 42.5407 - output_y_msle: 251.3945 - output_z_msle: 43.4197 - val_loss: 127.9008 - val_output_x_loss: 43.8969 - val_output_y_loss: 254.8172 - val_output_z_loss: 42.0760 - val_output_x_msle: 43.8969 - val_output_y_msle: 254.8172 - val_output_z_msle: 42.0760 - lr: 1.0000e-07\n",
      "Epoch 252/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 125.7020 - output_x_loss: 42.3981 - output_y_loss: 251.0413 - output_z_loss: 41.6312 - output_x_msle: 42.3981 - output_y_msle: 251.0413 - output_z_msle: 41.6312 - val_loss: 127.3516 - val_output_x_loss: 43.9273 - val_output_y_loss: 254.3620 - val_output_z_loss: 40.1796 - val_output_x_msle: 43.9273 - val_output_y_msle: 254.3620 - val_output_z_msle: 40.1796 - lr: 1.0000e-07\n",
      "Epoch 253/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 125.2069 - output_x_loss: 42.2990 - output_y_loss: 250.5865 - output_z_loss: 40.2635 - output_x_msle: 42.2990 - output_y_msle: 250.5865 - output_z_msle: 40.2635 - val_loss: 126.7381 - val_output_x_loss: 43.5194 - val_output_y_loss: 254.0399 - val_output_z_loss: 38.5716 - val_output_x_msle: 43.5194 - val_output_y_msle: 254.0399 - val_output_z_msle: 38.5716 - lr: 1.0000e-07\n",
      "Epoch 254/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 124.3337 - output_x_loss: 42.0732 - output_y_loss: 250.2730 - output_z_loss: 36.9761 - output_x_msle: 42.0732 - output_y_msle: 250.2730 - output_z_msle: 36.9761 - val_loss: 125.8420 - val_output_x_loss: 43.3882 - val_output_y_loss: 253.5800 - val_output_z_loss: 35.2735 - val_output_x_msle: 43.3882 - val_output_y_msle: 253.5800 - val_output_z_msle: 35.2735 - lr: 1.0000e-07\n",
      "Epoch 255/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 124.0225 - output_x_loss: 42.4920 - output_y_loss: 249.9717 - output_z_loss: 35.1851 - output_x_msle: 42.4920 - output_y_msle: 249.9717 - output_z_msle: 35.1851 - val_loss: 125.7411 - val_output_x_loss: 43.7028 - val_output_y_loss: 253.3629 - val_output_z_loss: 34.5742 - val_output_x_msle: 43.7028 - val_output_y_msle: 253.3629 - val_output_z_msle: 34.5742 - lr: 1.0000e-07\n",
      "Epoch 256/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 123.8411 - output_x_loss: 42.6704 - output_y_loss: 249.5377 - output_z_loss: 34.7891 - output_x_msle: 42.6704 - output_y_msle: 249.5377 - output_z_msle: 34.7891 - val_loss: 125.4569 - val_output_x_loss: 43.5968 - val_output_y_loss: 252.8949 - val_output_z_loss: 34.3010 - val_output_x_msle: 43.5968 - val_output_y_msle: 252.8949 - val_output_z_msle: 34.3010 - lr: 1.0000e-07\n",
      "Epoch 257/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 123.5535 - output_x_loss: 42.5613 - output_y_loss: 249.0961 - output_z_loss: 34.4530 - output_x_msle: 42.5613 - output_y_msle: 249.0961 - output_z_msle: 34.4530 - val_loss: 125.0703 - val_output_x_loss: 43.3728 - val_output_y_loss: 252.2645 - val_output_z_loss: 34.0770 - val_output_x_msle: 43.3728 - val_output_y_msle: 252.2645 - val_output_z_msle: 34.0770 - lr: 1.0000e-07\n",
      "Epoch 258/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 123.0072 - output_x_loss: 42.2177 - output_y_loss: 248.3844 - output_z_loss: 33.8317 - output_x_msle: 42.2177 - output_y_msle: 248.3844 - output_z_msle: 33.8317 - val_loss: 124.7309 - val_output_x_loss: 43.1204 - val_output_y_loss: 251.9643 - val_output_z_loss: 33.4850 - val_output_x_msle: 43.1204 - val_output_y_msle: 251.9643 - val_output_z_msle: 33.4850 - lr: 1.0000e-07\n",
      "Epoch 259/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 122.5639 - output_x_loss: 42.0917 - output_y_loss: 247.8446 - output_z_loss: 32.9467 - output_x_msle: 42.0917 - output_y_msle: 247.8446 - output_z_msle: 32.9467 - val_loss: 124.1514 - val_output_x_loss: 43.1123 - val_output_y_loss: 251.1440 - val_output_z_loss: 32.2441 - val_output_x_msle: 43.1123 - val_output_y_msle: 251.1440 - val_output_z_msle: 32.2441 - lr: 1.0000e-07\n",
      "Epoch 260/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 122.2044 - output_x_loss: 42.0630 - output_y_loss: 247.4052 - output_z_loss: 32.0854 - output_x_msle: 42.0630 - output_y_msle: 247.4052 - output_z_msle: 32.0854 - val_loss: 123.7572 - val_output_x_loss: 43.1053 - val_output_y_loss: 250.3597 - val_output_z_loss: 31.8562 - val_output_x_msle: 43.1053 - val_output_y_msle: 250.3597 - val_output_z_msle: 31.8562 - lr: 1.0000e-07\n",
      "Epoch 261/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 121.9778 - output_x_loss: 42.0411 - output_y_loss: 247.0010 - output_z_loss: 31.8047 - output_x_msle: 42.0411 - output_y_msle: 247.0010 - output_z_msle: 31.8047 - val_loss: 123.4525 - val_output_x_loss: 43.1017 - val_output_y_loss: 249.7195 - val_output_z_loss: 31.6200 - val_output_x_msle: 43.1017 - val_output_y_msle: 249.7195 - val_output_z_msle: 31.6200 - lr: 1.0000e-07\n",
      "Epoch 262/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 121.6086 - output_x_loss: 42.0356 - output_y_loss: 246.4842 - output_z_loss: 31.0031 - output_x_msle: 42.0356 - output_y_msle: 246.4842 - output_z_msle: 31.0031 - val_loss: 122.7848 - val_output_x_loss: 43.0976 - val_output_y_loss: 248.6245 - val_output_z_loss: 30.4798 - val_output_x_msle: 43.0976 - val_output_y_msle: 248.6245 - val_output_z_msle: 30.4798 - lr: 1.0000e-07\n",
      "Epoch 263/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 121.0645 - output_x_loss: 42.0282 - output_y_loss: 245.6601 - output_z_loss: 29.9455 - output_x_msle: 42.0282 - output_y_msle: 245.6601 - output_z_msle: 29.9455 - val_loss: 122.0336 - val_output_x_loss: 43.0944 - val_output_y_loss: 247.2775 - val_output_z_loss: 29.4239 - val_output_x_msle: 43.0944 - val_output_y_msle: 247.2775 - val_output_z_msle: 29.4239 - lr: 1.0000e-07\n",
      "Epoch 264/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 120.5342 - output_x_loss: 42.0076 - output_y_loss: 244.5543 - output_z_loss: 29.5472 - output_x_msle: 42.0076 - output_y_msle: 244.5543 - output_z_msle: 29.5472 - val_loss: 121.6274 - val_output_x_loss: 43.0907 - val_output_y_loss: 246.4084 - val_output_z_loss: 29.1389 - val_output_x_msle: 43.0907 - val_output_y_msle: 246.4084 - val_output_z_msle: 29.1389 - lr: 1.0000e-07\n",
      "Epoch 265/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 120.0693 - output_x_loss: 41.9993 - output_y_loss: 243.6372 - output_z_loss: 29.0732 - output_x_msle: 41.9993 - output_y_msle: 243.6372 - output_z_msle: 29.0732 - val_loss: 121.2710 - val_output_x_loss: 43.0864 - val_output_y_loss: 245.8765 - val_output_z_loss: 28.4292 - val_output_x_msle: 43.0864 - val_output_y_msle: 245.8765 - val_output_z_msle: 28.4292 - lr: 1.0000e-07\n",
      "Epoch 266/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 119.3445 - output_x_loss: 41.9768 - output_y_loss: 242.2327 - output_z_loss: 28.3036 - output_x_msle: 41.9768 - output_y_msle: 242.2327 - output_z_msle: 28.3036 - val_loss: 120.6466 - val_output_x_loss: 43.0835 - val_output_y_loss: 244.4279 - val_output_z_loss: 28.2102 - val_output_x_msle: 43.0835 - val_output_y_msle: 244.4279 - val_output_z_msle: 28.2102 - lr: 1.0000e-07\n",
      "Epoch 267/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 118.7140 - output_x_loss: 41.9528 - output_y_loss: 240.7900 - output_z_loss: 28.0843 - output_x_msle: 41.9528 - output_y_msle: 240.7900 - output_z_msle: 28.0843 - val_loss: 119.5148 - val_output_x_loss: 43.0777 - val_output_y_loss: 241.7479 - val_output_z_loss: 27.9230 - val_output_x_msle: 43.0777 - val_output_y_msle: 241.7479 - val_output_z_msle: 27.9230 - lr: 1.0000e-07\n",
      "Epoch 268/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 118.0841 - output_x_loss: 41.9147 - output_y_loss: 239.4388 - output_z_loss: 27.7135 - output_x_msle: 41.9147 - output_y_msle: 239.4388 - output_z_msle: 27.7135 - val_loss: 118.8790 - val_output_x_loss: 43.0736 - val_output_y_loss: 240.3015 - val_output_z_loss: 27.6444 - val_output_x_msle: 43.0736 - val_output_y_msle: 240.3015 - val_output_z_msle: 27.6444 - lr: 1.0000e-07\n",
      "Epoch 269/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 117.5688 - output_x_loss: 41.9258 - output_y_loss: 238.2327 - output_z_loss: 27.5269 - output_x_msle: 41.9258 - output_y_msle: 238.2327 - output_z_msle: 27.5269 - val_loss: 118.0653 - val_output_x_loss: 43.0706 - val_output_y_loss: 238.4119 - val_output_z_loss: 27.3613 - val_output_x_msle: 43.0706 - val_output_y_msle: 238.4119 - val_output_z_msle: 27.3613 - lr: 1.0000e-07\n",
      "Epoch 270/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 116.7729 - output_x_loss: 41.9073 - output_y_loss: 236.4184 - output_z_loss: 27.2132 - output_x_msle: 41.9073 - output_y_msle: 236.4184 - output_z_msle: 27.2132 - val_loss: 117.1280 - val_output_x_loss: 43.0666 - val_output_y_loss: 236.1864 - val_output_z_loss: 27.1340 - val_output_x_msle: 43.0666 - val_output_y_msle: 236.1864 - val_output_z_msle: 27.1340 - lr: 1.0000e-07\n",
      "Epoch 271/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 115.6929 - output_x_loss: 41.9021 - output_y_loss: 233.9371 - output_z_loss: 26.7856 - output_x_msle: 41.9021 - output_y_msle: 233.9371 - output_z_msle: 26.7856 - val_loss: 116.4746 - val_output_x_loss: 43.0602 - val_output_y_loss: 234.7229 - val_output_z_loss: 26.8068 - val_output_x_msle: 43.0602 - val_output_y_msle: 234.7229 - val_output_z_msle: 26.8068 - lr: 1.0000e-07\n",
      "Epoch 272/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 114.9519 - output_x_loss: 41.8941 - output_y_loss: 232.2492 - output_z_loss: 26.4733 - output_x_msle: 41.8941 - output_y_msle: 232.2492 - output_z_msle: 26.4733 - val_loss: 115.3774 - val_output_x_loss: 43.0474 - val_output_y_loss: 232.1291 - val_output_z_loss: 26.5341 - val_output_x_msle: 43.0474 - val_output_y_msle: 232.1291 - val_output_z_msle: 26.5341 - lr: 1.0000e-07\n",
      "Epoch 273/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 113.8964 - output_x_loss: 41.8165 - output_y_loss: 229.8357 - output_z_loss: 26.1778 - output_x_msle: 41.8165 - output_y_msle: 229.8357 - output_z_msle: 26.1778 - val_loss: 114.2493 - val_output_x_loss: 42.9716 - val_output_y_loss: 229.7138 - val_output_z_loss: 25.8755 - val_output_x_msle: 42.9716 - val_output_y_msle: 229.7138 - val_output_z_msle: 25.8755 - lr: 1.0000e-07\n",
      "Epoch 274/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 113.1808 - output_x_loss: 41.7136 - output_y_loss: 228.3527 - output_z_loss: 25.7713 - output_x_msle: 41.7136 - output_y_msle: 228.3527 - output_z_msle: 25.7713 - val_loss: 113.3428 - val_output_x_loss: 42.9660 - val_output_y_loss: 227.6241 - val_output_z_loss: 25.5338 - val_output_x_msle: 42.9660 - val_output_y_msle: 227.6241 - val_output_z_msle: 25.5338 - lr: 1.0000e-07\n",
      "Epoch 275/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 111.9719 - output_x_loss: 41.6992 - output_y_loss: 225.5386 - output_z_loss: 25.3837 - output_x_msle: 41.6992 - output_y_msle: 225.5386 - output_z_msle: 25.3837 - val_loss: 111.9455 - val_output_x_loss: 42.9641 - val_output_y_loss: 224.2856 - val_output_z_loss: 25.2282 - val_output_x_msle: 42.9641 - val_output_y_msle: 224.2856 - val_output_z_msle: 25.2282 - lr: 1.0000e-07\n",
      "Epoch 276/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 111.2205 - output_x_loss: 41.6952 - output_y_loss: 223.8219 - output_z_loss: 25.0685 - output_x_msle: 41.6952 - output_y_msle: 223.8219 - output_z_msle: 25.0685 - val_loss: 111.3721 - val_output_x_loss: 42.9603 - val_output_y_loss: 223.0329 - val_output_z_loss: 24.8742 - val_output_x_msle: 42.9603 - val_output_y_msle: 223.0329 - val_output_z_msle: 24.8742 - lr: 1.0000e-07\n",
      "Epoch 277/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 110.4445 - output_x_loss: 41.6890 - output_y_loss: 222.0955 - output_z_loss: 24.6539 - output_x_msle: 41.6890 - output_y_msle: 222.0955 - output_z_msle: 24.6539 - val_loss: 110.8120 - val_output_x_loss: 42.9559 - val_output_y_loss: 221.7739 - val_output_z_loss: 24.6003 - val_output_x_msle: 42.9559 - val_output_y_msle: 221.7739 - val_output_z_msle: 24.6003 - lr: 1.0000e-07\n",
      "Epoch 278/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 109.7480 - output_x_loss: 41.6680 - output_y_loss: 220.4947 - output_z_loss: 24.4146 - output_x_msle: 41.6680 - output_y_msle: 220.4947 - output_z_msle: 24.4146 - val_loss: 110.4436 - val_output_x_loss: 42.9513 - val_output_y_loss: 220.9498 - val_output_z_loss: 24.4156 - val_output_x_msle: 42.9513 - val_output_y_msle: 220.9498 - val_output_z_msle: 24.4156 - lr: 1.0000e-07\n",
      "Epoch 279/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 109.1609 - output_x_loss: 41.6576 - output_y_loss: 219.1019 - output_z_loss: 24.2854 - output_x_msle: 41.6576 - output_y_msle: 219.1019 - output_z_msle: 24.2854 - val_loss: 109.9578 - val_output_x_loss: 42.9376 - val_output_y_loss: 219.8759 - val_output_z_loss: 24.1620 - val_output_x_msle: 42.9376 - val_output_y_msle: 219.8759 - val_output_z_msle: 24.1620 - lr: 1.0000e-07\n",
      "Epoch 280/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 108.6102 - output_x_loss: 41.5705 - output_y_loss: 217.9215 - output_z_loss: 24.0672 - output_x_msle: 41.5705 - output_y_msle: 217.9215 - output_z_msle: 24.0672 - val_loss: 109.4606 - val_output_x_loss: 42.9329 - val_output_y_loss: 218.7854 - val_output_z_loss: 23.8663 - val_output_x_msle: 42.9329 - val_output_y_msle: 218.7854 - val_output_z_msle: 23.8663 - lr: 1.0000e-07\n",
      "Epoch 281/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 108.0847 - output_x_loss: 41.5653 - output_y_loss: 216.6970 - output_z_loss: 23.8989 - output_x_msle: 41.5653 - output_y_msle: 216.6970 - output_z_msle: 23.8989 - val_loss: 108.5066 - val_output_x_loss: 42.8540 - val_output_y_loss: 216.7162 - val_output_z_loss: 23.3924 - val_output_x_msle: 42.8540 - val_output_y_msle: 216.7162 - val_output_z_msle: 23.3924 - lr: 1.0000e-07\n",
      "Epoch 282/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 107.5318 - output_x_loss: 41.5492 - output_y_loss: 215.4379 - output_z_loss: 23.6847 - output_x_msle: 41.5492 - output_y_msle: 215.4379 - output_z_msle: 23.6847 - val_loss: 107.8550 - val_output_x_loss: 42.8511 - val_output_y_loss: 215.1373 - val_output_z_loss: 23.2984 - val_output_x_msle: 42.8511 - val_output_y_msle: 215.1373 - val_output_z_msle: 23.2984 - lr: 1.0000e-07\n",
      "Epoch 283/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 106.9831 - output_x_loss: 41.5465 - output_y_loss: 214.1986 - output_z_loss: 23.4253 - output_x_msle: 41.5465 - output_y_msle: 214.1986 - output_z_msle: 23.4253 - val_loss: 107.4148 - val_output_x_loss: 42.8475 - val_output_y_loss: 214.1330 - val_output_z_loss: 23.1128 - val_output_x_msle: 42.8475 - val_output_y_msle: 214.1330 - val_output_z_msle: 23.1128 - lr: 1.0000e-07\n",
      "Epoch 284/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 106.6622 - output_x_loss: 41.5594 - output_y_loss: 213.4751 - output_z_loss: 23.2426 - output_x_msle: 41.5594 - output_y_msle: 213.4751 - output_z_msle: 23.2426 - val_loss: 107.0564 - val_output_x_loss: 42.8505 - val_output_y_loss: 213.3228 - val_output_z_loss: 22.9354 - val_output_x_msle: 42.8505 - val_output_y_msle: 213.3228 - val_output_z_msle: 22.9354 - lr: 1.0000e-07\n",
      "Epoch 285/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 106.1540 - output_x_loss: 41.5449 - output_y_loss: 212.3605 - output_z_loss: 22.9594 - output_x_msle: 41.5449 - output_y_msle: 212.3605 - output_z_msle: 22.9594 - val_loss: 106.6554 - val_output_x_loss: 42.8453 - val_output_y_loss: 212.4964 - val_output_z_loss: 22.5935 - val_output_x_msle: 42.8453 - val_output_y_msle: 212.4964 - val_output_z_msle: 22.5935 - lr: 1.0000e-07\n",
      "Epoch 286/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 105.8374 - output_x_loss: 41.5398 - output_y_loss: 211.7691 - output_z_loss: 22.5692 - output_x_msle: 41.5398 - output_y_msle: 211.7691 - output_z_msle: 22.5692 - val_loss: 106.4761 - val_output_x_loss: 42.8396 - val_output_y_loss: 212.1240 - val_output_z_loss: 22.4534 - val_output_x_msle: 42.8396 - val_output_y_msle: 212.1240 - val_output_z_msle: 22.4534 - lr: 1.0000e-07\n",
      "Epoch 287/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 105.5746 - output_x_loss: 41.5350 - output_y_loss: 211.2953 - output_z_loss: 22.2124 - output_x_msle: 41.5350 - output_y_msle: 211.2953 - output_z_msle: 22.2124 - val_loss: 106.0551 - val_output_x_loss: 42.6755 - val_output_y_loss: 211.4470 - val_output_z_loss: 22.0304 - val_output_x_msle: 42.6755 - val_output_y_msle: 211.4470 - val_output_z_msle: 22.0304 - lr: 1.0000e-07\n",
      "Epoch 288/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 105.1260 - output_x_loss: 41.5306 - output_y_loss: 210.5658 - output_z_loss: 21.4368 - output_x_msle: 41.5306 - output_y_msle: 210.5658 - output_z_msle: 21.4368 - val_loss: 105.5598 - val_output_x_loss: 42.6678 - val_output_y_loss: 210.7597 - val_output_z_loss: 20.9442 - val_output_x_msle: 42.6678 - val_output_y_msle: 210.7597 - val_output_z_msle: 20.9442 - lr: 1.0000e-07\n",
      "Epoch 289/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 104.6072 - output_x_loss: 41.5272 - output_y_loss: 209.6443 - output_z_loss: 20.6926 - output_x_msle: 41.5272 - output_y_msle: 209.6443 - output_z_msle: 20.6926 - val_loss: 105.1201 - val_output_x_loss: 42.6030 - val_output_y_loss: 209.9937 - val_output_z_loss: 20.4073 - val_output_x_msle: 42.6030 - val_output_y_msle: 209.9937 - val_output_z_msle: 20.4073 - lr: 1.0000e-07\n",
      "Epoch 290/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 104.3058 - output_x_loss: 41.4179 - output_y_loss: 209.3214 - output_z_loss: 20.0506 - output_x_msle: 41.4179 - output_y_msle: 209.3214 - output_z_msle: 20.0506 - val_loss: 104.9093 - val_output_x_loss: 42.6019 - val_output_y_loss: 209.9659 - val_output_z_loss: 19.4108 - val_output_x_msle: 42.6019 - val_output_y_msle: 209.9659 - val_output_z_msle: 19.4108 - lr: 1.0000e-07\n",
      "Epoch 291/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 104.0392 - output_x_loss: 41.4228 - output_y_loss: 209.1997 - output_z_loss: 18.9511 - output_x_msle: 41.4228 - output_y_msle: 209.1997 - output_z_msle: 18.9511 - val_loss: 104.6210 - val_output_x_loss: 42.5898 - val_output_y_loss: 209.9381 - val_output_z_loss: 18.0492 - val_output_x_msle: 42.5898 - val_output_y_msle: 209.9381 - val_output_z_msle: 18.0492 - lr: 1.0000e-07\n",
      "Epoch 292/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 103.7229 - output_x_loss: 41.3448 - output_y_loss: 209.1508 - output_z_loss: 17.6234 - output_x_msle: 41.3448 - output_y_msle: 209.1508 - output_z_msle: 17.6234 - val_loss: 104.4423 - val_output_x_loss: 42.6385 - val_output_y_loss: 209.8224 - val_output_z_loss: 17.2895 - val_output_x_msle: 42.6385 - val_output_y_msle: 209.8224 - val_output_z_msle: 17.2895 - lr: 1.0000e-07\n",
      "Epoch 293/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 103.5256 - output_x_loss: 41.2912 - output_y_loss: 209.0124 - output_z_loss: 17.0208 - output_x_msle: 41.2912 - output_y_msle: 209.0124 - output_z_msle: 17.0208 - val_loss: 104.2904 - val_output_x_loss: 42.6319 - val_output_y_loss: 209.7646 - val_output_z_loss: 16.6591 - val_output_x_msle: 42.6319 - val_output_y_msle: 209.7646 - val_output_z_msle: 16.6591 - lr: 1.0000e-07\n",
      "Epoch 294/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 103.2091 - output_x_loss: 41.2163 - output_y_loss: 208.7754 - output_z_loss: 16.0619 - output_x_msle: 41.2163 - output_y_msle: 208.7754 - output_z_msle: 16.0619 - val_loss: 104.0186 - val_output_x_loss: 42.6265 - val_output_y_loss: 209.2894 - val_output_z_loss: 16.2611 - val_output_x_msle: 42.6265 - val_output_y_msle: 209.2894 - val_output_z_msle: 16.2611 - lr: 1.0000e-07\n",
      "Epoch 295/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 103.0350 - output_x_loss: 41.1389 - output_y_loss: 208.5964 - output_z_loss: 15.7044 - output_x_msle: 41.1389 - output_y_msle: 208.5964 - output_z_msle: 15.7044 - val_loss: 103.8170 - val_output_x_loss: 42.4574 - val_output_y_loss: 209.2792 - val_output_z_loss: 15.6115 - val_output_x_msle: 42.4574 - val_output_y_msle: 209.2792 - val_output_z_msle: 15.6115 - lr: 1.0000e-07\n",
      "Epoch 296/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.8735 - output_x_loss: 41.0948 - output_y_loss: 208.4897 - output_z_loss: 15.1982 - output_x_msle: 41.0948 - output_y_msle: 208.4897 - output_z_msle: 15.1982 - val_loss: 103.6878 - val_output_x_loss: 42.3260 - val_output_y_loss: 209.2309 - val_output_z_loss: 15.3251 - val_output_x_msle: 42.3260 - val_output_y_msle: 209.2309 - val_output_z_msle: 15.3251 - lr: 1.0000e-07\n",
      "Epoch 297/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.7713 - output_x_loss: 41.0515 - output_y_loss: 208.4476 - output_z_loss: 14.8580 - output_x_msle: 41.0515 - output_y_msle: 208.4476 - output_z_msle: 14.8580 - val_loss: 103.5518 - val_output_x_loss: 42.1573 - val_output_y_loss: 209.1497 - val_output_z_loss: 15.1453 - val_output_x_msle: 42.1573 - val_output_y_msle: 209.1497 - val_output_z_msle: 15.1453 - lr: 1.0000e-07\n",
      "Epoch 298/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.6557 - output_x_loss: 40.9754 - output_y_loss: 208.4096 - output_z_loss: 14.5084 - output_x_msle: 40.9754 - output_y_msle: 208.4096 - output_z_msle: 14.5084 - val_loss: 103.4665 - val_output_x_loss: 41.9877 - val_output_y_loss: 209.2202 - val_output_z_loss: 14.9165 - val_output_x_msle: 41.9877 - val_output_y_msle: 209.2202 - val_output_z_msle: 14.9165 - lr: 1.0000e-07\n",
      "Epoch 299/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.5443 - output_x_loss: 40.8763 - output_y_loss: 208.3987 - output_z_loss: 14.1716 - output_x_msle: 40.8763 - output_y_msle: 208.3987 - output_z_msle: 14.1716 - val_loss: 103.2312 - val_output_x_loss: 41.6345 - val_output_y_loss: 209.1359 - val_output_z_loss: 14.6150 - val_output_x_msle: 41.6345 - val_output_y_msle: 209.1359 - val_output_z_msle: 14.6150 - lr: 1.0000e-07\n",
      "Epoch 300/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.3693 - output_x_loss: 40.6379 - output_y_loss: 208.3920 - output_z_loss: 13.7870 - output_x_msle: 40.6379 - output_y_msle: 208.3920 - output_z_msle: 13.7870 - val_loss: 103.0366 - val_output_x_loss: 41.2997 - val_output_y_loss: 209.1283 - val_output_z_loss: 14.3267 - val_output_x_msle: 41.2997 - val_output_y_msle: 209.1283 - val_output_z_msle: 14.3267 - lr: 1.0000e-07\n",
      "Epoch 301/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.2634 - output_x_loss: 40.5218 - output_y_loss: 208.3846 - output_z_loss: 13.5044 - output_x_msle: 40.5218 - output_y_msle: 208.3846 - output_z_msle: 13.5044 - val_loss: 102.9362 - val_output_x_loss: 41.2789 - val_output_y_loss: 209.1198 - val_output_z_loss: 13.8833 - val_output_x_msle: 41.2789 - val_output_y_msle: 209.1198 - val_output_z_msle: 13.8833 - lr: 1.0000e-07\n",
      "Epoch 302/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.2200 - output_x_loss: 40.5132 - output_y_loss: 208.3589 - output_z_loss: 13.3558 - output_x_msle: 40.5132 - output_y_msle: 208.3589 - output_z_msle: 13.3558 - val_loss: 102.7521 - val_output_x_loss: 41.1110 - val_output_y_loss: 209.1104 - val_output_z_loss: 13.3176 - val_output_x_msle: 41.1110 - val_output_y_msle: 209.1104 - val_output_z_msle: 13.3176 - lr: 1.0000e-07\n",
      "Epoch 303/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 102.0872 - output_x_loss: 40.4801 - output_y_loss: 208.3517 - output_z_loss: 12.7722 - output_x_msle: 40.4801 - output_y_msle: 208.3517 - output_z_msle: 12.7722 - val_loss: 102.6019 - val_output_x_loss: 41.0995 - val_output_y_loss: 209.0965 - val_output_z_loss: 12.6176 - val_output_x_msle: 41.0995 - val_output_y_msle: 209.0965 - val_output_z_msle: 12.6176 - lr: 1.0000e-07\n",
      "Epoch 304/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.9873 - output_x_loss: 40.4740 - output_y_loss: 208.3437 - output_z_loss: 12.3012 - output_x_msle: 40.4740 - output_y_msle: 208.3437 - output_z_msle: 12.3012 - val_loss: 102.4400 - val_output_x_loss: 40.9964 - val_output_y_loss: 209.0050 - val_output_z_loss: 12.1972 - val_output_x_msle: 40.9964 - val_output_y_msle: 209.0050 - val_output_z_msle: 12.1972 - lr: 1.0000e-07\n",
      "Epoch 305/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.9364 - output_x_loss: 40.4905 - output_y_loss: 208.3372 - output_z_loss: 12.0266 - output_x_msle: 40.4905 - output_y_msle: 208.3372 - output_z_msle: 12.0266 - val_loss: 102.5711 - val_output_x_loss: 41.4032 - val_output_y_loss: 209.0018 - val_output_z_loss: 12.0454 - val_output_x_msle: 41.4032 - val_output_y_msle: 209.0018 - val_output_z_msle: 12.0454 - lr: 1.0000e-07\n",
      "Epoch 306/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.9262 - output_x_loss: 40.5101 - output_y_loss: 208.3317 - output_z_loss: 11.9475 - output_x_msle: 40.5101 - output_y_msle: 208.3317 - output_z_msle: 11.9475 - val_loss: 102.4767 - val_output_x_loss: 41.3935 - val_output_y_loss: 208.9962 - val_output_z_loss: 11.6041 - val_output_x_msle: 41.3935 - val_output_y_msle: 208.9962 - val_output_z_msle: 11.6041 - lr: 1.0000e-07\n",
      "Epoch 307/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.8641 - output_x_loss: 40.5033 - output_y_loss: 208.3224 - output_z_loss: 11.6688 - output_x_msle: 40.5033 - output_y_msle: 208.3224 - output_z_msle: 11.6688 - val_loss: 102.3789 - val_output_x_loss: 41.2280 - val_output_y_loss: 208.9894 - val_output_z_loss: 11.4599 - val_output_x_msle: 41.2280 - val_output_y_msle: 208.9894 - val_output_z_msle: 11.4599 - lr: 1.0000e-07\n",
      "Epoch 308/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.8184 - output_x_loss: 40.4977 - output_y_loss: 208.2904 - output_z_loss: 11.5155 - output_x_msle: 40.4977 - output_y_msle: 208.2904 - output_z_msle: 11.5155 - val_loss: 102.3573 - val_output_x_loss: 41.2182 - val_output_y_loss: 208.9788 - val_output_z_loss: 11.3924 - val_output_x_msle: 41.2182 - val_output_y_msle: 208.9788 - val_output_z_msle: 11.3924 - lr: 1.0000e-07\n",
      "Epoch 309/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.7211 - output_x_loss: 40.4923 - output_y_loss: 208.2552 - output_z_loss: 11.1105 - output_x_msle: 40.4923 - output_y_msle: 208.2552 - output_z_msle: 11.1105 - val_loss: 102.2421 - val_output_x_loss: 41.0611 - val_output_y_loss: 208.9673 - val_output_z_loss: 11.1537 - val_output_x_msle: 41.0611 - val_output_y_msle: 208.9673 - val_output_z_msle: 11.1537 - lr: 1.0000e-07\n",
      "Epoch 310/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.6318 - output_x_loss: 40.4872 - output_y_loss: 208.2221 - output_z_loss: 10.7404 - output_x_msle: 40.4872 - output_y_msle: 208.2221 - output_z_msle: 10.7404 - val_loss: 102.1898 - val_output_x_loss: 41.0422 - val_output_y_loss: 208.9573 - val_output_z_loss: 10.9499 - val_output_x_msle: 41.0422 - val_output_y_msle: 208.9573 - val_output_z_msle: 10.9499 - lr: 1.0000e-07\n",
      "Epoch 311/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.5096 - output_x_loss: 40.4821 - output_y_loss: 208.1907 - output_z_loss: 10.2021 - output_x_msle: 40.4821 - output_y_msle: 208.1907 - output_z_msle: 10.2021 - val_loss: 102.0991 - val_output_x_loss: 41.0331 - val_output_y_loss: 208.9466 - val_output_z_loss: 10.5361 - val_output_x_msle: 41.0331 - val_output_y_msle: 208.9466 - val_output_z_msle: 10.5361 - lr: 1.0000e-07\n",
      "Epoch 312/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.3283 - output_x_loss: 40.4770 - output_y_loss: 208.1601 - output_z_loss: 9.3671 - output_x_msle: 40.4770 - output_y_msle: 208.1601 - output_z_msle: 9.3671 - val_loss: 102.0258 - val_output_x_loss: 41.0253 - val_output_y_loss: 208.9368 - val_output_z_loss: 10.2049 - val_output_x_msle: 41.0253 - val_output_y_msle: 208.9368 - val_output_z_msle: 10.2049 - lr: 1.0000e-07\n",
      "Epoch 313/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.2362 - output_x_loss: 40.4721 - output_y_loss: 208.1458 - output_z_loss: 8.9451 - output_x_msle: 40.4721 - output_y_msle: 208.1458 - output_z_msle: 8.9451 - val_loss: 101.9420 - val_output_x_loss: 41.0184 - val_output_y_loss: 208.9246 - val_output_z_loss: 9.8239 - val_output_x_msle: 41.0184 - val_output_y_msle: 208.9246 - val_output_z_msle: 9.8239 - lr: 1.0000e-07\n",
      "Epoch 314/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 101.0723 - output_x_loss: 40.4672 - output_y_loss: 208.1053 - output_z_loss: 8.2164 - output_x_msle: 40.4672 - output_y_msle: 208.1053 - output_z_msle: 8.2164 - val_loss: 101.7631 - val_output_x_loss: 40.8885 - val_output_y_loss: 208.8956 - val_output_z_loss: 9.2471 - val_output_x_msle: 40.8885 - val_output_y_msle: 208.8956 - val_output_z_msle: 9.2471 - lr: 1.0000e-07\n",
      "Epoch 315/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.8480 - output_x_loss: 40.3931 - output_y_loss: 208.0463 - output_z_loss: 7.3610 - output_x_msle: 40.3931 - output_y_msle: 208.0463 - output_z_msle: 7.3610 - val_loss: 101.6327 - val_output_x_loss: 40.8694 - val_output_y_loss: 208.8854 - val_output_z_loss: 8.6537 - val_output_x_msle: 40.8694 - val_output_y_msle: 208.8854 - val_output_z_msle: 8.6537 - lr: 1.0000e-07\n",
      "Epoch 316/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.7548 - output_x_loss: 40.3468 - output_y_loss: 208.0342 - output_z_loss: 7.0120 - output_x_msle: 40.3468 - output_y_msle: 208.0342 - output_z_msle: 7.0120 - val_loss: 101.5843 - val_output_x_loss: 40.8618 - val_output_y_loss: 208.8716 - val_output_z_loss: 8.4544 - val_output_x_msle: 40.8618 - val_output_y_msle: 208.8716 - val_output_z_msle: 8.4544 - lr: 1.0000e-07\n",
      "Epoch 317/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.6769 - output_x_loss: 40.3389 - output_y_loss: 207.9989 - output_z_loss: 6.7090 - output_x_msle: 40.3389 - output_y_msle: 207.9989 - output_z_msle: 6.7090 - val_loss: 101.5487 - val_output_x_loss: 40.8553 - val_output_y_loss: 208.8556 - val_output_z_loss: 8.3218 - val_output_x_msle: 40.8553 - val_output_y_msle: 208.8556 - val_output_z_msle: 8.3218 - lr: 1.0000e-07\n",
      "Epoch 318/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.6553 - output_x_loss: 40.3510 - output_y_loss: 207.9671 - output_z_loss: 6.6399 - output_x_msle: 40.3510 - output_y_msle: 207.9671 - output_z_msle: 6.6399 - val_loss: 101.5130 - val_output_x_loss: 40.8531 - val_output_y_loss: 208.8420 - val_output_z_loss: 8.1748 - val_output_x_msle: 40.8531 - val_output_y_msle: 208.8420 - val_output_z_msle: 8.1748 - lr: 1.0000e-07\n",
      "Epoch 319/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.6153 - output_x_loss: 40.2963 - output_y_loss: 207.9511 - output_z_loss: 6.5817 - output_x_msle: 40.2963 - output_y_msle: 207.9511 - output_z_msle: 6.5817 - val_loss: 101.4371 - val_output_x_loss: 40.8468 - val_output_y_loss: 208.8198 - val_output_z_loss: 7.8523 - val_output_x_msle: 40.8468 - val_output_y_msle: 208.8198 - val_output_z_msle: 7.8523 - lr: 1.0000e-07\n",
      "Epoch 320/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.5704 - output_x_loss: 40.2907 - output_y_loss: 207.8972 - output_z_loss: 6.4761 - output_x_msle: 40.2907 - output_y_msle: 207.8972 - output_z_msle: 6.4761 - val_loss: 101.3340 - val_output_x_loss: 40.6929 - val_output_y_loss: 208.7993 - val_output_z_loss: 7.6856 - val_output_x_msle: 40.6929 - val_output_y_msle: 208.7993 - val_output_z_msle: 7.6856 - lr: 1.0000e-07\n",
      "Epoch 321/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.5362 - output_x_loss: 40.2860 - output_y_loss: 207.8638 - output_z_loss: 6.3815 - output_x_msle: 40.2860 - output_y_msle: 207.8638 - output_z_msle: 6.3815 - val_loss: 101.2406 - val_output_x_loss: 40.6749 - val_output_y_loss: 208.7594 - val_output_z_loss: 7.3346 - val_output_x_msle: 40.6749 - val_output_y_msle: 208.7594 - val_output_z_msle: 7.3346 - lr: 1.0000e-07\n",
      "Epoch 322/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.4897 - output_x_loss: 40.2813 - output_y_loss: 207.8301 - output_z_loss: 6.2257 - output_x_msle: 40.2813 - output_y_msle: 207.8301 - output_z_msle: 6.2257 - val_loss: 101.1718 - val_output_x_loss: 40.6674 - val_output_y_loss: 208.6709 - val_output_z_loss: 7.1823 - val_output_x_msle: 40.6674 - val_output_y_msle: 208.6709 - val_output_z_msle: 7.1823 - lr: 1.0000e-07\n",
      "Epoch 323/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.3689 - output_x_loss: 40.2061 - output_y_loss: 207.8152 - output_z_loss: 5.8018 - output_x_msle: 40.2061 - output_y_msle: 207.8152 - output_z_msle: 5.8018 - val_loss: 100.9700 - val_output_x_loss: 40.6517 - val_output_y_loss: 208.6383 - val_output_z_loss: 6.2702 - val_output_x_msle: 40.6517 - val_output_y_msle: 208.6383 - val_output_z_msle: 6.2702 - lr: 1.0000e-07\n",
      "Epoch 324/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 100.1057 - output_x_loss: 40.1858 - output_y_loss: 207.7934 - output_z_loss: 4.5701 - output_x_msle: 40.1858 - output_y_msle: 207.7934 - output_z_msle: 4.5701 - val_loss: 100.7445 - val_output_x_loss: 40.6483 - val_output_y_loss: 208.5351 - val_output_z_loss: 5.3556 - val_output_x_msle: 40.6483 - val_output_y_msle: 208.5351 - val_output_z_msle: 5.3556 - lr: 1.0000e-07\n",
      "Epoch 325/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.9589 - output_x_loss: 40.1578 - output_y_loss: 207.7511 - output_z_loss: 3.9769 - output_x_msle: 40.1578 - output_y_msle: 207.7511 - output_z_msle: 3.9769 - val_loss: 100.6254 - val_output_x_loss: 40.6414 - val_output_y_loss: 208.5112 - val_output_z_loss: 4.8217 - val_output_x_msle: 40.6414 - val_output_y_msle: 208.5112 - val_output_z_msle: 4.8217 - lr: 1.0000e-07\n",
      "Epoch 326/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.8024 - output_x_loss: 40.1738 - output_y_loss: 207.7100 - output_z_loss: 3.2443 - output_x_msle: 40.1738 - output_y_msle: 207.7100 - output_z_msle: 3.2443 - val_loss: 100.4115 - val_output_x_loss: 40.4545 - val_output_y_loss: 208.4922 - val_output_z_loss: 4.1640 - val_output_x_msle: 40.4545 - val_output_y_msle: 208.4922 - val_output_z_msle: 4.1640 - lr: 1.0000e-07\n",
      "Epoch 327/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.5495 - output_x_loss: 40.0242 - output_y_loss: 207.6924 - output_z_loss: 2.3141 - output_x_msle: 40.0242 - output_y_msle: 207.6924 - output_z_msle: 2.3141 - val_loss: 99.9426 - val_output_x_loss: 40.4511 - val_output_y_loss: 208.4734 - val_output_z_loss: 1.8639 - val_output_x_msle: 40.4511 - val_output_y_msle: 208.4734 - val_output_z_msle: 1.8639 - lr: 1.0000e-07\n",
      "Epoch 328/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.3096 - output_x_loss: 40.0237 - output_y_loss: 207.6387 - output_z_loss: 1.2229 - output_x_msle: 40.0237 - output_y_msle: 207.6387 - output_z_msle: 1.2229 - val_loss: 99.8865 - val_output_x_loss: 40.4505 - val_output_y_loss: 208.4180 - val_output_z_loss: 1.6954 - val_output_x_msle: 40.4505 - val_output_y_msle: 208.4180 - val_output_z_msle: 1.6954 - lr: 1.0000e-07\n",
      "Epoch 329/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.2744 - output_x_loss: 40.0222 - output_y_loss: 207.5579 - output_z_loss: 1.2120 - output_x_msle: 40.0222 - output_y_msle: 207.5579 - output_z_msle: 1.2120 - val_loss: 99.8615 - val_output_x_loss: 40.4483 - val_output_y_loss: 208.4095 - val_output_z_loss: 1.5916 - val_output_x_msle: 40.4483 - val_output_y_msle: 208.4095 - val_output_z_msle: 1.5916 - lr: 1.0000e-07\n",
      "Epoch 330/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.2523 - output_x_loss: 40.0201 - output_y_loss: 207.5152 - output_z_loss: 1.1908 - output_x_msle: 40.0201 - output_y_msle: 207.5152 - output_z_msle: 1.1908 - val_loss: 99.8535 - val_output_x_loss: 40.4459 - val_output_y_loss: 208.3980 - val_output_z_loss: 1.5796 - val_output_x_msle: 40.4459 - val_output_y_msle: 208.3980 - val_output_z_msle: 1.5796 - lr: 1.0000e-07\n",
      "Epoch 331/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.2308 - output_x_loss: 40.0180 - output_y_loss: 207.4672 - output_z_loss: 1.1838 - output_x_msle: 40.0180 - output_y_msle: 207.4672 - output_z_msle: 1.1838 - val_loss: 99.8405 - val_output_x_loss: 40.4438 - val_output_y_loss: 208.3872 - val_output_z_loss: 1.5406 - val_output_x_msle: 40.4438 - val_output_y_msle: 208.3872 - val_output_z_msle: 1.5406 - lr: 1.0000e-07\n",
      "Epoch 332/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.2180 - output_x_loss: 40.0161 - output_y_loss: 207.4573 - output_z_loss: 1.1433 - output_x_msle: 40.0161 - output_y_msle: 207.4573 - output_z_msle: 1.1433 - val_loss: 99.8052 - val_output_x_loss: 40.4417 - val_output_y_loss: 208.3718 - val_output_z_loss: 1.3989 - val_output_x_msle: 40.4417 - val_output_y_msle: 208.3718 - val_output_z_msle: 1.3989 - lr: 1.0000e-07\n",
      "Epoch 333/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.2083 - output_x_loss: 40.0141 - output_y_loss: 207.4457 - output_z_loss: 1.1219 - output_x_msle: 40.0141 - output_y_msle: 207.4457 - output_z_msle: 1.1219 - val_loss: 99.7635 - val_output_x_loss: 40.4396 - val_output_y_loss: 208.2770 - val_output_z_loss: 1.3843 - val_output_x_msle: 40.4396 - val_output_y_msle: 208.2770 - val_output_z_msle: 1.3843 - lr: 1.0000e-07\n",
      "Epoch 334/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.1856 - output_x_loss: 40.0122 - output_y_loss: 207.4066 - output_z_loss: 1.0902 - output_x_msle: 40.0122 - output_y_msle: 207.4066 - output_z_msle: 1.0902 - val_loss: 99.7341 - val_output_x_loss: 40.4374 - val_output_y_loss: 208.2558 - val_output_z_loss: 1.2840 - val_output_x_msle: 40.4374 - val_output_y_msle: 208.2558 - val_output_z_msle: 1.2840 - lr: 1.0000e-07\n",
      "Epoch 335/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.1639 - output_x_loss: 40.0102 - output_y_loss: 207.3767 - output_z_loss: 1.0456 - output_x_msle: 40.0102 - output_y_msle: 207.3767 - output_z_msle: 1.0456 - val_loss: 99.6931 - val_output_x_loss: 40.4351 - val_output_y_loss: 208.2373 - val_output_z_loss: 1.1205 - val_output_x_msle: 40.4351 - val_output_y_msle: 208.2373 - val_output_z_msle: 1.1205 - lr: 1.0000e-07\n",
      "Epoch 336/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.1142 - output_x_loss: 40.0081 - output_y_loss: 207.2911 - output_z_loss: 0.9727 - output_x_msle: 40.0081 - output_y_msle: 207.2911 - output_z_msle: 0.9727 - val_loss: 99.6847 - val_output_x_loss: 40.4327 - val_output_y_loss: 208.2209 - val_output_z_loss: 1.1162 - val_output_x_msle: 40.4327 - val_output_y_msle: 208.2209 - val_output_z_msle: 1.1162 - lr: 1.0000e-07\n",
      "Epoch 337/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.0877 - output_x_loss: 39.9795 - output_y_loss: 207.2570 - output_z_loss: 0.9658 - output_x_msle: 39.9795 - output_y_msle: 207.2570 - output_z_msle: 0.9658 - val_loss: 99.6745 - val_output_x_loss: 40.4294 - val_output_y_loss: 208.2029 - val_output_z_loss: 1.1081 - val_output_x_msle: 40.4294 - val_output_y_msle: 208.2029 - val_output_z_msle: 1.1081 - lr: 1.0000e-07\n",
      "Epoch 338/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.0764 - output_x_loss: 39.9754 - output_y_loss: 207.2451 - output_z_loss: 0.9412 - output_x_msle: 39.9754 - output_y_msle: 207.2451 - output_z_msle: 0.9412 - val_loss: 99.6595 - val_output_x_loss: 40.4263 - val_output_y_loss: 208.1764 - val_output_z_loss: 1.0922 - val_output_x_msle: 40.4263 - val_output_y_msle: 208.1764 - val_output_z_msle: 1.0922 - lr: 1.0000e-07\n",
      "Epoch 339/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.0538 - output_x_loss: 39.9635 - output_y_loss: 207.2294 - output_z_loss: 0.8832 - output_x_msle: 39.9635 - output_y_msle: 207.2294 - output_z_msle: 0.8832 - val_loss: 99.5673 - val_output_x_loss: 40.4235 - val_output_y_loss: 207.9888 - val_output_z_loss: 1.0118 - val_output_x_msle: 40.4235 - val_output_y_msle: 207.9888 - val_output_z_msle: 1.0118 - lr: 1.0000e-07\n",
      "Epoch 340/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 99.0341 - output_x_loss: 39.9434 - output_y_loss: 207.2050 - output_z_loss: 0.8739 - output_x_msle: 39.9434 - output_y_msle: 207.2050 - output_z_msle: 0.8739 - val_loss: 99.5457 - val_output_x_loss: 40.4209 - val_output_y_loss: 207.9446 - val_output_z_loss: 0.9975 - val_output_x_msle: 40.4209 - val_output_y_msle: 207.9446 - val_output_z_msle: 0.9975 - lr: 1.0000e-07\n",
      "Epoch 341/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.9969 - output_x_loss: 39.9407 - output_y_loss: 207.1453 - output_z_loss: 0.8122 - output_x_msle: 39.9407 - output_y_msle: 207.1453 - output_z_msle: 0.8122 - val_loss: 99.4934 - val_output_x_loss: 40.4183 - val_output_y_loss: 207.8589 - val_output_z_loss: 0.9126 - val_output_x_msle: 40.4183 - val_output_y_msle: 207.8589 - val_output_z_msle: 0.9126 - lr: 1.0000e-07\n",
      "Epoch 342/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.9871 - output_x_loss: 40.0399 - output_y_loss: 207.0399 - output_z_loss: 0.7757 - output_x_msle: 40.0399 - output_y_msle: 207.0399 - output_z_msle: 0.7757 - val_loss: 99.4348 - val_output_x_loss: 40.2934 - val_output_y_loss: 207.8385 - val_output_z_loss: 0.9103 - val_output_x_msle: 40.2934 - val_output_y_msle: 207.8385 - val_output_z_msle: 0.9103 - lr: 1.0000e-07\n",
      "Epoch 343/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.9060 - output_x_loss: 39.9077 - output_y_loss: 206.9707 - output_z_loss: 0.7730 - output_x_msle: 39.9077 - output_y_msle: 206.9707 - output_z_msle: 0.7730 - val_loss: 99.4269 - val_output_x_loss: 40.2893 - val_output_y_loss: 207.8240 - val_output_z_loss: 0.9076 - val_output_x_msle: 40.2893 - val_output_y_msle: 207.8240 - val_output_z_msle: 0.9076 - lr: 1.0000e-07\n",
      "Epoch 344/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.8830 - output_x_loss: 39.9052 - output_y_loss: 206.9197 - output_z_loss: 0.7650 - output_x_msle: 39.9052 - output_y_msle: 206.9197 - output_z_msle: 0.7650 - val_loss: 99.4148 - val_output_x_loss: 40.2854 - val_output_y_loss: 207.8050 - val_output_z_loss: 0.8933 - val_output_x_msle: 40.2854 - val_output_y_msle: 207.8050 - val_output_z_msle: 0.8933 - lr: 1.0000e-07\n",
      "Epoch 345/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.8565 - output_x_loss: 39.9179 - output_y_loss: 206.8589 - output_z_loss: 0.7291 - output_x_msle: 39.9179 - output_y_msle: 206.8589 - output_z_msle: 0.7291 - val_loss: 99.4085 - val_output_x_loss: 40.4133 - val_output_y_loss: 207.6642 - val_output_z_loss: 0.8873 - val_output_x_msle: 40.4133 - val_output_y_msle: 207.6642 - val_output_z_msle: 0.8873 - lr: 1.0000e-07\n",
      "Epoch 346/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.8383 - output_x_loss: 39.9605 - output_y_loss: 206.7715 - output_z_loss: 0.7274 - output_x_msle: 39.9605 - output_y_msle: 206.7715 - output_z_msle: 0.7274 - val_loss: 99.4011 - val_output_x_loss: 40.4094 - val_output_y_loss: 207.6539 - val_output_z_loss: 0.8789 - val_output_x_msle: 40.4094 - val_output_y_msle: 207.6539 - val_output_z_msle: 0.8789 - lr: 1.0000e-07\n",
      "Epoch 347/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.8322 - output_x_loss: 39.9570 - output_y_loss: 206.7606 - output_z_loss: 0.7261 - output_x_msle: 39.9570 - output_y_msle: 206.7606 - output_z_msle: 0.7261 - val_loss: 99.3814 - val_output_x_loss: 40.4068 - val_output_y_loss: 207.6429 - val_output_z_loss: 0.8078 - val_output_x_msle: 40.4068 - val_output_y_msle: 207.6429 - val_output_z_msle: 0.8078 - lr: 1.0000e-07\n",
      "Epoch 348/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.8252 - output_x_loss: 39.9545 - output_y_loss: 206.7462 - output_z_loss: 0.7245 - output_x_msle: 39.9545 - output_y_msle: 206.7462 - output_z_msle: 0.7245 - val_loss: 99.3742 - val_output_x_loss: 40.4042 - val_output_y_loss: 207.6279 - val_output_z_loss: 0.8067 - val_output_x_msle: 40.4042 - val_output_y_msle: 207.6279 - val_output_z_msle: 0.8067 - lr: 1.0000e-07\n",
      "Epoch 349/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.7848 - output_x_loss: 39.8904 - output_y_loss: 206.7106 - output_z_loss: 0.7220 - output_x_msle: 39.8904 - output_y_msle: 206.7106 - output_z_msle: 0.7220 - val_loss: 99.3643 - val_output_x_loss: 40.3952 - val_output_y_loss: 207.6129 - val_output_z_loss: 0.8050 - val_output_x_msle: 40.3952 - val_output_y_msle: 207.6129 - val_output_z_msle: 0.8050 - lr: 1.0000e-07\n",
      "Epoch 350/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.7659 - output_x_loss: 39.8818 - output_y_loss: 206.6745 - output_z_loss: 0.7173 - output_x_msle: 39.8818 - output_y_msle: 206.6745 - output_z_msle: 0.7173 - val_loss: 99.3555 - val_output_x_loss: 40.3926 - val_output_y_loss: 207.5950 - val_output_z_loss: 0.8023 - val_output_x_msle: 40.3926 - val_output_y_msle: 207.5950 - val_output_z_msle: 0.8023 - lr: 1.0000e-07\n",
      "Epoch 351/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.7206 - output_x_loss: 39.8183 - output_y_loss: 206.6363 - output_z_loss: 0.6936 - output_x_msle: 39.8183 - output_y_msle: 206.6363 - output_z_msle: 0.6936 - val_loss: 99.3444 - val_output_x_loss: 40.3879 - val_output_y_loss: 207.5735 - val_output_z_loss: 0.7989 - val_output_x_msle: 40.3879 - val_output_y_msle: 207.5735 - val_output_z_msle: 0.7989 - lr: 1.0000e-07\n",
      "Epoch 352/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.6980 - output_x_loss: 39.8125 - output_y_loss: 206.5949 - output_z_loss: 0.6751 - output_x_msle: 39.8125 - output_y_msle: 206.5949 - output_z_msle: 0.6751 - val_loss: 99.2805 - val_output_x_loss: 40.2621 - val_output_y_loss: 207.5405 - val_output_z_loss: 0.7971 - val_output_x_msle: 40.2621 - val_output_y_msle: 207.5405 - val_output_z_msle: 0.7971 - lr: 1.0000e-07\n",
      "Epoch 353/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.6776 - output_x_loss: 39.8093 - output_y_loss: 206.5485 - output_z_loss: 0.6722 - output_x_msle: 39.8093 - output_y_msle: 206.5485 - output_z_msle: 0.6722 - val_loss: 99.2304 - val_output_x_loss: 40.2570 - val_output_y_loss: 207.4217 - val_output_z_loss: 0.7948 - val_output_x_msle: 40.2570 - val_output_y_msle: 207.4217 - val_output_z_msle: 0.7948 - lr: 1.0000e-07\n",
      "Epoch 354/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.6370 - output_x_loss: 39.8063 - output_y_loss: 206.4538 - output_z_loss: 0.6649 - output_x_msle: 39.8063 - output_y_msle: 206.4538 - output_z_msle: 0.6649 - val_loss: 99.1754 - val_output_x_loss: 40.2530 - val_output_y_loss: 207.2928 - val_output_z_loss: 0.7853 - val_output_x_msle: 40.2530 - val_output_y_msle: 207.2928 - val_output_z_msle: 0.7853 - lr: 1.0000e-07\n",
      "Epoch 355/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.5500 - output_x_loss: 39.7244 - output_y_loss: 206.3320 - output_z_loss: 0.6372 - output_x_msle: 39.7244 - output_y_msle: 206.3320 - output_z_msle: 0.6372 - val_loss: 99.0595 - val_output_x_loss: 40.3347 - val_output_y_loss: 206.9253 - val_output_z_loss: 0.7771 - val_output_x_msle: 40.3347 - val_output_y_msle: 206.9253 - val_output_z_msle: 0.7771 - lr: 1.0000e-07\n",
      "Epoch 356/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.7645 - output_x_loss: 40.3057 - output_y_loss: 206.2993 - output_z_loss: 0.6125 - output_x_msle: 40.3057 - output_y_msle: 206.2993 - output_z_msle: 0.6125 - val_loss: 98.9294 - val_output_x_loss: 40.0479 - val_output_y_loss: 206.8897 - val_output_z_loss: 0.7719 - val_output_x_msle: 40.0479 - val_output_y_msle: 206.8897 - val_output_z_msle: 0.7719 - lr: 1.0000e-07\n",
      "Epoch 357/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.4731 - output_x_loss: 39.6287 - output_y_loss: 206.2516 - output_z_loss: 0.6049 - output_x_msle: 39.6287 - output_y_msle: 206.2516 - output_z_msle: 0.6049 - val_loss: 98.7392 - val_output_x_loss: 39.6067 - val_output_y_loss: 206.8607 - val_output_z_loss: 0.7611 - val_output_x_msle: 39.6067 - val_output_y_msle: 206.8607 - val_output_z_msle: 0.7611 - lr: 1.0000e-07\n",
      "Epoch 358/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.4218 - output_x_loss: 39.5217 - output_y_loss: 206.2426 - output_z_loss: 0.5801 - output_x_msle: 39.5217 - output_y_msle: 206.2426 - output_z_msle: 0.5801 - val_loss: 98.6735 - val_output_x_loss: 39.5206 - val_output_y_loss: 206.7856 - val_output_z_loss: 0.7553 - val_output_x_msle: 39.5206 - val_output_y_msle: 206.7856 - val_output_z_msle: 0.7553 - lr: 1.0000e-07\n",
      "Epoch 359/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3445 - output_x_loss: 39.3582 - output_y_loss: 206.2273 - output_z_loss: 0.5514 - output_x_msle: 39.3582 - output_y_msle: 206.2273 - output_z_msle: 0.5514 - val_loss: 98.7242 - val_output_x_loss: 39.6699 - val_output_y_loss: 206.7724 - val_output_z_loss: 0.7364 - val_output_x_msle: 39.6699 - val_output_y_msle: 206.7724 - val_output_z_msle: 0.7364 - lr: 1.0000e-07\n",
      "Epoch 360/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3816 - output_x_loss: 39.5219 - output_y_loss: 206.1925 - output_z_loss: 0.4788 - output_x_msle: 39.5219 - output_y_msle: 206.1925 - output_z_msle: 0.4788 - val_loss: 98.5932 - val_output_x_loss: 39.5132 - val_output_y_loss: 206.7592 - val_output_z_loss: 0.4211 - val_output_x_msle: 39.5132 - val_output_y_msle: 206.7592 - val_output_z_msle: 0.4211 - lr: 1.0000e-07\n",
      "Epoch 361/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2392 - output_x_loss: 39.2322 - output_y_loss: 206.1636 - output_z_loss: 0.4045 - output_x_msle: 39.2322 - output_y_msle: 206.1636 - output_z_msle: 0.4045 - val_loss: 98.5890 - val_output_x_loss: 39.5122 - val_output_y_loss: 206.7509 - val_output_z_loss: 0.4187 - val_output_x_msle: 39.5122 - val_output_y_msle: 206.7509 - val_output_z_msle: 0.4187 - lr: 1.0000e-07\n",
      "Epoch 362/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2198 - output_x_loss: 39.2116 - output_y_loss: 206.1372 - output_z_loss: 0.4015 - output_x_msle: 39.2116 - output_y_msle: 206.1372 - output_z_msle: 0.4015 - val_loss: 98.5847 - val_output_x_loss: 39.5112 - val_output_y_loss: 206.7435 - val_output_z_loss: 0.4139 - val_output_x_msle: 39.5112 - val_output_y_msle: 206.7435 - val_output_z_msle: 0.4139 - lr: 1.0000e-07\n",
      "Epoch 363/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2009 - output_x_loss: 39.1817 - output_y_loss: 206.1297 - output_z_loss: 0.3819 - output_x_msle: 39.1817 - output_y_msle: 206.1297 - output_z_msle: 0.3819 - val_loss: 98.5808 - val_output_x_loss: 39.5110 - val_output_y_loss: 206.7354 - val_output_z_loss: 0.4113 - val_output_x_msle: 39.5110 - val_output_y_msle: 206.7354 - val_output_z_msle: 0.4113 - lr: 1.0000e-07\n",
      "Epoch 364/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1909 - output_x_loss: 39.1660 - output_y_loss: 206.1212 - output_z_loss: 0.3802 - output_x_msle: 39.1660 - output_y_msle: 206.1212 - output_z_msle: 0.3802 - val_loss: 98.5754 - val_output_x_loss: 39.5093 - val_output_y_loss: 206.7261 - val_output_z_loss: 0.4063 - val_output_x_msle: 39.5093 - val_output_y_msle: 206.7261 - val_output_z_msle: 0.4063 - lr: 1.0000e-07\n",
      "Epoch 365/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 98.1857 - output_x_loss: 39.1643 - output_y_loss: 206.1110 - output_z_loss: 0.3777 - output_x_msle: 39.1643 - output_y_msle: 206.1110 - output_z_msle: 0.3777 - val_loss: 98.5682 - val_output_x_loss: 39.5075 - val_output_y_loss: 206.7150 - val_output_z_loss: 0.3962 - val_output_x_msle: 39.5075 - val_output_y_msle: 206.7150 - val_output_z_msle: 0.3962 - lr: 1.0000e-07\n",
      "Epoch 366/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1785 - output_x_loss: 39.1627 - output_y_loss: 206.0967 - output_z_loss: 0.3740 - output_x_msle: 39.1627 - output_y_msle: 206.0967 - output_z_msle: 0.3740 - val_loss: 98.5463 - val_output_x_loss: 39.5058 - val_output_y_loss: 206.7005 - val_output_z_loss: 0.3189 - val_output_x_msle: 39.5058 - val_output_y_msle: 206.7005 - val_output_z_msle: 0.3189 - lr: 1.0000e-07\n",
      "Epoch 367/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1634 - output_x_loss: 39.1609 - output_y_loss: 206.0640 - output_z_loss: 0.3670 - output_x_msle: 39.1609 - output_y_msle: 206.0640 - output_z_msle: 0.3670 - val_loss: 98.5398 - val_output_x_loss: 39.5039 - val_output_y_loss: 206.6880 - val_output_z_loss: 0.3151 - val_output_x_msle: 39.5039 - val_output_y_msle: 206.6880 - val_output_z_msle: 0.3151 - lr: 1.0000e-07\n",
      "Epoch 368/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3238 - output_x_loss: 39.5799 - output_y_loss: 206.0492 - output_z_loss: 0.3608 - output_x_msle: 39.5799 - output_y_msle: 206.0492 - output_z_msle: 0.3608 - val_loss: 98.8013 - val_output_x_loss: 40.1793 - val_output_y_loss: 206.6719 - val_output_z_loss: 0.3043 - val_output_x_msle: 40.1793 - val_output_y_msle: 206.6719 - val_output_z_msle: 0.3043 - lr: 1.0000e-07\n",
      "Epoch 369/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3511 - output_x_loss: 39.7369 - output_y_loss: 206.0151 - output_z_loss: 0.2512 - output_x_msle: 39.7369 - output_y_msle: 206.0151 - output_z_msle: 0.2512 - val_loss: 98.7936 - val_output_x_loss: 40.1775 - val_output_y_loss: 206.6571 - val_output_z_loss: 0.2990 - val_output_x_msle: 40.1775 - val_output_y_msle: 206.6571 - val_output_z_msle: 0.2990 - lr: 1.0000e-07\n",
      "Epoch 370/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3391 - output_x_loss: 39.7351 - output_y_loss: 205.9989 - output_z_loss: 0.2276 - output_x_msle: 39.7351 - output_y_msle: 205.9989 - output_z_msle: 0.2276 - val_loss: 98.7848 - val_output_x_loss: 40.1757 - val_output_y_loss: 206.6396 - val_output_z_loss: 0.2935 - val_output_x_msle: 40.1757 - val_output_y_msle: 206.6396 - val_output_z_msle: 0.2935 - lr: 1.0000e-07\n",
      "Epoch 371/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3197 - output_x_loss: 39.7333 - output_y_loss: 205.9641 - output_z_loss: 0.2034 - output_x_msle: 39.7333 - output_y_msle: 205.9641 - output_z_msle: 0.2034 - val_loss: 98.7755 - val_output_x_loss: 40.1739 - val_output_y_loss: 206.6223 - val_output_z_loss: 0.2853 - val_output_x_msle: 40.1739 - val_output_y_msle: 206.6223 - val_output_z_msle: 0.2853 - lr: 1.0000e-07\n",
      "Epoch 372/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.3050 - output_x_loss: 39.7315 - output_y_loss: 205.9442 - output_z_loss: 0.1737 - output_x_msle: 39.7315 - output_y_msle: 205.9442 - output_z_msle: 0.1737 - val_loss: 98.7616 - val_output_x_loss: 40.1721 - val_output_y_loss: 206.5994 - val_output_z_loss: 0.2649 - val_output_x_msle: 40.1721 - val_output_y_msle: 206.5994 - val_output_z_msle: 0.2649 - lr: 1.0000e-07\n",
      "Epoch 373/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2639 - output_x_loss: 39.7296 - output_y_loss: 205.9053 - output_z_loss: 0.0499 - output_x_msle: 39.7296 - output_y_msle: 205.9053 - output_z_msle: 0.0499 - val_loss: 98.6988 - val_output_x_loss: 40.1702 - val_output_y_loss: 206.5770 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1702 - val_output_y_msle: 206.5770 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 374/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2440 - output_x_loss: 39.7278 - output_y_loss: 205.8821 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7278 - output_y_msle: 205.8821 - output_z_msle: 0.0000e+00 - val_loss: 98.6870 - val_output_x_loss: 40.1683 - val_output_y_loss: 206.5492 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1683 - val_output_y_msle: 206.5492 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 375/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2270 - output_x_loss: 39.7260 - output_y_loss: 205.8415 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7260 - output_y_msle: 205.8415 - output_z_msle: 0.0000e+00 - val_loss: 98.6754 - val_output_x_loss: 40.1665 - val_output_y_loss: 206.5220 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1665 - val_output_y_msle: 206.5220 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 376/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.2084 - output_x_loss: 39.7241 - output_y_loss: 205.7970 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7241 - output_y_msle: 205.7970 - output_z_msle: 0.0000e+00 - val_loss: 98.6586 - val_output_x_loss: 40.1646 - val_output_y_loss: 206.4819 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1646 - val_output_y_msle: 206.4819 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 377/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1985 - output_x_loss: 39.7222 - output_y_loss: 205.7742 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7222 - output_y_msle: 205.7742 - output_z_msle: 0.0000e+00 - val_loss: 98.6088 - val_output_x_loss: 40.1627 - val_output_y_loss: 206.3592 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1627 - val_output_y_msle: 206.3592 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 378/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1862 - output_x_loss: 39.7203 - output_y_loss: 205.7452 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7203 - output_y_msle: 205.7452 - output_z_msle: 0.0000e+00 - val_loss: 98.5272 - val_output_x_loss: 40.1608 - val_output_y_loss: 206.1573 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1608 - val_output_y_msle: 206.1573 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 379/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1634 - output_x_loss: 39.7184 - output_y_loss: 205.6900 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7184 - output_y_msle: 205.6900 - output_z_msle: 0.0000e+00 - val_loss: 98.5085 - val_output_x_loss: 40.1588 - val_output_y_loss: 206.1124 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1588 - val_output_y_msle: 206.1124 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 380/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.1378 - output_x_loss: 39.7165 - output_y_loss: 205.6280 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7165 - output_y_msle: 205.6280 - output_z_msle: 0.0000e+00 - val_loss: 98.4833 - val_output_x_loss: 40.1568 - val_output_y_loss: 206.0513 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1568 - val_output_y_msle: 206.0513 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 381/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 98.0666 - output_x_loss: 39.7145 - output_y_loss: 205.4519 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7145 - output_y_msle: 205.4519 - output_z_msle: 0.0000e+00 - val_loss: 98.2964 - val_output_x_loss: 40.1550 - val_output_y_loss: 205.5860 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1550 - val_output_y_msle: 205.5860 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 382/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.9856 - output_x_loss: 39.7127 - output_y_loss: 205.2513 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7127 - output_y_msle: 205.2513 - output_z_msle: 0.0000e+00 - val_loss: 98.2410 - val_output_x_loss: 40.1531 - val_output_y_loss: 205.4495 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1531 - val_output_y_msle: 205.4495 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 383/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.9565 - output_x_loss: 39.7107 - output_y_loss: 205.1805 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7107 - output_y_msle: 205.1805 - output_z_msle: 0.0000e+00 - val_loss: 98.1645 - val_output_x_loss: 40.1510 - val_output_y_loss: 205.2602 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1510 - val_output_y_msle: 205.2602 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 384/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.9128 - output_x_loss: 39.7086 - output_y_loss: 205.0734 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7086 - output_y_msle: 205.0734 - output_z_msle: 0.0000e+00 - val_loss: 98.0171 - val_output_x_loss: 40.1489 - val_output_y_loss: 204.8938 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1489 - val_output_y_msle: 204.8938 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 385/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.8661 - output_x_loss: 39.7067 - output_y_loss: 204.9585 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7067 - output_y_msle: 204.9585 - output_z_msle: 0.0000e+00 - val_loss: 97.9924 - val_output_x_loss: 40.1470 - val_output_y_loss: 204.8340 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1470 - val_output_y_msle: 204.8340 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 386/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.8248 - output_x_loss: 39.7048 - output_y_loss: 204.8571 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7048 - output_y_msle: 204.8571 - output_z_msle: 0.0000e+00 - val_loss: 97.9712 - val_output_x_loss: 40.1451 - val_output_y_loss: 204.7830 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1451 - val_output_y_msle: 204.7830 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 387/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.7823 - output_x_loss: 39.7029 - output_y_loss: 204.7528 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7029 - output_y_msle: 204.7528 - output_z_msle: 0.0000e+00 - val_loss: 97.9398 - val_output_x_loss: 40.1432 - val_output_y_loss: 204.7063 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1432 - val_output_y_msle: 204.7063 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 388/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.7322 - output_x_loss: 39.7010 - output_y_loss: 204.6297 - output_z_loss: 0.0000e+00 - output_x_msle: 39.7010 - output_y_msle: 204.6297 - output_z_msle: 0.0000e+00 - val_loss: 97.8190 - val_output_x_loss: 40.1411 - val_output_y_loss: 204.4063 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1411 - val_output_y_msle: 204.4063 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 389/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.6820 - output_x_loss: 39.6989 - output_y_loss: 204.5061 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6989 - output_y_msle: 204.5061 - output_z_msle: 0.0000e+00 - val_loss: 97.7998 - val_output_x_loss: 40.1388 - val_output_y_loss: 204.3607 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1388 - val_output_y_msle: 204.3607 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 390/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.4771 - output_x_loss: 39.6966 - output_y_loss: 203.9962 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6966 - output_y_msle: 203.9962 - output_z_msle: 0.0000e+00 - val_loss: 97.5744 - val_output_x_loss: 40.1366 - val_output_y_loss: 203.7994 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1366 - val_output_y_msle: 203.7994 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 391/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.4368 - output_x_loss: 39.6948 - output_y_loss: 203.8972 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6948 - output_y_msle: 203.8972 - output_z_msle: 0.0000e+00 - val_loss: 97.5596 - val_output_x_loss: 40.1348 - val_output_y_loss: 203.7642 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 40.1348 - val_output_y_msle: 203.7642 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 392/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.4149 - output_x_loss: 39.6930 - output_y_loss: 203.8443 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6930 - output_y_msle: 203.8443 - output_z_msle: 0.0000e+00 - val_loss: 97.4805 - val_output_x_loss: 39.9879 - val_output_y_loss: 203.7133 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9879 - val_output_y_msle: 203.7133 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 393/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.3892 - output_x_loss: 39.6912 - output_y_loss: 203.7817 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6912 - output_y_msle: 203.7817 - output_z_msle: 0.0000e+00 - val_loss: 97.4202 - val_output_x_loss: 39.9765 - val_output_y_loss: 203.5739 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9765 - val_output_y_msle: 203.5739 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 394/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.3322 - output_x_loss: 39.6895 - output_y_loss: 203.6411 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6895 - output_y_msle: 203.6411 - output_z_msle: 0.0000e+00 - val_loss: 97.3217 - val_output_x_loss: 39.9753 - val_output_y_loss: 203.3288 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9753 - val_output_y_msle: 203.3288 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 395/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.2058 - output_x_loss: 39.6877 - output_y_loss: 203.3269 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6877 - output_y_msle: 203.3269 - output_z_msle: 0.0000e+00 - val_loss: 97.2149 - val_output_x_loss: 39.9705 - val_output_y_loss: 203.0668 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9705 - val_output_y_msle: 203.0668 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 396/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.1292 - output_x_loss: 39.6858 - output_y_loss: 203.1371 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6858 - output_y_msle: 203.1371 - output_z_msle: 0.0000e+00 - val_loss: 97.1405 - val_output_x_loss: 39.9658 - val_output_y_loss: 202.8855 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9658 - val_output_y_msle: 202.8855 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 397/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 97.0728 - output_x_loss: 39.6840 - output_y_loss: 202.9979 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6840 - output_y_msle: 202.9979 - output_z_msle: 0.0000e+00 - val_loss: 96.9688 - val_output_x_loss: 39.9623 - val_output_y_loss: 202.4597 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9623 - val_output_y_msle: 202.4597 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 398/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.8097 - output_x_loss: 39.6825 - output_y_loss: 202.3417 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6825 - output_y_msle: 202.3417 - output_z_msle: 0.0000e+00 - val_loss: 96.7343 - val_output_x_loss: 39.9594 - val_output_y_loss: 201.8763 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9594 - val_output_y_msle: 201.8763 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 399/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.6615 - output_x_loss: 39.6804 - output_y_loss: 201.9734 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6804 - output_y_msle: 201.9734 - output_z_msle: 0.0000e+00 - val_loss: 96.5072 - val_output_x_loss: 39.8375 - val_output_y_loss: 201.4304 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8375 - val_output_y_msle: 201.4304 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 400/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.6375 - output_x_loss: 39.6782 - output_y_loss: 201.9155 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6782 - output_y_msle: 201.9155 - output_z_msle: 0.0000e+00 - val_loss: 96.4391 - val_output_x_loss: 39.8312 - val_output_y_loss: 201.2665 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8312 - val_output_y_msle: 201.2665 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 401/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.5862 - output_x_loss: 39.6935 - output_y_loss: 201.7721 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6935 - output_y_msle: 201.7721 - output_z_msle: 0.0000e+00 - val_loss: 96.3623 - val_output_x_loss: 39.8328 - val_output_y_loss: 201.0729 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8328 - val_output_y_msle: 201.0729 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 402/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.5441 - output_x_loss: 39.6750 - output_y_loss: 201.6853 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6750 - output_y_msle: 201.6853 - output_z_msle: 0.0000e+00 - val_loss: 96.2987 - val_output_x_loss: 39.8268 - val_output_y_loss: 200.9199 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8268 - val_output_y_msle: 200.9199 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 403/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.4501 - output_x_loss: 39.6730 - output_y_loss: 201.4522 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6730 - output_y_msle: 201.4522 - output_z_msle: 0.0000e+00 - val_loss: 96.0624 - val_output_x_loss: 39.8225 - val_output_y_loss: 200.3334 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8225 - val_output_y_msle: 200.3334 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 404/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.4087 - output_x_loss: 39.6708 - output_y_loss: 201.3510 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6708 - output_y_msle: 201.3510 - output_z_msle: 0.0000e+00 - val_loss: 96.0062 - val_output_x_loss: 39.8188 - val_output_y_loss: 200.1967 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8188 - val_output_y_msle: 200.1967 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 405/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 96.3379 - output_x_loss: 39.6686 - output_y_loss: 201.1761 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6686 - output_y_msle: 201.1761 - output_z_msle: 0.0000e+00 - val_loss: 95.9803 - val_output_x_loss: 39.8155 - val_output_y_loss: 200.1351 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8155 - val_output_y_msle: 200.1351 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 406/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1924 - output_x_loss: 39.6667 - output_y_loss: 200.8143 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6667 - output_y_msle: 200.8143 - output_z_msle: 0.0000e+00 - val_loss: 95.7124 - val_output_x_loss: 39.8131 - val_output_y_loss: 199.4680 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8131 - val_output_y_msle: 199.4680 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 407/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1611 - output_x_loss: 39.6781 - output_y_loss: 200.7248 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6781 - output_y_msle: 200.7248 - output_z_msle: 0.0000e+00 - val_loss: 95.7631 - val_output_x_loss: 39.9468 - val_output_y_loss: 199.4609 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9468 - val_output_y_msle: 199.4609 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 408/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1522 - output_x_loss: 39.6966 - output_y_loss: 200.6838 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6966 - output_y_msle: 200.6838 - output_z_msle: 0.0000e+00 - val_loss: 95.7573 - val_output_x_loss: 39.9435 - val_output_y_loss: 199.4497 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9435 - val_output_y_msle: 199.4497 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 409/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1339 - output_x_loss: 39.6943 - output_y_loss: 200.6404 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6943 - output_y_msle: 200.6404 - output_z_msle: 0.0000e+00 - val_loss: 95.7509 - val_output_x_loss: 39.9404 - val_output_y_loss: 199.4369 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9404 - val_output_y_msle: 199.4369 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 410/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1297 - output_x_loss: 39.6919 - output_y_loss: 200.6325 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6919 - output_y_msle: 200.6325 - output_z_msle: 0.0000e+00 - val_loss: 95.7428 - val_output_x_loss: 39.9375 - val_output_y_loss: 199.4195 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9375 - val_output_y_msle: 199.4195 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 411/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.1120 - output_x_loss: 39.6896 - output_y_loss: 200.5903 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6896 - output_y_msle: 200.5903 - output_z_msle: 0.0000e+00 - val_loss: 95.7260 - val_output_x_loss: 39.9345 - val_output_y_loss: 199.3805 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9345 - val_output_y_msle: 199.3805 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 412/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.0895 - output_x_loss: 39.6873 - output_y_loss: 200.5365 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6873 - output_y_msle: 200.5365 - output_z_msle: 0.0000e+00 - val_loss: 95.6634 - val_output_x_loss: 39.9317 - val_output_y_loss: 199.2268 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9317 - val_output_y_msle: 199.2268 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 413/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.0774 - output_x_loss: 39.6850 - output_y_loss: 200.5084 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6850 - output_y_msle: 200.5084 - output_z_msle: 0.0000e+00 - val_loss: 95.6573 - val_output_x_loss: 39.9289 - val_output_y_loss: 199.2144 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.9289 - val_output_y_msle: 199.2144 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 414/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 96.0392 - output_x_loss: 39.6560 - output_y_loss: 200.4420 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6560 - output_y_msle: 200.4420 - output_z_msle: 0.0000e+00 - val_loss: 95.5255 - val_output_x_loss: 39.8033 - val_output_y_loss: 199.0104 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.8033 - val_output_y_msle: 199.0104 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 415/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.9902 - output_x_loss: 39.6181 - output_y_loss: 200.3572 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6181 - output_y_msle: 200.3572 - output_z_msle: 0.0000e+00 - val_loss: 95.5211 - val_output_x_loss: 39.7983 - val_output_y_loss: 199.0045 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.7983 - val_output_y_msle: 199.0045 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 416/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.9796 - output_x_loss: 39.6149 - output_y_loss: 200.3341 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6149 - output_y_msle: 200.3341 - output_z_msle: 0.0000e+00 - val_loss: 95.5178 - val_output_x_loss: 39.7942 - val_output_y_loss: 199.0004 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.7942 - val_output_y_msle: 199.0004 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 417/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.9768 - output_x_loss: 39.6122 - output_y_loss: 200.3298 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6122 - output_y_msle: 200.3298 - output_z_msle: 0.0000e+00 - val_loss: 95.4491 - val_output_x_loss: 39.7910 - val_output_y_loss: 198.8318 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.7910 - val_output_y_msle: 198.8318 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 418/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.9737 - output_x_loss: 39.6097 - output_y_loss: 200.3246 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6097 - output_y_msle: 200.3246 - output_z_msle: 0.0000e+00 - val_loss: 95.3797 - val_output_x_loss: 39.6278 - val_output_y_loss: 198.8214 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.6278 - val_output_y_msle: 198.8214 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 419/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.9702 - output_x_loss: 39.6072 - output_y_loss: 200.3183 - output_z_loss: 0.0000e+00 - output_x_msle: 39.6072 - output_y_msle: 200.3183 - output_z_msle: 0.0000e+00 - val_loss: 95.3740 - val_output_x_loss: 39.6220 - val_output_y_loss: 198.8131 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.6220 - val_output_y_msle: 198.8131 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 420/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.8626 - output_x_loss: 39.3622 - output_y_loss: 200.2943 - output_z_loss: 0.0000e+00 - output_x_msle: 39.3622 - output_y_msle: 200.2943 - output_z_msle: 0.0000e+00 - val_loss: 95.2148 - val_output_x_loss: 39.2300 - val_output_y_loss: 198.8070 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2300 - val_output_y_msle: 198.8070 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 421/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.7120 - output_x_loss: 39.0264 - output_y_loss: 200.2536 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0264 - output_y_msle: 200.2536 - output_z_msle: 0.0000e+00 - val_loss: 95.2109 - val_output_x_loss: 39.2264 - val_output_y_loss: 198.8009 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2264 - val_output_y_msle: 198.8009 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 422/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.7083 - output_x_loss: 39.0235 - output_y_loss: 200.2472 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0235 - output_y_msle: 200.2472 - output_z_msle: 0.0000e+00 - val_loss: 95.2066 - val_output_x_loss: 39.2227 - val_output_y_loss: 198.7938 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2227 - val_output_y_msle: 198.7938 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 423/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6800 - output_x_loss: 38.9950 - output_y_loss: 200.2049 - output_z_loss: 0.0000e+00 - output_x_msle: 38.9950 - output_y_msle: 200.2049 - output_z_msle: 0.0000e+00 - val_loss: 95.2009 - val_output_x_loss: 39.2180 - val_output_y_loss: 198.7842 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2180 - val_output_y_msle: 198.7842 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 424/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6600 - output_x_loss: 38.9900 - output_y_loss: 200.1600 - output_z_loss: 0.0000e+00 - output_x_msle: 38.9900 - output_y_msle: 200.1600 - output_z_msle: 0.0000e+00 - val_loss: 95.1967 - val_output_x_loss: 39.2145 - val_output_y_loss: 198.7772 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2145 - val_output_y_msle: 198.7772 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 425/500\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 95.6743 - output_x_loss: 39.0333 - output_y_loss: 200.1524 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0333 - output_y_msle: 200.1524 - output_z_msle: 0.0000e+00 - val_loss: 95.1939 - val_output_x_loss: 39.2139 - val_output_y_loss: 198.7709 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2139 - val_output_y_msle: 198.7709 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 426/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6637 - output_x_loss: 39.0142 - output_y_loss: 200.1451 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0142 - output_y_msle: 200.1451 - output_z_msle: 0.0000e+00 - val_loss: 95.1895 - val_output_x_loss: 39.2100 - val_output_y_loss: 198.7636 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2100 - val_output_y_msle: 198.7636 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 427/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6446 - output_x_loss: 39.0108 - output_y_loss: 200.1007 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0108 - output_y_msle: 200.1007 - output_z_msle: 0.0000e+00 - val_loss: 95.1844 - val_output_x_loss: 39.2062 - val_output_y_loss: 198.7548 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2062 - val_output_y_msle: 198.7548 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 428/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6313 - output_x_loss: 38.9875 - output_y_loss: 200.0907 - output_z_loss: 0.0000e+00 - output_x_msle: 38.9875 - output_y_msle: 200.0907 - output_z_msle: 0.0000e+00 - val_loss: 95.1817 - val_output_x_loss: 39.2079 - val_output_y_loss: 198.7464 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2079 - val_output_y_msle: 198.7464 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 429/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.6168 - output_x_loss: 39.0009 - output_y_loss: 200.0411 - output_z_loss: 0.0000e+00 - output_x_msle: 39.0009 - output_y_msle: 200.0411 - output_z_msle: 0.0000e+00 - val_loss: 95.1732 - val_output_x_loss: 39.2027 - val_output_y_loss: 198.7301 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.2027 - val_output_y_msle: 198.7301 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 430/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.5778 - output_x_loss: 38.9351 - output_y_loss: 200.0094 - output_z_loss: 0.0000e+00 - output_x_msle: 38.9351 - output_y_msle: 200.0094 - output_z_msle: 0.0000e+00 - val_loss: 95.1673 - val_output_x_loss: 39.1970 - val_output_y_loss: 198.7212 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1970 - val_output_y_msle: 198.7212 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 431/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.5570 - output_x_loss: 38.9289 - output_y_loss: 199.9637 - output_z_loss: 0.0000e+00 - output_x_msle: 38.9289 - output_y_msle: 199.9637 - output_z_msle: 0.0000e+00 - val_loss: 95.1612 - val_output_x_loss: 39.1931 - val_output_y_loss: 198.7098 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1931 - val_output_y_msle: 198.7098 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 432/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.5256 - output_x_loss: 38.8636 - output_y_loss: 199.9502 - output_z_loss: 0.0000e+00 - output_x_msle: 38.8636 - output_y_msle: 199.9502 - output_z_msle: 0.0000e+00 - val_loss: 95.1546 - val_output_x_loss: 39.1880 - val_output_y_loss: 198.6984 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1880 - val_output_y_msle: 198.6984 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 433/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.4881 - output_x_loss: 38.8224 - output_y_loss: 199.8978 - output_z_loss: 0.0000e+00 - output_x_msle: 38.8224 - output_y_msle: 199.8978 - output_z_msle: 0.0000e+00 - val_loss: 95.1441 - val_output_x_loss: 39.1808 - val_output_y_loss: 198.6794 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1808 - val_output_y_msle: 198.6794 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 434/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.4478 - output_x_loss: 38.7548 - output_y_loss: 199.8647 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7548 - output_y_msle: 199.8647 - output_z_msle: 0.0000e+00 - val_loss: 95.1375 - val_output_x_loss: 39.1772 - val_output_y_loss: 198.6665 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1772 - val_output_y_msle: 198.6665 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 435/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.4457 - output_x_loss: 38.7971 - output_y_loss: 199.8172 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7971 - output_y_msle: 199.8172 - output_z_msle: 0.0000e+00 - val_loss: 95.1323 - val_output_x_loss: 39.1790 - val_output_y_loss: 198.6518 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1790 - val_output_y_msle: 198.6518 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 436/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.4295 - output_x_loss: 38.7715 - output_y_loss: 199.8021 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7715 - output_y_msle: 199.8021 - output_z_msle: 0.0000e+00 - val_loss: 95.1245 - val_output_x_loss: 39.1750 - val_output_y_loss: 198.6363 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1750 - val_output_y_msle: 198.6363 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 437/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.4218 - output_x_loss: 38.7663 - output_y_loss: 199.7881 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7663 - output_y_msle: 199.7881 - output_z_msle: 0.0000e+00 - val_loss: 95.1154 - val_output_x_loss: 39.1719 - val_output_y_loss: 198.6166 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1719 - val_output_y_msle: 198.6166 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 438/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.3888 - output_x_loss: 38.7367 - output_y_loss: 199.7352 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7367 - output_y_msle: 199.7352 - output_z_msle: 0.0000e+00 - val_loss: 95.1027 - val_output_x_loss: 39.1687 - val_output_y_loss: 198.5880 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1687 - val_output_y_msle: 198.5880 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 439/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.3797 - output_x_loss: 38.7329 - output_y_loss: 199.7164 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7329 - output_y_msle: 199.7164 - output_z_msle: 0.0000e+00 - val_loss: 95.0585 - val_output_x_loss: 39.1657 - val_output_y_loss: 198.4804 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.1657 - val_output_y_msle: 198.4804 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 440/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.3442 - output_x_loss: 38.7046 - output_y_loss: 199.6558 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7046 - output_y_msle: 199.6558 - output_z_msle: 0.0000e+00 - val_loss: 94.9823 - val_output_x_loss: 39.0014 - val_output_y_loss: 198.4544 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.0014 - val_output_y_msle: 198.4544 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 441/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.3403 - output_x_loss: 38.7425 - output_y_loss: 199.6081 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7425 - output_y_msle: 199.6081 - output_z_msle: 0.0000e+00 - val_loss: 94.9727 - val_output_x_loss: 39.0000 - val_output_y_loss: 198.4318 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 39.0000 - val_output_y_msle: 198.4318 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 442/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.3068 - output_x_loss: 38.7253 - output_y_loss: 199.5417 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7253 - output_y_msle: 199.5417 - output_z_msle: 0.0000e+00 - val_loss: 94.9574 - val_output_x_loss: 38.9948 - val_output_y_loss: 198.3987 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.9948 - val_output_y_msle: 198.3987 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 443/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.2737 - output_x_loss: 38.6968 - output_y_loss: 199.4875 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6968 - output_y_msle: 199.4875 - output_z_msle: 0.0000e+00 - val_loss: 94.9423 - val_output_x_loss: 38.9896 - val_output_y_loss: 198.3663 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.9896 - val_output_y_msle: 198.3663 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 444/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.2496 - output_x_loss: 38.6919 - output_y_loss: 199.4321 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6919 - output_y_msle: 199.4321 - output_z_msle: 0.0000e+00 - val_loss: 94.8573 - val_output_x_loss: 38.9860 - val_output_y_loss: 198.1573 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.9860 - val_output_y_msle: 198.1573 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 445/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.2250 - output_x_loss: 38.6890 - output_y_loss: 199.3736 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6890 - output_y_msle: 199.3736 - output_z_msle: 0.0000e+00 - val_loss: 94.8193 - val_output_x_loss: 38.9825 - val_output_y_loss: 198.0658 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.9825 - val_output_y_msle: 198.0658 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 446/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.2119 - output_x_loss: 38.7039 - output_y_loss: 199.3259 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7039 - output_y_msle: 199.3259 - output_z_msle: 0.0000e+00 - val_loss: 94.7753 - val_output_x_loss: 38.9813 - val_output_y_loss: 197.9569 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.9813 - val_output_y_msle: 197.9569 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 447/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 95.1692 - output_x_loss: 38.6852 - output_y_loss: 199.2379 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6852 - output_y_msle: 199.2379 - output_z_msle: 0.0000e+00 - val_loss: 94.6770 - val_output_x_loss: 38.8166 - val_output_y_loss: 197.8759 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.8166 - val_output_y_msle: 197.8759 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 448/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.9986 - output_x_loss: 38.6567 - output_y_loss: 198.8396 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6567 - output_y_msle: 198.8396 - output_z_msle: 0.0000e+00 - val_loss: 94.4973 - val_output_x_loss: 38.8105 - val_output_y_loss: 197.4326 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.8105 - val_output_y_msle: 197.4326 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 449/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.8389 - output_x_loss: 38.6522 - output_y_loss: 198.4450 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6522 - output_y_msle: 198.4450 - output_z_msle: 0.0000e+00 - val_loss: 94.4818 - val_output_x_loss: 38.8723 - val_output_y_loss: 197.3322 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.8723 - val_output_y_msle: 197.3322 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 450/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.7410 - output_x_loss: 38.6453 - output_y_loss: 198.2071 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6453 - output_y_msle: 198.2071 - output_z_msle: 0.0000e+00 - val_loss: 94.3791 - val_output_x_loss: 38.8147 - val_output_y_loss: 197.1329 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.8147 - val_output_y_msle: 197.1329 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 451/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.6851 - output_x_loss: 38.7364 - output_y_loss: 197.9762 - output_z_loss: 0.0000e+00 - output_x_msle: 38.7364 - output_y_msle: 197.9762 - output_z_msle: 0.0000e+00 - val_loss: 94.2226 - val_output_x_loss: 38.8078 - val_output_y_loss: 196.7487 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.8078 - val_output_y_msle: 196.7487 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 452/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.6179 - output_x_loss: 38.6699 - output_y_loss: 197.8747 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6699 - output_y_msle: 197.8747 - output_z_msle: 0.0000e+00 - val_loss: 94.1650 - val_output_x_loss: 38.7979 - val_output_y_loss: 196.6145 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.7979 - val_output_y_msle: 196.6145 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 453/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.5648 - output_x_loss: 38.6287 - output_y_loss: 197.7832 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6287 - output_y_msle: 197.7832 - output_z_msle: 0.0000e+00 - val_loss: 94.1408 - val_output_x_loss: 38.7948 - val_output_y_loss: 196.5571 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.7948 - val_output_y_msle: 196.5571 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 454/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.5333 - output_x_loss: 38.6257 - output_y_loss: 197.7076 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6257 - output_y_msle: 197.7076 - output_z_msle: 0.0000e+00 - val_loss: 94.0037 - val_output_x_loss: 38.6365 - val_output_y_loss: 196.3728 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.6365 - val_output_y_msle: 196.3728 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 455/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.4099 - output_x_loss: 38.6231 - output_y_loss: 197.4017 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6231 - output_y_msle: 197.4017 - output_z_msle: 0.0000e+00 - val_loss: 93.8864 - val_output_x_loss: 38.6275 - val_output_y_loss: 196.0885 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.6275 - val_output_y_msle: 196.0885 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 456/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.3592 - output_x_loss: 38.6204 - output_y_loss: 197.2776 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6204 - output_y_msle: 197.2776 - output_z_msle: 0.0000e+00 - val_loss: 93.7456 - val_output_x_loss: 38.6227 - val_output_y_loss: 195.7413 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.6227 - val_output_y_msle: 195.7413 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 457/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.2946 - output_x_loss: 38.6179 - output_y_loss: 197.1187 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6179 - output_y_msle: 197.1187 - output_z_msle: 0.0000e+00 - val_loss: 93.6590 - val_output_x_loss: 38.4729 - val_output_y_loss: 195.6747 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4729 - val_output_y_msle: 195.6747 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 458/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.2366 - output_x_loss: 38.6152 - output_y_loss: 196.9761 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6152 - output_y_msle: 196.9761 - output_z_msle: 0.0000e+00 - val_loss: 93.5882 - val_output_x_loss: 38.4534 - val_output_y_loss: 195.5172 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4534 - val_output_y_msle: 195.5172 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 459/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.1537 - output_x_loss: 38.6128 - output_y_loss: 196.7713 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6128 - output_y_msle: 196.7713 - output_z_msle: 0.0000e+00 - val_loss: 93.4108 - val_output_x_loss: 38.4489 - val_output_y_loss: 195.0782 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4489 - val_output_y_msle: 195.0782 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 460/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 94.0898 - output_x_loss: 38.6104 - output_y_loss: 196.6141 - output_z_loss: 0.0000e+00 - output_x_msle: 38.6104 - output_y_msle: 196.6141 - output_z_msle: 0.0000e+00 - val_loss: 93.2730 - val_output_x_loss: 38.4445 - val_output_y_loss: 194.7381 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4445 - val_output_y_msle: 194.7381 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 461/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9898 - output_x_loss: 38.5471 - output_y_loss: 196.4276 - output_z_loss: 0.0000e+00 - output_x_msle: 38.5471 - output_y_msle: 196.4276 - output_z_msle: 0.0000e+00 - val_loss: 93.2289 - val_output_x_loss: 38.4366 - val_output_y_loss: 194.6357 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4366 - val_output_y_msle: 194.6357 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 462/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9754 - output_x_loss: 38.5249 - output_y_loss: 196.4135 - output_z_loss: 0.0000e+00 - output_x_msle: 38.5249 - output_y_msle: 196.4135 - output_z_msle: 0.0000e+00 - val_loss: 93.2213 - val_output_x_loss: 38.4324 - val_output_y_loss: 194.6208 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4324 - val_output_y_msle: 194.6208 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 463/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9593 - output_x_loss: 38.5036 - output_y_loss: 196.3945 - output_z_loss: 0.0000e+00 - output_x_msle: 38.5036 - output_y_msle: 196.3945 - output_z_msle: 0.0000e+00 - val_loss: 93.2105 - val_output_x_loss: 38.4286 - val_output_y_loss: 194.5976 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.4286 - val_output_y_msle: 194.5976 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 464/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9436 - output_x_loss: 38.5002 - output_y_loss: 196.3589 - output_z_loss: 0.0000e+00 - output_x_msle: 38.5002 - output_y_msle: 196.3589 - output_z_msle: 0.0000e+00 - val_loss: 93.1379 - val_output_x_loss: 38.2632 - val_output_y_loss: 194.5816 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2632 - val_output_y_msle: 194.5816 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 465/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9362 - output_x_loss: 38.4971 - output_y_loss: 196.3434 - output_z_loss: 0.0000e+00 - output_x_msle: 38.4971 - output_y_msle: 196.3434 - output_z_msle: 0.0000e+00 - val_loss: 93.1278 - val_output_x_loss: 38.2571 - val_output_y_loss: 194.5624 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2571 - val_output_y_msle: 194.5624 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 466/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.9269 - output_x_loss: 38.4941 - output_y_loss: 196.3233 - output_z_loss: 0.0000e+00 - output_x_msle: 38.4941 - output_y_msle: 196.3233 - output_z_msle: 0.0000e+00 - val_loss: 93.1146 - val_output_x_loss: 38.2525 - val_output_y_loss: 194.5340 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2525 - val_output_y_msle: 194.5340 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 467/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.8936 - output_x_loss: 38.4488 - output_y_loss: 196.2852 - output_z_loss: 0.0000e+00 - output_x_msle: 38.4488 - output_y_msle: 196.2852 - output_z_msle: 0.0000e+00 - val_loss: 93.0994 - val_output_x_loss: 38.2487 - val_output_y_loss: 194.4999 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2487 - val_output_y_msle: 194.4999 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 468/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.8355 - output_x_loss: 38.3921 - output_y_loss: 196.1966 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3921 - output_y_msle: 196.1966 - output_z_msle: 0.0000e+00 - val_loss: 92.9208 - val_output_x_loss: 38.2411 - val_output_y_loss: 194.0610 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2411 - val_output_y_msle: 194.0610 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 469/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.6839 - output_x_loss: 38.3663 - output_y_loss: 195.8436 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3663 - output_y_msle: 195.8436 - output_z_msle: 0.0000e+00 - val_loss: 92.8428 - val_output_x_loss: 38.2400 - val_output_y_loss: 193.8669 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2400 - val_output_y_msle: 193.8669 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 470/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.6776 - output_x_loss: 38.3717 - output_y_loss: 195.8223 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3717 - output_y_msle: 195.8223 - output_z_msle: 0.0000e+00 - val_loss: 92.8579 - val_output_x_loss: 38.3048 - val_output_y_loss: 193.8398 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.3048 - val_output_y_msle: 193.8398 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 471/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.6439 - output_x_loss: 38.3438 - output_y_loss: 195.7658 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3438 - output_y_msle: 195.7658 - output_z_msle: 0.0000e+00 - val_loss: 92.8177 - val_output_x_loss: 38.2312 - val_output_y_loss: 193.8130 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2312 - val_output_y_msle: 193.8130 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 472/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.6057 - output_x_loss: 38.3259 - output_y_loss: 195.6884 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3259 - output_y_msle: 195.6884 - output_z_msle: 0.0000e+00 - val_loss: 92.8047 - val_output_x_loss: 38.2295 - val_output_y_loss: 193.7824 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2295 - val_output_y_msle: 193.7824 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 473/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.5961 - output_x_loss: 38.3239 - output_y_loss: 195.6664 - output_z_loss: 0.0000e+00 - output_x_msle: 38.3239 - output_y_msle: 195.6664 - output_z_msle: 0.0000e+00 - val_loss: 92.7575 - val_output_x_loss: 38.2278 - val_output_y_loss: 193.6658 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2278 - val_output_y_msle: 193.6658 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 474/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.5144 - output_x_loss: 38.2619 - output_y_loss: 195.5241 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2619 - output_y_msle: 195.5241 - output_z_msle: 0.0000e+00 - val_loss: 92.7387 - val_output_x_loss: 38.2249 - val_output_y_loss: 193.6217 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2249 - val_output_y_msle: 193.6217 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 475/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.4551 - output_x_loss: 38.2771 - output_y_loss: 195.3607 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2771 - output_y_msle: 195.3607 - output_z_msle: 0.0000e+00 - val_loss: 92.7303 - val_output_x_loss: 38.2241 - val_output_y_loss: 193.6017 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2241 - val_output_y_msle: 193.6017 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 476/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.3975 - output_x_loss: 38.2568 - output_y_loss: 195.2369 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2568 - output_y_msle: 195.2369 - output_z_msle: 0.0000e+00 - val_loss: 92.7199 - val_output_x_loss: 38.2226 - val_output_y_loss: 193.5772 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2226 - val_output_y_msle: 193.5772 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 477/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.3844 - output_x_loss: 38.2551 - output_y_loss: 195.2058 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2551 - output_y_msle: 195.2058 - output_z_msle: 0.0000e+00 - val_loss: 92.7051 - val_output_x_loss: 38.2212 - val_output_y_loss: 193.5415 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2212 - val_output_y_msle: 193.5415 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 478/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.3527 - output_x_loss: 38.2475 - output_y_loss: 195.1340 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2475 - output_y_msle: 195.1340 - output_z_msle: 0.0000e+00 - val_loss: 92.6901 - val_output_x_loss: 38.2194 - val_output_y_loss: 193.5060 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2194 - val_output_y_msle: 193.5060 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 479/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.3239 - output_x_loss: 38.2428 - output_y_loss: 195.0668 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2428 - output_y_msle: 195.0668 - output_z_msle: 0.0000e+00 - val_loss: 92.6573 - val_output_x_loss: 38.2195 - val_output_y_loss: 193.4238 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2195 - val_output_y_msle: 193.4238 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 480/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.2889 - output_x_loss: 38.2253 - output_y_loss: 194.9970 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2253 - output_y_msle: 194.9970 - output_z_msle: 0.0000e+00 - val_loss: 92.6338 - val_output_x_loss: 38.2180 - val_output_y_loss: 193.3664 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2180 - val_output_y_msle: 193.3664 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 481/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.2696 - output_x_loss: 38.2236 - output_y_loss: 194.9505 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2236 - output_y_msle: 194.9505 - output_z_msle: 0.0000e+00 - val_loss: 92.5146 - val_output_x_loss: 38.2166 - val_output_y_loss: 193.0699 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2166 - val_output_y_msle: 193.0699 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 482/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.1490 - output_x_loss: 38.1879 - output_y_loss: 194.6848 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1879 - output_y_msle: 194.6848 - output_z_msle: 0.0000e+00 - val_loss: 92.3600 - val_output_x_loss: 38.0991 - val_output_y_loss: 192.8010 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.0991 - val_output_y_msle: 192.8010 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 483/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.0987 - output_x_loss: 38.2021 - output_y_loss: 194.5448 - output_z_loss: 0.0000e+00 - output_x_msle: 38.2021 - output_y_msle: 194.5448 - output_z_msle: 0.0000e+00 - val_loss: 92.2815 - val_output_x_loss: 38.2151 - val_output_y_loss: 192.4888 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2151 - val_output_y_msle: 192.4888 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 484/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 93.0292 - output_x_loss: 38.1861 - output_y_loss: 194.3867 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1861 - output_y_msle: 194.3867 - output_z_msle: 0.0000e+00 - val_loss: 92.2064 - val_output_x_loss: 38.2132 - val_output_y_loss: 192.3029 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2132 - val_output_y_msle: 192.3029 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 485/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.9844 - output_x_loss: 38.1835 - output_y_loss: 194.2775 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1835 - output_y_msle: 194.2775 - output_z_msle: 0.0000e+00 - val_loss: 92.1846 - val_output_x_loss: 38.2117 - val_output_y_loss: 192.2497 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2117 - val_output_y_msle: 192.2497 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 486/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.9648 - output_x_loss: 38.1815 - output_y_loss: 194.2304 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1815 - output_y_msle: 194.2304 - output_z_msle: 0.0000e+00 - val_loss: 92.0694 - val_output_x_loss: 38.0902 - val_output_y_loss: 192.0833 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.0902 - val_output_y_msle: 192.0833 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 487/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.9163 - output_x_loss: 38.1977 - output_y_loss: 194.0932 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1977 - output_y_msle: 194.0932 - output_z_msle: 0.0000e+00 - val_loss: 92.0623 - val_output_x_loss: 38.2098 - val_output_y_loss: 191.9460 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2098 - val_output_y_msle: 191.9460 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 488/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.9053 - output_x_loss: 38.1799 - output_y_loss: 194.0833 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1799 - output_y_msle: 194.0833 - output_z_msle: 0.0000e+00 - val_loss: 92.0568 - val_output_x_loss: 38.2082 - val_output_y_loss: 191.9337 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2082 - val_output_y_msle: 191.9337 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 489/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8841 - output_x_loss: 38.1433 - output_y_loss: 194.0671 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1433 - output_y_msle: 194.0671 - output_z_msle: 0.0000e+00 - val_loss: 92.0459 - val_output_x_loss: 38.2061 - val_output_y_loss: 191.9086 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2061 - val_output_y_msle: 191.9086 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 490/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8702 - output_x_loss: 38.1404 - output_y_loss: 194.0353 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1404 - output_y_msle: 194.0353 - output_z_msle: 0.0000e+00 - val_loss: 91.9873 - val_output_x_loss: 38.0865 - val_output_y_loss: 191.8818 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.0865 - val_output_y_msle: 191.8818 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 491/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8513 - output_x_loss: 38.1048 - output_y_loss: 194.0234 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1048 - output_y_msle: 194.0234 - output_z_msle: 0.0000e+00 - val_loss: 91.9453 - val_output_x_loss: 38.0797 - val_output_y_loss: 191.7836 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.0797 - val_output_y_msle: 191.7836 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 492/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8506 - output_x_loss: 38.1165 - output_y_loss: 194.0102 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1165 - output_y_msle: 194.0102 - output_z_msle: 0.0000e+00 - val_loss: 91.9852 - val_output_x_loss: 38.2019 - val_output_y_loss: 191.7610 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2019 - val_output_y_msle: 191.7610 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 493/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8388 - output_x_loss: 38.1011 - output_y_loss: 193.9961 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1011 - output_y_msle: 193.9961 - output_z_msle: 0.0000e+00 - val_loss: 91.9449 - val_output_x_loss: 38.2002 - val_output_y_loss: 191.6619 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.2002 - val_output_y_msle: 191.6619 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 494/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8305 - output_x_loss: 38.0988 - output_y_loss: 193.9774 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0988 - output_y_msle: 193.9774 - output_z_msle: 0.0000e+00 - val_loss: 91.8905 - val_output_x_loss: 38.0795 - val_output_y_loss: 191.6467 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 38.0795 - val_output_y_msle: 191.6467 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 495/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.8134 - output_x_loss: 38.0969 - output_y_loss: 193.9367 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0969 - output_y_msle: 193.9367 - output_z_msle: 0.0000e+00 - val_loss: 91.8197 - val_output_x_loss: 37.9183 - val_output_y_loss: 191.6308 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9183 - val_output_y_msle: 191.6308 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 496/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.7956 - output_x_loss: 38.0951 - output_y_loss: 193.8939 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0951 - output_y_msle: 193.8939 - output_z_msle: 0.0000e+00 - val_loss: 91.8095 - val_output_x_loss: 37.9118 - val_output_y_loss: 191.6118 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9118 - val_output_y_msle: 191.6118 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 497/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.7843 - output_x_loss: 38.0933 - output_y_loss: 193.8674 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0933 - output_y_msle: 193.8674 - output_z_msle: 0.0000e+00 - val_loss: 91.7980 - val_output_x_loss: 37.9079 - val_output_y_loss: 191.5872 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9079 - val_output_y_msle: 191.5872 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 498/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.7554 - output_x_loss: 38.0916 - output_y_loss: 193.7970 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0916 - output_y_msle: 193.7970 - output_z_msle: 0.0000e+00 - val_loss: 91.7847 - val_output_x_loss: 37.9049 - val_output_y_loss: 191.5568 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9049 - val_output_y_msle: 191.5568 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 499/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.7510 - output_x_loss: 38.1085 - output_y_loss: 193.7691 - output_z_loss: 0.0000e+00 - output_x_msle: 38.1085 - output_y_msle: 193.7691 - output_z_msle: 0.0000e+00 - val_loss: 91.7370 - val_output_x_loss: 37.9092 - val_output_y_loss: 191.4332 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9092 - val_output_y_msle: 191.4332 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 500/500\n",
      "165/165 [==============================] - 1s 5ms/step - loss: 92.6805 - output_x_loss: 38.0549 - output_y_loss: 193.6464 - output_z_loss: 0.0000e+00 - output_x_msle: 38.0549 - output_y_msle: 193.6464 - output_z_msle: 0.0000e+00 - val_loss: 91.7241 - val_output_x_loss: 37.9016 - val_output_y_loss: 191.4086 - val_output_z_loss: 0.0000e+00 - val_output_x_msle: 37.9016 - val_output_y_msle: 191.4086 - val_output_z_msle: 0.0000e+00 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using numpy formatted training and validation data.\n",
    "history = model.fit(\n",
    "    [X_train], [y_train_x, y_train_y, y_train_z],\n",
    "    epochs=input_num_epochs,\n",
    "    validation_data=([X_valid], [y_valid_x, y_valid_y, y_valid_z]),\n",
    "    batch_size=input_batch_size,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>output_x_loss</th>\n",
       "      <th>output_y_loss</th>\n",
       "      <th>output_z_loss</th>\n",
       "      <th>output_x_msle</th>\n",
       "      <th>output_y_msle</th>\n",
       "      <th>output_z_msle</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_output_x_loss</th>\n",
       "      <th>val_output_y_loss</th>\n",
       "      <th>val_output_z_loss</th>\n",
       "      <th>val_output_x_msle</th>\n",
       "      <th>val_output_y_msle</th>\n",
       "      <th>val_output_z_msle</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308.794922</td>\n",
       "      <td>300.815460</td>\n",
       "      <td>304.258240</td>\n",
       "      <td>333.827881</td>\n",
       "      <td>300.815460</td>\n",
       "      <td>304.258240</td>\n",
       "      <td>333.827881</td>\n",
       "      <td>312.070465</td>\n",
       "      <td>303.575073</td>\n",
       "      <td>308.729370</td>\n",
       "      <td>335.743378</td>\n",
       "      <td>303.575073</td>\n",
       "      <td>308.729370</td>\n",
       "      <td>335.743378</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307.511597</td>\n",
       "      <td>300.678345</td>\n",
       "      <td>303.924072</td>\n",
       "      <td>328.352631</td>\n",
       "      <td>300.678345</td>\n",
       "      <td>303.924072</td>\n",
       "      <td>328.352631</td>\n",
       "      <td>311.204865</td>\n",
       "      <td>303.556396</td>\n",
       "      <td>308.537231</td>\n",
       "      <td>331.836700</td>\n",
       "      <td>303.556396</td>\n",
       "      <td>308.537231</td>\n",
       "      <td>331.836700</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306.352081</td>\n",
       "      <td>300.520966</td>\n",
       "      <td>303.558685</td>\n",
       "      <td>323.600372</td>\n",
       "      <td>300.520966</td>\n",
       "      <td>303.558685</td>\n",
       "      <td>323.600372</td>\n",
       "      <td>310.156799</td>\n",
       "      <td>303.511139</td>\n",
       "      <td>308.551056</td>\n",
       "      <td>326.659485</td>\n",
       "      <td>303.511139</td>\n",
       "      <td>308.551056</td>\n",
       "      <td>326.659485</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>305.305542</td>\n",
       "      <td>300.413483</td>\n",
       "      <td>303.615204</td>\n",
       "      <td>318.470184</td>\n",
       "      <td>300.413483</td>\n",
       "      <td>303.615204</td>\n",
       "      <td>318.470184</td>\n",
       "      <td>308.942322</td>\n",
       "      <td>303.252960</td>\n",
       "      <td>308.228851</td>\n",
       "      <td>321.747833</td>\n",
       "      <td>303.252960</td>\n",
       "      <td>308.228851</td>\n",
       "      <td>321.747833</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304.492554</td>\n",
       "      <td>300.282684</td>\n",
       "      <td>303.484802</td>\n",
       "      <td>314.928101</td>\n",
       "      <td>300.282684</td>\n",
       "      <td>303.484802</td>\n",
       "      <td>314.928101</td>\n",
       "      <td>308.539703</td>\n",
       "      <td>303.038055</td>\n",
       "      <td>308.399414</td>\n",
       "      <td>319.823334</td>\n",
       "      <td>303.038055</td>\n",
       "      <td>308.399414</td>\n",
       "      <td>319.823334</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>92.916344</td>\n",
       "      <td>38.197678</td>\n",
       "      <td>194.093216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.197678</td>\n",
       "      <td>194.093216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.062317</td>\n",
       "      <td>38.209846</td>\n",
       "      <td>191.945953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.209846</td>\n",
       "      <td>191.945953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>92.905312</td>\n",
       "      <td>38.179920</td>\n",
       "      <td>194.083344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.179920</td>\n",
       "      <td>194.083344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.056763</td>\n",
       "      <td>38.208210</td>\n",
       "      <td>191.933701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.208210</td>\n",
       "      <td>191.933701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>92.884148</td>\n",
       "      <td>38.143311</td>\n",
       "      <td>194.067078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.143311</td>\n",
       "      <td>194.067078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.045883</td>\n",
       "      <td>38.206089</td>\n",
       "      <td>191.908630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.206089</td>\n",
       "      <td>191.908630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>92.870232</td>\n",
       "      <td>38.140419</td>\n",
       "      <td>194.035278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.140419</td>\n",
       "      <td>194.035278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.987320</td>\n",
       "      <td>38.086479</td>\n",
       "      <td>191.881805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.086479</td>\n",
       "      <td>191.881805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>92.851265</td>\n",
       "      <td>38.104767</td>\n",
       "      <td>194.023422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.104767</td>\n",
       "      <td>194.023422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.945305</td>\n",
       "      <td>38.079659</td>\n",
       "      <td>191.783569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.079659</td>\n",
       "      <td>191.783569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>491 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loss  output_x_loss  output_y_loss  output_z_loss  output_x_msle  \\\n",
       "0    308.794922     300.815460     304.258240     333.827881     300.815460   \n",
       "1    307.511597     300.678345     303.924072     328.352631     300.678345   \n",
       "2    306.352081     300.520966     303.558685     323.600372     300.520966   \n",
       "3    305.305542     300.413483     303.615204     318.470184     300.413483   \n",
       "4    304.492554     300.282684     303.484802     314.928101     300.282684   \n",
       "..          ...            ...            ...            ...            ...   \n",
       "486   92.916344      38.197678     194.093216       0.000000      38.197678   \n",
       "487   92.905312      38.179920     194.083344       0.000000      38.179920   \n",
       "488   92.884148      38.143311     194.067078       0.000000      38.143311   \n",
       "489   92.870232      38.140419     194.035278       0.000000      38.140419   \n",
       "490   92.851265      38.104767     194.023422       0.000000      38.104767   \n",
       "\n",
       "     output_y_msle  output_z_msle    val_loss  val_output_x_loss  \\\n",
       "0       304.258240     333.827881  312.070465         303.575073   \n",
       "1       303.924072     328.352631  311.204865         303.556396   \n",
       "2       303.558685     323.600372  310.156799         303.511139   \n",
       "3       303.615204     318.470184  308.942322         303.252960   \n",
       "4       303.484802     314.928101  308.539703         303.038055   \n",
       "..             ...            ...         ...                ...   \n",
       "486     194.093216       0.000000   92.062317          38.209846   \n",
       "487     194.083344       0.000000   92.056763          38.208210   \n",
       "488     194.067078       0.000000   92.045883          38.206089   \n",
       "489     194.035278       0.000000   91.987320          38.086479   \n",
       "490     194.023422       0.000000   91.945305          38.079659   \n",
       "\n",
       "     val_output_y_loss  val_output_z_loss  val_output_x_msle  \\\n",
       "0           308.729370         335.743378         303.575073   \n",
       "1           308.537231         331.836700         303.556396   \n",
       "2           308.551056         326.659485         303.511139   \n",
       "3           308.228851         321.747833         303.252960   \n",
       "4           308.399414         319.823334         303.038055   \n",
       "..                 ...                ...                ...   \n",
       "486         191.945953           0.000000          38.209846   \n",
       "487         191.933701           0.000000          38.208210   \n",
       "488         191.908630           0.000000          38.206089   \n",
       "489         191.881805           0.000000          38.086479   \n",
       "490         191.783569           0.000000          38.079659   \n",
       "\n",
       "     val_output_y_msle  val_output_z_msle            lr  \n",
       "0           308.729370         335.743378  1.000000e-07  \n",
       "1           308.537231         331.836700  1.000000e-07  \n",
       "2           308.551056         326.659485  1.000000e-07  \n",
       "3           308.228851         321.747833  1.000000e-07  \n",
       "4           308.399414         319.823334  1.000000e-07  \n",
       "..                 ...                ...           ...  \n",
       "486         191.945953           0.000000  1.000000e-07  \n",
       "487         191.933701           0.000000  1.000000e-07  \n",
       "488         191.908630           0.000000  1.000000e-07  \n",
       "489         191.881805           0.000000  1.000000e-07  \n",
       "490         191.783569           0.000000  1.000000e-07  \n",
       "\n",
       "[491 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert training history to dataframe for analysis and plotting.\n",
    "complete_history_data = pd.DataFrame(history.history)\n",
    "complete_history_data.head(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e886d43623964988bb7c662bfd75bb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1969072ff48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a90f0a60db4c27a7da5861427acb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate MSEs.\n",
    "fig2, mse_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "mse_plots[0][0].plot(complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]])\n",
    "#mse_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "mse_plots[0][1].plot(complete_history_data[[\"output_y_msle\", \"val_output_y_msle\"]])\n",
    "#mse_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "mse_plots[1][0].plot(complete_history_data[[\"output_z_msle\", \"val_output_z_msle\"]])\n",
    "#mse_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93ac067db84ae88a5fd895b9f08532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate loss.\n",
    "fig, loss_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "loss_plots[0][0].plot(complete_history_data[[\"loss\", \"val_loss\"]])\n",
    "#loss_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[0][1].plot(complete_history_data[[\"output_x_loss\", \"val_output_x_loss\"]])\n",
    "#loss_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][0].plot(complete_history_data[[\"output_y_loss\", \"val_output_y_loss\"]])\n",
    "#loss_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][1].plot(complete_history_data[[\"output_z_loss\", \"val_output_z_loss\"]])\n",
    "#loss_plots[1][1].set_ylim(0,1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4501,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 3ms/step - loss: 94.2831 - output_x_loss: 37.8731 - output_y_loss: 197.8348 - output_z_loss: 0.0000e+00 - output_x_msle: 37.8731 - output_y_msle: 197.8348 - output_z_msle: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[94.28313446044922,\n",
       " 37.873050689697266,\n",
       " 197.8347625732422,\n",
       " 0.0,\n",
       " 37.873050689697266,\n",
       " 197.8347625732422,\n",
       " 0.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test],[y_test_x, y_test_y, y_test_z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values and Inspect Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, z_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_x</th>\n",
       "      <th>model_x</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>model_y</th>\n",
       "      <th>pred_z</th>\n",
       "      <th>model_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.290365e+11</td>\n",
       "      <td>2.414112e+12</td>\n",
       "      <td>-6.760124e+11</td>\n",
       "      <td>4.196512e+11</td>\n",
       "      <td>-6.312607e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.153878e+11</td>\n",
       "      <td>-1.636469e+12</td>\n",
       "      <td>1.344921e+12</td>\n",
       "      <td>2.865577e+12</td>\n",
       "      <td>-2.769244e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.189568e+12</td>\n",
       "      <td>5.092482e+11</td>\n",
       "      <td>9.201201e+11</td>\n",
       "      <td>3.642873e+12</td>\n",
       "      <td>-6.788279e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.874498e+11</td>\n",
       "      <td>2.476983e+12</td>\n",
       "      <td>-1.146537e+12</td>\n",
       "      <td>1.140440e+12</td>\n",
       "      <td>-3.458987e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.192929e+11</td>\n",
       "      <td>2.421839e+12</td>\n",
       "      <td>-6.059463e+11</td>\n",
       "      <td>4.562690e+11</td>\n",
       "      <td>-5.886205e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.282768e+12</td>\n",
       "      <td>2.278304e+12</td>\n",
       "      <td>-1.044575e+12</td>\n",
       "      <td>2.079514e+12</td>\n",
       "      <td>-4.002635e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.218959e+12</td>\n",
       "      <td>1.882752e+12</td>\n",
       "      <td>-3.804256e+11</td>\n",
       "      <td>2.764791e+12</td>\n",
       "      <td>-3.558199e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.704070e+11</td>\n",
       "      <td>6.637551e+11</td>\n",
       "      <td>-2.875987e+11</td>\n",
       "      <td>-1.512500e+12</td>\n",
       "      <td>-1.858160e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.916086e+11</td>\n",
       "      <td>1.151652e+12</td>\n",
       "      <td>1.282034e+12</td>\n",
       "      <td>3.472693e+12</td>\n",
       "      <td>-1.082247e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.309224e+12</td>\n",
       "      <td>2.428307e+12</td>\n",
       "      <td>-1.417456e+12</td>\n",
       "      <td>1.564511e+12</td>\n",
       "      <td>-2.844275e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred_x       model_x        pred_y       model_y        pred_z  \\\n",
       "0  6.290365e+11  2.414112e+12 -6.760124e+11  4.196512e+11 -6.312607e+11   \n",
       "1 -1.153878e+11 -1.636469e+12  1.344921e+12  2.865577e+12 -2.769244e+11   \n",
       "2  1.189568e+12  5.092482e+11  9.201201e+11  3.642873e+12 -6.788279e+11   \n",
       "3  9.874498e+11  2.476983e+12 -1.146537e+12  1.140440e+12 -3.458987e+11   \n",
       "4  6.192929e+11  2.421839e+12 -6.059463e+11  4.562690e+11 -5.886205e+11   \n",
       "5  1.282768e+12  2.278304e+12 -1.044575e+12  2.079514e+12 -4.002635e+11   \n",
       "6  1.218959e+12  1.882752e+12 -3.804256e+11  2.764791e+12 -3.558199e+11   \n",
       "7 -3.704070e+11  6.637551e+11 -2.875987e+11 -1.512500e+12 -1.858160e+11   \n",
       "8  5.916086e+11  1.151652e+12  1.282034e+12  3.472693e+12 -1.082247e+12   \n",
       "9  1.309224e+12  2.428307e+12 -1.417456e+12  1.564511e+12 -2.844275e+11   \n",
       "\n",
       "   model_z  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      0.0  \n",
       "8      0.0  \n",
       "9      0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison = pd.DataFrame(data=np.concatenate((x_pred, y_test_x.reshape(-1,1), y_pred, y_test_y.reshape(-1,1), z_pred, y_test_z.reshape(-1,1)), axis=1),\n",
    "                                    columns=['pred_x', 'model_x', 'pred_y', 'model_y', 'pred_z', 'model_z'])\n",
    "pred_model_comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f00cb4ad3040608d39ffb0c5ca4d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1953ebdcfc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_x\", \"model_x\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de57a8bedd01470dba18c83a9270356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x195716a5388>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_y\", \"model_y\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac67a174abb5483ea9a51d67d7d89ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x195716a5288>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model_comparison[[\"pred_z\", \"model_z\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
