{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet Simulator with Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Craig Boger\n",
    "06/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes the model prototyping and learning of v1.01 and tries to expand upon it in 2 key areas.\n",
    "\n",
    "1) Perform data normalization and processing in TF data libraries.\n",
    "2) Take predictions in normalized form and output them in their unormalized form for use in simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straight Up Just Stealing Someone's Code and Trying to Run It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to benrules2: https://gist.github.com/benrules2/220d56ea6fe9a85a4d762128b11adfba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a1ee9dd9d4ad98d96bd0d49b80099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class point:\n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class body:\n",
    "    def __init__(self, location, mass, velocity, name = \"\"):\n",
    "        self.location = location\n",
    "        self.mass = mass\n",
    "        self.velocity = velocity\n",
    "        self.name = name\n",
    "\n",
    "def calculate_single_body_acceleration(bodies, body_index):\n",
    "    G_const = 6.67408e-11 #m3 kg-1 s-2\n",
    "    acceleration = point(0,0,0)\n",
    "    target_body = bodies[body_index]\n",
    "    for index, external_body in enumerate(bodies):\n",
    "        if index != body_index:\n",
    "            r = (target_body.location.x - external_body.location.x)**2 + (target_body.location.y - external_body.location.y)**2 + (target_body.location.z - external_body.location.z)**2\n",
    "            r = math.sqrt(r)\n",
    "            tmp = G_const * external_body.mass / r**3\n",
    "            acceleration.x += tmp * (external_body.location.x - target_body.location.x)\n",
    "            acceleration.y += tmp * (external_body.location.y - target_body.location.y)\n",
    "            acceleration.z += tmp * (external_body.location.z - target_body.location.z)\n",
    "\n",
    "    return acceleration\n",
    "\n",
    "def compute_velocity(bodies, time_step = 1):\n",
    "    for body_index, target_body in enumerate(bodies):\n",
    "        acceleration = calculate_single_body_acceleration(bodies, body_index)\n",
    "\n",
    "        target_body.velocity.x += acceleration.x * time_step\n",
    "        target_body.velocity.y += acceleration.y * time_step\n",
    "        target_body.velocity.z += acceleration.z * time_step \n",
    "\n",
    "\n",
    "def update_location(bodies, time_step = 1):\n",
    "    for target_body in bodies:\n",
    "        target_body.location.x += target_body.velocity.x * time_step\n",
    "        target_body.location.y += target_body.velocity.y * time_step\n",
    "        target_body.location.z += target_body.velocity.z * time_step\n",
    "\n",
    "def compute_gravity_step(bodies, time_step = 1):\n",
    "    compute_velocity(bodies, time_step = time_step)\n",
    "    update_location(bodies, time_step = time_step)\n",
    "\n",
    "def plot_output(bodies, outfile = None):\n",
    "    fig = plot.figure()\n",
    "    colours = ['r','b','g','y','m','c']\n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "    max_range = 0\n",
    "    for current_body in bodies: \n",
    "        max_dim = max(max(current_body[\"x\"]),max(current_body[\"y\"]),max(current_body[\"z\"]))\n",
    "        if max_dim > max_range:\n",
    "            max_range = max_dim\n",
    "        ax.plot(current_body[\"x\"], current_body[\"y\"], current_body[\"z\"], c = random.choice(colours), label = current_body[\"name\"])        \n",
    "    \n",
    "    ax.set_xlim([-max_range,max_range])    \n",
    "    ax.set_ylim([-max_range,max_range])\n",
    "    ax.set_zlim([-max_range,max_range])\n",
    "    ax.legend()        \n",
    "\n",
    "    if outfile:\n",
    "        plot.savefig(outfile)\n",
    "    else:\n",
    "        plot.show()\n",
    "\n",
    "def run_simulation(bodies, names = None, time_step = 1, number_of_steps = 10000, report_freq = 100):\n",
    "\n",
    "    #create output container for each body\n",
    "    body_locations_hist = []\n",
    "    for current_body in bodies:\n",
    "        body_locations_hist.append({\"x\":[], \"y\":[], \"z\":[], \"name\":current_body.name})\n",
    "        \n",
    "    for i in range(1,number_of_steps):\n",
    "        compute_gravity_step(bodies, time_step = 1000)            \n",
    "        \n",
    "        if i % report_freq == 0:\n",
    "            for index, body_location in enumerate(body_locations_hist):\n",
    "                body_location[\"x\"].append(bodies[index].location.x)\n",
    "                body_location[\"y\"].append(bodies[index].location.y)           \n",
    "                body_location[\"z\"].append(bodies[index].location.z)       \n",
    "\n",
    "    return body_locations_hist        \n",
    "            \n",
    "#planet data (location (m), mass (kg), velocity (m/s)\n",
    "sun = {\"location\":point(0,0,0), \"mass\":2e30, \"velocity\":point(0,0,0)}\n",
    "mercury = {\"location\":point(0,5.7e10,0), \"mass\":3.285e23, \"velocity\":point(47000,0,0)}\n",
    "venus = {\"location\":point(0,1.1e11,0), \"mass\":4.8e24, \"velocity\":point(35000,0,0)}\n",
    "earth = {\"location\":point(0,1.5e11,0), \"mass\":6e24, \"velocity\":point(30000,0,0)}\n",
    "mars = {\"location\":point(0,2.2e11,0), \"mass\":2.4e24, \"velocity\":point(24000,0,0)}\n",
    "jupiter = {\"location\":point(0,7.7e11,0), \"mass\":1e28, \"velocity\":point(13000,0,0)}\n",
    "saturn = {\"location\":point(0,1.4e12,0), \"mass\":5.7e26, \"velocity\":point(9000,0,0)}\n",
    "uranus = {\"location\":point(0,2.8e12,0), \"mass\":8.7e25, \"velocity\":point(6835,0,0)}\n",
    "neptune = {\"location\":point(0,4.5e12,0), \"mass\":1e26, \"velocity\":point(5477,0,0)}\n",
    "pluto = {\"location\":point(0,3.7e12,0), \"mass\":1.3e22, \"velocity\":point(4748,0,0)}\n",
    "# TODO: Add random sattellite here.\n",
    "satellite_1 = {\"location\":point(1e5,3.7e5,0), \"mass\":1.7e1, \"velocity\":point(4748,0,0)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #build list of planets in the simulation, or create your own\n",
    "    bodies = [\n",
    "        body( location = sun[\"location\"], mass = sun[\"mass\"], velocity = sun[\"velocity\"], name = \"sun\"),\n",
    "        body( location = earth[\"location\"], mass = earth[\"mass\"], velocity = earth[\"velocity\"], name = \"earth\"),\n",
    "        body( location = mars[\"location\"], mass = mars[\"mass\"], velocity = mars[\"velocity\"], name = \"mars\"),\n",
    "        body( location = venus[\"location\"], mass = venus[\"mass\"], velocity = venus[\"velocity\"], name = \"venus\"),\n",
    "        body( location = mercury[\"location\"], mass = mercury[\"mass\"], velocity = mercury[\"velocity\"], name = \"mercury\"),\n",
    "        body( location = jupiter[\"location\"], mass = jupiter[\"mass\"], velocity = jupiter[\"velocity\"], name = \"jupiter\"),\n",
    "        body( location = saturn[\"location\"], mass = saturn[\"mass\"], velocity = saturn[\"velocity\"], name = \"saturn\"),\n",
    "        \n",
    "        #body( location = satellite_1[\"location\"], mass = satellite_1[\"mass\"], velocity = satellite_1[\"velocity\"], name = \"sattellite_1\")\n",
    "        ]\n",
    "    \n",
    "    # Original defaults of simulation\n",
    "    # motions = run_simulation(bodies, time_step = 100, number_of_steps = 80000, report_freq = 1000)\n",
    "    # Try messing with report frequency to get more data.\n",
    "    motions = run_simulation(bodies, time_step = 100, number_of_steps = 300000, report_freq = 100)\n",
    "    plot_output(motions, outfile = 'orbits.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take motions data from the above simulation and convert it to a Pandas dataframe.  The \"motions\" output is a list of python dictionaries that can be converted into a dataframe and then manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.172247210875407, 49.37608388489302, 166.613...</td>\n",
       "      <td>[6056.974666438165, 24107.571980251058, 54150....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2999802268.7576785, 5998418130.158717, 899466...</td>\n",
       "      <td>[149970049800.53976, 149880804272.02502, 14973...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2399949856.0043564, 4799598821.688435, 719864...</td>\n",
       "      <td>[219986083529.99896, 219944611139.58228, 21987...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[3499415066.461402, 6995320910.112684, 1048421...</td>\n",
       "      <td>[109944304437.46532, 109778376868.05923, 10950...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4694355206.034602, 9354859805.633783, 1394777...</td>\n",
       "      <td>[56792631335.43017, 56175843268.08082, 5515329...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mercury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1299999366.480654, 2599994931.4665866, 389998...</td>\n",
       "      <td>[769998863548.677, 769995476701.667, 769989839...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[899999928.8208524, 1799999430.5240006, 269999...</td>\n",
       "      <td>[1399999647585.8357, 1399998597321.9666, 13999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>saturn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  [6.172247210875407, 49.37608388489302, 166.613...   \n",
       "1  [2999802268.7576785, 5998418130.158717, 899466...   \n",
       "2  [2399949856.0043564, 4799598821.688435, 719864...   \n",
       "3  [3499415066.461402, 6995320910.112684, 1048421...   \n",
       "4  [4694355206.034602, 9354859805.633783, 1394777...   \n",
       "5  [1299999366.480654, 2599994931.4665866, 389998...   \n",
       "6  [899999928.8208524, 1799999430.5240006, 269999...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [6056.974666438165, 24107.571980251058, 54150....   \n",
       "1  [149970049800.53976, 149880804272.02502, 14973...   \n",
       "2  [219986083529.99896, 219944611139.58228, 21987...   \n",
       "3  [109944304437.46532, 109778376868.05923, 10950...   \n",
       "4  [56792631335.43017, 56175843268.08082, 5515329...   \n",
       "5  [769998863548.677, 769995476701.667, 769989839...   \n",
       "6  [1399999647585.8357, 1399998597321.9666, 13999...   \n",
       "\n",
       "                                                   z     name  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      sun  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    earth  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     mars  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    venus  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  mercury  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  jupiter  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   saturn  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "motions_df = pd.DataFrame(motions)\n",
    "motions_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to separate out each row of list or dataframe into its own dataframe.\n",
    "# Will later put these dataframes back together into 1 large dataframe.\n",
    "\n",
    "motions_df_list = []\n",
    "for body in motions:\n",
    "    motions_df_list.append(pd.DataFrame(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>1.099443e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>1.097784e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>1.095024e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>1.091166e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>1.086215e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>-5.289650e+10</td>\n",
       "      <td>8.213631e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>-5.030464e+10</td>\n",
       "      <td>8.447291e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>-4.763994e+10</td>\n",
       "      <td>8.672745e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>-4.490500e+10</td>\n",
       "      <td>8.889761e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>-4.210250e+10</td>\n",
       "      <td>9.098119e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x             y    z   name\n",
       "0     3.499415e+09  1.099443e+11  0.0  venus\n",
       "1     6.995321e+09  1.097784e+11  0.0  venus\n",
       "2     1.048421e+10  1.095024e+11  0.0  venus\n",
       "3     1.396259e+10  1.091166e+11  0.0  venus\n",
       "4     1.742697e+10  1.086215e+11  0.0  venus\n",
       "...            ...           ...  ...    ...\n",
       "2994 -5.289650e+10  8.213631e+10  0.0  venus\n",
       "2995 -5.030464e+10  8.447291e+10  0.0  venus\n",
       "2996 -4.763994e+10  8.672745e+10  0.0  venus\n",
       "2997 -4.490500e+10  8.889761e+10  0.0  venus\n",
       "2998 -4.210250e+10  9.098119e+10  0.0  venus\n",
       "\n",
       "[2999 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions_df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>earth_y</th>\n",
       "      <th>earth_z</th>\n",
       "      <th>mars_x</th>\n",
       "      <th>mars_y</th>\n",
       "      <th>mars_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>...</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>jupiter_x</th>\n",
       "      <th>jupiter_y</th>\n",
       "      <th>jupiter_z</th>\n",
       "      <th>saturn_x</th>\n",
       "      <th>saturn_y</th>\n",
       "      <th>saturn_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.172247e+00</td>\n",
       "      <td>6.056975e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>1.499700e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.399950e+09</td>\n",
       "      <td>2.199861e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.694355e+09</td>\n",
       "      <td>5.679263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.299999e+09</td>\n",
       "      <td>7.699989e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.999999e+08</td>\n",
       "      <td>1.400000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.937608e+01</td>\n",
       "      <td>2.410757e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>1.498808e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.799599e+09</td>\n",
       "      <td>2.199446e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.354860e+09</td>\n",
       "      <td>5.617584e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.599995e+09</td>\n",
       "      <td>7.699955e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.799999e+09</td>\n",
       "      <td>1.399999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666139e+02</td>\n",
       "      <td>5.415063e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>1.497323e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.198646e+09</td>\n",
       "      <td>2.198756e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394778e+10</td>\n",
       "      <td>5.515330e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.899983e+09</td>\n",
       "      <td>7.699898e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.699998e+09</td>\n",
       "      <td>1.399997e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948280e+02</td>\n",
       "      <td>9.618418e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>1.495246e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.596791e+09</td>\n",
       "      <td>2.197790e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843961e+10</td>\n",
       "      <td>5.373113e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.199959e+09</td>\n",
       "      <td>7.699820e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.599995e+09</td>\n",
       "      <td>1.399994e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.708690e+02</td>\n",
       "      <td>1.502055e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>1.492578e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.199373e+10</td>\n",
       "      <td>2.196549e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279721e+10</td>\n",
       "      <td>5.191794e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.499921e+09</td>\n",
       "      <td>7.699718e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.499991e+09</td>\n",
       "      <td>1.399991e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.138605e+06</td>\n",
       "      <td>5.394756e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441446e+11</td>\n",
       "      <td>-4.894462e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.875072e+11</td>\n",
       "      <td>1.033965e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578892e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.050288e+10</td>\n",
       "      <td>-4.133032e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.242400e+11</td>\n",
       "      <td>7.596504e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.633698e+10</td>\n",
       "      <td>1.396785e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.259034e+06</td>\n",
       "      <td>5.506067e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431961e+11</td>\n",
       "      <td>-5.174263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.885864e+11</td>\n",
       "      <td>1.011770e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238219e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606635e+10</td>\n",
       "      <td>-4.407853e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.255223e+11</td>\n",
       "      <td>7.594341e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.723499e+10</td>\n",
       "      <td>1.396718e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.381576e+06</td>\n",
       "      <td>5.618472e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421936e+11</td>\n",
       "      <td>-5.452104e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.896398e+11</td>\n",
       "      <td>9.894374e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.963735e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137176e+10</td>\n",
       "      <td>-4.638960e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.268043e+11</td>\n",
       "      <td>7.592156e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.813296e+10</td>\n",
       "      <td>1.396650e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.506234e+06</td>\n",
       "      <td>5.731969e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411373e+11</td>\n",
       "      <td>-5.727882e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.906674e+11</td>\n",
       "      <td>9.669701e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536788e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646399e+10</td>\n",
       "      <td>-4.823713e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280859e+11</td>\n",
       "      <td>7.589949e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.903089e+10</td>\n",
       "      <td>1.396581e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.633010e+06</td>\n",
       "      <td>5.846559e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400277e+11</td>\n",
       "      <td>-6.001494e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916689e+11</td>\n",
       "      <td>9.443710e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104600e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139102e+10</td>\n",
       "      <td>-4.959978e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293671e+11</td>\n",
       "      <td>7.587719e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.992877e+10</td>\n",
       "      <td>1.396511e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sun_x         sun_y  sun_z       earth_x       earth_y  earth_z  \\\n",
       "0   6.172247e+00  6.056975e+03    0.0  2.999802e+09  1.499700e+11      0.0   \n",
       "1   4.937608e+01  2.410757e+04    0.0  5.998418e+09  1.498808e+11      0.0   \n",
       "2   1.666139e+02  5.415063e+04    0.0  8.994662e+09  1.497323e+11      0.0   \n",
       "3   3.948280e+02  9.618418e+04    0.0  1.198735e+10  1.495246e+11      0.0   \n",
       "4   7.708690e+02  1.502055e+05    0.0  1.497529e+10  1.492578e+11      0.0   \n",
       "..           ...           ...    ...           ...           ...      ...   \n",
       "95  4.138605e+06  5.394756e+07    0.0  1.441446e+11 -4.894462e+10      0.0   \n",
       "96  4.259034e+06  5.506067e+07    0.0  1.431961e+11 -5.174263e+10      0.0   \n",
       "97  4.381576e+06  5.618472e+07    0.0  1.421936e+11 -5.452104e+10      0.0   \n",
       "98  4.506234e+06  5.731969e+07    0.0  1.411373e+11 -5.727882e+10      0.0   \n",
       "99  4.633010e+06  5.846559e+07    0.0  1.400277e+11 -6.001494e+10      0.0   \n",
       "\n",
       "          mars_x        mars_y  mars_z       venus_x  ...  venus_z  \\\n",
       "0   2.399950e+09  2.199861e+11     0.0  3.499415e+09  ...      0.0   \n",
       "1   4.799599e+09  2.199446e+11     0.0  6.995321e+09  ...      0.0   \n",
       "2   7.198646e+09  2.198756e+11     0.0  1.048421e+10  ...      0.0   \n",
       "3   9.596791e+09  2.197790e+11     0.0  1.396259e+10  ...      0.0   \n",
       "4   1.199373e+10  2.196549e+11     0.0  1.742697e+10  ...      0.0   \n",
       "..           ...           ...     ...           ...  ...      ...   \n",
       "95  1.875072e+11  1.033965e+11     0.0  1.578892e+10  ...      0.0   \n",
       "96  1.885864e+11  1.011770e+11     0.0  1.238219e+10  ...      0.0   \n",
       "97  1.896398e+11  9.894374e+10     0.0  8.963735e+09  ...      0.0   \n",
       "98  1.906674e+11  9.669701e+10     0.0  5.536788e+09  ...      0.0   \n",
       "99  1.916689e+11  9.443710e+10     0.0  2.104600e+09  ...      0.0   \n",
       "\n",
       "       mercury_x     mercury_y  mercury_z     jupiter_x     jupiter_y  \\\n",
       "0   4.694355e+09  5.679263e+10        0.0  1.299999e+09  7.699989e+11   \n",
       "1   9.354860e+09  5.617584e+10        0.0  2.599995e+09  7.699955e+11   \n",
       "2   1.394778e+10  5.515330e+10        0.0  3.899983e+09  7.699898e+11   \n",
       "3   1.843961e+10  5.373113e+10        0.0  5.199959e+09  7.699820e+11   \n",
       "4   2.279721e+10  5.191794e+10        0.0  6.499921e+09  7.699718e+11   \n",
       "..           ...           ...        ...           ...           ...   \n",
       "95  3.050288e+10 -4.133032e+10        0.0  1.242400e+11  7.596504e+11   \n",
       "96  2.606635e+10 -4.407853e+10        0.0  1.255223e+11  7.594341e+11   \n",
       "97  2.137176e+10 -4.638960e+10        0.0  1.268043e+11  7.592156e+11   \n",
       "98  1.646399e+10 -4.823713e+10        0.0  1.280859e+11  7.589949e+11   \n",
       "99  1.139102e+10 -4.959978e+10        0.0  1.293671e+11  7.587719e+11   \n",
       "\n",
       "    jupiter_z      saturn_x      saturn_y  saturn_z  \n",
       "0         0.0  8.999999e+08  1.400000e+12       0.0  \n",
       "1         0.0  1.799999e+09  1.399999e+12       0.0  \n",
       "2         0.0  2.699998e+09  1.399997e+12       0.0  \n",
       "3         0.0  3.599995e+09  1.399994e+12       0.0  \n",
       "4         0.0  4.499991e+09  1.399991e+12       0.0  \n",
       "..        ...           ...           ...       ...  \n",
       "95        0.0  8.633698e+10  1.396785e+12       0.0  \n",
       "96        0.0  8.723499e+10  1.396718e+12       0.0  \n",
       "97        0.0  8.813296e+10  1.396650e+12       0.0  \n",
       "98        0.0  8.903089e+10  1.396581e+12       0.0  \n",
       "99        0.0  8.992877e+10  1.396511e+12       0.0  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the dataframes into a single, large dataframe.\n",
    "# Can later choose a planet to be the target we train to predict.\n",
    "complete_motion_df = None\n",
    "\n",
    "for body in motions_df_list:\n",
    "    # Append name of body to each column and remove the name column\n",
    "    body_name = body.loc[0, \"name\"]\n",
    "    body.columns = [body_name + \"_x\",\n",
    "                    body_name + \"_y\",\n",
    "                    body_name + \"_z\",\n",
    "                    \"name\"]\n",
    "    # Add current body to the complete dataframe.\n",
    "    complete_motion_df = pd.concat([complete_motion_df, body.iloc[:, 0:3]], axis=1)\n",
    "\n",
    "complete_motion_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single dataframe with all bodies and all positions with each time step as the index of our rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Create a tf.data Dataset from the Constructed, Unrandomized, Unnormalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python â‰¥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn â‰¥0.20 is required\n",
    "# Probably not needed since not using regressor or doing any feature engineering.\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler  # Scaler for normalizing data.\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaler for normalizing data.\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow â‰¥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "# Recommended to enable eager execution when developing model.\n",
    "# Processing data: https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Use sklearn for data processing\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0-tf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here with Trying to Process Data with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the difficulties is using a mixture of numpy, pandas, and sklearn to take input data (influx), arrange it, split it out, normalize it, and then train a model.  With tf.data input pipelines (similar to sklearn pipelines), we can create data and machine learning pipelines for training or inference.  This allows us to encapsulate not only the machine learning into a Tensorflow model, but the necessary transformations to that data.  That allows us to deploy the model and data transformations as a single object to the later simulator. \\\n",
    "The input pipeline let's us take raw data from any source, like csv, numpy arrays, distributed file system, etc, and convert it into the tensors we will use to train our model.\n",
    "\n",
    "Intro to tensors:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "Good source on how data loading and preprocessing is usually done: https://stackoverflow.com/questions/55321905/want-to-split-train-and-test-data-gotten-from-a-csv-with-tensorflow\n",
    "1) Load the data into memory with numpy\n",
    "2) Split the data into train and validation\n",
    "\n",
    "Since we are not using a massive dataset, then we might be able to use tf.split to split an exsting tf dataset into train and validation.\n",
    "https://docs.w3cub.com/tensorflow~python/tf/split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf dataset from slices (numpy array, pandas dataframe, etc). \n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "Probably one of the better articles on using tensorflow datasets: \\\n",
    "https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "\n",
    "TF documentation on tf.data: Building Tensorflow Input Pipelines: \\\n",
    "https://www.tensorflow.org/guide/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>earth_y</th>\n",
       "      <th>earth_z</th>\n",
       "      <th>mars_x</th>\n",
       "      <th>mars_y</th>\n",
       "      <th>mars_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>...</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>jupiter_x</th>\n",
       "      <th>jupiter_y</th>\n",
       "      <th>jupiter_z</th>\n",
       "      <th>saturn_x</th>\n",
       "      <th>saturn_y</th>\n",
       "      <th>saturn_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.913052e+10</td>\n",
       "      <td>5.697825e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031225e+11</td>\n",
       "      <td>-1.223594e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.302001e+10</td>\n",
       "      <td>-1.716263e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.002964e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.017515e+09</td>\n",
       "      <td>5.837242e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.631005e+11</td>\n",
       "      <td>-2.753003e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.107118e+12</td>\n",
       "      <td>-2.487850e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.140607e+08</td>\n",
       "      <td>1.970896e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.590686e+10</td>\n",
       "      <td>1.248203e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.825935e+11</td>\n",
       "      <td>1.158515e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.919243e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.852436e+09</td>\n",
       "      <td>5.868333e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.563034e+11</td>\n",
       "      <td>3.832339e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.342220e+11</td>\n",
       "      <td>1.270662e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.277441e+09</td>\n",
       "      <td>6.153926e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.063472e+10</td>\n",
       "      <td>1.357785e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.140996e+11</td>\n",
       "      <td>-1.619832e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.161885e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.274079e+10</td>\n",
       "      <td>-4.420687e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.949120e+11</td>\n",
       "      <td>-4.303914e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.850200e+11</td>\n",
       "      <td>8.695186e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.609521e+10</td>\n",
       "      <td>7.067926e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.739695e+10</td>\n",
       "      <td>-1.400178e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.472678e+10</td>\n",
       "      <td>2.212236e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.718303e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.897295e+10</td>\n",
       "      <td>5.108178e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.344394e+11</td>\n",
       "      <td>-5.661212e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.181920e+12</td>\n",
       "      <td>4.580841e+10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.858243e+08</td>\n",
       "      <td>1.090659e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.774886e+10</td>\n",
       "      <td>-1.168880e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.587114e+11</td>\n",
       "      <td>1.476854e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.090252e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.607403e+10</td>\n",
       "      <td>-4.724951e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.248041e+11</td>\n",
       "      <td>5.560248e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.950233e+11</td>\n",
       "      <td>1.330987e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.100623e+09</td>\n",
       "      <td>6.546513e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.283906e+11</td>\n",
       "      <td>9.461551e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.351698e+10</td>\n",
       "      <td>-1.764600e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.114823e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.653575e+10</td>\n",
       "      <td>-3.935061e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.284106e+11</td>\n",
       "      <td>-5.053616e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.023429e+12</td>\n",
       "      <td>8.084042e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.514854e+09</td>\n",
       "      <td>5.051286e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.211126e+11</td>\n",
       "      <td>-9.251051e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.039225e+10</td>\n",
       "      <td>2.061022e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.792590e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.114215e+10</td>\n",
       "      <td>3.829003e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.094123e+11</td>\n",
       "      <td>-2.175656e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.785511e+11</td>\n",
       "      <td>1.006023e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.020214e+10</td>\n",
       "      <td>4.964760e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.293342e+11</td>\n",
       "      <td>2.897758e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.755809e+11</td>\n",
       "      <td>8.900954e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.200260e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.127132e+10</td>\n",
       "      <td>-7.908808e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.114179e+11</td>\n",
       "      <td>-1.217226e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050034e+12</td>\n",
       "      <td>-3.723713e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.505772e+09</td>\n",
       "      <td>4.203653e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.062249e+10</td>\n",
       "      <td>1.505449e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.763547e+11</td>\n",
       "      <td>1.230483e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.079756e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.467028e+09</td>\n",
       "      <td>6.105685e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.454870e+11</td>\n",
       "      <td>-5.301734e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.942544e+11</td>\n",
       "      <td>1.090635e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.006126e+09</td>\n",
       "      <td>5.400038e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.987484e+10</td>\n",
       "      <td>-1.461589e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.860521e+11</td>\n",
       "      <td>1.190036e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.628537e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.674793e+10</td>\n",
       "      <td>-2.682882e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.825711e+11</td>\n",
       "      <td>-2.850314e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.123178e+11</td>\n",
       "      <td>9.669482e+11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sun_x         sun_y  sun_z       earth_x       earth_y  earth_z  \\\n",
       "0  1.913052e+10  5.697825e+09    0.0  1.031225e+11 -1.223594e+11      0.0   \n",
       "1  7.140607e+08  1.970896e+09    0.0 -8.590686e+10  1.248203e+11      0.0   \n",
       "2  5.277441e+09  6.153926e+09    0.0 -7.063472e+10  1.357785e+11      0.0   \n",
       "3  1.609521e+10  7.067926e+09    0.0 -2.739695e+10 -1.400178e+11      0.0   \n",
       "4  2.858243e+08  1.090659e+09    0.0  9.774886e+10 -1.168880e+11      0.0   \n",
       "5  6.100623e+09  6.546513e+09    0.0  1.283906e+11  9.461551e+10      0.0   \n",
       "6  3.514854e+09  5.051286e+09    0.0  1.211126e+11 -9.251051e+10      0.0   \n",
       "7  2.020214e+10  4.964760e+09    0.0 -1.293342e+11  2.897758e+10      0.0   \n",
       "8  2.505772e+09  4.203653e+09    0.0 -3.062249e+10  1.505449e+11      0.0   \n",
       "9  4.006126e+09  5.400038e+09    0.0 -1.987484e+10 -1.461589e+11      0.0   \n",
       "\n",
       "         mars_x        mars_y  mars_z       venus_x  ...  venus_z  \\\n",
       "0 -7.302001e+10 -1.716263e+11     0.0 -8.002964e+10  ...      0.0   \n",
       "1  1.825935e+11  1.158515e+11     0.0  2.919243e+10  ...      0.0   \n",
       "2  1.140996e+11 -1.619832e+11     0.0  1.161885e+11  ...      0.0   \n",
       "3  6.472678e+10  2.212236e+11     0.0  4.718303e+10  ...      0.0   \n",
       "4 -1.587114e+11  1.476854e+11     0.0  1.090252e+11  ...      0.0   \n",
       "5 -7.351698e+10 -1.764600e+11     0.0 -7.114823e+10  ...      0.0   \n",
       "6  9.039225e+10  2.061022e+11     0.0  8.792590e+10  ...      0.0   \n",
       "7 -1.755809e+11  8.900954e+10     0.0  7.200260e+10  ...      0.0   \n",
       "8 -1.763547e+11  1.230483e+11     0.0 -1.079756e+11  ...      0.0   \n",
       "9  1.860521e+11  1.190036e+11     0.0 -7.628537e+10  ...      0.0   \n",
       "\n",
       "      mercury_x     mercury_y  mercury_z     jupiter_x     jupiter_y  \\\n",
       "0 -2.017515e+09  5.837242e+10        0.0 -6.631005e+11 -2.753003e+11   \n",
       "1 -4.852436e+09  5.868333e+10        0.0  6.563034e+11  3.832339e+11   \n",
       "2  1.274079e+10 -4.420687e+10        0.0  5.949120e+11 -4.303914e+11   \n",
       "3 -1.897295e+10  5.108178e+10        0.0 -4.344394e+11 -5.661212e+11   \n",
       "4 -1.607403e+10 -4.724951e+10        0.0  5.248041e+11  5.560248e+11   \n",
       "5 -1.653575e+10 -3.935061e+10        0.0  5.284106e+11 -5.053616e+11   \n",
       "6 -4.114215e+10  3.829003e+10        0.0  7.094123e+11 -2.175656e+11   \n",
       "7 -3.127132e+10 -7.908808e+09        0.0 -7.114179e+11 -1.217226e+11   \n",
       "8 -1.467028e+09  6.105685e+10        0.0  7.454870e+11 -5.301734e+10   \n",
       "9 -3.674793e+10 -2.682882e+10        0.0  6.825711e+11 -2.850314e+11   \n",
       "\n",
       "   jupiter_z      saturn_x      saturn_y  saturn_z  \n",
       "0        0.0  1.107118e+12 -2.487850e+11       0.0  \n",
       "1        0.0  5.342220e+11  1.270662e+12       0.0  \n",
       "2        0.0  9.850200e+11  8.695186e+11       0.0  \n",
       "3        0.0  1.181920e+12  4.580841e+10       0.0  \n",
       "4        0.0  3.950233e+11  1.330987e+12       0.0  \n",
       "5        0.0  1.023429e+12  8.084042e+11       0.0  \n",
       "6        0.0  8.785511e+11  1.006023e+12       0.0  \n",
       "7        0.0  1.050034e+12 -3.723713e+11       0.0  \n",
       "8        0.0  7.942544e+11  1.090635e+12       0.0  \n",
       "9        0.0  9.123178e+11  9.669482e+11       0.0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with randomizing the data.  This is going to be a bit redundant, but fuck it.\n",
    "# I can't figure out right now how to split a tensorflow dataset into train, validation, and test sets.\n",
    "complete_motion_df = complete_motion_df.sample(frac=1).reset_index(drop=True)\n",
    "complete_motion_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "complete_motion_df.drop(complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "# Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output.\n",
    "# Convert targets to numpy arrays as well so we can use them in the model.\n",
    "target_x_np = target.iloc[:,0].to_numpy()\n",
    "target_y_np = target.iloc[:,1].to_numpy()\n",
    "target_z_np = target.iloc[:,2].to_numpy()\n",
    "# Convert dataframe with whole dataset to a numpy array for use in both testing and converting to tf.dataset for training.\n",
    "# Usually training, validation, and test data would be coming from different CSV files or sources.\n",
    "# complete_motion_df only consists of input data at this point.\n",
    "complete_motion_np = complete_motion_df.to_numpy()\n",
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "#Split data\n",
    "X_train, X_valid, X_test = complete_motion_np[:train_size], complete_motion_np[train_size:(train_size+val_size)], complete_motion_np[(train_size + val_size):]\n",
    "y_train_x, y_valid_x, y_test_x = target_x_np[:train_size], target_x_np[train_size:(train_size+val_size)], target_x_np[(train_size + val_size):]\n",
    "y_train_y, y_valid_y, y_test_y = target_y_np[:train_size], target_y_np[train_size:(train_size+val_size)], target_y_np[(train_size + val_size):]\n",
    "y_train_z, y_valid_z, y_test_z = target_z_np[:train_size], target_z_np[train_size:(train_size+val_size)], target_z_np[(train_size + val_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorflow datasets from numpy arrays for train and va;idation data.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train_x.reshape(-1,1), y_train_y.reshape(-1,1), y_train_z.reshape(-1,1)))\n",
    "validation_data = tf.data.Dataset.from_tensor_slices((X_valid, y_valid_x.reshape(-1,1), y_valid_y.reshape(-1,1), y_valid_z.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the input and targets while also converting to a numpy array.\n",
    "#complete_target_x = complete_motion_df.iloc[:, -3].values.reshape(-1,1)\n",
    "#complete_target_y = complete_motion_df.iloc[:, -2].values.reshape(-1,1)\n",
    "#complete_target_z = complete_motion_df.iloc[:, -1].values.reshape(-1,1)\n",
    "#complete_X_input = complete_motion_df.iloc[:, 0:-3].values\n",
    "# Create a tensorflow dataset from the numpy array \"slices\" of the raw dataframe.\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((complete_X_input, complete_target_x, complete_target_y, complete_target_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [ 1.91305181e+10  5.69782500e+09  0.00000000e+00  1.03122544e+11\n",
      " -1.22359366e+11  0.00000000e+00 -7.30200126e+10 -1.71626298e+11\n",
      "  0.00000000e+00 -8.00296384e+10  5.46822814e+10  0.00000000e+00\n",
      " -2.01751456e+09  5.83724159e+10  0.00000000e+00 -6.63100477e+11\n",
      " -2.75300342e+11  0.00000000e+00] Target_X: [1.10711815e+12] Target_Y: [-2.48784994e+11] Target_Z: [0.]\n",
      "Features: [ 7.14060685e+08  1.97089623e+09  0.00000000e+00 -8.59068594e+10\n",
      "  1.24820252e+11  0.00000000e+00  1.82593503e+11  1.15851466e+11\n",
      "  0.00000000e+00  2.91924336e+10  1.08257820e+11  0.00000000e+00\n",
      " -4.85243646e+09  5.86833262e+10  0.00000000e+00  6.56303439e+11\n",
      "  3.83233919e+11  0.00000000e+00] Target_X: [5.34222009e+11] Target_Y: [1.27066174e+12] Target_Z: [0.]\n",
      "Features: [ 5.27744127e+09  6.15392572e+09  0.00000000e+00 -7.06347222e+10\n",
      "  1.35778460e+11  0.00000000e+00  1.14099593e+11 -1.61983171e+11\n",
      "  0.00000000e+00  1.16188484e+11  3.78256828e+07  0.00000000e+00\n",
      "  1.27407942e+10 -4.42068683e+10  0.00000000e+00  5.94912002e+11\n",
      " -4.30391386e+11  0.00000000e+00] Target_X: [9.85019987e+11] Target_Y: [8.69518567e+11] Target_Z: [0.]\n",
      "Features: [ 1.60952135e+10  7.06792558e+09  0.00000000e+00 -2.73969542e+10\n",
      " -1.40017820e+11  0.00000000e+00  6.47267810e+10  2.21223583e+11\n",
      "  0.00000000e+00  4.71830331e+10 -1.00593953e+11  0.00000000e+00\n",
      " -1.89729489e+10  5.10817791e+10  0.00000000e+00 -4.34439357e+11\n",
      " -5.66121199e+11  0.00000000e+00] Target_X: [1.18191951e+12] Target_Y: [4.58084125e+10] Target_Z: [0.]\n",
      "Features: [ 2.85824254e+08  1.09065909e+09  0.00000000e+00  9.77488566e+10\n",
      " -1.16887972e+11  0.00000000e+00 -1.58711445e+11  1.47685402e+11\n",
      "  0.00000000e+00  1.09025209e+11  2.24878093e+10  0.00000000e+00\n",
      " -1.60740259e+10 -4.72495085e+10  0.00000000e+00  5.24804093e+11\n",
      "  5.56024823e+11  0.00000000e+00] Target_X: [3.9502333e+11] Target_Y: [1.33098734e+12] Target_Z: [0.]\n"
     ]
    }
   ],
   "source": [
    "# Iterate through dataset and print the input and targets.\n",
    "# Will select top 5 to iterate through.\n",
    "for feat, targ_x, targ_y, targ_z in train_data.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize the Data and Create Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is not that large, a batch size of 1 for processing the data should be ok.  Just randomizing training data for shits and giggles even though already randomized from pandas dataframe.  Hopfully in the future I can figure out how to read the whole dataset into a tensforflow dataset, then split up that dataset into multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.shuffle(buffer_size=100).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[ 1.86430047e+09  3.54901340e+09  0.00000000e+00 -1.28758496e+11\n",
      "  -7.53271950e+10  0.00000000e+00 -1.68560097e+11 -1.06995372e+11\n",
      "   0.00000000e+00  1.12683880e+11 -4.32772765e+09  0.00000000e+00\n",
      "  -2.50563357e+10 -4.01237018e+10  0.00000000e+00  7.47532526e+11\n",
      "   7.47924725e+10  0.00000000e+00]] Target_X: [[7.25337426e+11]] Target_Y: [[1.14871212e+12]] Target_Z: [[0.]]\n",
      "Features: [[ 2.20634147e+10  3.18474861e+09  0.00000000e+00 -1.03384927e+11\n",
      "  -8.38927282e+10  0.00000000e+00  2.02629479e+11 -9.15594642e+10\n",
      "   0.00000000e+00 -7.78932919e+10  5.05564305e+10  0.00000000e+00\n",
      "  -2.33843382e+10  3.52166996e+10  0.00000000e+00 -6.90472192e+11\n",
      "   2.49423723e+11  0.00000000e+00]] Target_X: [[8.57381081e+11]] Target_Y: [[-6.37352384e+11]] Target_Z: [[0.]]\n",
      "Features: [[ 1.99753454e+10  5.13380497e+09  0.00000000e+00 -1.22205437e+11\n",
      "  -4.95788590e+10  0.00000000e+00 -1.88943919e+11  2.32520785e+10\n",
      "   0.00000000e+00  1.27627395e+11 -2.30576754e+10  0.00000000e+00\n",
      "   7.22307712e+10 -4.77152078e+09  0.00000000e+00 -7.03495715e+11\n",
      "  -1.57064734e+11  0.00000000e+00]] Target_X: [[1.06419094e+12]] Target_Y: [[-3.44971847e+11]] Target_Z: [[0.]]\n",
      "Features: [[ 2.11731071e+10  4.13613570e+09  0.00000000e+00  1.60381858e+11\n",
      "   6.26301893e+10  0.00000000e+00  8.15836150e+10  2.15164494e+11\n",
      "   0.00000000e+00  6.75017384e+10  1.04003329e+11  0.00000000e+00\n",
      "  -1.24924162e+10 -3.49262544e+10  0.00000000e+00 -7.25138930e+11\n",
      "   5.11307013e+10  0.00000000e+00]] Target_X: [[9.71263884e+11]] Target_Y: [[-4.99971245e+11]] Target_Z: [[0.]]\n",
      "Features: [[ 3.71086426e+09  5.19492047e+09  0.00000000e+00  7.11499325e+10\n",
      "  -1.32432009e+11  0.00000000e+00  1.35649112e+11  1.78237363e+11\n",
      "   0.00000000e+00  2.38353116e+10 -1.05068276e+11  0.00000000e+00\n",
      "   4.77604607e+10  3.92535127e+10  0.00000000e+00  6.99284050e+11\n",
      "  -2.45348049e+11  0.00000000e+00]] Target_X: [[8.92487494e+11]] Target_Y: [[9.90302685e+11]] Target_Z: [[0.]]\n"
     ]
    }
   ],
   "source": [
    "for feat, targ_x, targ_y, targ_z in train_data.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BatchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-90df03dce17c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_data.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try using tf.split to split the tf dataset into training, validation, and test datasets.\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "# Split into 3 tensors with sizes calculated above along dimension 0 (rows).\n",
    "# https://docs.w3cub.com/tensorflow~python/tf/split/\n",
    "training_data, validation_data, test_data = tf.split(dataset, num_or_size_splits=3, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Quick Neural Net for Predicting Jupiter's Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Preprocessing Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try creating a preprocessing layer of the neural network that will standardize the data without external normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create standardization class we inheret from keras.layers\n",
    "# Can possibly be replaced with keras.layers.Normalization\n",
    "# Stolen from https://github.com/ageron/handson-ml2/blob/master/13_loading_and_preprocessing_data.ipynb\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to adapt the standardization class to each column of our training data.\n",
    "#Set the input shape\n",
    "std_layer = Standardization(input_shape = complete_motion_np.shape[1:])\n",
    "std_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Creating Single Input, Multiple Output Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a regression NN where instead of designating an output layer of 3 nodes, 3 output layers of a single node are used to designate specific datasets and loss functions.  Still need to figure out later how to get a 3 node output to correspond to the input training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functional API to build basic NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use functional API to build basic NN architecture.\n",
    "#input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "#hidden1 = keras.layers.Dense(300, activation=\"tanh\")(input_main)\n",
    "#hidden2 = keras.layers.Dense(300, activation=\"tanh\")(hidden1)\n",
    "#output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "#output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "#output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Standardization' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-22fbb90d6a76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Use functional API to build basic NN architecture.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_main\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tanh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_main\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mhidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tanh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"output_x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\py37_ML_Playground\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;31m# Eager execution on data tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\py37_ML_Playground\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[1;32m-> 2398\u001b[1;33m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   2399\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\py37_ML_Playground\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         spec.max_ndim is not None):\n\u001b[1;32m--> 166\u001b[1;33m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0;32m    168\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' is incompatible with the layer: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Standardization' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Use functional API to build basic NN architecture.\n",
    "# CONTINUE FROM HERE.  MAYBE SWITCH TO BATCH NORMALIZATION FROM BOOK?\n",
    "input_main = std_layer\n",
    "hidden1 = keras.layers.Dense(300, activation=\"tanh\")(input_main)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"tanh\")(hidden1)\n",
    "output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with specified input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with specified input and output layers\n",
    "model = keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with specified loss functions for each output and specify weighting to provide each output.\n",
    "# Weighting X and Y output more than Z\n",
    "model.compile(loss=[\"mse\", \"mse\", \"mse\"], \n",
    "              loss_weights=[0.4, 0.4, 0.2], \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with separate x, y, z training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [X_train], [y_train_x, y_train_y, y_train_z],\n",
    "    epochs=1000,\n",
    "    validation_data=([X_valid], [y_valid_x, y_valid_y, y_valid_z])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert training history to dataframe for analysis and plotting.\n",
    "complete_history_data = pd.DataFrame(history.history)\n",
    "complete_history_data.head(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate MSEs.\n",
    "fig2, mse_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "mse_plots[0][0].plot(complete_history_data[[\"output_x_mse\", \"val_output_x_mse\"]])\n",
    "#mse_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "mse_plots[0][1].plot(complete_history_data[[\"output_y_mse\", \"val_output_y_mse\"]])\n",
    "mse_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "mse_plots[1][0].plot(complete_history_data[[\"output_z_mse\", \"val_output_z_mse\"]])\n",
    "mse_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate loss.\n",
    "fig, loss_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "loss_plots[0][0].plot(complete_history_data[[\"loss\", \"val_loss\"]])\n",
    "loss_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[0][1].plot(complete_history_data[[\"output_x_loss\", \"val_output_x_loss\"]])\n",
    "loss_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][0].plot(complete_history_data[[\"output_y_loss\", \"val_output_y_loss\"]])\n",
    "loss_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][1].plot(complete_history_data[[\"output_z_loss\", \"val_output_z_loss\"]])\n",
    "loss_plots[1][1].set_ylim(0,1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([X_test],[y_test_x, y_test_y, y_test_z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values and Inspect Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, z_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison = pd.DataFrame(data=np.concatenate((x_pred, y_test_x.reshape(-1,1), y_pred, y_test_y.reshape(-1,1), z_pred, y_test_z.reshape(-1,1)), axis=1),\n",
    "                                    columns=['pred_x', 'model_x', 'pred_y', 'model_y', 'pred_z', 'model_z'])\n",
    "pred_model_comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_x\", \"model_x\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_y\", \"model_y\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_z\", \"model_z\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
