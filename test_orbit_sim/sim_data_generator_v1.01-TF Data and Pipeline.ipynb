{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet Simulator with Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Craig Boger\n",
    "06/07/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script takes the model prototyping and learning of v1.01 and tries to expand upon it in 2 key areas.\n",
    "\n",
    "1) Perform data normalization and processing in TF data libraries.\n",
    "2) Take predictions in normalized form and output them in their unormalized form for use in simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straight Up Just Stealing Someone's Code and Trying to Run It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to benrules2: https://gist.github.com/benrules2/220d56ea6fe9a85a4d762128b11adfba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b754d6e58441ee853b14930b1c680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "class point:\n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "class body:\n",
    "    def __init__(self, location, mass, velocity, name = \"\"):\n",
    "        self.location = location\n",
    "        self.mass = mass\n",
    "        self.velocity = velocity\n",
    "        self.name = name\n",
    "\n",
    "def calculate_single_body_acceleration(bodies, body_index):\n",
    "    G_const = 6.67408e-11 #m3 kg-1 s-2\n",
    "    acceleration = point(0,0,0)\n",
    "    target_body = bodies[body_index]\n",
    "    for index, external_body in enumerate(bodies):\n",
    "        if index != body_index:\n",
    "            r = (target_body.location.x - external_body.location.x)**2 + (target_body.location.y - external_body.location.y)**2 + (target_body.location.z - external_body.location.z)**2\n",
    "            r = math.sqrt(r)\n",
    "            tmp = G_const * external_body.mass / r**3\n",
    "            acceleration.x += tmp * (external_body.location.x - target_body.location.x)\n",
    "            acceleration.y += tmp * (external_body.location.y - target_body.location.y)\n",
    "            acceleration.z += tmp * (external_body.location.z - target_body.location.z)\n",
    "\n",
    "    return acceleration\n",
    "\n",
    "def compute_velocity(bodies, time_step = 1):\n",
    "    for body_index, target_body in enumerate(bodies):\n",
    "        acceleration = calculate_single_body_acceleration(bodies, body_index)\n",
    "\n",
    "        target_body.velocity.x += acceleration.x * time_step\n",
    "        target_body.velocity.y += acceleration.y * time_step\n",
    "        target_body.velocity.z += acceleration.z * time_step \n",
    "\n",
    "\n",
    "def update_location(bodies, time_step = 1):\n",
    "    for target_body in bodies:\n",
    "        target_body.location.x += target_body.velocity.x * time_step\n",
    "        target_body.location.y += target_body.velocity.y * time_step\n",
    "        target_body.location.z += target_body.velocity.z * time_step\n",
    "\n",
    "def compute_gravity_step(bodies, time_step = 1):\n",
    "    compute_velocity(bodies, time_step = time_step)\n",
    "    update_location(bodies, time_step = time_step)\n",
    "\n",
    "def plot_output(bodies, outfile = None):\n",
    "    fig = plot.figure()\n",
    "    colours = ['r','b','g','y','m','c']\n",
    "    ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "    max_range = 0\n",
    "    for current_body in bodies: \n",
    "        max_dim = max(max(current_body[\"x\"]),max(current_body[\"y\"]),max(current_body[\"z\"]))\n",
    "        if max_dim > max_range:\n",
    "            max_range = max_dim\n",
    "        ax.plot(current_body[\"x\"], current_body[\"y\"], current_body[\"z\"], c = random.choice(colours), label = current_body[\"name\"])        \n",
    "    \n",
    "    ax.set_xlim([-max_range,max_range])    \n",
    "    ax.set_ylim([-max_range,max_range])\n",
    "    ax.set_zlim([-max_range,max_range])\n",
    "    ax.legend()        \n",
    "\n",
    "    if outfile:\n",
    "        plot.savefig(outfile)\n",
    "    else:\n",
    "        plot.show()\n",
    "\n",
    "def run_simulation(bodies, names = None, time_step = 1, number_of_steps = 10000, report_freq = 100):\n",
    "\n",
    "    #create output container for each body\n",
    "    body_locations_hist = []\n",
    "    for current_body in bodies:\n",
    "        body_locations_hist.append({\"x\":[], \"y\":[], \"z\":[], \"name\":current_body.name})\n",
    "        \n",
    "    for i in range(1,number_of_steps):\n",
    "        compute_gravity_step(bodies, time_step = 1000)            \n",
    "        \n",
    "        if i % report_freq == 0:\n",
    "            for index, body_location in enumerate(body_locations_hist):\n",
    "                body_location[\"x\"].append(bodies[index].location.x)\n",
    "                body_location[\"y\"].append(bodies[index].location.y)           \n",
    "                body_location[\"z\"].append(bodies[index].location.z)       \n",
    "\n",
    "    return body_locations_hist        \n",
    "            \n",
    "#planet data (location (m), mass (kg), velocity (m/s)\n",
    "sun = {\"location\":point(0,0,0), \"mass\":2e30, \"velocity\":point(0,0,0)}\n",
    "mercury = {\"location\":point(0,5.7e10,0), \"mass\":3.285e23, \"velocity\":point(47000,0,0)}\n",
    "venus = {\"location\":point(0,1.1e11,0), \"mass\":4.8e24, \"velocity\":point(35000,0,0)}\n",
    "earth = {\"location\":point(0,1.5e11,0), \"mass\":6e24, \"velocity\":point(30000,0,0)}\n",
    "mars = {\"location\":point(0,2.2e11,0), \"mass\":2.4e24, \"velocity\":point(24000,0,0)}\n",
    "jupiter = {\"location\":point(0,7.7e11,0), \"mass\":1e28, \"velocity\":point(13000,0,0)}\n",
    "saturn = {\"location\":point(0,1.4e12,0), \"mass\":5.7e26, \"velocity\":point(9000,0,0)}\n",
    "uranus = {\"location\":point(0,2.8e12,0), \"mass\":8.7e25, \"velocity\":point(6835,0,0)}\n",
    "neptune = {\"location\":point(0,4.5e12,0), \"mass\":1e26, \"velocity\":point(5477,0,0)}\n",
    "pluto = {\"location\":point(0,3.7e12,0), \"mass\":1.3e22, \"velocity\":point(4748,0,0)}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #build list of planets in the simulation, or create your own\n",
    "    bodies = [\n",
    "        body( location = sun[\"location\"], mass = sun[\"mass\"], velocity = sun[\"velocity\"], name = \"sun\"),\n",
    "        body( location = mercury[\"location\"], mass = mercury[\"mass\"], velocity = mercury[\"velocity\"], name = \"mercury\"),\n",
    "        body( location = venus[\"location\"], mass = venus[\"mass\"], velocity = venus[\"velocity\"], name = \"venus\"),\n",
    "        body( location = earth[\"location\"], mass = earth[\"mass\"], velocity = earth[\"velocity\"], name = \"earth\"),\n",
    "        body( location = mars[\"location\"], mass = mars[\"mass\"], velocity = mars[\"velocity\"], name = \"mars\"),\n",
    "        body( location = jupiter[\"location\"], mass = jupiter[\"mass\"], velocity = jupiter[\"velocity\"], name = \"jupiter\"),\n",
    "        body( location = saturn[\"location\"], mass = saturn[\"mass\"], velocity = saturn[\"velocity\"], name = \"saturn\"),\n",
    "        body( location = uranus[\"location\"], mass = uranus[\"mass\"], velocity = uranus[\"velocity\"], name = \"uranus\"),\n",
    "        body( location = neptune[\"location\"], mass = neptune[\"mass\"], velocity = neptune[\"velocity\"], name = \"neptune\"),\n",
    "        body( location = pluto[\"location\"], mass = pluto[\"mass\"], velocity = pluto[\"velocity\"], name = \"pluto\")\n",
    "        ]\n",
    "    \n",
    "    # Original defaults of simulation\n",
    "    # motions = run_simulation(bodies, time_step = 100, number_of_steps = 80000, report_freq = 1000)\n",
    "    # Try messing with report frequency to get more data.\n",
    "    motions = run_simulation(bodies, time_step = 10, number_of_steps = 6000000, report_freq = 100)\n",
    "    plot_output(motions, outfile = 'orbits.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take motions data from the above simulation and convert it to a Pandas dataframe.  The \"motions\" output is a list of python dictionaries that can be converted into a dataframe and then manipulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.17261536148749, 49.37902931004262, 166.6238...</td>\n",
       "      <td>[6062.379510449177, 24129.08432936523, 54198.9...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4694355206.032213, 9354859805.615133, 1394777...</td>\n",
       "      <td>[56792631341.03519, 56175843290.39122, 5515329...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mercury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3499415066.4596167, 6995320910.098446, 104842...</td>\n",
       "      <td>[109944304443.26683, 109778376891.15071, 10950...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2999802268.7561436, 5998418130.146453, 899466...</td>\n",
       "      <td>[149970049806.4969, 149880804295.7356, 1497322...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2399949856.0031266, 4799598821.678605, 719864...</td>\n",
       "      <td>[219986083536.2445, 219944611164.44067, 219875...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1299999366.479779, 2599994931.4595885, 389998...</td>\n",
       "      <td>[769998863558.2162, 769995476739.6332, 7699898...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[899999928.8199571, 1799999430.5168397, 269999...</td>\n",
       "      <td>[1399999647604.3037, 1399998597395.4744, 13999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>saturn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[683499993.1607178, 1366999945.2816358, 205049...</td>\n",
       "      <td>[2799999913115.264, 2799999654181.5522, 279999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>uranus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[547699998.6801858, 1095399989.4406931, 164309...</td>\n",
       "      <td>[4499999966439.355, 4499999866422.006, 4499999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[474799997.95801955, 949599983.6629324, 142439...</td>\n",
       "      <td>[3699999950348.1753, 3699999802375.9053, 36999...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>pluto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  \\\n",
       "0  [6.17261536148749, 49.37902931004262, 166.6238...   \n",
       "1  [4694355206.032213, 9354859805.615133, 1394777...   \n",
       "2  [3499415066.4596167, 6995320910.098446, 104842...   \n",
       "3  [2999802268.7561436, 5998418130.146453, 899466...   \n",
       "4  [2399949856.0031266, 4799598821.678605, 719864...   \n",
       "5  [1299999366.479779, 2599994931.4595885, 389998...   \n",
       "6  [899999928.8199571, 1799999430.5168397, 269999...   \n",
       "7  [683499993.1607178, 1366999945.2816358, 205049...   \n",
       "8  [547699998.6801858, 1095399989.4406931, 164309...   \n",
       "9  [474799997.95801955, 949599983.6629324, 142439...   \n",
       "\n",
       "                                                   y  \\\n",
       "0  [6062.379510449177, 24129.08432936523, 54198.9...   \n",
       "1  [56792631341.03519, 56175843290.39122, 5515329...   \n",
       "2  [109944304443.26683, 109778376891.15071, 10950...   \n",
       "3  [149970049806.4969, 149880804295.7356, 1497322...   \n",
       "4  [219986083536.2445, 219944611164.44067, 219875...   \n",
       "5  [769998863558.2162, 769995476739.6332, 7699898...   \n",
       "6  [1399999647604.3037, 1399998597395.4744, 13999...   \n",
       "7  [2799999913115.264, 2799999654181.5522, 279999...   \n",
       "8  [4499999966439.355, 4499999866422.006, 4499999...   \n",
       "9  [3699999950348.1753, 3699999802375.9053, 36999...   \n",
       "\n",
       "                                                   z     name  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      sun  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  mercury  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    venus  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    earth  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     mars  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  jupiter  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   saturn  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   uranus  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  neptune  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    pluto  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "motions_df = pd.DataFrame(motions)\n",
    "motions_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to separate out each row of list or dataframe into its own dataframe.\n",
    "# Will later put these dataframes back together into 1 large dataframe.\n",
    "\n",
    "motions_df_list = []\n",
    "for body in motions:\n",
    "    motions_df_list.append(pd.DataFrame(body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>1.499700e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>1.498808e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>1.497323e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>1.495246e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>1.492578e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59994</th>\n",
       "      <td>2.689581e+11</td>\n",
       "      <td>-6.753826e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>2.676697e+11</td>\n",
       "      <td>-6.488198e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>2.664329e+11</td>\n",
       "      <td>-6.220061e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>2.652481e+11</td>\n",
       "      <td>-5.949513e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>2.641158e+11</td>\n",
       "      <td>-5.676655e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y    z   name\n",
       "0      2.999802e+09  1.499700e+11  0.0  earth\n",
       "1      5.998418e+09  1.498808e+11  0.0  earth\n",
       "2      8.994662e+09  1.497323e+11  0.0  earth\n",
       "3      1.198735e+10  1.495246e+11  0.0  earth\n",
       "4      1.497529e+10  1.492578e+11  0.0  earth\n",
       "...             ...           ...  ...    ...\n",
       "59994  2.689581e+11 -6.753826e+10  0.0  earth\n",
       "59995  2.676697e+11 -6.488198e+10  0.0  earth\n",
       "59996  2.664329e+11 -6.220061e+10  0.0  earth\n",
       "59997  2.652481e+11 -5.949513e+10  0.0  earth\n",
       "59998  2.641158e+11 -5.676655e+10  0.0  earth\n",
       "\n",
       "[59999 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motions_df_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sun_x</th>\n",
       "      <th>sun_y</th>\n",
       "      <th>sun_z</th>\n",
       "      <th>mercury_x</th>\n",
       "      <th>mercury_y</th>\n",
       "      <th>mercury_z</th>\n",
       "      <th>venus_x</th>\n",
       "      <th>venus_y</th>\n",
       "      <th>venus_z</th>\n",
       "      <th>earth_x</th>\n",
       "      <th>...</th>\n",
       "      <th>saturn_z</th>\n",
       "      <th>uranus_x</th>\n",
       "      <th>uranus_y</th>\n",
       "      <th>uranus_z</th>\n",
       "      <th>neptune_x</th>\n",
       "      <th>neptune_y</th>\n",
       "      <th>neptune_z</th>\n",
       "      <th>pluto_x</th>\n",
       "      <th>pluto_y</th>\n",
       "      <th>pluto_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.172615e+00</td>\n",
       "      <td>6.062380e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.694355e+09</td>\n",
       "      <td>5.679263e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.499415e+09</td>\n",
       "      <td>1.099443e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999802e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.835000e+08</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.477000e+08</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.748000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.937903e+01</td>\n",
       "      <td>2.412908e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.354860e+09</td>\n",
       "      <td>5.617584e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.995321e+09</td>\n",
       "      <td>1.097784e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.998418e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.367000e+09</td>\n",
       "      <td>2.800000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.095400e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.496000e+08</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.666238e+02</td>\n",
       "      <td>5.419895e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.394778e+10</td>\n",
       "      <td>5.515330e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.048421e+10</td>\n",
       "      <td>1.095024e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.994662e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.050500e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643100e+09</td>\n",
       "      <td>4.500000e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.424400e+09</td>\n",
       "      <td>3.700000e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.948516e+02</td>\n",
       "      <td>9.627002e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.843961e+10</td>\n",
       "      <td>5.373113e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.396259e+10</td>\n",
       "      <td>1.091166e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.198735e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.734000e+09</td>\n",
       "      <td>2.799999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.190800e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.899200e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.709150e+02</td>\n",
       "      <td>1.503396e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.279721e+10</td>\n",
       "      <td>5.191794e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.742697e+10</td>\n",
       "      <td>1.086215e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.497529e+10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.417499e+09</td>\n",
       "      <td>2.799998e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.738500e+09</td>\n",
       "      <td>4.499999e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374000e+09</td>\n",
       "      <td>3.699999e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.138930e+06</td>\n",
       "      <td>5.399689e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.050288e+10</td>\n",
       "      <td>-4.133027e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.578892e+10</td>\n",
       "      <td>-1.109137e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.441446e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.560995e+10</td>\n",
       "      <td>2.799207e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.257803e+10</td>\n",
       "      <td>4.499694e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.557899e+10</td>\n",
       "      <td>3.699547e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.259370e+06</td>\n",
       "      <td>5.511102e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.606635e+10</td>\n",
       "      <td>-4.407848e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.238219e+10</td>\n",
       "      <td>-1.113485e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.431961e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.629326e+10</td>\n",
       "      <td>2.799191e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.312570e+10</td>\n",
       "      <td>4.499687e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.605374e+10</td>\n",
       "      <td>3.699537e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4.381922e+06</td>\n",
       "      <td>5.623611e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137176e+10</td>\n",
       "      <td>-4.638955e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.963734e+09</td>\n",
       "      <td>-1.116778e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421936e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.697656e+10</td>\n",
       "      <td>2.799174e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.367336e+10</td>\n",
       "      <td>4.499681e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.652848e+10</td>\n",
       "      <td>3.699528e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.506591e+06</td>\n",
       "      <td>5.737214e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.646399e+10</td>\n",
       "      <td>-4.823708e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.536787e+09</td>\n",
       "      <td>-1.119012e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.411373e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.765986e+10</td>\n",
       "      <td>2.799157e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.422102e+10</td>\n",
       "      <td>4.499674e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700322e+10</td>\n",
       "      <td>3.699518e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.633378e+06</td>\n",
       "      <td>5.851910e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.139102e+10</td>\n",
       "      <td>-4.959972e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.104599e+09</td>\n",
       "      <td>-1.120185e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400277e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.834316e+10</td>\n",
       "      <td>2.799140e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.476868e+10</td>\n",
       "      <td>4.499668e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.747796e+10</td>\n",
       "      <td>3.699508e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sun_x         sun_y  sun_z     mercury_x     mercury_y  mercury_z  \\\n",
       "0   6.172615e+00  6.062380e+03    0.0  4.694355e+09  5.679263e+10        0.0   \n",
       "1   4.937903e+01  2.412908e+04    0.0  9.354860e+09  5.617584e+10        0.0   \n",
       "2   1.666238e+02  5.419895e+04    0.0  1.394778e+10  5.515330e+10        0.0   \n",
       "3   3.948516e+02  9.627002e+04    0.0  1.843961e+10  5.373113e+10        0.0   \n",
       "4   7.709150e+02  1.503396e+05    0.0  2.279721e+10  5.191794e+10        0.0   \n",
       "..           ...           ...    ...           ...           ...        ...   \n",
       "95  4.138930e+06  5.399689e+07    0.0  3.050288e+10 -4.133027e+10        0.0   \n",
       "96  4.259370e+06  5.511102e+07    0.0  2.606635e+10 -4.407848e+10        0.0   \n",
       "97  4.381922e+06  5.623611e+07    0.0  2.137176e+10 -4.638955e+10        0.0   \n",
       "98  4.506591e+06  5.737214e+07    0.0  1.646399e+10 -4.823708e+10        0.0   \n",
       "99  4.633378e+06  5.851910e+07    0.0  1.139102e+10 -4.959972e+10        0.0   \n",
       "\n",
       "         venus_x       venus_y  venus_z       earth_x  ...  saturn_z  \\\n",
       "0   3.499415e+09  1.099443e+11      0.0  2.999802e+09  ...       0.0   \n",
       "1   6.995321e+09  1.097784e+11      0.0  5.998418e+09  ...       0.0   \n",
       "2   1.048421e+10  1.095024e+11      0.0  8.994662e+09  ...       0.0   \n",
       "3   1.396259e+10  1.091166e+11      0.0  1.198735e+10  ...       0.0   \n",
       "4   1.742697e+10  1.086215e+11      0.0  1.497529e+10  ...       0.0   \n",
       "..           ...           ...      ...           ...  ...       ...   \n",
       "95  1.578892e+10 -1.109137e+11      0.0  1.441446e+11  ...       0.0   \n",
       "96  1.238219e+10 -1.113485e+11      0.0  1.431961e+11  ...       0.0   \n",
       "97  8.963734e+09 -1.116778e+11      0.0  1.421936e+11  ...       0.0   \n",
       "98  5.536787e+09 -1.119012e+11      0.0  1.411373e+11  ...       0.0   \n",
       "99  2.104599e+09 -1.120185e+11      0.0  1.400277e+11  ...       0.0   \n",
       "\n",
       "        uranus_x      uranus_y  uranus_z     neptune_x     neptune_y  \\\n",
       "0   6.835000e+08  2.800000e+12       0.0  5.477000e+08  4.500000e+12   \n",
       "1   1.367000e+09  2.800000e+12       0.0  1.095400e+09  4.500000e+12   \n",
       "2   2.050500e+09  2.799999e+12       0.0  1.643100e+09  4.500000e+12   \n",
       "3   2.734000e+09  2.799999e+12       0.0  2.190800e+09  4.499999e+12   \n",
       "4   3.417499e+09  2.799998e+12       0.0  2.738500e+09  4.499999e+12   \n",
       "..           ...           ...       ...           ...           ...   \n",
       "95  6.560995e+10  2.799207e+12       0.0  5.257803e+10  4.499694e+12   \n",
       "96  6.629326e+10  2.799191e+12       0.0  5.312570e+10  4.499687e+12   \n",
       "97  6.697656e+10  2.799174e+12       0.0  5.367336e+10  4.499681e+12   \n",
       "98  6.765986e+10  2.799157e+12       0.0  5.422102e+10  4.499674e+12   \n",
       "99  6.834316e+10  2.799140e+12       0.0  5.476868e+10  4.499668e+12   \n",
       "\n",
       "    neptune_z       pluto_x       pluto_y  pluto_z  \n",
       "0         0.0  4.748000e+08  3.700000e+12      0.0  \n",
       "1         0.0  9.496000e+08  3.700000e+12      0.0  \n",
       "2         0.0  1.424400e+09  3.700000e+12      0.0  \n",
       "3         0.0  1.899200e+09  3.699999e+12      0.0  \n",
       "4         0.0  2.374000e+09  3.699999e+12      0.0  \n",
       "..        ...           ...           ...      ...  \n",
       "95        0.0  4.557899e+10  3.699547e+12      0.0  \n",
       "96        0.0  4.605374e+10  3.699537e+12      0.0  \n",
       "97        0.0  4.652848e+10  3.699528e+12      0.0  \n",
       "98        0.0  4.700322e+10  3.699518e+12      0.0  \n",
       "99        0.0  4.747796e+10  3.699508e+12      0.0  \n",
       "\n",
       "[100 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the dataframes into a single, large dataframe.\n",
    "# Can later choose a planet to be the target we train to predict.\n",
    "complete_motion_df = None\n",
    "\n",
    "for body in motions_df_list:\n",
    "    # Append name of body to each column and remove the name column\n",
    "    body_name = body.loc[0, \"name\"]\n",
    "    body.columns = [body_name + \"_x\",\n",
    "                    body_name + \"_y\",\n",
    "                    body_name + \"_z\",\n",
    "                    \"name\"]\n",
    "    # Add current body to the complete dataframe.\n",
    "    complete_motion_df = pd.concat([complete_motion_df, body.iloc[:, 0:3]], axis=1)\n",
    "\n",
    "complete_motion_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59999, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_motion_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the simulation data for later loading and use\n",
    "complete_motion_df.to_csv(\"raw_model_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a single dataframe with all bodies and all positions with each time step as the index of our rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Create a tf.data Dataset from the Constructed, Unrandomized, Unnormalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python â‰¥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn â‰¥0.20 is required\n",
    "# Probably not needed since not using regressor or doing any feature engineering.\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler  # Scaler for normalizing data.\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scaler for normalizing data.\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow â‰¥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "# Recommended to enable eager execution when developing model.\n",
    "# Processing data: https://www.youtube.com/watch?v=oFFbKogYdfc\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# Import Keras\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Use sklearn for data processing\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Here with Trying to Process Data with Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the difficulties is using a mixture of numpy, pandas, and sklearn to take input data (influx), arrange it, split it out, normalize it, and then train a model.  With tf.data input pipelines (similar to sklearn pipelines), we can create data and machine learning pipelines for training or inference.  This allows us to encapsulate not only the machine learning into a Tensorflow model, but the necessary transformations to that data.  That allows us to deploy the model and data transformations as a single object to the later simulator. \\\n",
    "The input pipeline let's us take raw data from any source, like csv, numpy arrays, distributed file system, etc, and convert it into the tensors we will use to train our model.\n",
    "\n",
    "Intro to tensors:\n",
    "https://www.tensorflow.org/guide/tensor\n",
    "\n",
    "Good source on how data loading and preprocessing is usually done: https://stackoverflow.com/questions/55321905/want-to-split-train-and-test-data-gotten-from-a-csv-with-tensorflow\n",
    "1) Load the data into memory with numpy\n",
    "2) Split the data into train and validation\n",
    "\n",
    "Since we are not using a massive dataset, then we might be able to use tf.split to split an exsting tf dataset into train and validation.\n",
    "https://docs.w3cub.com/tensorflow~python/tf/split/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Numpy Version of the Data as a Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of the complete dataframe and shuffle it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy1_complete_motion_df = complete_motion_df.copy()\n",
    "copy1_complete_motion_df = copy1_complete_motion_df.sample(frac=1).reset_index(drop=True)\n",
    "copy1_complete_motion_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split out the target x,y,z columns as the last 3 columns in the dataframe.  Skipping scaling and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = copy1_complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "copy1_complete_motion_df.drop(copy1_complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x = target.iloc[:,0]\n",
    "target_y = target.iloc[:,1]\n",
    "target_z = target.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all pandas dataframes to numpy arrays so they are compatible with Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_motion_np = copy1_complete_motion_df.to_numpy()\n",
    "target_np = target.to_numpy()\n",
    "target_x_np = target_x.to_numpy()\n",
    "target_y_np = target_y.to_numpy()\n",
    "target_z_np = target_z.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "X_train, X_valid, X_test = complete_motion_np[:train_size], complete_motion_np[train_size:(train_size+val_size)], complete_motion_np[(train_size + val_size):]\n",
    "y_train_x, y_valid_x, y_test_x = target_x_np[:train_size], target_x_np[train_size:(train_size+val_size)], target_x_np[(train_size + val_size):]\n",
    "y_train_y, y_valid_y, y_test_y = target_y_np[:train_size], target_y_np[train_size:(train_size+val_size)], target_y_np[(train_size + val_size):]\n",
    "y_train_z, y_valid_z, y_test_z = target_z_np[:train_size], target_z_np[train_size:(train_size+val_size)], target_z_np[(train_size + val_size):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a tf dataset from slices (numpy array, pandas dataframe, etc). \n",
    "https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "\n",
    "Probably one of the better articles on using tensorflow datasets: \\\n",
    "https://adventuresinmachinelearning.com/tensorflow-dataset-tutorial/\n",
    "\n",
    "TF documentation on tf.data: Building Tensorflow Input Pipelines: \\\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "Method for splitting tensorflow datasets into train, validation, and test: \\\n",
    "https://stackoverflow.com/questions/51125266/how-do-i-split-tensorflow-datasets/51126863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into input and targets for the x, y, and z coordinates.\n",
    "# Assuming last 3 columns in the dataframe are the target x,y, and z values.  \n",
    "target = complete_motion_df.iloc[:,-3:]\n",
    "# Drop target from main dataframe.\n",
    "complete_motion_df.drop(complete_motion_df.iloc[:,-3:], axis = 1, inplace = True)\n",
    "# Split the x, y, and z coordinates out for the target to use a specific dataset for each possible coordinate output.\n",
    "# Convert targets to numpy arrays as well so we can use them in the model.\n",
    "target_x_np = target.iloc[:,0].to_numpy()\n",
    "target_y_np = target.iloc[:,1].to_numpy()\n",
    "target_z_np = target.iloc[:,2].to_numpy()\n",
    "# Usually training, validation, and test data would be coming from different CSV files or sources.\n",
    "# complete_motion_df only consists of input data at this point.\n",
    "complete_motion_np = complete_motion_df.to_numpy()\n",
    "\n",
    "#Create one large tensorflow dataset.\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((complete_motion_np, \n",
    "                                                   target_x_np, \n",
    "                                                   target_y_np,\n",
    "                                                   target_z_np)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_motion_np[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dataset and print the input and targets.\n",
    "# Will select top 5 to iterate through.\n",
    "for feat, targ_x, targ_y, targ_z in full_dataset.take(5):\n",
    "    print('Features: {} Target_X: {} Target_Y: {} Target_Z: {}'.format(feat, targ_x, targ_y, targ_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the full dataset before splitting into train, validation, and test.\n",
    "# Since dataset can fit in memory, can set buffer to be the size of the data.\n",
    "full_dataset_num_samples = complete_motion_df.shape[0]  #Get the size of the dataset to set the randomize buffer\n",
    "#full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples).batch(1)\n",
    "full_dataset = full_dataset.shuffle(buffer_size=full_dataset_num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train, validation, and test sets.\n",
    "# Setup train, validation, and test splits\n",
    "DATASET_SIZE = len(complete_motion_df)\n",
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.15 * DATASET_SIZE)\n",
    "test_size = int(0.15 * DATASET_SIZE)\n",
    "# Take the shuffled dataset and split into train, validation, and test datasets.\n",
    "train_dataset = full_dataset.take(train_size)   # Take top of dataset for training data\n",
    "test_dataset = full_dataset.skip(train_size)    # Take the rest of the dataset for validation and test\n",
    "val_dataset = test_dataset.skip(test_size)      # Take a part of the test data for validation during training\n",
    "test_dataset = test_dataset.take(test_size)     # Get rid of the validation data from the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a Quick Neural Net for Predicting Jupiter's Position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \\\n",
    "<br>\n",
    "Instead of using sklearn to normalize or manually making a normalization and standardization layer like p. 431 of the book, try using at least 1 Batch normalization layer after the input layer.  Can also add after hidden layers. \\\n",
    "<br>\n",
    "Might need to add an activation function to the output layer later to help with scaling of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Creating Single Input, Multiple Output Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to create a regression NN where instead of designating an output layer of 3 nodes, 3 output layers of a single node are used to designate specific datasets and loss functions.  Still need to figure out later how to get a 3 node output to correspond to the input training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use functional API to build basic NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions with different versions of the neural network.\n",
    "\n",
    "def get_model1(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_2(input_shape):\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=input_shape)\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"tanh\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(100, activation=\"tanh\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "    # Best parameters so far: keras.optimizers.RMSprop(lr=0.1, rho=0.9)\n",
    "    return keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "def get_model_3(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal1)\n",
    "    normal2 = keras.layers.BatchNormalization()(hidden1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"elu\", kernel_initializer=\"he_normal\")(normal2)\n",
    "    normal3 = keras.layers.BatchNormalization()(hidden2)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(normal3)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(normal3)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(normal3)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    \n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=10, rho=0.9)\n",
    "    \n",
    "def get_model_4(input_shape):\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    normal1 = keras.layers.BatchNormalization()(input_main)\n",
    "    hidden1 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(normal1)\n",
    "    hidden2 = keras.layers.Dense(1000, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=2, rho=0.9)\n",
    "    \n",
    "def get_model_5(input_shape):  #Best one yet.  Typically takes about 1500 epochs to get decend results.\n",
    "    # Use functional API to build basic NN architecture.\n",
    "    input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "    hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "    output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "    output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "    output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "    model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "    #Set \n",
    "    input_losses = [\"mae\", \"mae\", \"mae\"]\n",
    "    input_loss_weights = [0.4, 0.4, 0.2]\n",
    "    input_optimizer = keras.optimizers.RMSprop(lr=0.0000005, rho=0.01)\n",
    "    input_metrics = [\"mae\"]\n",
    "    input_num_epochs = 200\n",
    "    input_batch_size = 64\n",
    "\n",
    "    model.summary()\n",
    "    #Also can use and probably should use Adam\n",
    "    input_optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model with specified input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with specified input and output layers.\n",
    "# Select which model to try.\n",
    "# Pass shape of input layer to the function.\n",
    "#model = get_model_2(complete_motion_np.shape[1:])\n",
    "\n",
    "# Use functional API to build basic NN architecture.\n",
    "input_main = keras.layers.Input(shape=complete_motion_np.shape[1:])\n",
    "hidden1 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(input_main)\n",
    "hidden2 = keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\")(hidden1)\n",
    "output_x = keras.layers.Dense(1, activation=\"linear\", name=\"output_x\")(hidden2)\n",
    "output_y = keras.layers.Dense(1, activation=\"linear\", name=\"output_y\")(hidden2)\n",
    "output_z = keras.layers.Dense(1, activation=\"linear\", name=\"output_z\")(hidden2)\n",
    "\n",
    "model =  keras.Model(inputs=[input_main], outputs=[output_x, output_y, output_z])\n",
    "\n",
    "#Set \n",
    "input_losses = [\"msle\", \"msle\", \"msle\"]\n",
    "input_loss_weights = [0.4, 0.4, 0.2]\n",
    "input_optimizer = keras.optimizers.Adam(learning_rate=1e-7, beta_1=0.9, beta_2=0.999)\n",
    "input_metrics = [\"msle\"]\n",
    "input_num_epochs = 500\n",
    "input_batch_size = 128\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before fitting the model, create callbacks for the various stages.\n",
    "\n",
    "# Callback to implement overfitting.  Helps with regularization.  \n",
    "# Keep from over-training.  Stops training when validation error starts increasing again.\n",
    "# https://lambdalabs.com/blog/tensorflow-2-0-tutorial-04-early-stopping/\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                                 min_delta=0.0001,\n",
    "                                                 patience=20)\n",
    "\n",
    "# Callback for learning rate scheduling.  This way we can start with a higher learning rate then reduce as we go.\n",
    "# Reducing the learning rate by a factor of \"factor\" every so many epochs or \"patience\".\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=50)\n",
    "\n",
    "#Create list of all callbacks.\n",
    "#callback_list = [early_stopping_cb, lr_scheduler]\n",
    "callback_list = [lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with specified loss functions for each output and specify weighting to provide each output.\n",
    "# Weighting X and Y output more than Z\n",
    "model.compile(loss=input_losses, \n",
    "              loss_weights=input_loss_weights, \n",
    "              optimizer=input_optimizer,\n",
    "              metrics=input_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with separate x, y, z training sets.  Choose either numpy data or tensorflow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit the model using numpy formatted training and validation data.\n",
    "history = model.fit(\n",
    "    [X_train], [y_train_x, y_train_y, y_train_z],\n",
    "    epochs=input_num_epochs,\n",
    "    validation_data=([X_valid], [y_valid_x, y_valid_y, y_valid_z]),\n",
    "    batch_size=input_batch_size,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert training history to dataframe for analysis and plotting.\n",
    "complete_history_data = pd.DataFrame(history.history)\n",
    "complete_history_data.head(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate MSEs.\n",
    "fig2, mse_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "mse_plots[0][0].plot(complete_history_data[[\"output_x_msle\", \"val_output_x_msle\"]])\n",
    "#mse_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "mse_plots[0][1].plot(complete_history_data[[\"output_y_msle\", \"val_output_y_msle\"]])\n",
    "#mse_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "mse_plots[1][0].plot(complete_history_data[[\"output_z_msle\", \"val_output_z_msle\"]])\n",
    "#mse_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure of subplots to plot total loss, x coordinate loss, y coordinate loss, and z coordinate loss.\n",
    "fig, loss_plots = plt.subplots(2,2)\n",
    "\n",
    "\n",
    "#plot losses in each quadrant of the figure.\n",
    "loss_plots[0][0].plot(complete_history_data[[\"loss\", \"val_loss\"]])\n",
    "#loss_plots[0][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[0][1].plot(complete_history_data[[\"output_x_loss\", \"val_output_x_loss\"]])\n",
    "#loss_plots[0][1].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][0].plot(complete_history_data[[\"output_y_loss\", \"val_output_y_loss\"]])\n",
    "#loss_plots[1][0].set_ylim(0,1)\n",
    "\n",
    "loss_plots[1][1].plot(complete_history_data[[\"output_z_loss\", \"val_output_z_loss\"]])\n",
    "#loss_plots[1][1].set_ylim(0,1)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([X_test],[y_test_x, y_test_y, y_test_z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Values and Inspect Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred, y_pred, z_pred = model.predict([X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison = pd.DataFrame(data=np.concatenate((x_pred, y_test_x.reshape(-1,1), y_pred, y_test_y.reshape(-1,1), z_pred, y_test_z.reshape(-1,1)), axis=1),\n",
    "                                    columns=['pred_x', 'model_x', 'pred_y', 'model_y', 'pred_z', 'model_z'])\n",
    "pred_model_comparison.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_x\", \"model_x\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_y\", \"model_y\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model_comparison[[\"pred_z\", \"model_z\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
